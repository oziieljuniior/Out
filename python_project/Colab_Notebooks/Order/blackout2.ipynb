{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:55:20.691340: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-01 12:55:20.780408: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-01 12:55:21.210487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 12:55:24.744265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Carregada ...\n"
     ]
    }
   ],
   "source": [
    "data_inicial = pd.read_csv('/home/darkcover/Documentos/Out/dados/data_final2.csv')\n",
    "data_inicial = data_inicial.drop(columns=['Unnamed: 0'])\n",
    "print(\"Data Carregada ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada               0\n",
      "level                0\n",
      "apostar              0\n",
      "acerto               0\n",
      "contagem             0\n",
      "odd                  0\n",
      "odd_entrada          0\n",
      "odd_saida            0\n",
      "media80              0\n",
      "desvpad80geral       0\n",
      "percentil80geral     0\n",
      "cv80                 0\n",
      "roc80                1\n",
      "media160             0\n",
      "desvpad160geral      0\n",
      "percentil160geral    0\n",
      "cv160                0\n",
      "roc160               1\n",
      "media320             0\n",
      "desvpad320geral      0\n",
      "percentil320geral    0\n",
      "cv320                0\n",
      "roc320               1\n",
      "media640             0\n",
      "desvpad640geral      0\n",
      "percentil640geral    0\n",
      "cv640                0\n",
      "roc640               1\n",
      "dtype: int64\n",
      "Rodada               0\n",
      "level                0\n",
      "apostar              0\n",
      "acerto               0\n",
      "contagem             0\n",
      "odd                  0\n",
      "odd_entrada          0\n",
      "odd_saida            0\n",
      "media80              0\n",
      "desvpad80geral       0\n",
      "percentil80geral     0\n",
      "cv80                 0\n",
      "roc80                0\n",
      "media160             0\n",
      "desvpad160geral      0\n",
      "percentil160geral    0\n",
      "cv160                0\n",
      "roc160               0\n",
      "media320             0\n",
      "desvpad320geral      0\n",
      "percentil320geral    0\n",
      "cv320                0\n",
      "roc320               0\n",
      "media640             0\n",
      "desvpad640geral      0\n",
      "percentil640geral    0\n",
      "cv640                0\n",
      "roc640               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há valores NaN ou infinitos\n",
    "print(np.isnan(data_inicial).sum())\n",
    "print(np.isinf(data_inicial).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicial = data_inicial.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data_inicial[['odd_entrada', \"media80\", \"desvpad80geral\", \"percentil80geral\", \"cv80\", \"roc80\", \"media160\", \"desvpad160geral\", \"percentil160geral\", \"cv160\", \"roc160\",\"media320\", \"desvpad320geral\", \"percentil320geral\", \"cv320\", \"roc320\", \"media640\", \"desvpad640geral\", \"percentil640geral\", \"cv640\", \"roc640\"]].values\n",
    "\n",
    "y1 = data_inicial['odd_saida'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há valores NaN ou infinitos\n",
    "print(np.isnan(X1).sum())\n",
    "print(np.isinf(X1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os recursos (importante para redes neurais)\n",
    "scaler1 = StandardScaler()\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar os rótulos para binarizar em relação a 5\n",
    "y_train_bin = binarize(y_train1.reshape(-1, 1), threshold=5).reshape(-1)\n",
    "y_test_bin = binarize(y_test1.reshape(-1, 1), threshold=5).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 351ms/step - accuracy: 0.5775 - loss: 0.7206 - val_accuracy: 0.5756 - val_loss: 0.6852\n",
      "Epoch 2/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 383ms/step - accuracy: 0.5778 - loss: 0.6830 - val_accuracy: 0.5756 - val_loss: 0.6819\n",
      "Epoch 3/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 365ms/step - accuracy: 0.5763 - loss: 0.6816 - val_accuracy: 0.5756 - val_loss: 0.6817\n",
      "Epoch 4/5\n"
     ]
    }
   ],
   "source": [
    "# Definir o modelo com a nova camada de saída\n",
    "model_binary = Sequential()\n",
    "model_binary.add(Input(shape=(X_train1.shape[1], 1)))\n",
    "model_binary.add(LSTM(64, return_sequences=True))\n",
    "model_binary.add(Dropout(0.2))\n",
    "model_binary.add(LSTM(64))\n",
    "model_binary.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model_binary.add(Dense(1, activation='sigmoid'))  # Saída binária para probabilidade\n",
    "\n",
    "# Compilar o modelo com ajustes\n",
    "model_binary.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo com os rótulos binarizados\n",
    "model_binary.fit(X_train1.reshape(X_train1.shape[0], X_train1.shape[1], 1), y_train_bin, epochs=5, batch_size=640, validation_split=0.2)\n",
    "\n",
    "# Resumo do modelo\n",
    "model_binary.summary()\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "accuracy_binary = model_binary.evaluate(X_test1.reshape(X_test1.shape[0], X_test1.shape[1], 1), y_test_bin)[1]\n",
    "print(f'Acurácia do modelo binário: {accuracy_binary}')\n",
    "\n",
    "# Fazer previsões com probabilidade\n",
    "predictions_binary = model_binary.predict(X_test1.reshape(X_test1.shape[0], X_test1.shape[1], 1))\n",
    "\n",
    "# Arredondar as previsões para obter rótulos de classe\n",
    "predicted_labels_binary = (predictions_binary >= 0.5).astype(int)\n",
    "\n",
    "# Calcular o F1-Score para a nova configuração binária\n",
    "f1_binary = f1_score(y_test_bin, predicted_labels_binary, average='weighted')\n",
    "\n",
    "print(f'F1-Score do modelo binário: {f1_binary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Random Forest: 0.541175\n",
      "F1-Score do Random Forest: 0.5175711261556278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Criar o modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "rf_model.fit(X_train1, y_train_bin)\n",
    "\n",
    "# Fazer previsões\n",
    "rf_predictions = rf_model.predict(X_test1)\n",
    "\n",
    "# Calcular a acurácia e o F1-Score\n",
    "rf_accuracy = accuracy_score(y_test_bin, rf_predictions)\n",
    "rf_f1 = f1_score(y_test_bin, rf_predictions, average='weighted')\n",
    "\n",
    "print(f'Acurácia do Random Forest: {rf_accuracy}')\n",
    "print(f'F1-Score do Random Forest: {rf_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Criar o modelo SVM\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "svm_model.fit(X_train1, y_train_bin)\n",
    "\n",
    "# Fazer previsões\n",
    "svm_predictions = svm_model.predict(X_test1)\n",
    "\n",
    "# Calcular a acurácia e o F1-Score\n",
    "svm_accuracy = accuracy_score(y_test_bin, svm_predictions)\n",
    "svm_f1 = f1_score(y_test_bin, svm_predictions, average='weighted')\n",
    "\n",
    "print(f'Acurácia do SVM: {svm_accuracy}')\n",
    "print(f'F1-Score do SVM: {svm_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do XGBoost: 0.564825\n",
      "F1-Score do XGBoost: 0.47236298266987514\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Criar o modelo XGBoost\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "xgb_model.fit(X_train1, y_train_bin)\n",
    "\n",
    "# Fazer previsões\n",
    "xgb_predictions = xgb_model.predict(X_test1)\n",
    "\n",
    "# Calcular a acurácia e o F1-Score\n",
    "xgb_accuracy = accuracy_score(y_test_bin, xgb_predictions)\n",
    "xgb_f1 = f1_score(y_test_bin, xgb_predictions, average='weighted')\n",
    "\n",
    "print(f'Acurácia do XGBoost: {xgb_accuracy}')\n",
    "print(f'F1-Score do XGBoost: {xgb_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da Regressão Logística: 0.579025\n",
      "F1-Score da Regressão Logística: 0.425071370331179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criar o modelo de regressão logística\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "logreg_model.fit(X_train1, y_train_bin)\n",
    "\n",
    "# Fazer previsões\n",
    "logreg_predictions = logreg_model.predict(X_test1)\n",
    "\n",
    "# Calcular a acurácia e o F1-Score\n",
    "logreg_accuracy = accuracy_score(y_test_bin, logreg_predictions)\n",
    "logreg_f1 = f1_score(y_test_bin, logreg_predictions, average='weighted')\n",
    "\n",
    "print(f'Acurácia da Regressão Logística: {logreg_accuracy}')\n",
    "print(f'F1-Score da Regressão Logística: {logreg_f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
