/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
Insera a entrada até onde o modelo deve ser carregado --> ------------------------------------------------------------------------
Número da Entrada - 0 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 1 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 2 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 24.83
------------------------------------------------------------------------
Número da Entrada - 3 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.25
------------------------------------------------------------------------
Número da Entrada - 4 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.55
------------------------------------------------------------------------
Número da Entrada - 5 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 6 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.52
------------------------------------------------------------------------
Número da Entrada - 7 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 8 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.57
------------------------------------------------------------------------
Número da Entrada - 9 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 10 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 11 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.16
------------------------------------------------------------------------
Número da Entrada - 12 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 13 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 14 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 15 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 16 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.88
------------------------------------------------------------------------
Número da Entrada - 17 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 18 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 19 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 20 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.8
------------------------------------------------------------------------
Número da Entrada - 21 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.48
------------------------------------------------------------------------
Número da Entrada - 22 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 23 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 24 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 25 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 26 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.5
------------------------------------------------------------------------
Número da Entrada - 27 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.32
------------------------------------------------------------------------
Número da Entrada - 28 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 29 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.45
------------------------------------------------------------------------
Número da Entrada - 30 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.95
------------------------------------------------------------------------
Número da Entrada - 31 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.7
------------------------------------------------------------------------
Número da Entrada - 32 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.78
------------------------------------------------------------------------
Número da Entrada - 33 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 34 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.04
------------------------------------------------------------------------
Número da Entrada - 35 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 36 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 37 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 38 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 39 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 40 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.44
------------------------------------------------------------------------
Número da Entrada - 41 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 42 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 43 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 44 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 45 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 46 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 47 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.96
------------------------------------------------------------------------
Número da Entrada - 48 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.21
------------------------------------------------------------------------
Número da Entrada - 49 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.19
------------------------------------------------------------------------
Número da Entrada - 50 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.51
------------------------------------------------------------------------
Número da Entrada - 51 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 52 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 53 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 54 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 55 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 56 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 57 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 58 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 59 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.79
------------------------------------------------------------------------
Número da Entrada - 60 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.18
------------------------------------------------------------------------
Número da Entrada - 61 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.79
------------------------------------------------------------------------
Número da Entrada - 62 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.75
------------------------------------------------------------------------
Número da Entrada - 63 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.8
------------------------------------------------------------------------
Número da Entrada - 64 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 65 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 66 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.47
------------------------------------------------------------------------
Número da Entrada - 67 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 68 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.93
------------------------------------------------------------------------
Número da Entrada - 69 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.55
------------------------------------------------------------------------
Número da Entrada - 70 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 71 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.54
------------------------------------------------------------------------
Número da Entrada - 72 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.13
------------------------------------------------------------------------
Número da Entrada - 73 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.2
------------------------------------------------------------------------
Número da Entrada - 74 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 75 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.95
------------------------------------------------------------------------
Número da Entrada - 76 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 77 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.84
------------------------------------------------------------------------
Número da Entrada - 78 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.73
------------------------------------------------------------------------
Número da Entrada - 79 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.87
------------------------------------------------------------------------
Número da Entrada - 80 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 81 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.07
------------------------------------------------------------------------
Número da Entrada - 82 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 83 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 84 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.17
------------------------------------------------------------------------
Número da Entrada - 85 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 86 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 87 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.8
------------------------------------------------------------------------
Número da Entrada - 88 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 89 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 93.91
------------------------------------------------------------------------
Número da Entrada - 90 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.17
------------------------------------------------------------------------
Número da Entrada - 91 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 92 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 93 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.29
------------------------------------------------------------------------
Número da Entrada - 94 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.85
------------------------------------------------------------------------
Número da Entrada - 95 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 547.44
------------------------------------------------------------------------
Número da Entrada - 96 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.5
------------------------------------------------------------------------
Número da Entrada - 97 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 98 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 99 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.76
------------------------------------------------------------------------
Número da Entrada - 100 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 101 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.49
------------------------------------------------------------------------
Número da Entrada - 102 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 103 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.64
------------------------------------------------------------------------
Número da Entrada - 104 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.51
------------------------------------------------------------------------
Número da Entrada - 105 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 106 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.96
------------------------------------------------------------------------
Número da Entrada - 107 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 108 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.51
------------------------------------------------------------------------
Número da Entrada - 109 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 21.63
------------------------------------------------------------------------
Número da Entrada - 110 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 27.5
------------------------------------------------------------------------
Número da Entrada - 111 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 112 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 29.87
------------------------------------------------------------------------
Número da Entrada - 113 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.69
------------------------------------------------------------------------
Número da Entrada - 114 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.92
------------------------------------------------------------------------
Número da Entrada - 115 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 116 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 117 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.42
------------------------------------------------------------------------
Número da Entrada - 118 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.27
------------------------------------------------------------------------
Número da Entrada - 119 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.4
------------------------------------------------------------------------
Número da Entrada - 120 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 121 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.24
------------------------------------------------------------------------
Número da Entrada - 122 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 123 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 124 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.62
------------------------------------------------------------------------
Número da Entrada - 125 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.44
------------------------------------------------------------------------
Número da Entrada - 126 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.61
------------------------------------------------------------------------
Número da Entrada - 127 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 128 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 129 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 130 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 131 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.28
------------------------------------------------------------------------
Número da Entrada - 132 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 133 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.9
------------------------------------------------------------------------
Número da Entrada - 134 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.99
------------------------------------------------------------------------
Número da Entrada - 135 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 136 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.14
------------------------------------------------------------------------
Número da Entrada - 137 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 138 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.75
------------------------------------------------------------------------
Número da Entrada - 139 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.59
------------------------------------------------------------------------
Número da Entrada - 140 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.53
------------------------------------------------------------------------
Número da Entrada - 141 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 142 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 143 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.56
------------------------------------------------------------------------
Número da Entrada - 144 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 145 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.92
------------------------------------------------------------------------
Número da Entrada - 146 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 147 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 148 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.37
------------------------------------------------------------------------
Número da Entrada - 149 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.19
------------------------------------------------------------------------
Número da Entrada - 150 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.0
------------------------------------------------------------------------
Número da Entrada - 151 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.12
------------------------------------------------------------------------
Número da Entrada - 152 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.8
------------------------------------------------------------------------
Número da Entrada - 153 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.74
------------------------------------------------------------------------
Número da Entrada - 154 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 155 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 156 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 157 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 158 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.5
------------------------------------------------------------------------
Número da Entrada - 159 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 160 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 161 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.61
------------------------------------------------------------------------
Número da Entrada - 162 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 163 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 164 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.05
------------------------------------------------------------------------
Número da Entrada - 165 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 35.4
------------------------------------------------------------------------
Número da Entrada - 166 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.12
------------------------------------------------------------------------
Número da Entrada - 167 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.84
------------------------------------------------------------------------
Número da Entrada - 168 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 57.77
------------------------------------------------------------------------
Número da Entrada - 169 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 170 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.28
------------------------------------------------------------------------
Número da Entrada - 171 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 172 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 173 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.24
------------------------------------------------------------------------
Número da Entrada - 174 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 175 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 176 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 177 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 178 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 179 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.18
------------------------------------------------------------------------
Número da Entrada - 180 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.48
------------------------------------------------------------------------
Número da Entrada - 181 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 182 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 183 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 184 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 185 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.72
------------------------------------------------------------------------
Número da Entrada - 186 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.56
------------------------------------------------------------------------
Número da Entrada - 187 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 188 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.09
------------------------------------------------------------------------
Número da Entrada - 189 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 190 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 191 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.09
------------------------------------------------------------------------
Número da Entrada - 192 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.68
------------------------------------------------------------------------
Número da Entrada - 193 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 194 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 195 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.41
------------------------------------------------------------------------
Número da Entrada - 196 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 197 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 198 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 199 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 200 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 201 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.99
------------------------------------------------------------------------
Número da Entrada - 202 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.68
------------------------------------------------------------------------
Número da Entrada - 203 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.22
------------------------------------------------------------------------
Número da Entrada - 204 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 205 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.42
------------------------------------------------------------------------
Número da Entrada - 206 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 207 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.93
------------------------------------------------------------------------
Número da Entrada - 208 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 209 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.27
------------------------------------------------------------------------
Número da Entrada - 210 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.59
------------------------------------------------------------------------
Número da Entrada - 211 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.74
------------------------------------------------------------------------
Número da Entrada - 212 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.89
------------------------------------------------------------------------
Número da Entrada - 213 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 214 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 215 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.06
------------------------------------------------------------------------
Número da Entrada - 216 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.53
------------------------------------------------------------------------
Número da Entrada - 217 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 218 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 219 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 220 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.71
------------------------------------------------------------------------
Número da Entrada - 221 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 18.79
------------------------------------------------------------------------
Número da Entrada - 222 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.14
------------------------------------------------------------------------
Número da Entrada - 223 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 224 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 225 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.4
------------------------------------------------------------------------
Número da Entrada - 226 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.57
------------------------------------------------------------------------
Número da Entrada - 227 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 228 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 229 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 230 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.4
------------------------------------------------------------------------
Número da Entrada - 231 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.29
------------------------------------------------------------------------
Número da Entrada - 232 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.34
------------------------------------------------------------------------
Número da Entrada - 233 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 234 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.44
------------------------------------------------------------------------
Número da Entrada - 235 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.72
------------------------------------------------------------------------
Número da Entrada - 236 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 237 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 238 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.39
------------------------------------------------------------------------
Número da Entrada - 239 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.88
------------------------------------------------------------------------
Número da Entrada - 240 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.09
------------------------------------------------------------------------
Número da Entrada - 241 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.48
------------------------------------------------------------------------
Número da Entrada - 242 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.78
------------------------------------------------------------------------
Número da Entrada - 243 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 244 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 245 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 246 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.79
------------------------------------------------------------------------
Número da Entrada - 247 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.34
------------------------------------------------------------------------
Número da Entrada - 248 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 249 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 250 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.03
------------------------------------------------------------------------
Número da Entrada - 251 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 252 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 253 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.67
------------------------------------------------------------------------
Número da Entrada - 254 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 255 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 256 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 257 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.58
------------------------------------------------------------------------
Número da Entrada - 258 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 259 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 260 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 261 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 262 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 263 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 264 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 265 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 266 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 267 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.66
------------------------------------------------------------------------
Número da Entrada - 268 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 67.78
------------------------------------------------------------------------
Número da Entrada - 269 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 270 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 9.12
------------------------------------------------------------------------
Número da Entrada - 271 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.2
------------------------------------------------------------------------
Número da Entrada - 272 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.56
------------------------------------------------------------------------
Número da Entrada - 273 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 274 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 275 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 276 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.31
------------------------------------------------------------------------
Número da Entrada - 277 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.3
------------------------------------------------------------------------
Número da Entrada - 278 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 279 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 280 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 281 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 282 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 283 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.92
------------------------------------------------------------------------
Número da Entrada - 284 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.08
------------------------------------------------------------------------
Número da Entrada - 285 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.5
------------------------------------------------------------------------
Número da Entrada - 286 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 287 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.45
------------------------------------------------------------------------
Número da Entrada - 288 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.23
------------------------------------------------------------------------
Número da Entrada - 289 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.44
------------------------------------------------------------------------
Número da Entrada - 290 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 291 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 292 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 293 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.39
------------------------------------------------------------------------
Número da Entrada - 294 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.45
------------------------------------------------------------------------
Número da Entrada - 295 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 296 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.16
------------------------------------------------------------------------
Número da Entrada - 297 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 298 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 299 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 36.82
------------------------------------------------------------------------
Número da Entrada - 300 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.49
------------------------------------------------------------------------
Número da Entrada - 301 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.82
------------------------------------------------------------------------
Número da Entrada - 302 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.8
------------------------------------------------------------------------
Número da Entrada - 303 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 304 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 305 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.65
------------------------------------------------------------------------
Número da Entrada - 306 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 307 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 308 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 309 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.81
------------------------------------------------------------------------
Número da Entrada - 310 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 311 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 312 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 313 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 314 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 315 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 316 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 317 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 318 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 319 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 320 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.49
------------------------------------------------------------------------
Número da Entrada - 321 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 12.09
------------------------------------------------------------------------
Número da Entrada - 322 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 68.2
------------------------------------------------------------------------
Número da Entrada - 323 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 324 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 325 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 326 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 78.5
------------------------------------------------------------------------
Número da Entrada - 327 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 328 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.26
------------------------------------------------------------------------
Número da Entrada - 329 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 330 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 331 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 332 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.18
------------------------------------------------------------------------
Número da Entrada - 333 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 334 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 335 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.27
------------------------------------------------------------------------
Número da Entrada - 336 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 337 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 338 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.0
------------------------------------------------------------------------
Número da Entrada - 339 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.79
------------------------------------------------------------------------
Número da Entrada - 340 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 341 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 342 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.49
------------------------------------------------------------------------
Número da Entrada - 343 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 344 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 345 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 346 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 347 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 348 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.58
------------------------------------------------------------------------
Número da Entrada - 349 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 289.84
------------------------------------------------------------------------
Número da Entrada - 350 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 351 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.84
------------------------------------------------------------------------
Número da Entrada - 352 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.28
------------------------------------------------------------------------
Número da Entrada - 353 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.77
------------------------------------------------------------------------
Número da Entrada - 354 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 355 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.85
------------------------------------------------------------------------
Número da Entrada - 356 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.22
------------------------------------------------------------------------
Número da Entrada - 357 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.85
------------------------------------------------------------------------
Número da Entrada - 358 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 359 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.44
------------------------------------------------------------------------
Número da Entrada - 360 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
************************************************************
Carregando dados ...
360 360 360
(331, 30) (331, 30) (331, 30)
(331, 90) (331, 30)
Matrix_30: [(331, 90), (331, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1806 - accuracy: 0.3424 - precision: 0.3424 - recall: 0.3424 - f1_score: 0.4622 - val_loss: 0.2474 - val_accuracy: 0.7021 - val_precision: 0.7021 - val_recall: 0.7021 - val_f1_score: 0.0000e+00 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.4377 - accuracy: 0.6739 - precision: 0.6739 - recall: 0.6739 - f1_score: 0.0000e+00 - val_loss: 0.1469 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.7647 - 73ms/epoch - 73ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1306 - accuracy: 0.8098 - precision: 0.8098 - recall: 0.8098 - f1_score: 0.7651 - val_loss: 0.3721 - val_accuracy: 0.2979 - val_precision: 0.2979 - val_recall: 0.2979 - val_f1_score: 0.4590 - 73ms/epoch - 73ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2609 - accuracy: 0.3261 - precision: 0.3261 - recall: 0.3261 - f1_score: 0.4918 - val_loss: 0.2823 - val_accuracy: 0.2979 - val_precision: 0.2979 - val_recall: 0.2979 - val_f1_score: 0.4590 - 74ms/epoch - 74ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2008 - accuracy: 0.3261 - precision: 0.3261 - recall: 0.3261 - f1_score: 0.4918 - val_loss: 0.1807 - val_accuracy: 0.4043 - val_precision: 0.4043 - val_recall: 0.4043 - val_f1_score: 0.5000 - 78ms/epoch - 78ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1426 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.5660 - val_loss: 0.1450 - val_accuracy: 0.8085 - val_precision: 0.8085 - val_recall: 0.8085 - val_f1_score: 0.6400 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1402 - accuracy: 0.8533 - precision: 0.8533 - recall: 0.8533 - f1_score: 0.7652 - val_loss: 0.1389 - val_accuracy: 0.7234 - val_precision: 0.7234 - val_recall: 0.7234 - val_f1_score: 0.1333 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1552 - accuracy: 0.7446 - precision: 0.7446 - recall: 0.7446 - f1_score: 0.3733 - val_loss: 0.1390 - val_accuracy: 0.7021 - val_precision: 0.7021 - val_recall: 0.7021 - val_f1_score: 0.0000e+00 - 74ms/epoch - 74ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.2059 - val_loss: 0.1380 - val_accuracy: 0.7234 - val_precision: 0.7234 - val_recall: 0.7234 - val_f1_score: 0.1333 - 75ms/epoch - 75ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.7174 - precision: 0.7174 - recall: 0.7174 - f1_score: 0.2571 - val_loss: 0.1370 - val_accuracy: 0.7872 - val_precision: 0.7872 - val_recall: 0.7872 - val_f1_score: 0.4444 - 81ms/epoch - 81ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1461 - accuracy: 0.7935 - precision: 0.7935 - recall: 0.7935 - f1_score: 0.5476 - val_loss: 0.1413 - val_accuracy: 0.7872 - val_precision: 0.7872 - val_recall: 0.7872 - val_f1_score: 0.5833 - 73ms/epoch - 73ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1349 - accuracy: 0.8641 - precision: 0.8641 - recall: 0.8641 - f1_score: 0.7748 - val_loss: 0.1532 - val_accuracy: 0.6809 - val_precision: 0.6809 - val_recall: 0.6809 - val_f1_score: 0.6154 - 70ms/epoch - 70ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1303 - accuracy: 0.8152 - precision: 0.8152 - recall: 0.8152 - f1_score: 0.7733 - val_loss: 0.1692 - val_accuracy: 0.5957 - val_precision: 0.5957 - val_recall: 0.5957 - val_f1_score: 0.5957 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1324 - accuracy: 0.6685 - precision: 0.6685 - recall: 0.6685 - f1_score: 0.6630 - val_loss: 0.1784 - val_accuracy: 0.4255 - val_precision: 0.4255 - val_recall: 0.4255 - val_f1_score: 0.5091 - 73ms/epoch - 73ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1341 - accuracy: 0.6033 - precision: 0.6033 - recall: 0.6033 - f1_score: 0.6218 - val_loss: 0.1732 - val_accuracy: 0.5745 - val_precision: 0.5745 - val_recall: 0.5745 - val_f1_score: 0.5833 - 73ms/epoch - 73ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1298 - accuracy: 0.6467 - precision: 0.6467 - recall: 0.6467 - f1_score: 0.6486 - val_loss: 0.1574 - val_accuracy: 0.6596 - val_precision: 0.6596 - val_recall: 0.6596 - val_f1_score: 0.6190 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1212 - accuracy: 0.7228 - precision: 0.7228 - recall: 0.7228 - f1_score: 0.7018 - val_loss: 0.1397 - val_accuracy: 0.7447 - val_precision: 0.7447 - val_recall: 0.7447 - val_f1_score: 0.6471 - 73ms/epoch - 73ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1138 - accuracy: 0.8587 - precision: 0.8587 - recall: 0.8587 - f1_score: 0.8194 - val_loss: 0.1267 - val_accuracy: 0.8085 - val_precision: 0.8085 - val_recall: 0.8085 - val_f1_score: 0.6667 - 75ms/epoch - 75ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1106 - accuracy: 0.9185 - precision: 0.9185 - recall: 0.9185 - f1_score: 0.8780 - val_loss: 0.1190 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.6364 - 73ms/epoch - 73ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1097 - accuracy: 0.9022 - precision: 0.9022 - recall: 0.9022 - f1_score: 0.8421 - val_loss: 0.1144 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.6364 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1068 - accuracy: 0.9076 - precision: 0.9076 - recall: 0.9076 - f1_score: 0.8468 - val_loss: 0.1111 - val_accuracy: 0.8511 - val_precision: 0.8511 - val_recall: 0.8511 - val_f1_score: 0.6957 - 106ms/epoch - 106ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1002 - accuracy: 0.9130 - precision: 0.9130 - recall: 0.9130 - f1_score: 0.8596 - val_loss: 0.1092 - val_accuracy: 0.8723 - val_precision: 0.8723 - val_recall: 0.8723 - val_f1_score: 0.7857 - 106ms/epoch - 106ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0927 - accuracy: 0.9402 - precision: 0.9402 - recall: 0.9402 - f1_score: 0.9106 - val_loss: 0.1109 - val_accuracy: 0.8085 - val_precision: 0.8085 - val_recall: 0.8085 - val_f1_score: 0.7097 - 109ms/epoch - 109ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0872 - accuracy: 0.9239 - precision: 0.9239 - recall: 0.9239 - f1_score: 0.8939 - val_loss: 0.1133 - val_accuracy: 0.7872 - val_precision: 0.7872 - val_recall: 0.7872 - val_f1_score: 0.7059 - 110ms/epoch - 110ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0836 - accuracy: 0.8913 - precision: 0.8913 - recall: 0.8913 - f1_score: 0.8571 - val_loss: 0.1113 - val_accuracy: 0.7872 - val_precision: 0.7872 - val_recall: 0.7872 - val_f1_score: 0.7059 - 73ms/epoch - 73ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0794 - accuracy: 0.8913 - precision: 0.8913 - recall: 0.8913 - f1_score: 0.8571 - val_loss: 0.1021 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.7500 - 75ms/epoch - 75ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0732 - accuracy: 0.9185 - precision: 0.9185 - recall: 0.9185 - f1_score: 0.8889 - val_loss: 0.0904 - val_accuracy: 0.8723 - val_precision: 0.8723 - val_recall: 0.8723 - val_f1_score: 0.7857 - 74ms/epoch - 74ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0673 - accuracy: 0.9511 - precision: 0.9511 - recall: 0.9511 - f1_score: 0.9280 - val_loss: 0.0822 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8000 - 72ms/epoch - 72ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0644 - accuracy: 0.9402 - precision: 0.9402 - recall: 0.9402 - f1_score: 0.9106 - val_loss: 0.0782 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8000 - 77ms/epoch - 77ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0599 - accuracy: 0.9402 - precision: 0.9402 - recall: 0.9402 - f1_score: 0.9106 - val_loss: 0.0771 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8276 - 75ms/epoch - 75ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0542 - accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - f1_score: 0.9194 - val_loss: 0.0784 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8276 - 72ms/epoch - 72ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0509 - accuracy: 0.9511 - precision: 0.9511 - recall: 0.9511 - f1_score: 0.9302 - val_loss: 0.0757 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8276 - 78ms/epoch - 78ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0477 - accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - f1_score: 0.9231 - val_loss: 0.0672 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936 - val_f1_score: 0.8276 - 75ms/epoch - 75ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0428 - accuracy: 0.9565 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9375 - val_loss: 0.0593 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 74ms/epoch - 74ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0394 - accuracy: 0.9674 - precision: 0.9674 - recall: 0.9674 - f1_score: 0.9516 - val_loss: 0.0549 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 74ms/epoch - 74ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0368 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - f1_score: 0.9421 - val_loss: 0.0523 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 72ms/epoch - 72ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0328 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0522 - val_accuracy: 0.9149 - val_precision: 0.9149 - val_recall: 0.9149 - val_f1_score: 0.8571 - 72ms/epoch - 72ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0299 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0509 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8966 - 71ms/epoch - 71ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0278 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0454 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 70ms/epoch - 70ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0247 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0397 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 73ms/epoch - 73ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0363 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 71ms/epoch - 71ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0208 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0348 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0183 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0353 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 75ms/epoch - 75ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0167 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0345 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9333 - 71ms/epoch - 71ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0153 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0307 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 74ms/epoch - 74ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0136 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 72ms/epoch - 72ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0124 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9286 - 72ms/epoch - 72ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 73ms/epoch - 73ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0100 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 74ms/epoch - 74ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0091 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_f1_score: 0.9333 - 73ms/epoch - 73ms/step

🔍 Resultados no Teste:
Loss: 0.0239
Accuracy: 0.9700
Precision: 0.9700
Recall: 0.9700
F1 Score: 0.9434
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
360 360 360
(331, 30) (331, 30) (331, 30)
(331, 90) (331, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 124ms/step
[[0.50639147 0.49360847]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 361 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 0.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
361 361 361
(332, 30) (332, 30) (332, 30)
(332, 90) (332, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.78116775 0.21883228]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 362 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 1.06
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 0.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
362 362 362
(333, 30) (333, 30) (333, 30)
(333, 90) (333, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8904947 0.1095053]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 363 | Acuracia_0: 0 | Contagem Geral: 2.0 
Ordem Natural: 0.0
Entrada: 1.3
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 33.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
363 363 363
(334, 30) (334, 30) (334, 30)
(334, 90) (334, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9523274  0.04767261]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 364 | Acuracia_0: 0 | Contagem Geral: 2.0 
Ordem Natural: 0.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
364 364 364
(335, 30) (335, 30) (335, 30)
(335, 90) (335, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.80799645 0.19200349]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 365 | Acuracia_0: 0 | Contagem Geral: 2.0 
Ordem Natural: 0.0
Entrada: 1.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
365 365 365
(336, 30) (336, 30) (336, 30)
(336, 90) (336, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.29463378 0.7053662 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 366 | Acuracia_0: 0 | Contagem Geral: 2.0 
Ordem Natural: 0.0
Entrada: 10.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 1.0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
366 366 366
(337, 30) (337, 30) (337, 30)
(337, 90) (337, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.36470148 0.6352985 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 367 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 1.0
Entrada: 2.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
367 367 367
(338, 30) (338, 30) (338, 30)
(338, 90) (338, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89620596 0.10379407]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 368 | Acuracia_0: 0 | Contagem Geral: 4.0 
Ordem Natural: 1.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
368 368 368
(339, 30) (339, 30) (339, 30)
(339, 90) (339, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8083549  0.19164506]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 369 | Acuracia_0: 0 | Contagem Geral: 4.0 
Ordem Natural: 2.0
Entrada: 4.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 44.4444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
369 369 369
(340, 30) (340, 30) (340, 30)
(340, 90) (340, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.49263167 0.5073683 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 370 | Acuracia_0: 0 | Contagem Geral: 4.0 
Ordem Natural: 3.0
Entrada: 1.93
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 40.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
370 370 370
(341, 30) (341, 30) (341, 30)
(341, 90) (341, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8641924  0.13580751]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 371 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 3.0
Entrada: 1.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 45.4545
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
371 371 371
(342, 30) (342, 30) (342, 30)
(342, 90) (342, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.903146   0.09685405]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 372 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 3.0
Entrada: 285.21
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 41.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
372 372 372
(343, 30) (343, 30) (343, 30)
(343, 90) (343, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90656114 0.09343889]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 373 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 4.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 46.1538
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
373 373 373
(344, 30) (344, 30) (344, 30)
(344, 90) (344, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 36ms/step
[[0.94089776 0.05910221]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 374 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 4.0
Entrada: 3.26
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 42.8571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
374 374 374
(345, 30) (345, 30) (345, 30)
(345, 90) (345, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 36ms/step
[[0.88724446 0.11275554]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 375 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 5.0
Entrada: 7.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 40.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
375 375 375
(346, 30) (346, 30) (346, 30)
(346, 90) (346, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 39ms/step
[[0.76628834 0.23371167]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 376 | Acuracia_0: 0 | Contagem Geral: 5.0 
Ordem Natural: 6.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_0: 0.0 
Precisao modelo Geral: 37.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
376 376 376
(347, 30) (347, 30) (347, 30)
(347, 90) (347, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[[0.43735638 0.56264365]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 377 | Acuracia_0: 0 | Contagem Geral: 6.0 
Ordem Natural: 6.0
Entrada: 1.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0.0 
Precisao modelo Geral: 35.2941
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
377 377 377
(348, 30) (348, 30) (348, 30)
(348, 90) (348, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8404606  0.15953936]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 378 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 6.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 38.8889
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
378 378 378
(349, 30) (349, 30) (349, 30)
(349, 90) (349, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97885484 0.02114518]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 379 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 6.0
Entrada: 3.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 36.8421
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
379 379 379
(350, 30) (350, 30) (350, 30)
(350, 90) (350, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.94179946 0.05820047]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 380 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 2.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 40.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
380 380 380
(351, 30) (351, 30) (351, 30)
(351, 90) (351, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
[[0.8745087  0.12549134]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 381 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 42.8571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
381 381 381
(352, 30) (352, 30) (352, 30)
(352, 90) (352, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8624252  0.13757479]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 382 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 1.14
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 45.4545
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
382 382 382
(353, 30) (353, 30) (353, 30)
(353, 90) (353, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89679646 0.10320356]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 383 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 1.75
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 47.8261
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
383 383 383
(354, 30) (354, 30) (354, 30)
(354, 90) (354, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.9512561  0.04874389]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 384 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
384 384 384
(355, 30) (355, 30) (355, 30)
(355, 90) (355, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9546753  0.04532468]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 385 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 7.0
Entrada: 4.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 48.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
385 385 385
(356, 30) (356, 30) (356, 30)
(356, 90) (356, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89370126 0.10629873]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 386 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 8.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 46.1538
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
386 386 386
(357, 30) (357, 30) (357, 30)
(357, 90) (357, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8330709  0.16692917]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 387 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 9.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 44.4444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
387 387 387
(358, 30) (358, 30) (358, 30)
(358, 90) (358, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9235409  0.07645913]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 388 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 46.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
388 388 388
(359, 30) (359, 30) (359, 30)
(359, 90) (359, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9487876 0.0512124]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 389 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0 
Precisao modelo Geral: 48.2759
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
389 389 389
(360, 30) (360, 30) (360, 30)
(360, 90) (360, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.92904    0.07096002]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 390 | Acuracia_0: 0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_30: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
390 390 390
(361, 30) (361, 30) (361, 30)
(361, 90) (361, 30)
Matrix_30: [(361, 90), (361, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1688 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.5143 - val_loss: 0.1492 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.6000 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1219 - accuracy: 0.7910 - precision: 0.7910 - recall: 0.7910 - f1_score: 0.7558 - val_loss: 0.1675 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.0000e+00 - 159ms/epoch - 159ms/step
Epoch 3/50
1/1 - 0s - loss: 0.3643 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.0845 - val_loss: 0.2472 - val_accuracy: 0.3529 - val_precision: 0.3529 - val_recall: 0.3529 - val_f1_score: 0.4407 - 140ms/epoch - 140ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - f1_score: 0.5763 - val_loss: 0.4584 - val_accuracy: 0.2549 - val_precision: 0.2549 - val_recall: 0.2549 - val_f1_score: 0.4062 - 97ms/epoch - 97ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2875 - accuracy: 0.3383 - precision: 0.3383 - recall: 0.3383 - f1_score: 0.5056 - val_loss: 0.2571 - val_accuracy: 0.2745 - val_precision: 0.2745 - val_recall: 0.2745 - val_f1_score: 0.4127 - 173ms/epoch - 173ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1620 - accuracy: 0.4677 - precision: 0.4677 - recall: 0.4677 - f1_score: 0.5597 - val_loss: 0.1112 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8889 - 148ms/epoch - 148ms/step
Epoch 7/50
1/1 - 0s - loss: 0.0959 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - f1_score: 0.8707 - val_loss: 0.0913 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.5556 - 154ms/epoch - 154ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1369 - accuracy: 0.7960 - precision: 0.7960 - recall: 0.7960 - f1_score: 0.5773 - val_loss: 0.0954 - val_accuracy: 0.8039 - val_precision: 0.8039 - val_recall: 0.8039 - val_f1_score: 0.3750 - 175ms/epoch - 175ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.7413 - precision: 0.7413 - recall: 0.7413 - f1_score: 0.3953 - val_loss: 0.0902 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.5556 - 133ms/epoch - 133ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1320 - accuracy: 0.7960 - precision: 0.7960 - recall: 0.7960 - f1_score: 0.5773 - val_loss: 0.0955 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8333 - 84ms/epoch - 84ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1041 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8525 - val_loss: 0.1192 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8276 - 77ms/epoch - 77ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1005 - accuracy: 0.8756 - precision: 0.8756 - recall: 0.8756 - f1_score: 0.8447 - val_loss: 0.1487 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.5652 - 76ms/epoch - 76ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1108 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.7010 - val_loss: 0.1606 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.5417 - 76ms/epoch - 76ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1157 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.6667 - val_loss: 0.1498 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.5652 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1090 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.6974 - val_loss: 0.1253 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.6486 - 77ms/epoch - 77ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0959 - accuracy: 0.8209 - precision: 0.8209 - recall: 0.8209 - f1_score: 0.7907 - val_loss: 0.1002 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0853 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - f1_score: 0.8947 - val_loss: 0.0831 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8800 - 82ms/epoch - 82ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0826 - accuracy: 0.9353 - precision: 0.9353 - recall: 0.9353 - f1_score: 0.9008 - val_loss: 0.0745 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0845 - accuracy: 0.9154 - precision: 0.9154 - recall: 0.9154 - f1_score: 0.8618 - val_loss: 0.0706 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0832 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8525 - val_loss: 0.0693 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8333 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0757 - accuracy: 0.9353 - precision: 0.9353 - recall: 0.9353 - f1_score: 0.8976 - val_loss: 0.0720 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8800 - 75ms/epoch - 75ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0669 - accuracy: 0.9502 - precision: 0.9502 - recall: 0.9502 - f1_score: 0.9265 - val_loss: 0.0820 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0626 - accuracy: 0.9254 - precision: 0.9254 - recall: 0.9254 - f1_score: 0.9007 - val_loss: 0.0954 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.7273 - 82ms/epoch - 82ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0638 - accuracy: 0.8955 - precision: 0.8955 - recall: 0.8955 - f1_score: 0.8662 - val_loss: 0.0958 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.7273 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0618 - accuracy: 0.8905 - precision: 0.8905 - recall: 0.8905 - f1_score: 0.8608 - val_loss: 0.0836 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8000 - 84ms/epoch - 84ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0554 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8831 - val_loss: 0.0692 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0498 - accuracy: 0.9403 - precision: 0.9403 - recall: 0.9403 - f1_score: 0.9189 - val_loss: 0.0588 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 75ms/epoch - 75ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0475 - accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - f1_score: 0.9635 - val_loss: 0.0532 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8800 - 76ms/epoch - 76ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0469 - accuracy: 0.9602 - precision: 0.9602 - recall: 0.9602 - f1_score: 0.9403 - val_loss: 0.0508 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8800 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0450 - accuracy: 0.9652 - precision: 0.9652 - recall: 0.9652 - f1_score: 0.9474 - val_loss: 0.0507 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8800 - 75ms/epoch - 75ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0410 - accuracy: 0.9801 - precision: 0.9801 - recall: 0.9801 - f1_score: 0.9706 - val_loss: 0.0533 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 82ms/epoch - 82ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0371 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9784 - val_loss: 0.0582 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0353 - accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - f1_score: 0.9645 - val_loss: 0.0627 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8276 - 78ms/epoch - 78ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9502 - precision: 0.9502 - recall: 0.9502 - f1_score: 0.9315 - val_loss: 0.0618 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8276 - 80ms/epoch - 80ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0330 - accuracy: 0.9602 - precision: 0.9602 - recall: 0.9602 - f1_score: 0.9444 - val_loss: 0.0548 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8276 - 75ms/epoch - 75ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0296 - accuracy: 0.9801 - precision: 0.9801 - recall: 0.9801 - f1_score: 0.9714 - val_loss: 0.0468 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 73ms/epoch - 73ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0271 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - f1_score: 0.9855 - val_loss: 0.0414 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 74ms/epoch - 74ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0262 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - f1_score: 0.9853 - val_loss: 0.0387 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 95ms/epoch - 95ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0254 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.0382 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 74ms/epoch - 74ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0233 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - f1_score: 0.9853 - val_loss: 0.0400 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 74ms/epoch - 74ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0211 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0435 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8889 - 75ms/epoch - 75ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0199 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0462 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0192 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0447 - val_accuracy: 0.9216 - val_precision: 0.9216 - val_recall: 0.9216 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0179 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0398 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8889 - 73ms/epoch - 73ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0161 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0346 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 90ms/epoch - 90ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0149 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1_score: 0.9927 - val_loss: 0.0311 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 77ms/epoch - 77ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0142 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 83ms/epoch - 83ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0134 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9231 - 87ms/epoch - 87ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0122 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.8889 - 105ms/epoch - 105ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9608 - val_f1_score: 0.9286 - 120ms/epoch - 120ms/step

🔍 Resultados no Teste:
Loss: 0.0355
Accuracy: 0.9450
Precision: 0.9450
Recall: 0.9450
F1 Score: 0.9000
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
390 390 390
(361, 30) (361, 30) (361, 30)
(361, 90) (361, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 87ms/step
[[0.940251   0.05974904]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 391 | Acuracia_1: 0.0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_1: 0.0 
Precisao modelo Geral: 51.6129
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
391 391 391
(362, 30) (362, 30) (362, 30)
(362, 90) (362, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.93559915 0.06440092]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 392 | Acuracia_2: 0.0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_2: 0.0 
Precisao modelo Geral: 53.125
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
392 392 392
(363, 30) (363, 30) (363, 30)
(363, 90) (363, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8760879  0.12391216]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 393 | Acuracia_3: 0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_3: 0 
Precisao modelo Geral: 54.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
393 393 393
(364, 30) (364, 30) (364, 30)
(364, 90) (364, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.61322576 0.3867742 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 394 | Acuracia_4: 0 | Contagem Geral: 7.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_4: 0.0 
Precisao modelo Geral: 52.9412
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
394 394 394
(365, 30) (365, 30) (365, 30)
(365, 90) (365, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8037374  0.19626258]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 395 | Acuracia_5: 0 | Contagem Geral: 8.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_5: 0 
Precisao modelo Geral: 54.2857
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
395 395 395
(366, 30) (366, 30) (366, 30)
(366, 90) (366, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8167277  0.18327224]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 396 | Acuracia_6: 1.0 | Contagem Geral: 8.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_6: 1.0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
396 396 396
(367, 30) (367, 30) (367, 30)
(367, 90) (367, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.62690604 0.37309396]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 397 | Acuracia_7: 0.0 | Contagem Geral: 8.0 
Ordem Natural: 10.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_7: 0.5 
Precisao modelo Geral: 56.7568
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
397 397 397
(368, 30) (368, 30) (368, 30)
(368, 90) (368, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8981897  0.10181022]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 398 | Acuracia_8: 0 | Contagem Geral: 9.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_8: 0 
Precisao modelo Geral: 57.8947
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
398 398 398
(369, 30) (369, 30) (369, 30)
(369, 90) (369, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94198066 0.05801935]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 399 | Acuracia_9: 0 | Contagem Geral: 9.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_9: 0 
Precisao modelo Geral: 58.9744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
399 399 399
(370, 30) (370, 30) (370, 30)
(370, 90) (370, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.7229268  0.27707326]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 400 | Acuracia_10: 0.0 | Contagem Geral: 9.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_10: 0.0 
Precisao modelo Geral: 57.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
400 400 400
(371, 30) (371, 30) (371, 30)
(371, 90) (371, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.83711827 0.16288172]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 401 | Acuracia_11: 0 | Contagem Geral: 10.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_11: 0 
Precisao modelo Geral: 58.5366
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
401 401 401
(372, 30) (372, 30) (372, 30)
(372, 90) (372, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.78333074 0.21666929]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 402 | Acuracia_12: 0 | Contagem Geral: 10.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_12: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
402 402 402
(373, 30) (373, 30) (373, 30)
(373, 90) (373, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 38ms/step
[[0.449124   0.55087596]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 403 | Acuracia_13: 0 | Contagem Geral: 11.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_13: 0.0 
Precisao modelo Geral: 55.814
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
403 403 403
(374, 30) (374, 30) (374, 30)
(374, 90) (374, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.86218745 0.13781255]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 404 | Acuracia_14: 0 | Contagem Geral: 12.0 
Ordem Natural: 11.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_14: 0 
Precisao modelo Geral: 54.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
404 404 404
(375, 30) (375, 30) (375, 30)
(375, 90) (375, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9739153  0.02608466]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 405 | Acuracia_15: 0 | Contagem Geral: 12.0 
Ordem Natural: 12.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_15: 0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
405 405 405
(376, 30) (376, 30) (376, 30)
(376, 90) (376, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.85531694 0.14468311]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 406 | Acuracia_16: 0.0 | Contagem Geral: 12.0 
Ordem Natural: 12.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_16: 0.0 
Precisao modelo Geral: 54.3478
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
406 406 406
(377, 30) (377, 30) (377, 30)
(377, 90) (377, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5693545  0.43064556]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 407 | Acuracia_17: 0.0 | Contagem Geral: 12.0 
Ordem Natural: 13.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 15.3846 | Acuracia_17: 0.0 
Precisao modelo Geral: 53.1915
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
407 407 407
(378, 30) (378, 30) (378, 30)
(378, 90) (378, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.53966886 0.46033117]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 408 | Acuracia_18: 0 | Contagem Geral: 13.0 
Ordem Natural: 13.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_18: 1.0 
Precisao modelo Geral: 54.1667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
408 408 408
(379, 30) (379, 30) (379, 30)
(379, 90) (379, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8542421  0.14575791]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 409 | Acuracia_19: 0 | Contagem Geral: 14.0 
Ordem Natural: 14.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_19: 0 
Precisao modelo Geral: 55.102
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
409 409 409
(380, 30) (380, 30) (380, 30)
(380, 90) (380, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89727503 0.10272495]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 410 | Acuracia_20: 0 | Contagem Geral: 14.0 
Ordem Natural: 14.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_20: 0 
Precisao modelo Geral: 54.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
410 410 410
(381, 30) (381, 30) (381, 30)
(381, 90) (381, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93191874 0.06808128]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 411 | Acuracia_21: 0 | Contagem Geral: 14.0 
Ordem Natural: 15.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_21: 0 
Precisao modelo Geral: 54.902
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
411 411 411
(382, 30) (382, 30) (382, 30)
(382, 90) (382, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8976419 0.1023581]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 412 | Acuracia_22: 0 | Contagem Geral: 14.0 
Ordem Natural: 15.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_22: 0 
Precisao modelo Geral: 53.8462
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
412 412 412
(383, 30) (383, 30) (383, 30)
(383, 90) (383, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.47423932 0.5257607 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 413 | Acuracia_23: 0 | Contagem Geral: 14.0 
Ordem Natural: 16.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_23: 1.0 
Precisao modelo Geral: 54.717
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
413 413 413
(384, 30) (384, 30) (384, 30)
(384, 90) (384, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.21898787 0.7810122 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 414 | Acuracia_24: 0 | Contagem Geral: 15.0 
Ordem Natural: 17.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_24: 0.0 
Precisao modelo Geral: 53.7037
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
414 414 414
(385, 30) (385, 30) (385, 30)
(385, 90) (385, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.30208606 0.69791394]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 415 | Acuracia_25: 0 | Contagem Geral: 16.0 
Ordem Natural: 17.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_25: 0.0 
Precisao modelo Geral: 52.7273
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
415 415 415
(386, 30) (386, 30) (386, 30)
(386, 90) (386, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.81723434 0.18276569]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 416 | Acuracia_26: 0 | Contagem Geral: 17.0 
Ordem Natural: 17.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_26: 0 
Precisao modelo Geral: 53.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
416 416 416
(387, 30) (387, 30) (387, 30)
(387, 90) (387, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9824306 0.0175694]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 417 | Acuracia_27: 0 | Contagem Geral: 17.0 
Ordem Natural: 17.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_27: 0 
Precisao modelo Geral: 54.386
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
417 417 417
(388, 30) (388, 30) (388, 30)
(388, 90) (388, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94618464 0.05381532]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 418 | Acuracia_28: 0 | Contagem Geral: 17.0 
Ordem Natural: 17.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_28: 0 
Precisao modelo Geral: 53.4483
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
418 418 418
(389, 30) (389, 30) (389, 30)
(389, 90) (389, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9272042  0.07279581]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 419 | Acuracia_29: 0 | Contagem Geral: 17.0 
Ordem Natural: 18.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_29: 0 
Precisao modelo Geral: 54.2373
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
419 419 419
(390, 30) (390, 30) (390, 30)
(390, 90) (390, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89288336 0.10711662]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 420 | Acuracia_0: 0 | Contagem Geral: 17.0 
Ordem Natural: 18.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_30: 0 
Precisao modelo Geral: 53.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
420 420 420
(391, 30) (391, 30) (391, 30)
(391, 90) (391, 30)
Matrix_30: [(391, 90), (391, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1758 - accuracy: 0.5367 - precision: 0.5367 - recall: 0.5367 - f1_score: 0.3567 - val_loss: 0.3474 - val_accuracy: 0.2727 - val_precision: 0.2727 - val_recall: 0.2727 - val_f1_score: 0.4286 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.2494 - accuracy: 0.3303 - precision: 0.3303 - recall: 0.3303 - f1_score: 0.4966 - val_loss: 0.1341 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.0000e+00 - 202ms/epoch - 202ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1761 - accuracy: 0.6743 - precision: 0.6743 - recall: 0.6743 - f1_score: 0.0533 - val_loss: 0.1326 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.0000e+00 - 140ms/epoch - 140ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1844 - accuracy: 0.6697 - precision: 0.6697 - recall: 0.6697 - f1_score: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.8182 - val_precision: 0.8182 - val_recall: 0.8182 - val_f1_score: 0.5455 - 161ms/epoch - 161ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1489 - accuracy: 0.8165 - precision: 0.8165 - recall: 0.8165 - f1_score: 0.6296 - val_loss: 0.1676 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5283 - 132ms/epoch - 132ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1443 - accuracy: 0.6422 - precision: 0.6422 - recall: 0.6422 - f1_score: 0.6486 - val_loss: 0.1939 - val_accuracy: 0.3091 - val_precision: 0.3091 - val_recall: 0.3091 - val_f1_score: 0.4412 - 213ms/epoch - 213ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1525 - accuracy: 0.4037 - precision: 0.4037 - recall: 0.4037 - f1_score: 0.5255 - val_loss: 0.1903 - val_accuracy: 0.3091 - val_precision: 0.3091 - val_recall: 0.3091 - val_f1_score: 0.4412 - 117ms/epoch - 117ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1491 - accuracy: 0.4312 - precision: 0.4312 - recall: 0.4312 - f1_score: 0.5373 - val_loss: 0.1699 - val_accuracy: 0.5273 - val_precision: 0.5273 - val_recall: 0.5273 - val_f1_score: 0.5357 - 146ms/epoch - 146ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1384 - accuracy: 0.6330 - precision: 0.6330 - recall: 0.6330 - f1_score: 0.6429 - val_loss: 0.1471 - val_accuracy: 0.7818 - val_precision: 0.7818 - val_recall: 0.7818 - val_f1_score: 0.7000 - 181ms/epoch - 181ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1297 - accuracy: 0.8440 - precision: 0.8440 - recall: 0.8440 - f1_score: 0.8068 - val_loss: 0.1302 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8571 - 197ms/epoch - 197ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1267 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8235 - val_loss: 0.1203 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8148 - 261ms/epoch - 261ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1258 - accuracy: 0.8624 - precision: 0.8624 - recall: 0.8624 - f1_score: 0.7541 - val_loss: 0.1159 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8148 - 162ms/epoch - 162ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1208 - accuracy: 0.8716 - precision: 0.8716 - recall: 0.8716 - f1_score: 0.7742 - val_loss: 0.1164 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_f1_score: 0.8966 - 147ms/epoch - 147ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1116 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8286 - val_loss: 0.1229 - val_accuracy: 0.8182 - val_precision: 0.8182 - val_recall: 0.8182 - val_f1_score: 0.7368 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1036 - accuracy: 0.9083 - precision: 0.9083 - recall: 0.9083 - f1_score: 0.8765 - val_loss: 0.1335 - val_accuracy: 0.6909 - val_precision: 0.6909 - val_recall: 0.6909 - val_f1_score: 0.6222 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1005 - accuracy: 0.8486 - precision: 0.8486 - recall: 0.8486 - f1_score: 0.8136 - val_loss: 0.1378 - val_accuracy: 0.6727 - val_precision: 0.6727 - val_recall: 0.6727 - val_f1_score: 0.6087 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0977 - accuracy: 0.8165 - precision: 0.8165 - recall: 0.8165 - f1_score: 0.7826 - val_loss: 0.1248 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.6512 - 77ms/epoch - 77ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0895 - accuracy: 0.8670 - precision: 0.8670 - recall: 0.8670 - f1_score: 0.8324 - val_loss: 0.1037 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 80ms/epoch - 80ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0815 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - f1_score: 0.8679 - val_loss: 0.0885 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_f1_score: 0.8966 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0788 - accuracy: 0.9083 - precision: 0.9083 - recall: 0.9083 - f1_score: 0.8649 - val_loss: 0.0824 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_f1_score: 0.8966 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0747 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - f1_score: 0.8889 - val_loss: 0.0851 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0667 - accuracy: 0.9083 - precision: 0.9083 - recall: 0.9083 - f1_score: 0.8684 - val_loss: 0.0965 - val_accuracy: 0.8182 - val_precision: 0.8182 - val_recall: 0.8182 - val_f1_score: 0.7368 - 75ms/epoch - 75ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0633 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - f1_score: 0.8727 - val_loss: 0.1003 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1_score: 0.7179 - 80ms/epoch - 80ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0612 - accuracy: 0.8945 - precision: 0.8945 - recall: 0.8945 - f1_score: 0.8623 - val_loss: 0.0853 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0544 - accuracy: 0.9174 - precision: 0.9174 - recall: 0.9174 - f1_score: 0.8875 - val_loss: 0.0691 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0512 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - f1_score: 0.8980 - val_loss: 0.0635 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0491 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - f1_score: 0.9167 - val_loss: 0.0677 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_f1_score: 0.9032 - 74ms/epoch - 74ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9495 - precision: 0.9495 - recall: 0.9495 - f1_score: 0.9272 - val_loss: 0.0778 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.8000 - 77ms/epoch - 77ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0411 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - f1_score: 0.9045 - val_loss: 0.0772 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.8000 - 85ms/epoch - 85ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0386 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - f1_score: 0.8987 - val_loss: 0.0642 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0340 - accuracy: 0.9633 - precision: 0.9633 - recall: 0.9633 - f1_score: 0.9467 - val_loss: 0.0553 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 77ms/epoch - 77ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0326 - accuracy: 0.9633 - precision: 0.9633 - recall: 0.9633 - f1_score: 0.9452 - val_loss: 0.0548 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0294 - accuracy: 0.9679 - precision: 0.9679 - recall: 0.9679 - f1_score: 0.9524 - val_loss: 0.0609 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 94ms/epoch - 94ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0262 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - f1_score: 0.9595 - val_loss: 0.0650 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8750 - 84ms/epoch - 84ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0249 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - f1_score: 0.9664 - val_loss: 0.0582 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 79ms/epoch - 79ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0217 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - f1_score: 0.9664 - val_loss: 0.0495 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 74ms/epoch - 74ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0197 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9790 - val_loss: 0.0464 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0182 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9790 - val_loss: 0.0483 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0156 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954 - f1_score: 0.9931 - val_loss: 0.0520 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 76ms/epoch - 76ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0144 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - f1_score: 0.9863 - val_loss: 0.0503 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 76ms/epoch - 76ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0129 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - f1_score: 0.9863 - val_loss: 0.0439 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 74ms/epoch - 74ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 75ms/epoch - 75ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0103 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 84ms/epoch - 84ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0090 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 80ms/epoch - 80ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0078 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0072 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 88ms/epoch - 88ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0064 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 92ms/epoch - 92ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 74ms/epoch - 74ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 76ms/epoch - 76ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0340
Accuracy: 0.9322
Precision: 0.9322
Recall: 0.9322
F1 Score: 0.8824
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
420 420 420
(391, 30) (391, 30) (391, 30)
(391, 90) (391, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 87ms/step
[[0.941825   0.05817501]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 421 | Acuracia_1: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 19.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_1: 0.0 
Precisao modelo Geral: 52.459
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
421 421 421
(392, 30) (392, 30) (392, 30)
(392, 90) (392, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97752875 0.02247125]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 422 | Acuracia_2: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 20.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_2: 0.0 
Precisao modelo Geral: 53.2258
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
422 422 422
(393, 30) (393, 30) (393, 30)
(393, 90) (393, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.948642   0.05135801]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 423 | Acuracia_3: 0 | Contagem Geral: 17.0 
Ordem Natural: 20.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_3: 0 
Precisao modelo Geral: 53.9683
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
423 423 423
(394, 30) (394, 30) (394, 30)
(394, 90) (394, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8751141  0.12488594]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 424 | Acuracia_4: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 20.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_4: 0.0 
Precisao modelo Geral: 53.125
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
424 424 424
(395, 30) (395, 30) (395, 30)
(395, 90) (395, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8944641  0.10553589]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 425 | Acuracia_5: 0 | Contagem Geral: 17.0 
Ordem Natural: 21.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_5: 0 
Precisao modelo Geral: 53.8462
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
425 425 425
(396, 30) (396, 30) (396, 30)
(396, 90) (396, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9850508  0.01494921]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 426 | Acuracia_6: 1.0 | Contagem Geral: 17.0 
Ordem Natural: 21.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_6: 1.0 
Precisao modelo Geral: 53.0303
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
426 426 426
(397, 30) (397, 30) (397, 30)
(397, 90) (397, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9820094  0.01799056]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 427 | Acuracia_7: 0.5 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_7: 0.5 
Precisao modelo Geral: 53.7313
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
427 427 427
(398, 30) (398, 30) (398, 30)
(398, 90) (398, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9833296 0.0166704]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 428 | Acuracia_8: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_8: 0 
Precisao modelo Geral: 54.4118
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
428 428 428
(399, 30) (399, 30) (399, 30)
(399, 90) (399, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98661    0.01339005]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 429 | Acuracia_9: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_9: 0 
Precisao modelo Geral: 55.0725
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
429 429 429
(400, 30) (400, 30) (400, 30)
(400, 90) (400, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98365456 0.01634549]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 430 | Acuracia_10: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_10: 0.0 
Precisao modelo Geral: 55.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
430 430 430
(401, 30) (401, 30) (401, 30)
(401, 90) (401, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9745377  0.02546226]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 431 | Acuracia_11: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_11: 0 
Precisao modelo Geral: 56.338
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
431 431 431
(402, 30) (402, 30) (402, 30)
(402, 90) (402, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9803626  0.01963733]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 432 | Acuracia_12: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_12: 0.0 
Precisao modelo Geral: 56.9444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
432 432 432
(403, 30) (403, 30) (403, 30)
(403, 90) (403, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99297285 0.00702714]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 433 | Acuracia_13: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_13: 0.0 
Precisao modelo Geral: 57.5342
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
433 433 433
(404, 30) (404, 30) (404, 30)
(404, 90) (404, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97081316 0.02918686]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 434 | Acuracia_14: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_14: 0 
Precisao modelo Geral: 58.1081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
434 434 434
(405, 30) (405, 30) (405, 30)
(405, 90) (405, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96759653 0.03240354]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 435 | Acuracia_15: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_15: 0 
Precisao modelo Geral: 58.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
435 435 435
(406, 30) (406, 30) (406, 30)
(406, 90) (406, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98448455 0.01551544]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 436 | Acuracia_16: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.2105
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
436 436 436
(407, 30) (407, 30) (407, 30)
(407, 90) (407, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 36ms/step
[[0.97064304 0.02935694]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 437 | Acuracia_17: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_17: 0.0 
Precisao modelo Geral: 59.7403
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
437 437 437
(408, 30) (408, 30) (408, 30)
(408, 90) (408, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98220223 0.01779777]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 438 | Acuracia_18: 1.0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_18: 1.0 
Precisao modelo Geral: 60.2564
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
438 438 438
(409, 30) (409, 30) (409, 30)
(409, 90) (409, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9874024  0.01259768]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 439 | Acuracia_19: 0 | Contagem Geral: 17.0 
Ordem Natural: 22.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_19: 0 
Precisao modelo Geral: 59.4937
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
439 439 439
(410, 30) (410, 30) (410, 30)
(410, 90) (410, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96627474 0.03372525]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 440 | Acuracia_20: 0 | Contagem Geral: 17.0 
Ordem Natural: 23.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_20: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
440 440 440
(411, 30) (411, 30) (411, 30)
(411, 90) (411, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.8757341  0.12426594]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 441 | Acuracia_21: 0 | Contagem Geral: 17.0 
Ordem Natural: 23.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_21: 0 
Precisao modelo Geral: 60.4938
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
441 441 441
(412, 30) (412, 30) (412, 30)
(412, 90) (412, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9570459  0.04295412]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 442 | Acuracia_22: 0 | Contagem Geral: 17.0 
Ordem Natural: 23.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_22: 0 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
442 442 442
(413, 30) (413, 30) (413, 30)
(413, 90) (413, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9821885 0.0178115]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 443 | Acuracia_23: 1.0 | Contagem Geral: 17.0 
Ordem Natural: 23.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_23: 1.0 
Precisao modelo Geral: 61.4458
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
443 443 443
(414, 30) (414, 30) (414, 30)
(414, 90) (414, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9777744  0.02222559]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 444 | Acuracia_24: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 23.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_24: 0.0 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
444 444 444
(415, 30) (415, 30) (415, 30)
(415, 90) (415, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9333581  0.06664197]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 445 | Acuracia_25: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_25: 0.0 
Precisao modelo Geral: 61.1765
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
445 445 445
(416, 30) (416, 30) (416, 30)
(416, 90) (416, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8866645  0.11333545]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 446 | Acuracia_26: 0 | Contagem Geral: 17.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_26: 0 
Precisao modelo Geral: 61.6279
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
446 446 446
(417, 30) (417, 30) (417, 30)
(417, 90) (417, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9759444  0.02405559]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 447 | Acuracia_27: 0 | Contagem Geral: 17.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_27: 0 
Precisao modelo Geral: 62.069
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
447 447 447
(418, 30) (418, 30) (418, 30)
(418, 90) (418, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86245525 0.13754474]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 448 | Acuracia_28: 0 | Contagem Geral: 17.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_28: 0 
Precisao modelo Geral: 62.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
448 448 448
(419, 30) (419, 30) (419, 30)
(419, 90) (419, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.73828757 0.2617124 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 449 | Acuracia_29: 0 | Contagem Geral: 17.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_29: 0.0 
Precisao modelo Geral: 61.7978
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
449 449 449
(420, 30) (420, 30) (420, 30)
(420, 90) (420, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96244764 0.03755231]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 450 | Acuracia_0: 0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_30: 0 
Precisao modelo Geral: 62.2222
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2833 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3461 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.7776 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1518 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 153ms/epoch - 153ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2742 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1762 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.5000 - 152ms/epoch - 152ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.5448 - val_loss: 0.2710 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 92ms/epoch - 92ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2107 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2972 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 79ms/epoch - 79ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2259 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2656 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 77ms/epoch - 77ms/step
Epoch 7/50
1/1 - 0s - loss: 0.2036 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2138 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1706 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.5161 - 79ms/epoch - 79ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.5789 - val_loss: 0.1455 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.6667 - 86ms/epoch - 86ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.7447 - precision: 0.7447 - recall: 0.7447 - f1_score: 0.4643 - val_loss: 0.1367 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.5600 - 80ms/epoch - 80ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.7489 - precision: 0.7489 - recall: 0.7489 - f1_score: 0.3918 - val_loss: 0.1370 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.6154 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.7702 - precision: 0.7702 - recall: 0.7702 - f1_score: 0.4706 - val_loss: 0.1443 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7879 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1498 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - f1_score: 0.6569 - val_loss: 0.1581 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.5660 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1455 - accuracy: 0.7191 - precision: 0.7191 - recall: 0.7191 - f1_score: 0.6667 - val_loss: 0.1724 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.5161 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1464 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.5804 - val_loss: 0.1779 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.4848 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1463 - accuracy: 0.4766 - precision: 0.4766 - recall: 0.4766 - f1_score: 0.5461 - val_loss: 0.1707 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.5000 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1417 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.5944 - val_loss: 0.1552 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.5882 - 79ms/epoch - 79ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1349 - accuracy: 0.7447 - precision: 0.7447 - recall: 0.7447 - f1_score: 0.7115 - val_loss: 0.1388 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.6818 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1304 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.7784 - val_loss: 0.1268 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1292 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7639 - val_loss: 0.1207 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8667 - 85ms/epoch - 85ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1275 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.7591 - val_loss: 0.1196 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8667 - 79ms/epoch - 79ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1228 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.7857 - val_loss: 0.1231 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7568 - 83ms/epoch - 83ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1169 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7848 - val_loss: 0.1299 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.6818 - 80ms/epoch - 80ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1130 - accuracy: 0.8468 - precision: 0.8468 - recall: 0.8468 - f1_score: 0.7907 - val_loss: 0.1359 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6522 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1111 - accuracy: 0.8128 - precision: 0.8128 - recall: 0.8128 - f1_score: 0.7660 - val_loss: 0.1354 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6522 - 78ms/epoch - 78ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1083 - accuracy: 0.8085 - precision: 0.8085 - recall: 0.8085 - f1_score: 0.7619 - val_loss: 0.1269 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 80ms/epoch - 80ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1035 - accuracy: 0.8468 - precision: 0.8468 - recall: 0.8468 - f1_score: 0.8000 - val_loss: 0.1145 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7000 - 78ms/epoch - 78ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0987 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.8024 - val_loss: 0.1038 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7778 - 87ms/epoch - 87ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0959 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8052 - val_loss: 0.0975 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 76ms/epoch - 76ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0936 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8267 - val_loss: 0.0958 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0898 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8212 - val_loss: 0.0983 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7568 - 81ms/epoch - 81ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0855 - accuracy: 0.8638 - precision: 0.8638 - recall: 0.8638 - f1_score: 0.8025 - val_loss: 0.1027 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7317 - 85ms/epoch - 85ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0827 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8304 - val_loss: 0.1041 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 83ms/epoch - 83ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0806 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8276 - val_loss: 0.0988 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 81ms/epoch - 81ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0772 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8324 - val_loss: 0.0894 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 76ms/epoch - 76ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0736 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.8313 - val_loss: 0.0811 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 83ms/epoch - 83ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0712 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8462 - val_loss: 0.0767 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0689 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8421 - val_loss: 0.0763 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0656 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8662 - val_loss: 0.0787 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 90ms/epoch - 90ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0628 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8727 - val_loss: 0.0804 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 91ms/epoch - 91ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0608 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8743 - val_loss: 0.0774 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 88ms/epoch - 88ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0582 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8795 - val_loss: 0.0706 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 93ms/epoch - 93ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0552 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8834 - val_loss: 0.0645 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 105ms/epoch - 105ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0530 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8846 - val_loss: 0.0614 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0508 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8903 - val_loss: 0.0613 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 82ms/epoch - 82ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0480 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.8974 - val_loss: 0.0627 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 79ms/epoch - 79ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0456 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8944 - val_loss: 0.0626 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 77ms/epoch - 77ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0435 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8944 - val_loss: 0.0588 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0409 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.9000 - val_loss: 0.0536 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 80ms/epoch - 80ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0386 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9351 - val_loss: 0.0504 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step

🔍 Resultados no Teste:
Loss: 0.0677
Accuracy: 0.8819
Precision: 0.8819
Recall: 0.8819
F1 Score: 0.7945
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2640 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.9950 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.7873 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3979 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.3053 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1457 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6667 - 76ms/epoch - 76ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1530 - accuracy: 0.7362 - precision: 0.7362 - recall: 0.7362 - f1_score: 0.6076 - val_loss: 0.1311 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.1176 - 74ms/epoch - 74ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2306 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1334 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2367 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1286 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1904 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.2222 - 77ms/epoch - 77ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1587 - accuracy: 0.7532 - precision: 0.7532 - recall: 0.7532 - f1_score: 0.3556 - val_loss: 0.1572 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.6222 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7351 - val_loss: 0.1792 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.5000 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1571 - accuracy: 0.4128 - precision: 0.4128 - recall: 0.4128 - f1_score: 0.5175 - val_loss: 0.1958 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 113ms/epoch - 113ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1635 - accuracy: 0.3234 - precision: 0.3234 - recall: 0.3234 - f1_score: 0.4821 - val_loss: 0.2024 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 118ms/epoch - 118ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1992 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 106ms/epoch - 106ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.1893 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.4507 - 98ms/epoch - 98ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.3617 - precision: 0.3617 - recall: 0.3617 - f1_score: 0.4966 - val_loss: 0.1776 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.5000 - 98ms/epoch - 98ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1545 - accuracy: 0.4553 - precision: 0.4553 - recall: 0.4553 - f1_score: 0.5362 - val_loss: 0.1670 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.5614 - 102ms/epoch - 102ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1511 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.6325 - val_loss: 0.1573 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.5833 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1486 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - f1_score: 0.7487 - val_loss: 0.1489 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7027 - 80ms/epoch - 80ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1470 - accuracy: 0.8383 - precision: 0.8383 - recall: 0.8383 - f1_score: 0.7625 - val_loss: 0.1422 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7333 - 80ms/epoch - 80ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1461 - accuracy: 0.8468 - precision: 0.8468 - recall: 0.8468 - f1_score: 0.7353 - val_loss: 0.1373 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7143 - 82ms/epoch - 82ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1452 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.7154 - val_loss: 0.1339 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7143 - 110ms/epoch - 110ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1437 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.6942 - val_loss: 0.1320 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7143 - 114ms/epoch - 114ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1413 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.6942 - val_loss: 0.1312 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8000 - 154ms/epoch - 154ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1379 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.7328 - val_loss: 0.1317 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 115ms/epoch - 115ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1341 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7571 - val_loss: 0.1331 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 104ms/epoch - 104ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1303 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8000 - val_loss: 0.1352 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7568 - 89ms/epoch - 89ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1271 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8199 - val_loss: 0.1370 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6512 - 85ms/epoch - 85ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1243 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8276 - val_loss: 0.1379 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.6383 - 88ms/epoch - 88ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1216 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8090 - val_loss: 0.1368 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.6250 - 81ms/epoch - 81ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1187 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8111 - val_loss: 0.1333 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6522 - 129ms/epoch - 129ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1153 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.8156 - val_loss: 0.1277 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 115ms/epoch - 115ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1116 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8235 - val_loss: 0.1210 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7778 - 139ms/epoch - 139ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1081 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8447 - val_loss: 0.1144 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 132ms/epoch - 132ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1050 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8235 - val_loss: 0.1089 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 144ms/epoch - 144ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1022 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8188 - val_loss: 0.1050 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 140ms/epoch - 140ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0993 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8188 - val_loss: 0.1030 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 95ms/epoch - 95ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0958 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8267 - val_loss: 0.1027 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 77ms/epoch - 77ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0921 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8516 - val_loss: 0.1035 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0887 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8696 - val_loss: 0.1041 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0858 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8434 - val_loss: 0.1030 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 81ms/epoch - 81ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0830 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8521 - val_loss: 0.0993 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 82ms/epoch - 82ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0798 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8521 - val_loss: 0.0935 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 80ms/epoch - 80ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0764 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8659 - val_loss: 0.0872 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 87ms/epoch - 87ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0732 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8820 - val_loss: 0.0817 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 85ms/epoch - 85ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0705 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8846 - val_loss: 0.0780 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 82ms/epoch - 82ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0677 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8903 - val_loss: 0.0761 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 78ms/epoch - 78ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0647 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.8974 - val_loss: 0.0757 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0618 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9125 - val_loss: 0.0754 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 80ms/epoch - 80ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0593 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8957 - val_loss: 0.0739 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 75ms/epoch - 75ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0569 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8902 - val_loss: 0.0704 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 78ms/epoch - 78ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0543 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.9012 - val_loss: 0.0655 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 75ms/epoch - 75ms/step

🔍 Resultados no Teste:
Loss: 0.0763
Accuracy: 0.8504
Precision: 0.8504
Recall: 0.8504
F1 Score: 0.7595
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1786 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.3600 - val_loss: 0.4359 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3106 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1461 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.4348 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1509 - accuracy: 0.8128 - precision: 0.8128 - recall: 0.8128 - f1_score: 0.6000 - val_loss: 0.1401 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 78ms/epoch - 78ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2225 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1299 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 75ms/epoch - 75ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.7106 - precision: 0.7106 - recall: 0.7106 - f1_score: 0.1500 - val_loss: 0.1472 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7317 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1358 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8428 - val_loss: 0.1839 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4444 - 79ms/epoch - 79ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1452 - accuracy: 0.4553 - precision: 0.4553 - recall: 0.4553 - f1_score: 0.5362 - val_loss: 0.2025 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4384 - 86ms/epoch - 86ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1536 - accuracy: 0.3489 - precision: 0.3489 - recall: 0.3489 - f1_score: 0.4917 - val_loss: 0.1896 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4444 - 76ms/epoch - 76ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1450 - accuracy: 0.4255 - precision: 0.4255 - recall: 0.4255 - f1_score: 0.5230 - val_loss: 0.1595 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.5333 - 80ms/epoch - 80ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1295 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.6727 - val_loss: 0.1306 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1222 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8630 - val_loss: 0.1145 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1236 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.7541 - val_loss: 0.1092 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1181 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.7840 - val_loss: 0.1114 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1068 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8551 - val_loss: 0.1207 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7500 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0998 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8727 - val_loss: 0.1309 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.6250 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0982 - accuracy: 0.8383 - precision: 0.8383 - recall: 0.8383 - f1_score: 0.7957 - val_loss: 0.1314 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.6250 - 75ms/epoch - 75ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0950 - accuracy: 0.8340 - precision: 0.8340 - recall: 0.8340 - f1_score: 0.7914 - val_loss: 0.1185 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 79ms/epoch - 79ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0869 - accuracy: 0.8638 - precision: 0.8638 - recall: 0.8638 - f1_score: 0.8222 - val_loss: 0.0994 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 80ms/epoch - 80ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0791 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.9000 - val_loss: 0.0846 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0767 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9091 - val_loss: 0.0777 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0742 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.8841 - val_loss: 0.0772 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0670 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9116 - val_loss: 0.0832 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0611 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9057 - val_loss: 0.0907 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 77ms/epoch - 77ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0594 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8810 - val_loss: 0.0878 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0559 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8810 - val_loss: 0.0736 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 80ms/epoch - 80ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0495 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9241 - val_loss: 0.0597 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0461 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9467 - val_loss: 0.0530 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0444 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9306 - val_loss: 0.0524 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 83ms/epoch - 83ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0393 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9530 - val_loss: 0.0568 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 80ms/epoch - 80ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0357 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9487 - val_loss: 0.0594 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0343 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9427 - val_loss: 0.0525 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 79ms/epoch - 79ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0306 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9548 - val_loss: 0.0422 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0274 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0368 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0263 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9664 - val_loss: 0.0359 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0232 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9664 - val_loss: 0.0380 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 75ms/epoch - 75ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0208 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9801 - val_loss: 0.0389 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0197 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9737 - val_loss: 0.0345 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0173 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9801 - val_loss: 0.0293 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0156 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0270 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0146 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0263 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0127 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0268 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0115 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0264 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0107 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0236 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0093 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0212 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 80ms/epoch - 80ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0084 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0078 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0068 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0056 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step

🔍 Resultados no Teste:
Loss: 0.0289
Accuracy: 0.9606
Precision: 0.9606
Recall: 0.9606
F1 Score: 0.9275
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> Resposta inválida. Por favor, insira 's' ou 'n'.
************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1751 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.3600 - val_loss: 0.9547 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.6920 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1870 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.4706 - 75ms/epoch - 75ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1500 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5021 - f1_score: 0.5551 - val_loss: 0.1677 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 4/50
1/1 - 0s - loss: 0.3257 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1613 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 79ms/epoch - 79ms/step
Epoch 5/50
1/1 - 0s - loss: 0.3101 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1324 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 79ms/epoch - 79ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2182 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1298 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.2222 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.7319 - precision: 0.7319 - recall: 0.7319 - f1_score: 0.2588 - val_loss: 0.1599 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.6000 - 78ms/epoch - 78ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1484 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.6727 - val_loss: 0.2029 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2267 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1771 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2233 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 75ms/epoch - 75ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2044 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1820 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.4507 - 77ms/epoch - 77ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.3915 - precision: 0.3915 - recall: 0.3915 - f1_score: 0.5086 - val_loss: 0.1631 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.5614 - 76ms/epoch - 76ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1452 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.6578 - val_loss: 0.1494 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.6842 - 77ms/epoch - 77ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1424 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8295 - val_loss: 0.1404 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7879 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1421 - accuracy: 0.8638 - precision: 0.8638 - recall: 0.8638 - f1_score: 0.7746 - val_loss: 0.1348 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8387 - 74ms/epoch - 74ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1419 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.7368 - val_loss: 0.1313 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8667 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1401 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.7287 - val_loss: 0.1297 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8667 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1363 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7463 - val_loss: 0.1299 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7879 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.7917 - val_loss: 0.1322 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7429 - 79ms/epoch - 79ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1262 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8743 - val_loss: 0.1365 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 80ms/epoch - 80ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1229 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8132 - val_loss: 0.1415 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.6957 - 79ms/epoch - 79ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1211 - accuracy: 0.8085 - precision: 0.8085 - recall: 0.8085 - f1_score: 0.7668 - val_loss: 0.1448 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6667 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1198 - accuracy: 0.7745 - precision: 0.7745 - recall: 0.7745 - f1_score: 0.7363 - val_loss: 0.1444 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6667 - 76ms/epoch - 76ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1177 - accuracy: 0.7702 - precision: 0.7702 - recall: 0.7702 - f1_score: 0.7327 - val_loss: 0.1396 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6809 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1141 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7513 - val_loss: 0.1316 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6977 - 79ms/epoch - 79ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1096 - accuracy: 0.8340 - precision: 0.8340 - recall: 0.8340 - f1_score: 0.7914 - val_loss: 0.1222 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7179 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1053 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8506 - val_loss: 0.1134 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 76ms/epoch - 76ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1019 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8588 - val_loss: 0.1064 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0995 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8395 - val_loss: 0.1013 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 76ms/epoch - 76ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0973 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8322 - val_loss: 0.0979 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 75ms/epoch - 75ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0943 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8138 - val_loss: 0.0963 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 76ms/epoch - 76ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0903 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8387 - val_loss: 0.0966 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 92ms/epoch - 92ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0861 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8675 - val_loss: 0.0982 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 105ms/epoch - 105ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0826 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8639 - val_loss: 0.0990 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7568 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0800 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8588 - val_loss: 0.0966 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7368 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0771 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.0905 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0736 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8639 - val_loss: 0.0828 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 85ms/epoch - 85ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0701 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8795 - val_loss: 0.0762 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 87ms/epoch - 87ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0674 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9057 - val_loss: 0.0720 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 90ms/epoch - 90ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0646 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9079 - val_loss: 0.0703 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0613 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9172 - val_loss: 0.0705 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 99ms/epoch - 99ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0581 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0706 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0557 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0681 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0530 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0628 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0500 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9250 - val_loss: 0.0574 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 74ms/epoch - 74ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0478 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9290 - val_loss: 0.0543 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9342 - val_loss: 0.0536 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 78ms/epoch - 78ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9412 - val_loss: 0.0540 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 80ms/epoch - 80ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0412 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9427 - val_loss: 0.0531 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 74ms/epoch - 74ms/step

🔍 Resultados no Teste:
Loss: 0.0768
Accuracy: 0.8898
Precision: 0.8898
Recall: 0.8898
F1 Score: 0.8158
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1934 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.0476 - val_loss: 0.8780 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.6497 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3246 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 213ms/epoch - 213ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2365 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1379 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 208ms/epoch - 208ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1778 - accuracy: 0.6979 - precision: 0.6979 - recall: 0.6979 - f1_score: 0.1013 - val_loss: 0.1458 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 170ms/epoch - 170ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2487 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1363 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 109ms/epoch - 109ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2010 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.2222 - 100ms/epoch - 100ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.7149 - precision: 0.7149 - recall: 0.7149 - f1_score: 0.1928 - val_loss: 0.1677 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.5614 - 163ms/epoch - 163ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1524 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.6271 - val_loss: 0.2012 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 167ms/epoch - 167ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1675 - accuracy: 0.3277 - precision: 0.3277 - recall: 0.3277 - f1_score: 0.4837 - val_loss: 0.2070 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 218ms/epoch - 218ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.1850 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4384 - 184ms/epoch - 184ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1549 - accuracy: 0.3915 - precision: 0.3915 - recall: 0.3915 - f1_score: 0.5086 - val_loss: 0.1543 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6667 - 171ms/epoch - 171ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1406 - accuracy: 0.7702 - precision: 0.7702 - recall: 0.7702 - f1_score: 0.7327 - val_loss: 0.1321 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8000 - 131ms/epoch - 131ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1384 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.7287 - val_loss: 0.1217 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.4000 - 106ms/epoch - 106ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1427 - accuracy: 0.8085 - precision: 0.8085 - recall: 0.8085 - f1_score: 0.5794 - val_loss: 0.1172 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.4762 - 80ms/epoch - 80ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1391 - accuracy: 0.8170 - precision: 0.8170 - recall: 0.8170 - f1_score: 0.6055 - val_loss: 0.1187 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8276 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1277 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.7481 - val_loss: 0.1262 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7429 - 76ms/epoch - 76ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1187 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7952 - val_loss: 0.1349 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7273 - 91ms/epoch - 91ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1151 - accuracy: 0.8213 - precision: 0.8213 - recall: 0.8213 - f1_score: 0.7766 - val_loss: 0.1363 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6667 - 80ms/epoch - 80ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1112 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - f1_score: 0.7590 - val_loss: 0.1262 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7442 - 79ms/epoch - 79ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1043 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.7956 - val_loss: 0.1105 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7368 - 78ms/epoch - 78ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0982 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8098 - val_loss: 0.0990 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7879 - 81ms/epoch - 81ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0959 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8493 - val_loss: 0.0953 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0915 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8400 - val_loss: 0.0985 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7368 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0856 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8221 - val_loss: 0.1049 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7317 - 76ms/epoch - 76ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0828 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.8372 - val_loss: 0.1048 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 79ms/epoch - 79ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0801 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8295 - val_loss: 0.0951 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7179 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0753 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8521 - val_loss: 0.0831 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 78ms/epoch - 78ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0717 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8323 - val_loss: 0.0761 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 80ms/epoch - 80ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0697 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8477 - val_loss: 0.0753 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 81ms/epoch - 81ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0658 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8662 - val_loss: 0.0788 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7778 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0622 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8554 - val_loss: 0.0813 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7500 - 80ms/epoch - 80ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0602 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8757 - val_loss: 0.0766 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0569 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8757 - val_loss: 0.0678 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 86ms/epoch - 86ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0535 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8765 - val_loss: 0.0612 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 75ms/epoch - 75ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0513 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9020 - val_loss: 0.0591 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 98ms/epoch - 98ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0485 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9079 - val_loss: 0.0605 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 80ms/epoch - 80ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0454 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9125 - val_loss: 0.0623 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0598 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 74ms/epoch - 74ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0409 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9068 - val_loss: 0.0542 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 75ms/epoch - 75ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0381 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9299 - val_loss: 0.0497 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 76ms/epoch - 76ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0362 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9412 - val_loss: 0.0478 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 76ms/epoch - 76ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0340 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9412 - val_loss: 0.0480 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 77ms/epoch - 77ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0316 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9481 - val_loss: 0.0484 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 76ms/epoch - 76ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0299 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9419 - val_loss: 0.0464 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 77ms/epoch - 77ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0280 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9542 - val_loss: 0.0426 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0260 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9669 - val_loss: 0.0395 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 76ms/epoch - 76ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0244 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0379 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0227 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0373 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 74ms/epoch - 74ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0210 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0367 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0196 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0349 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0507
Accuracy: 0.9055
Precision: 0.9055
Recall: 0.9055
F1 Score: 0.8421
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2305 - accuracy: 0.3106 - precision: 0.3106 - recall: 0.3106 - f1_score: 0.4740 - val_loss: 0.4846 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 1.0537 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 96ms/epoch - 96ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2846 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.2478 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 117ms/epoch - 117ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1998 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3753 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 138ms/epoch - 138ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2843 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3091 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 204ms/epoch - 204ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2306 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2077 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 196ms/epoch - 196ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.1533 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.4000 - 176ms/epoch - 176ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.7957 - precision: 0.7957 - recall: 0.7957 - f1_score: 0.5472 - val_loss: 0.1424 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 144ms/epoch - 144ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1904 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 177ms/epoch - 177ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1973 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 75ms/epoch - 75ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1750 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.0526 - val_loss: 0.1434 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.6923 - 77ms/epoch - 77ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1508 - accuracy: 0.8085 - precision: 0.8085 - recall: 0.8085 - f1_score: 0.5872 - val_loss: 0.1645 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.5263 - 81ms/epoch - 81ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1448 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.6407 - val_loss: 0.1924 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 78ms/epoch - 78ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1535 - accuracy: 0.3532 - precision: 0.3532 - recall: 0.3532 - f1_score: 0.4933 - val_loss: 0.2086 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 81ms/epoch - 81ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2035 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1564 - accuracy: 0.3234 - precision: 0.3234 - recall: 0.3234 - f1_score: 0.4821 - val_loss: 0.1822 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.4571 - 79ms/epoch - 79ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1435 - accuracy: 0.4170 - precision: 0.4170 - recall: 0.4170 - f1_score: 0.5193 - val_loss: 0.1564 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.5556 - 85ms/epoch - 85ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.7234 - precision: 0.7234 - recall: 0.7234 - f1_score: 0.6948 - val_loss: 0.1354 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1249 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8485 - val_loss: 0.1225 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8000 - 78ms/epoch - 78ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1236 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8529 - val_loss: 0.1162 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8276 - 77ms/epoch - 77ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1223 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8062 - val_loss: 0.1145 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8276 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1169 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8444 - val_loss: 0.1174 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1099 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8844 - val_loss: 0.1252 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7500 - 81ms/epoch - 81ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1061 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8457 - val_loss: 0.1331 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 76ms/epoch - 76ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1053 - accuracy: 0.8128 - precision: 0.8128 - recall: 0.8128 - f1_score: 0.7708 - val_loss: 0.1329 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1028 - accuracy: 0.8085 - precision: 0.8085 - recall: 0.8085 - f1_score: 0.7668 - val_loss: 0.1227 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6977 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0971 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8315 - val_loss: 0.1085 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 76ms/epoch - 76ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0916 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8931 - val_loss: 0.0970 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 82ms/epoch - 82ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0889 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9041 - val_loss: 0.0903 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0870 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8794 - val_loss: 0.0879 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0829 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8794 - val_loss: 0.0895 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0777 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.8993 - val_loss: 0.0941 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 76ms/epoch - 76ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0742 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8957 - val_loss: 0.0975 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 76ms/epoch - 76ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0722 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8862 - val_loss: 0.0947 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 79ms/epoch - 79ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0692 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8862 - val_loss: 0.0859 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 84ms/epoch - 84ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0648 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9182 - val_loss: 0.0762 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 81ms/epoch - 81ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0616 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9342 - val_loss: 0.0696 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0596 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9178 - val_loss: 0.0666 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 78ms/epoch - 78ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0570 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9241 - val_loss: 0.0669 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 78ms/epoch - 78ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0534 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9467 - val_loss: 0.0693 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 79ms/epoch - 79ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0507 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9419 - val_loss: 0.0707 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 78ms/epoch - 78ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0489 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9367 - val_loss: 0.0675 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 79ms/epoch - 79ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0464 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9367 - val_loss: 0.0608 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 75ms/epoch - 75ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0435 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9481 - val_loss: 0.0546 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0414 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9600 - val_loss: 0.0509 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 80ms/epoch - 80ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0396 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9600 - val_loss: 0.0499 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0372 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9600 - val_loss: 0.0508 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 84ms/epoch - 84ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0349 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9605 - val_loss: 0.0514 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 75ms/epoch - 75ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0334 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9610 - val_loss: 0.0494 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 80ms/epoch - 80ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0316 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9610 - val_loss: 0.0449 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0587
Accuracy: 0.8898
Precision: 0.8898
Recall: 0.8898
F1 Score: 0.8108
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1784 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.3799 - val_loss: 0.8594 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.6246 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1397 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 110ms/epoch - 110ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1562 - accuracy: 0.7702 - precision: 0.7702 - recall: 0.7702 - f1_score: 0.4490 - val_loss: 0.1836 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 96ms/epoch - 96ms/step
Epoch 4/50
1/1 - 0s - loss: 0.3193 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1319 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 83ms/epoch - 83ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.7234 - precision: 0.7234 - recall: 0.7234 - f1_score: 0.2169 - val_loss: 0.1618 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.5660 - 106ms/epoch - 106ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1335 - accuracy: 0.7617 - precision: 0.7617 - recall: 0.7617 - f1_score: 0.7228 - val_loss: 0.2222 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4384 - 104ms/epoch - 104ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.3362 - precision: 0.3362 - recall: 0.3362 - f1_score: 0.4868 - val_loss: 0.2378 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 132ms/epoch - 132ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1702 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.2133 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4444 - 196ms/epoch - 196ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1562 - accuracy: 0.3574 - precision: 0.3574 - recall: 0.3574 - f1_score: 0.4950 - val_loss: 0.1761 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.5000 - 202ms/epoch - 202ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1383 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.5992 - val_loss: 0.1452 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 167ms/epoch - 167ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1316 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8098 - val_loss: 0.1283 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.6154 - 185ms/epoch - 185ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1369 - accuracy: 0.8255 - precision: 0.8255 - recall: 0.8255 - f1_score: 0.6496 - val_loss: 0.1224 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.4762 - 142ms/epoch - 142ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1404 - accuracy: 0.7957 - precision: 0.7957 - recall: 0.7957 - f1_score: 0.5556 - val_loss: 0.1209 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.6087 - 102ms/epoch - 102ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1349 - accuracy: 0.8255 - precision: 0.8255 - recall: 0.8255 - f1_score: 0.6435 - val_loss: 0.1231 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8000 - 86ms/epoch - 86ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1257 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.7519 - val_loss: 0.1291 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1184 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8442 - val_loss: 0.1370 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.6818 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1154 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8249 - val_loss: 0.1434 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.6154 - 79ms/epoch - 79ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1146 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7513 - val_loss: 0.1448 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.5926 - 86ms/epoch - 86ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1127 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7513 - val_loss: 0.1394 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.6275 - 79ms/epoch - 79ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1086 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7513 - val_loss: 0.1279 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6977 - 77ms/epoch - 77ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1027 - accuracy: 0.8468 - precision: 0.8468 - recall: 0.8468 - f1_score: 0.8022 - val_loss: 0.1140 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0979 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8712 - val_loss: 0.1026 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0958 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8553 - val_loss: 0.0965 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0938 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8472 - val_loss: 0.0942 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0898 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8533 - val_loss: 0.0951 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 81ms/epoch - 81ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0854 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8718 - val_loss: 0.0979 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 75ms/epoch - 75ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0821 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8589 - val_loss: 0.1003 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 80ms/epoch - 80ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0795 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8521 - val_loss: 0.1002 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0771 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8471 - val_loss: 0.0951 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0735 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8471 - val_loss: 0.0844 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0693 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8889 - val_loss: 0.0740 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 77ms/epoch - 77ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0666 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8846 - val_loss: 0.0700 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 79ms/epoch - 79ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0640 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8903 - val_loss: 0.0707 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 78ms/epoch - 78ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0603 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9057 - val_loss: 0.0728 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 79ms/epoch - 79ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0580 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8957 - val_loss: 0.0725 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0559 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8795 - val_loss: 0.0693 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0534 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8848 - val_loss: 0.0639 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 77ms/epoch - 77ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0507 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9125 - val_loss: 0.0581 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0480 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9182 - val_loss: 0.0538 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0455 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9161 - val_loss: 0.0521 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 80ms/epoch - 80ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0430 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9231 - val_loss: 0.0526 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 81ms/epoch - 81ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0407 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9182 - val_loss: 0.0523 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 86ms/epoch - 86ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0390 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9182 - val_loss: 0.0486 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 84ms/epoch - 84ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0366 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9231 - val_loss: 0.0439 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 93ms/epoch - 93ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0344 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9351 - val_loss: 0.0411 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 89ms/epoch - 89ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0326 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9474 - val_loss: 0.0403 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 98ms/epoch - 98ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0305 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9474 - val_loss: 0.0407 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 86ms/epoch - 86ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0286 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9481 - val_loss: 0.0401 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 83ms/epoch - 83ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0270 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9481 - val_loss: 0.0373 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0251 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9605 - val_loss: 0.0344 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0505
Accuracy: 0.8976
Precision: 0.8976
Recall: 0.8976
F1 Score: 0.8267
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2348 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.7705 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.5808 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.3913 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 83ms/epoch - 83ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2884 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1903 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.4638 - 76ms/epoch - 76ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1727 - accuracy: 0.4128 - precision: 0.4128 - recall: 0.4128 - f1_score: 0.5036 - val_loss: 0.1462 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1950 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 72ms/epoch - 72ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2085 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 80ms/epoch - 80ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1877 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 101ms/epoch - 101ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.7106 - precision: 0.7106 - recall: 0.7106 - f1_score: 0.1500 - val_loss: 0.1646 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.5714 - 126ms/epoch - 126ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.7277 - precision: 0.7277 - recall: 0.7277 - f1_score: 0.6952 - val_loss: 0.1915 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4444 - 104ms/epoch - 104ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.3532 - precision: 0.3532 - recall: 0.3532 - f1_score: 0.4933 - val_loss: 0.2062 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 97ms/epoch - 97ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.3234 - precision: 0.3234 - recall: 0.3234 - f1_score: 0.4821 - val_loss: 0.1981 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4444 - 100ms/epoch - 100ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.3447 - precision: 0.3447 - recall: 0.3447 - f1_score: 0.4901 - val_loss: 0.1744 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.5000 - 115ms/epoch - 115ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1495 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.5670 - val_loss: 0.1490 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6190 - 88ms/epoch - 88ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1410 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8068 - val_loss: 0.1322 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.6667 - 93ms/epoch - 93ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1412 - accuracy: 0.8383 - precision: 0.8383 - recall: 0.8383 - f1_score: 0.6833 - val_loss: 0.1250 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.4000 - 84ms/epoch - 84ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1429 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.5149 - val_loss: 0.1226 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.5455 - 109ms/epoch - 109ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1389 - accuracy: 0.8255 - precision: 0.8255 - recall: 0.8255 - f1_score: 0.6306 - val_loss: 0.1239 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.7857 - 207ms/epoch - 207ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1303 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7302 - val_loss: 0.1297 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7429 - 207ms/epoch - 207ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1230 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.8272 - val_loss: 0.1382 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6190 - 184ms/epoch - 184ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1199 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8111 - val_loss: 0.1443 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.6250 - 99ms/epoch - 99ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1183 - accuracy: 0.8170 - precision: 0.8170 - recall: 0.8170 - f1_score: 0.7749 - val_loss: 0.1431 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.6383 - 98ms/epoch - 98ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1147 - accuracy: 0.8170 - precision: 0.8170 - recall: 0.8170 - f1_score: 0.7749 - val_loss: 0.1338 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6522 - 99ms/epoch - 99ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1086 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.7978 - val_loss: 0.1209 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7179 - 176ms/epoch - 176ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1027 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.8235 - val_loss: 0.1095 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7647 - 131ms/epoch - 131ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0995 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8025 - val_loss: 0.1025 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8000 - 133ms/epoch - 133ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0975 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7703 - val_loss: 0.0995 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8125 - 141ms/epoch - 141ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0931 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.7843 - val_loss: 0.1006 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7778 - 198ms/epoch - 198ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0873 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8050 - val_loss: 0.1053 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7000 - 112ms/epoch - 112ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0835 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8304 - val_loss: 0.1087 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 74ms/epoch - 74ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0816 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8681 - f1_score: 0.8268 - val_loss: 0.1043 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 75ms/epoch - 75ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0781 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8362 - val_loss: 0.0932 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7179 - 77ms/epoch - 77ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0734 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - f1_score: 0.8452 - val_loss: 0.0825 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 83ms/epoch - 83ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0709 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8176 - val_loss: 0.0767 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 82ms/epoch - 82ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0694 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8129 - val_loss: 0.0756 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 79ms/epoch - 79ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0657 - accuracy: 0.8766 - precision: 0.8766 - recall: 0.8766 - f1_score: 0.8176 - val_loss: 0.0787 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8000 - 89ms/epoch - 89ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0623 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8623 - val_loss: 0.0820 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 77ms/epoch - 77ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0610 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.0786 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0585 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.0698 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 80ms/epoch - 80ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0550 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8675 - val_loss: 0.0627 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 82ms/epoch - 82ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0534 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8790 - val_loss: 0.0598 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8485 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0514 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8846 - val_loss: 0.0604 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0482 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8875 - val_loss: 0.0627 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0464 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8834 - val_loss: 0.0615 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 80ms/epoch - 80ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0446 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8902 - val_loss: 0.0559 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 83ms/epoch - 83ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0418 - accuracy: 0.9319 - precision: 0.9319 - recall: 0.9319 - f1_score: 0.9000 - val_loss: 0.0507 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0400 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9281 - val_loss: 0.0483 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0382 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9404 - val_loss: 0.0482 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 80ms/epoch - 80ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0357 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9412 - val_loss: 0.0491 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 75ms/epoch - 75ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0340 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9299 - val_loss: 0.0476 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 82ms/epoch - 82ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0322 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9359 - val_loss: 0.0436 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step

🔍 Resultados no Teste:
Loss: 0.0673
Accuracy: 0.8819
Precision: 0.8819
Recall: 0.8819
F1 Score: 0.7945
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1804 - accuracy: 0.4638 - precision: 0.4638 - recall: 0.4638 - f1_score: 0.3700 - val_loss: 0.1327 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.5926 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1273 - accuracy: 0.8638 - precision: 0.8638 - recall: 0.8638 - f1_score: 0.7808 - val_loss: 0.5234 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.3609 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1076 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.5600 - 78ms/epoch - 78ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1145 - accuracy: 0.8723 - precision: 0.8723 - recall: 0.8723 - f1_score: 0.7541 - val_loss: 0.1542 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2696 - accuracy: 0.7021 - precision: 0.7021 - recall: 0.7021 - f1_score: 0.1026 - val_loss: 0.1072 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.3158 - 78ms/epoch - 78ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1456 - accuracy: 0.7787 - precision: 0.7787 - recall: 0.7787 - f1_score: 0.4694 - val_loss: 0.1301 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7442 - 77ms/epoch - 77ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1019 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.8066 - val_loss: 0.2056 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.4638 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1402 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.5714 - val_loss: 0.2328 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.4507 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.5324 - val_loss: 0.1944 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.4848 - 78ms/epoch - 78ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1329 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.5827 - val_loss: 0.1370 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6809 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1032 - accuracy: 0.8128 - precision: 0.8128 - recall: 0.8128 - f1_score: 0.7708 - val_loss: 0.1031 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0999 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8406 - val_loss: 0.0947 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.6667 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1155 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.7179 - val_loss: 0.0929 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.4762 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1201 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.6726 - val_loss: 0.0902 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7407 - 79ms/epoch - 79ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1067 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.7705 - val_loss: 0.0929 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 75ms/epoch - 75ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0903 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8358 - val_loss: 0.1060 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7368 - 76ms/epoch - 76ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0843 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.1245 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6809 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0881 - accuracy: 0.8340 - precision: 0.8340 - recall: 0.8340 - f1_score: 0.7914 - val_loss: 0.1356 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.6531 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0916 - accuracy: 0.7915 - precision: 0.7915 - recall: 0.7915 - f1_score: 0.7513 - val_loss: 0.1304 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6809 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0872 - accuracy: 0.8213 - precision: 0.8213 - recall: 0.8213 - f1_score: 0.7789 - val_loss: 0.1114 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.7111 - 77ms/epoch - 77ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0767 - accuracy: 0.8638 - precision: 0.8638 - recall: 0.8638 - f1_score: 0.8222 - val_loss: 0.0896 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 87ms/epoch - 87ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0677 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0742 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0655 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9103 - val_loss: 0.0665 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 80ms/epoch - 80ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0672 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8529 - val_loss: 0.0627 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 82ms/epoch - 82ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0648 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8696 - val_loss: 0.0626 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0570 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9014 - val_loss: 0.0693 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8750 - 79ms/epoch - 79ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0516 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9103 - val_loss: 0.0803 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7500 - 78ms/epoch - 78ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0518 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8862 - val_loss: 0.0840 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6977 - 77ms/epoch - 77ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0516 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.0754 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 78ms/epoch - 78ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0469 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - f1_score: 0.8970 - val_loss: 0.0615 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0417 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9427 - val_loss: 0.0511 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0403 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9530 - val_loss: 0.0463 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0403 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9241 - val_loss: 0.0450 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 79ms/epoch - 79ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0376 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9388 - val_loss: 0.0469 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 79ms/epoch - 79ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0334 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9600 - val_loss: 0.0521 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0317 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9673 - val_loss: 0.0561 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 79ms/epoch - 79ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0315 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9487 - val_loss: 0.0534 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 76ms/epoch - 76ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0296 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9610 - val_loss: 0.0455 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0265 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9673 - val_loss: 0.0382 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0248 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0343 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0245 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9664 - val_loss: 0.0329 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9032 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0229 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0334 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 77ms/epoch - 77ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0206 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9801 - val_loss: 0.0357 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 82ms/epoch - 82ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0193 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9801 - val_loss: 0.0372 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 77ms/epoch - 77ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0188 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9737 - val_loss: 0.0353 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9737 - val_loss: 0.0308 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 74ms/epoch - 74ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0157 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0271 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0148 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0252 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 88ms/epoch - 88ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0144 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0245 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0132 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step

🔍 Resultados no Teste:
Loss: 0.0377
Accuracy: 0.9134
Precision: 0.9134
Recall: 0.9134
F1 Score: 0.8533
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1825 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.3366 - val_loss: 0.2878 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2098 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.1314 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2431 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1161 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.3158 - 79ms/epoch - 79ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.7362 - precision: 0.7362 - recall: 0.7362 - f1_score: 0.2791 - val_loss: 0.1504 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6667 - 78ms/epoch - 78ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1328 - accuracy: 0.7787 - precision: 0.7787 - recall: 0.7787 - f1_score: 0.7374 - val_loss: 0.2025 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4384 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.3532 - precision: 0.3532 - recall: 0.3532 - f1_score: 0.4933 - val_loss: 0.2083 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4384 - 76ms/epoch - 76ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.3319 - precision: 0.3319 - recall: 0.3319 - f1_score: 0.4852 - val_loss: 0.1770 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.4571 - 78ms/epoch - 78ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1387 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.5627 - val_loss: 0.1404 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.6977 - 76ms/epoch - 76ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1231 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - f1_score: 0.8000 - val_loss: 0.1164 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8667 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1223 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.7939 - val_loss: 0.1078 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.6667 - 73ms/epoch - 73ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1250 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.7167 - val_loss: 0.1056 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1162 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.7874 - val_loss: 0.1114 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1037 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8421 - val_loss: 0.1273 - val_accuracy: 0.8136 - val_precision: 0.8136 - val_recall: 0.8136 - val_f1_score: 0.7317 - 74ms/epoch - 74ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1001 - accuracy: 0.8468 - precision: 0.8468 - recall: 0.8468 - f1_score: 0.8043 - val_loss: 0.1367 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.6522 - 74ms/epoch - 74ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0994 - accuracy: 0.8043 - precision: 0.8043 - recall: 0.8043 - f1_score: 0.7629 - val_loss: 0.1238 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.6818 - 75ms/epoch - 75ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0904 - accuracy: 0.8298 - precision: 0.8298 - recall: 0.8298 - f1_score: 0.7872 - val_loss: 0.0988 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 73ms/epoch - 73ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0795 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8780 - val_loss: 0.0809 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 75ms/epoch - 75ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0763 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8732 - val_loss: 0.0734 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 81ms/epoch - 81ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0725 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8633 - val_loss: 0.0742 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 79ms/epoch - 79ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0627 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9128 - val_loss: 0.0847 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 80ms/epoch - 80ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0582 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8639 - val_loss: 0.0895 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7500 - 76ms/epoch - 76ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0568 - accuracy: 0.9021 - precision: 0.9021 - recall: 0.9021 - f1_score: 0.8655 - val_loss: 0.0739 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 81ms/epoch - 81ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0492 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8902 - val_loss: 0.0561 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0451 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9459 - val_loss: 0.0485 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 92ms/epoch - 92ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0439 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9379 - val_loss: 0.0481 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 88ms/epoch - 88ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0379 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9459 - val_loss: 0.0541 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 92ms/epoch - 92ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0349 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - f1_score: 0.9481 - val_loss: 0.0548 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0334 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9241 - val_loss: 0.0431 - val_accuracy: 0.9492 - val_precision: 0.9492 - val_recall: 0.9492 - val_f1_score: 0.9091 - 79ms/epoch - 79ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0287 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9600 - val_loss: 0.0342 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 78ms/epoch - 78ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0279 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9595 - val_loss: 0.0330 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0246 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9664 - val_loss: 0.0361 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 76ms/epoch - 76ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0221 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9669 - val_loss: 0.0367 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0211 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9737 - val_loss: 0.0302 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0182 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0245 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 80ms/epoch - 80ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0169 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0224 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0156 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9865 - val_loss: 0.0225 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 77ms/epoch - 77ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0134 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0239 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 81ms/epoch - 81ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0125 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0224 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 76ms/epoch - 76ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0113 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0185 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 78ms/epoch - 78ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0098 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 79ms/epoch - 79ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0092 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9932 - val_loss: 0.0153 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 77ms/epoch - 77ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 82ms/epoch - 82ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0072 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 86ms/epoch - 86ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0068 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 91ms/epoch - 91ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 95ms/epoch - 95ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0054 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 109ms/epoch - 109ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 75ms/epoch - 75ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 75ms/epoch - 75ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 75ms/epoch - 75ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0038 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9697 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0353
Accuracy: 0.9449
Precision: 0.9449
Recall: 0.9449
F1 Score: 0.8986
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.9708054  0.02919456]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 451 | Acuracia_1: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_1: 0.0 
Precisao modelo Geral: 62.6374
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
451 451 451
(422, 30) (422, 30) (422, 30)
(422, 90) (422, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8258191  0.17418094]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 452 | Acuracia_2: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_2: 0.0 
Precisao modelo Geral: 63.0435
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
452 452 452
(423, 30) (423, 30) (423, 30)
(423, 90) (423, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94670284 0.0532972 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 453 | Acuracia_3: 0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_3: 0 
Precisao modelo Geral: 63.4409
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
453 453 453
(424, 30) (424, 30) (424, 30)
(424, 90) (424, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93288404 0.06711593]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 454 | Acuracia_4: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_4: 0.0 
Precisao modelo Geral: 63.8298
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
454 454 454
(425, 30) (425, 30) (425, 30)
(425, 90) (425, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.91323334 0.08676669]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 455 | Acuracia_5: 0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_5: 0 
Precisao modelo Geral: 64.2105
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
455 455 455
(426, 30) (426, 30) (426, 30)
(426, 90) (426, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95558417 0.04441578]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 456 | Acuracia_6: 1.0 | Contagem Geral: 18.0 
Ordem Natural: 24.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_6: 1.0 
Precisao modelo Geral: 63.5417
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
456 456 456
(427, 30) (427, 30) (427, 30)
(427, 90) (427, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9579068  0.04209328]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 457 | Acuracia_7: 0.5 | Contagem Geral: 18.0 
Ordem Natural: 25.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_7: 0.5 
Precisao modelo Geral: 63.9175
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
457 457 457
(428, 30) (428, 30) (428, 30)
(428, 90) (428, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9506494  0.04935057]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 458 | Acuracia_8: 0 | Contagem Geral: 18.0 
Ordem Natural: 25.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_8: 0 
Precisao modelo Geral: 64.2857
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
458 458 458
(429, 30) (429, 30) (429, 30)
(429, 90) (429, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94193804 0.05806202]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 459 | Acuracia_9: 0 | Contagem Geral: 18.0 
Ordem Natural: 25.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_9: 0 
Precisao modelo Geral: 64.6465
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
459 459 459
(430, 30) (430, 30) (430, 30)
(430, 90) (430, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8866592  0.11334077]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 460 | Acuracia_10: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 25.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_10: 0.0 
Precisao modelo Geral: 65.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
460 460 460
(431, 30) (431, 30) (431, 30)
(431, 90) (431, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8665136  0.13348639]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 461 | Acuracia_11: 0 | Contagem Geral: 18.0 
Ordem Natural: 25.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_11: 0 
Precisao modelo Geral: 64.3564
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
461 461 461
(432, 30) (432, 30) (432, 30)
(432, 90) (432, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89935887 0.10064112]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 462 | Acuracia_12: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_12: 0.0 
Precisao modelo Geral: 64.7059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
462 462 462
(433, 30) (433, 30) (433, 30)
(433, 90) (433, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9365668  0.06343313]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 463 | Acuracia_13: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_13: 0.0 
Precisao modelo Geral: 65.0485
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
463 463 463
(434, 30) (434, 30) (434, 30)
(434, 90) (434, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97356695 0.02643303]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 464 | Acuracia_14: 0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_14: 0 
Precisao modelo Geral: 65.3846
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
464 464 464
(435, 30) (435, 30) (435, 30)
(435, 90) (435, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9525028  0.04749725]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 465 | Acuracia_15: 0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_15: 0 
Precisao modelo Geral: 65.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
465 465 465
(436, 30) (436, 30) (436, 30)
(436, 90) (436, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89688015 0.10311982]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 466 | Acuracia_16: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_16: 0.0 
Precisao modelo Geral: 66.0377
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
466 466 466
(437, 30) (437, 30) (437, 30)
(437, 90) (437, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6168056  0.38319442]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 467 | Acuracia_17: 0.0 | Contagem Geral: 18.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.0526 | Acuracia_17: 0.0 
Precisao modelo Geral: 65.4206
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
467 467 467
(438, 30) (438, 30) (438, 30)
(438, 90) (438, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96799225 0.03200773]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 468 | Acuracia_18: 1.0 | Contagem Geral: 19.0 
Ordem Natural: 26.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.0526 | Acuracia_18: 1.0 
Precisao modelo Geral: 64.8148
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
468 468 468
(439, 30) (439, 30) (439, 30)
(439, 90) (439, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99021614 0.00978386]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 469 | Acuracia_19: 0 | Contagem Geral: 19.0 
Ordem Natural: 27.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.0526 | Acuracia_19: 0 
Precisao modelo Geral: 64.2202
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
469 469 469
(440, 30) (440, 30) (440, 30)
(440, 90) (440, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9754749  0.02452517]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 470 | Acuracia_20: 0 | Contagem Geral: 19.0 
Ordem Natural: 28.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.0526 | Acuracia_20: 0 
Precisao modelo Geral: 64.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
470 470 470
(441, 30) (441, 30) (441, 30)
(441, 90) (441, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.86147654 0.13852349]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 471 | Acuracia_21: 0 | Contagem Geral: 19.0 
Ordem Natural: 28.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.0526 | Acuracia_21: 0 
Precisao modelo Geral: 64.8649
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
471 471 471
(442, 30) (442, 30) (442, 30)
(442, 90) (442, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.48121113 0.5187889 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 472 | Acuracia_22: 0 | Contagem Geral: 19.0 
Ordem Natural: 28.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_22: 1.0 
Precisao modelo Geral: 65.1786
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
472 472 472
(443, 30) (443, 30) (443, 30)
(443, 90) (443, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 38ms/step
[[0.97143066 0.02856936]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 473 | Acuracia_23: 1.0 | Contagem Geral: 20.0 
Ordem Natural: 29.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_23: 1.0 
Precisao modelo Geral: 65.4867
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
473 473 473
(444, 30) (444, 30) (444, 30)
(444, 90) (444, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.988531   0.01146897]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 474 | Acuracia_24: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 29.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_24: 0.0 
Precisao modelo Geral: 65.7895
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
474 474 474
(445, 30) (445, 30) (445, 30)
(445, 90) (445, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9411943  0.05880569]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 475 | Acuracia_25: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 29.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_25: 0.0 
Precisao modelo Geral: 66.087
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
475 475 475
(446, 30) (446, 30) (446, 30)
(446, 90) (446, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9755854 0.0244146]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 476 | Acuracia_26: 0 | Contagem Geral: 20.0 
Ordem Natural: 29.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_26: 0 
Precisao modelo Geral: 65.5172
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
476 476 476
(447, 30) (447, 30) (447, 30)
(447, 90) (447, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9646278 0.0353722]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 477 | Acuracia_27: 0 | Contagem Geral: 20.0 
Ordem Natural: 30.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_27: 0 
Precisao modelo Geral: 65.812
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
477 477 477
(448, 30) (448, 30) (448, 30)
(448, 90) (448, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9720844  0.02791559]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 478 | Acuracia_28: 0 | Contagem Geral: 20.0 
Ordem Natural: 30.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_28: 0 
Precisao modelo Geral: 66.1017
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
478 478 478
(449, 30) (449, 30) (449, 30)
(449, 90) (449, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96953726 0.03046276]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 479 | Acuracia_29: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 30.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_29: 0.0 
Precisao modelo Geral: 66.3866
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
479 479 479
(450, 30) (450, 30) (450, 30)
(450, 90) (450, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9619412  0.03805886]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 480 | Acuracia_0: 0 | Contagem Geral: 20.0 
Ordem Natural: 30.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_30: 0 
Precisao modelo Geral: 65.8333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2042 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.0851 - val_loss: 0.5289 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3999 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2183 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 74ms/epoch - 74ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.3333 - precision: 0.3333 - recall: 0.3333 - f1_score: 0.4909 - val_loss: 0.1454 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 90ms/epoch - 90ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2165 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 79ms/epoch - 79ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2094 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.1053 - 76ms/epoch - 76ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1716 - accuracy: 0.6825 - precision: 0.6825 - recall: 0.6825 - f1_score: 0.0244 - val_loss: 0.1530 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.5641 - 80ms/epoch - 80ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1566 - accuracy: 0.8135 - precision: 0.8135 - recall: 0.8135 - f1_score: 0.7251 - val_loss: 0.1729 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.5217 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.4643 - precision: 0.4643 - recall: 0.4643 - f1_score: 0.5424 - val_loss: 0.1839 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.4800 - 75ms/epoch - 75ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.3730 - precision: 0.3730 - recall: 0.3730 - f1_score: 0.5031 - val_loss: 0.1774 - val_accuracy: 0.4444 - val_precision: 0.4444 - val_recall: 0.4444 - val_f1_score: 0.5070 - 78ms/epoch - 78ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1556 - accuracy: 0.4286 - precision: 0.4286 - recall: 0.4286 - f1_score: 0.5263 - val_loss: 0.1586 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.6316 - 88ms/epoch - 88ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1460 - accuracy: 0.6270 - precision: 0.6270 - recall: 0.6270 - f1_score: 0.6299 - val_loss: 0.1389 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7907 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1399 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.8068 - val_loss: 0.1256 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7879 - 82ms/epoch - 82ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1390 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - f1_score: 0.7429 - val_loss: 0.1191 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7500 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1353 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.7259 - val_loss: 0.1184 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 84ms/epoch - 84ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1259 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8366 - val_loss: 0.1246 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1186 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.8132 - val_loss: 0.1317 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7500 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1162 - accuracy: 0.7976 - precision: 0.7976 - recall: 0.7976 - f1_score: 0.7583 - val_loss: 0.1271 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7500 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1109 - accuracy: 0.8135 - precision: 0.8135 - recall: 0.8135 - f1_score: 0.7751 - val_loss: 0.1108 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 89ms/epoch - 89ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1020 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8324 - val_loss: 0.0942 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 79ms/epoch - 79ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0970 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8537 - val_loss: 0.0854 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 79ms/epoch - 79ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0937 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8571 - val_loss: 0.0840 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 82ms/epoch - 82ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0862 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8659 - val_loss: 0.0894 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0804 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8571 - val_loss: 0.0931 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 76ms/epoch - 76ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0776 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8466 - val_loss: 0.0846 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 75ms/epoch - 75ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0717 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8634 - val_loss: 0.0700 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 79ms/epoch - 79ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0662 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9017 - val_loss: 0.0608 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 79ms/epoch - 79ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0639 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.8970 - val_loss: 0.0594 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 74ms/epoch - 74ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0590 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9176 - val_loss: 0.0641 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0546 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9029 - val_loss: 0.0670 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 81ms/epoch - 81ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0525 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9040 - val_loss: 0.0596 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 81ms/epoch - 81ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0482 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9143 - val_loss: 0.0494 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 79ms/epoch - 79ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0450 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9176 - val_loss: 0.0448 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 80ms/epoch - 80ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0426 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9286 - val_loss: 0.0457 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 79ms/epoch - 79ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0389 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9286 - val_loss: 0.0486 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 75ms/epoch - 75ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0365 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9249 - val_loss: 0.0470 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0341 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9249 - val_loss: 0.0403 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0311 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9518 - val_loss: 0.0347 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0292 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9634 - val_loss: 0.0329 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0267 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9634 - val_loss: 0.0336 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 83ms/epoch - 83ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0245 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9634 - val_loss: 0.0336 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 91ms/epoch - 91ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0229 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9639 - val_loss: 0.0300 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0208 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0258 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0192 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0236 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 80ms/epoch - 80ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0177 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0231 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0160 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9818 - val_loss: 0.0229 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0148 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - f1_score: 0.9878 - val_loss: 0.0210 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0134 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9939 - val_loss: 0.0185 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0121 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9939 - val_loss: 0.0170 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9444 - 81ms/epoch - 81ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0112 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 76ms/epoch - 76ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0102 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 82ms/epoch - 82ms/step

🔍 Resultados no Teste:
Loss: 0.0435
Accuracy: 0.9044
Precision: 0.9044
Recall: 0.9044
F1 Score: 0.8169
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> Resposta inválida. Por favor, insira 's' ou 'n'.
************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2039 - accuracy: 0.3254 - precision: 0.3254 - recall: 0.3254 - f1_score: 0.4848 - val_loss: 0.3554 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.7310 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1307 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 86ms/epoch - 86ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1881 - accuracy: 0.6825 - precision: 0.6825 - recall: 0.6825 - f1_score: 0.0244 - val_loss: 0.2552 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 82ms/epoch - 82ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2007 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.3221 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 82ms/epoch - 82ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2466 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2458 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 81ms/epoch - 81ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1899 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1671 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.5217 - 80ms/epoch - 80ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1481 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.5806 - val_loss: 0.1334 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7586 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1523 - accuracy: 0.7817 - precision: 0.7817 - recall: 0.7817 - f1_score: 0.5299 - val_loss: 0.1258 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.2857 - 79ms/epoch - 79ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.2581 - val_loss: 0.1247 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4348 - 79ms/epoch - 79ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1575 - accuracy: 0.7460 - precision: 0.7460 - recall: 0.7460 - f1_score: 0.3469 - val_loss: 0.1292 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8485 - 80ms/epoch - 80ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1424 - accuracy: 0.8294 - precision: 0.8294 - recall: 0.8294 - f1_score: 0.6560 - val_loss: 0.1425 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7826 - 82ms/epoch - 82ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1343 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - f1_score: 0.8000 - val_loss: 0.1627 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.5217 - 82ms/epoch - 82ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1370 - accuracy: 0.5397 - precision: 0.5397 - recall: 0.5397 - f1_score: 0.5827 - val_loss: 0.1744 - val_accuracy: 0.3968 - val_precision: 0.3968 - val_recall: 0.3968 - val_f1_score: 0.4865 - 81ms/epoch - 81ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1411 - accuracy: 0.4325 - precision: 0.4325 - recall: 0.4325 - f1_score: 0.5311 - val_loss: 0.1650 - val_accuracy: 0.4921 - val_precision: 0.4921 - val_recall: 0.4921 - val_f1_score: 0.5294 - 80ms/epoch - 80ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1342 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.5625 - val_loss: 0.1442 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.6792 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1230 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.7013 - val_loss: 0.1246 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 78ms/epoch - 78ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1157 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8902 - val_loss: 0.1107 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 79ms/epoch - 79ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1127 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8456 - val_loss: 0.1024 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 78ms/epoch - 78ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1091 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8299 - val_loss: 0.0986 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 76ms/epoch - 76ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1013 - accuracy: 0.9206 - precision: 0.9206 - recall: 0.9206 - f1_score: 0.8684 - val_loss: 0.1003 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0934 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9157 - val_loss: 0.1074 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0902 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8729 - val_loss: 0.1113 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 98ms/epoch - 98ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0887 - accuracy: 0.8730 - precision: 0.8730 - recall: 0.8730 - f1_score: 0.8333 - val_loss: 0.1043 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7826 - 131ms/epoch - 131ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0836 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8541 - val_loss: 0.0900 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 104ms/epoch - 104ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0770 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9029 - val_loss: 0.0770 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 190ms/epoch - 190ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0734 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9268 - val_loss: 0.0693 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 159ms/epoch - 159ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0715 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9114 - val_loss: 0.0665 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 200ms/epoch - 200ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0675 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9250 - val_loss: 0.0684 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0622 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9277 - val_loss: 0.0735 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 89ms/epoch - 89ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0592 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9186 - val_loss: 0.0764 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 182ms/epoch - 182ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0575 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9029 - val_loss: 0.0716 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 406ms/epoch - 406ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0540 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9029 - val_loss: 0.0617 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 183ms/epoch - 183ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0499 - accuracy: 0.9603 - precision: 0.9603 - recall: 0.9603 - f1_score: 0.9405 - val_loss: 0.0528 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 132ms/epoch - 132ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0473 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9512 - val_loss: 0.0480 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 105ms/epoch - 105ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0451 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9512 - val_loss: 0.0475 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 89ms/epoch - 89ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0421 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9512 - val_loss: 0.0499 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 151ms/epoch - 151ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0394 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9461 - val_loss: 0.0514 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 166ms/epoch - 166ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0376 - accuracy: 0.9603 - precision: 0.9603 - recall: 0.9603 - f1_score: 0.9405 - val_loss: 0.0478 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 149ms/epoch - 149ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0352 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9461 - val_loss: 0.0412 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 140ms/epoch - 140ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0327 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9576 - val_loss: 0.0359 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 177ms/epoch - 177ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0311 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9571 - val_loss: 0.0337 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 127ms/epoch - 127ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0293 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9689 - val_loss: 0.0339 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0271 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0351 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0256 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9697 - val_loss: 0.0343 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0242 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9759 - val_loss: 0.0307 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9816 - val_loss: 0.0265 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 80ms/epoch - 80ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0210 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9753 - val_loss: 0.0238 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0198 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9753 - val_loss: 0.0230 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0185 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9816 - val_loss: 0.0232 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 84ms/epoch - 84ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0172 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - f1_score: 0.9878 - val_loss: 0.0232 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step

🔍 Resultados no Teste:
Loss: 0.0512
Accuracy: 0.9044
Precision: 0.9044
Recall: 0.9044
F1 Score: 0.8169
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1839 - accuracy: 0.3333 - precision: 0.3333 - recall: 0.3333 - f1_score: 0.4815 - val_loss: 0.2330 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.4930 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1276 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.6667 - 79ms/epoch - 79ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.7579 - precision: 0.7579 - recall: 0.7579 - f1_score: 0.4078 - val_loss: 0.2714 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 77ms/epoch - 77ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2146 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.3085 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 76ms/epoch - 76ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2388 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2482 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 86ms/epoch - 86ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1951 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1869 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 79ms/epoch - 79ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1593 - accuracy: 0.3294 - precision: 0.3294 - recall: 0.3294 - f1_score: 0.4894 - val_loss: 0.1524 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.7111 - 82ms/epoch - 82ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1505 - accuracy: 0.8056 - precision: 0.8056 - recall: 0.8056 - f1_score: 0.7380 - val_loss: 0.1384 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.6154 - 84ms/epoch - 84ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.7421 - precision: 0.7421 - recall: 0.7421 - f1_score: 0.3434 - val_loss: 0.1339 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 78ms/epoch - 78ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.6944 - precision: 0.6944 - recall: 0.6944 - f1_score: 0.0941 - val_loss: 0.1321 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 83ms/epoch - 83ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.0714 - val_loss: 0.1315 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4348 - 81ms/epoch - 81ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.2581 - val_loss: 0.1346 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7879 - 83ms/epoch - 83ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1469 - accuracy: 0.8730 - precision: 0.8730 - recall: 0.8730 - f1_score: 0.7647 - val_loss: 0.1446 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7727 - 80ms/epoch - 80ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.8690 - precision: 0.8690 - recall: 0.8690 - f1_score: 0.8254 - val_loss: 0.1573 - val_accuracy: 0.6508 - val_precision: 0.6508 - val_recall: 0.6508 - val_f1_score: 0.6207 - 81ms/epoch - 81ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1428 - accuracy: 0.6111 - precision: 0.6111 - recall: 0.6111 - f1_score: 0.6231 - val_loss: 0.1641 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5455 - 83ms/epoch - 83ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1435 - accuracy: 0.5317 - precision: 0.5317 - recall: 0.5317 - f1_score: 0.5786 - val_loss: 0.1602 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_recall: 0.5556 - val_f1_score: 0.5625 - 81ms/epoch - 81ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1398 - accuracy: 0.5754 - precision: 0.5754 - recall: 0.5754 - f1_score: 0.6022 - val_loss: 0.1481 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.7200 - 76ms/epoch - 76ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1328 - accuracy: 0.7103 - precision: 0.7103 - recall: 0.7103 - f1_score: 0.6894 - val_loss: 0.1333 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 81ms/epoch - 81ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1262 - accuracy: 0.8730 - precision: 0.8730 - recall: 0.8730 - f1_score: 0.8351 - val_loss: 0.1204 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 82ms/epoch - 82ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1223 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8415 - val_loss: 0.1115 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8649 - 82ms/epoch - 82ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1202 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8322 - val_loss: 0.1063 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8889 - 76ms/epoch - 76ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1168 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8322 - val_loss: 0.1046 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8649 - 81ms/epoch - 81ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1108 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8258 - val_loss: 0.1071 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 79ms/epoch - 79ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1046 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8421 - val_loss: 0.1136 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7826 - 84ms/epoch - 84ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1014 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - f1_score: 0.8421 - val_loss: 0.1182 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 83ms/epoch - 83ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0998 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.8122 - val_loss: 0.1141 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 114ms/epoch - 114ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0958 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.8247 - val_loss: 0.1025 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 125ms/epoch - 125ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0898 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8342 - val_loss: 0.0900 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 114ms/epoch - 114ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0855 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8690 - val_loss: 0.0811 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 98ms/epoch - 98ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0834 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8625 - val_loss: 0.0766 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 103ms/epoch - 103ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0802 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8553 - val_loss: 0.0765 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 177ms/epoch - 177ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0751 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8834 - val_loss: 0.0803 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 176ms/epoch - 176ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0709 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8814 - val_loss: 0.0843 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 179ms/epoch - 179ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0686 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8571 - val_loss: 0.0815 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 170ms/epoch - 170ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0653 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8667 - val_loss: 0.0717 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 136ms/epoch - 136ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0605 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8914 - val_loss: 0.0613 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 94ms/epoch - 94ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0573 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8916 - val_loss: 0.0551 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 95ms/epoch - 95ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0550 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.9012 - val_loss: 0.0540 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 87ms/epoch - 87ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0513 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9146 - val_loss: 0.0567 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 88ms/epoch - 88ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0478 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9123 - val_loss: 0.0588 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 84ms/epoch - 84ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9017 - val_loss: 0.0549 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0428 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9176 - val_loss: 0.0467 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 182ms/epoch - 182ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0396 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9157 - val_loss: 0.0405 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 148ms/epoch - 148ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0376 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9441 - val_loss: 0.0385 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 145ms/epoch - 145ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0351 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9500 - val_loss: 0.0398 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 143ms/epoch - 143ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0323 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9506 - val_loss: 0.0414 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 148ms/epoch - 148ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0305 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9461 - val_loss: 0.0386 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 87ms/epoch - 87ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0283 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9518 - val_loss: 0.0329 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0259 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9689 - val_loss: 0.0288 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0243 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9689 - val_loss: 0.0276 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 81ms/epoch - 81ms/step

🔍 Resultados no Teste:
Loss: 0.0619
Accuracy: 0.8750
Precision: 0.8750
Recall: 0.8750
F1 Score: 0.7536
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1906 - accuracy: 0.3254 - precision: 0.3254 - recall: 0.3254 - f1_score: 0.4880 - val_loss: 0.3277 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.6891 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 80ms/epoch - 80ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2390 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1802 - val_accuracy: 0.3492 - val_precision: 0.3492 - val_recall: 0.3492 - val_f1_score: 0.4675 - 79ms/epoch - 79ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.3849 - precision: 0.3849 - recall: 0.3849 - f1_score: 0.5110 - val_loss: 0.2882 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 79ms/epoch - 79ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2242 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2965 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 75ms/epoch - 75ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2279 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2514 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1955 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2025 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1662 - val_accuracy: 0.5397 - val_precision: 0.5397 - val_recall: 0.5397 - val_f1_score: 0.5538 - 77ms/epoch - 77ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.5913 - precision: 0.5913 - recall: 0.5913 - f1_score: 0.5961 - val_loss: 0.1456 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7500 - 76ms/epoch - 76ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.7857 - precision: 0.7857 - recall: 0.7857 - f1_score: 0.5645 - val_loss: 0.1366 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.4167 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.2737 - val_loss: 0.1324 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4348 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.2174 - val_loss: 0.1317 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.6897 - 82ms/epoch - 82ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.7619 - precision: 0.7619 - recall: 0.7619 - f1_score: 0.4340 - val_loss: 0.1365 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8000 - 80ms/epoch - 80ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1444 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.7338 - val_loss: 0.1493 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.6667 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1387 - accuracy: 0.7659 - precision: 0.7659 - recall: 0.7659 - f1_score: 0.7230 - val_loss: 0.1670 - val_accuracy: 0.5079 - val_precision: 0.5079 - val_recall: 0.5079 - val_f1_score: 0.5373 - 75ms/epoch - 75ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1426 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.5745 - val_loss: 0.1751 - val_accuracy: 0.4444 - val_precision: 0.4444 - val_recall: 0.4444 - val_f1_score: 0.5070 - 76ms/epoch - 76ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1450 - accuracy: 0.4405 - precision: 0.4405 - recall: 0.4405 - f1_score: 0.5347 - val_loss: 0.1664 - val_accuracy: 0.5079 - val_precision: 0.5079 - val_recall: 0.5079 - val_f1_score: 0.5373 - 77ms/epoch - 77ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1392 - accuracy: 0.5397 - precision: 0.5397 - recall: 0.5397 - f1_score: 0.5827 - val_loss: 0.1479 - val_accuracy: 0.6825 - val_precision: 0.6825 - val_recall: 0.6825 - val_f1_score: 0.6429 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1297 - accuracy: 0.7063 - precision: 0.7063 - recall: 0.7063 - f1_score: 0.6810 - val_loss: 0.1296 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7727 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1234 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - f1_score: 0.8315 - val_loss: 0.1168 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8889 - 80ms/epoch - 80ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1222 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8188 - val_loss: 0.1095 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1219 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.7943 - val_loss: 0.1059 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1181 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8085 - val_loss: 0.1057 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8889 - 77ms/epoch - 77ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1111 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8267 - val_loss: 0.1097 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1049 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8736 - val_loss: 0.1165 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 78ms/epoch - 78ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1020 - accuracy: 0.8730 - precision: 0.8730 - recall: 0.8730 - f1_score: 0.8316 - val_loss: 0.1215 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7500 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1008 - accuracy: 0.8254 - precision: 0.8254 - recall: 0.8254 - f1_score: 0.7822 - val_loss: 0.1194 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7500 - 75ms/epoch - 75ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0976 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.7783 - val_loss: 0.1097 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 77ms/epoch - 77ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0919 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8360 - val_loss: 0.0970 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0865 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8764 - val_loss: 0.0863 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0837 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8902 - val_loss: 0.0797 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8889 - 76ms/epoch - 76ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0817 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.8961 - val_loss: 0.0768 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 77ms/epoch - 77ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0779 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.8961 - val_loss: 0.0776 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 78ms/epoch - 78ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0729 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9231 - val_loss: 0.0814 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0694 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8927 - val_loss: 0.0847 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0674 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8681 - val_loss: 0.0825 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 76ms/epoch - 76ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0645 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8681 - val_loss: 0.0743 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0602 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8927 - val_loss: 0.0644 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 75ms/epoch - 75ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0567 - accuracy: 0.9603 - precision: 0.9603 - recall: 0.9603 - f1_score: 0.9405 - val_loss: 0.0573 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 81ms/epoch - 81ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0547 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9500 - val_loss: 0.0539 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 93ms/epoch - 93ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0521 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9565 - val_loss: 0.0540 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0484 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9565 - val_loss: 0.0564 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 103ms/epoch - 103ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0456 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9518 - val_loss: 0.0579 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 77ms/epoch - 77ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0439 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9349 - val_loss: 0.0549 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 76ms/epoch - 76ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0414 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9461 - val_loss: 0.0484 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0384 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0423 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0364 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9565 - val_loss: 0.0388 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 80ms/epoch - 80ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9625 - val_loss: 0.0381 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0323 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9625 - val_loss: 0.0392 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0302 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9753 - val_loss: 0.0401 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 80ms/epoch - 80ms/step

🔍 Resultados no Teste:
Loss: 0.0631
Accuracy: 0.8750
Precision: 0.8750
Recall: 0.8750
F1 Score: 0.7733
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1997 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2630 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.5465 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 116ms/epoch - 116ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1856 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.2259 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 113ms/epoch - 113ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1845 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2826 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 95ms/epoch - 95ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2210 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2535 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 152ms/epoch - 152ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1991 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2038 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 90ms/epoch - 90ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1682 - val_accuracy: 0.6032 - val_precision: 0.6032 - val_recall: 0.6032 - val_f1_score: 0.5902 - 99ms/epoch - 99ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.5992 - precision: 0.5992 - recall: 0.5992 - f1_score: 0.5844 - val_loss: 0.1509 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.5000 - 93ms/epoch - 93ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.7302 - precision: 0.7302 - recall: 0.7302 - f1_score: 0.3929 - val_loss: 0.1446 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.4167 - 88ms/epoch - 88ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.7183 - precision: 0.7183 - recall: 0.7183 - f1_score: 0.2680 - val_loss: 0.1420 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4800 - 171ms/epoch - 171ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.7460 - precision: 0.7460 - recall: 0.7460 - f1_score: 0.3846 - val_loss: 0.1438 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7368 - 224ms/epoch - 224ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1526 - accuracy: 0.8056 - precision: 0.8056 - recall: 0.8056 - f1_score: 0.6370 - val_loss: 0.1528 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.6800 - 204ms/epoch - 204ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1440 - accuracy: 0.7421 - precision: 0.7421 - recall: 0.7421 - f1_score: 0.6919 - val_loss: 0.1678 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.5000 - 154ms/epoch - 154ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1446 - accuracy: 0.5437 - precision: 0.5437 - recall: 0.5437 - f1_score: 0.5848 - val_loss: 0.1786 - val_accuracy: 0.3968 - val_precision: 0.3968 - val_recall: 0.3968 - val_f1_score: 0.4865 - 163ms/epoch - 163ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1477 - accuracy: 0.4524 - precision: 0.4524 - recall: 0.4524 - f1_score: 0.5400 - val_loss: 0.1771 - val_accuracy: 0.3968 - val_precision: 0.3968 - val_recall: 0.3968 - val_f1_score: 0.4865 - 143ms/epoch - 143ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1458 - accuracy: 0.4643 - precision: 0.4643 - recall: 0.4643 - f1_score: 0.5455 - val_loss: 0.1647 - val_accuracy: 0.5079 - val_precision: 0.5079 - val_recall: 0.5079 - val_f1_score: 0.5373 - 106ms/epoch - 106ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1387 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.5870 - val_loss: 0.1473 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.6667 - 80ms/epoch - 80ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1309 - accuracy: 0.7302 - precision: 0.7302 - recall: 0.7302 - f1_score: 0.7018 - val_loss: 0.1313 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1264 - accuracy: 0.8492 - precision: 0.8492 - recall: 0.8492 - f1_score: 0.7935 - val_loss: 0.1201 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8500 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1248 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - f1_score: 0.7722 - val_loss: 0.1140 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8205 - 83ms/epoch - 83ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1222 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.7919 - val_loss: 0.1123 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8500 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1164 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.7848 - val_loss: 0.1155 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 78ms/epoch - 78ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1099 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8249 - val_loss: 0.1210 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 81ms/epoch - 81ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1060 - accuracy: 0.8413 - precision: 0.8413 - recall: 0.8413 - f1_score: 0.7980 - val_loss: 0.1227 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.7347 - 78ms/epoch - 78ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1029 - accuracy: 0.8175 - precision: 0.8175 - recall: 0.8175 - f1_score: 0.7767 - val_loss: 0.1156 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 79ms/epoch - 79ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0973 - accuracy: 0.8373 - precision: 0.8373 - recall: 0.8373 - f1_score: 0.7960 - val_loss: 0.1022 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 81ms/epoch - 81ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0907 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8449 - val_loss: 0.0891 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0862 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8324 - val_loss: 0.0808 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 80ms/epoch - 80ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0829 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8402 - val_loss: 0.0781 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0781 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8421 - val_loss: 0.0805 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0732 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8539 - val_loss: 0.0842 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 79ms/epoch - 79ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0705 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8541 - val_loss: 0.0823 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 81ms/epoch - 81ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0674 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8541 - val_loss: 0.0733 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 76ms/epoch - 76ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0630 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8603 - val_loss: 0.0634 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 83ms/epoch - 83ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0601 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8772 - val_loss: 0.0582 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 75ms/epoch - 75ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0577 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8876 - val_loss: 0.0585 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 86ms/epoch - 86ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0539 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8902 - val_loss: 0.0621 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 96ms/epoch - 96ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0510 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8715 - val_loss: 0.0629 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 85ms/epoch - 85ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0489 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8715 - val_loss: 0.0568 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 86ms/epoch - 86ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0457 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8914 - val_loss: 0.0485 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 104ms/epoch - 104ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0430 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9123 - val_loss: 0.0441 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 76ms/epoch - 76ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0410 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9231 - val_loss: 0.0444 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 84ms/epoch - 84ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0380 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9231 - val_loss: 0.0467 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 80ms/epoch - 80ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0358 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9123 - val_loss: 0.0455 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 76ms/epoch - 76ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0337 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9186 - val_loss: 0.0397 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0310 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9294 - val_loss: 0.0344 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 80ms/epoch - 80ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0292 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9512 - val_loss: 0.0324 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 93ms/epoch - 93ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0271 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0332 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 105ms/epoch - 105ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0249 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9576 - val_loss: 0.0335 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0233 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9581 - val_loss: 0.0306 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0769
Accuracy: 0.8824
Precision: 0.8824
Recall: 0.8824
F1 Score: 0.7838
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1838 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4834 - val_loss: 0.2823 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.5931 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1308 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 76ms/epoch - 76ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2015 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.2087 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 78ms/epoch - 78ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1735 - accuracy: 0.3294 - precision: 0.3294 - recall: 0.3294 - f1_score: 0.4894 - val_loss: 0.3010 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 75ms/epoch - 75ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2326 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2632 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 90ms/epoch - 90ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2033 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1870 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4615 - 120ms/epoch - 120ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.3452 - precision: 0.3452 - recall: 0.3452 - f1_score: 0.4954 - val_loss: 0.1408 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8205 - 126ms/epoch - 126ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1513 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.6715 - val_loss: 0.1293 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.2857 - 111ms/epoch - 111ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1714 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.2174 - val_loss: 0.1279 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.2000 - 78ms/epoch - 78ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1767 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.2000 - val_loss: 0.1267 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4348 - 97ms/epoch - 97ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.7302 - precision: 0.7302 - recall: 0.7302 - f1_score: 0.3061 - val_loss: 0.1300 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8108 - 88ms/epoch - 88ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1431 - accuracy: 0.8333 - precision: 0.8333 - recall: 0.8333 - f1_score: 0.6719 - val_loss: 0.1442 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 77ms/epoch - 77ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1333 - accuracy: 0.8056 - precision: 0.8056 - recall: 0.8056 - f1_score: 0.7538 - val_loss: 0.1669 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5455 - 92ms/epoch - 92ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1374 - accuracy: 0.5635 - precision: 0.5635 - recall: 0.5635 - f1_score: 0.5956 - val_loss: 0.1824 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.4800 - 82ms/epoch - 82ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1435 - accuracy: 0.4008 - precision: 0.4008 - recall: 0.4008 - f1_score: 0.5176 - val_loss: 0.1782 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.5000 - 91ms/epoch - 91ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1400 - accuracy: 0.4563 - precision: 0.4563 - recall: 0.4563 - f1_score: 0.5418 - val_loss: 0.1586 - val_accuracy: 0.5873 - val_precision: 0.5873 - val_recall: 0.5873 - val_f1_score: 0.5806 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1289 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.6429 - val_loss: 0.1359 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 89ms/epoch - 89ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1192 - accuracy: 0.8095 - precision: 0.8095 - recall: 0.8095 - f1_score: 0.7670 - val_loss: 0.1186 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 95ms/epoch - 95ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1159 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8571 - val_loss: 0.1083 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8421 - 83ms/epoch - 83ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1163 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - f1_score: 0.8082 - val_loss: 0.1026 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8649 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1143 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.7972 - val_loss: 0.1007 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 92ms/epoch - 92ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1074 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8400 - val_loss: 0.1038 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 112ms/epoch - 112ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0993 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8690 - val_loss: 0.1129 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 149ms/epoch - 149ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0954 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8360 - val_loss: 0.1232 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.7200 - 110ms/epoch - 110ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0959 - accuracy: 0.8135 - precision: 0.8135 - recall: 0.8135 - f1_score: 0.7751 - val_loss: 0.1198 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.7347 - 156ms/epoch - 156ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0922 - accuracy: 0.8254 - precision: 0.8254 - recall: 0.8254 - f1_score: 0.7864 - val_loss: 0.1040 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 135ms/epoch - 135ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0844 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8449 - val_loss: 0.0872 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 125ms/epoch - 125ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0792 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8772 - val_loss: 0.0761 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 87ms/epoch - 87ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0777 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8820 - val_loss: 0.0708 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 95ms/epoch - 95ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0744 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8861 - val_loss: 0.0713 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 84ms/epoch - 84ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0680 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8848 - val_loss: 0.0779 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 161ms/epoch - 161ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0641 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8764 - val_loss: 0.0833 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 81ms/epoch - 81ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0633 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8696 - val_loss: 0.0768 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 103ms/epoch - 103ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0592 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8791 - val_loss: 0.0633 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 97ms/epoch - 97ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0542 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9006 - val_loss: 0.0532 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 110ms/epoch - 110ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0526 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9193 - val_loss: 0.0490 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 113ms/epoch - 113ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0503 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9250 - val_loss: 0.0498 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 226ms/epoch - 226ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9325 - val_loss: 0.0543 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 297ms/epoch - 297ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0431 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9186 - val_loss: 0.0558 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 201ms/epoch - 201ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0417 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9257 - val_loss: 0.0491 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 176ms/epoch - 176ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0381 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9467 - val_loss: 0.0398 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 201ms/epoch - 201ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0351 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9512 - val_loss: 0.0340 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 149ms/epoch - 149ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0338 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9625 - val_loss: 0.0324 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 151ms/epoch - 151ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0312 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9625 - val_loss: 0.0339 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0284 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9756 - val_loss: 0.0357 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0271 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9701 - val_loss: 0.0331 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0251 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9759 - val_loss: 0.0273 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 97ms/epoch - 97ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0227 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - f1_score: 0.9878 - val_loss: 0.0229 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 98ms/epoch - 98ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0214 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9753 - val_loss: 0.0211 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 109ms/epoch - 109ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0199 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9816 - val_loss: 0.0212 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 103ms/epoch - 103ms/step

🔍 Resultados no Teste:
Loss: 0.0548
Accuracy: 0.9044
Precision: 0.9044
Recall: 0.9044
F1 Score: 0.8169
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1722 - accuracy: 0.4722 - precision: 0.4722 - recall: 0.4722 - f1_score: 0.5233 - val_loss: 0.1657 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3253 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7660 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1321 - accuracy: 0.8095 - precision: 0.8095 - recall: 0.8095 - f1_score: 0.7647 - val_loss: 0.3051 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 82ms/epoch - 82ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2348 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2426 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 77ms/epoch - 77ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1842 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1588 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714 - 79ms/epoch - 79ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1332 - accuracy: 0.6349 - precision: 0.6349 - recall: 0.6349 - f1_score: 0.6378 - val_loss: 0.1224 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 77ms/epoch - 77ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1320 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.7606 - val_loss: 0.1141 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.5600 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1461 - accuracy: 0.7659 - precision: 0.7659 - recall: 0.7659 - f1_score: 0.4272 - val_loss: 0.1120 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.4348 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1462 - accuracy: 0.7579 - precision: 0.7579 - recall: 0.7579 - f1_score: 0.3960 - val_loss: 0.1118 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7586 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1338 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.6218 - val_loss: 0.1165 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8571 - 86ms/epoch - 86ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1210 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8312 - val_loss: 0.1283 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 131ms/epoch - 131ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1158 - accuracy: 0.8730 - precision: 0.8730 - recall: 0.8730 - f1_score: 0.8333 - val_loss: 0.1412 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.6667 - 117ms/epoch - 117ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1169 - accuracy: 0.7421 - precision: 0.7421 - recall: 0.7421 - f1_score: 0.7137 - val_loss: 0.1436 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.6316 - 167ms/epoch - 167ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1155 - accuracy: 0.7063 - precision: 0.7063 - recall: 0.7063 - f1_score: 0.6864 - val_loss: 0.1326 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.6923 - 186ms/epoch - 186ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1081 - accuracy: 0.7738 - precision: 0.7738 - recall: 0.7738 - f1_score: 0.7397 - val_loss: 0.1151 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 159ms/epoch - 159ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0995 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8757 - val_loss: 0.0992 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 131ms/epoch - 131ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0945 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9146 - val_loss: 0.0888 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 138ms/epoch - 138ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0927 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.8889 - val_loss: 0.0834 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 192ms/epoch - 192ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0889 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.8933 - val_loss: 0.0818 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 303ms/epoch - 303ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0820 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9114 - val_loss: 0.0846 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 130ms/epoch - 130ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0755 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9102 - val_loss: 0.0902 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 110ms/epoch - 110ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0722 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.9000 - val_loss: 0.0930 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 123ms/epoch - 123ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0699 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8950 - val_loss: 0.0879 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 101ms/epoch - 101ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0654 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8950 - val_loss: 0.0765 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 222ms/epoch - 222ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0594 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9249 - val_loss: 0.0648 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 139ms/epoch - 139ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0552 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9212 - val_loss: 0.0569 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 143ms/epoch - 143ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0528 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9325 - val_loss: 0.0535 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 142ms/epoch - 142ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0492 - accuracy: 0.9603 - precision: 0.9603 - recall: 0.9603 - f1_score: 0.9383 - val_loss: 0.0543 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 142ms/epoch - 142ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0445 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9518 - val_loss: 0.0585 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0411 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9467 - val_loss: 0.0613 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 76ms/epoch - 76ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0392 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9302 - val_loss: 0.0578 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9231 - 83ms/epoch - 83ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0361 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9467 - val_loss: 0.0497 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0324 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9581 - val_loss: 0.0421 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0301 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0380 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 75ms/epoch - 75ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0371 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 81ms/epoch - 81ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0255 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1_score: 0.9693 - val_loss: 0.0388 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 86ms/epoch - 86ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0229 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9756 - val_loss: 0.0408 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0214 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9759 - val_loss: 0.0390 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 76ms/epoch - 76ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0197 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9759 - val_loss: 0.0338 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 74ms/epoch - 74ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9818 - val_loss: 0.0289 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 82ms/epoch - 82ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0160 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9816 - val_loss: 0.0261 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0149 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9938 - val_loss: 0.0252 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 82ms/epoch - 82ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0133 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 86ms/epoch - 86ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0119 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0111 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9939 - val_loss: 0.0243 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 85ms/epoch - 85ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0101 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0089 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0081 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9444 - 76ms/epoch - 76ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9444 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0067 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9444 - 82ms/epoch - 82ms/step

🔍 Resultados no Teste:
Loss: 0.0396
Accuracy: 0.9265
Precision: 0.9265
Recall: 0.9265
F1 Score: 0.8571
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2023 - accuracy: 0.3452 - precision: 0.3452 - recall: 0.3452 - f1_score: 0.4860 - val_loss: 0.3364 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.7159 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.1357 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1976 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.2787 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 80ms/epoch - 80ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2180 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.3360 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 80ms/epoch - 80ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2590 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.2641 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.4444 - 84ms/epoch - 84ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2032 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4865 - val_loss: 0.1913 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4615 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1575 - accuracy: 0.3810 - precision: 0.3810 - recall: 0.3810 - f1_score: 0.5094 - val_loss: 0.1537 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.6818 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1487 - accuracy: 0.7897 - precision: 0.7897 - recall: 0.7897 - f1_score: 0.7104 - val_loss: 0.1413 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.3478 - 80ms/epoch - 80ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.7341 - precision: 0.7341 - recall: 0.7341 - f1_score: 0.3366 - val_loss: 0.1389 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.2000 - 76ms/epoch - 76ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.6984 - precision: 0.6984 - recall: 0.6984 - f1_score: 0.1364 - val_loss: 0.1382 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.1053 - 80ms/epoch - 80ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.6984 - precision: 0.6984 - recall: 0.6984 - f1_score: 0.1364 - val_loss: 0.1379 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.2000 - 78ms/epoch - 78ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.2174 - val_loss: 0.1390 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.4167 - 83ms/epoch - 83ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1552 - accuracy: 0.7579 - precision: 0.7579 - recall: 0.7579 - f1_score: 0.4190 - val_loss: 0.1426 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7059 - 78ms/epoch - 78ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1470 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - f1_score: 0.7465 - val_loss: 0.1491 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 79ms/epoch - 79ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.8021 - val_loss: 0.1574 - val_accuracy: 0.6825 - val_precision: 0.6825 - val_recall: 0.6825 - val_f1_score: 0.6429 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1408 - accuracy: 0.6865 - precision: 0.6865 - recall: 0.6865 - f1_score: 0.6695 - val_loss: 0.1658 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.5217 - 80ms/epoch - 80ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1421 - accuracy: 0.5516 - precision: 0.5516 - recall: 0.5516 - f1_score: 0.5891 - val_loss: 0.1713 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.5000 - 80ms/epoch - 80ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1434 - accuracy: 0.4841 - precision: 0.4841 - recall: 0.4841 - f1_score: 0.5548 - val_loss: 0.1715 - val_accuracy: 0.4127 - val_precision: 0.4127 - val_recall: 0.4127 - val_f1_score: 0.4932 - 81ms/epoch - 81ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1424 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.5567 - val_loss: 0.1660 - val_accuracy: 0.4921 - val_precision: 0.4921 - val_recall: 0.4921 - val_f1_score: 0.5294 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1385 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.5870 - val_loss: 0.1563 - val_accuracy: 0.6349 - val_precision: 0.6349 - val_recall: 0.6349 - val_f1_score: 0.6102 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1328 - accuracy: 0.6508 - precision: 0.6508 - recall: 0.6508 - f1_score: 0.6480 - val_loss: 0.1449 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.7059 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1270 - accuracy: 0.7579 - precision: 0.7579 - recall: 0.7579 - f1_score: 0.7240 - val_loss: 0.1340 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1226 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - f1_score: 0.8144 - val_loss: 0.1247 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1200 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8452 - val_loss: 0.1178 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1181 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8280 - val_loss: 0.1130 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 76ms/epoch - 76ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1156 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8312 - val_loss: 0.1100 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 86ms/epoch - 86ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1117 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8333 - val_loss: 0.1091 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8500 - 85ms/epoch - 85ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1069 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8466 - val_loss: 0.1103 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 76ms/epoch - 76ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1023 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - f1_score: 0.8439 - val_loss: 0.1129 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 83ms/epoch - 83ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0990 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - f1_score: 0.8511 - val_loss: 0.1149 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0967 - accuracy: 0.8611 - precision: 0.8611 - recall: 0.8611 - f1_score: 0.8205 - val_loss: 0.1139 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 77ms/epoch - 77ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0939 - accuracy: 0.8492 - precision: 0.8492 - recall: 0.8492 - f1_score: 0.8081 - val_loss: 0.1088 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 79ms/epoch - 79ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0898 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.8247 - val_loss: 0.1006 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 84ms/epoch - 84ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0850 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8743 - val_loss: 0.0919 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 81ms/epoch - 81ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0811 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8814 - val_loss: 0.0849 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0782 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8929 - val_loss: 0.0799 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 80ms/epoch - 80ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0754 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8727 - val_loss: 0.0769 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 80ms/epoch - 80ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0717 - accuracy: 0.9206 - precision: 0.9206 - recall: 0.9206 - f1_score: 0.8795 - val_loss: 0.0762 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 78ms/epoch - 78ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0676 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9186 - val_loss: 0.0770 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 76ms/epoch - 76ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0643 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9143 - val_loss: 0.0763 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8372 - 79ms/epoch - 79ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0612 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8989 - val_loss: 0.0726 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0577 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.9040 - val_loss: 0.0662 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.9000 - 80ms/epoch - 80ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0540 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444 - f1_score: 0.9195 - val_loss: 0.0605 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 83ms/epoch - 83ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0511 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9302 - val_loss: 0.0560 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 76ms/epoch - 76ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0485 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9349 - val_loss: 0.0533 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0456 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9524 - val_loss: 0.0516 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0424 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9524 - val_loss: 0.0507 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 90ms/epoch - 90ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0396 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9524 - val_loss: 0.0495 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 90ms/epoch - 90ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0373 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9524 - val_loss: 0.0464 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 85ms/epoch - 85ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9581 - val_loss: 0.0417 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 100ms/epoch - 100ms/step

🔍 Resultados no Teste:
Loss: 0.0606
Accuracy: 0.9044
Precision: 0.9044
Recall: 0.9044
F1 Score: 0.8169
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2046 - accuracy: 0.2460 - precision: 0.2460 - recall: 0.2460 - f1_score: 0.2213 - val_loss: 0.1751 - val_accuracy: 0.5079 - val_precision: 0.5079 - val_recall: 0.5079 - val_f1_score: 0.4918 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6111 - precision: 0.6111 - recall: 0.6111 - f1_score: 0.6142 - val_loss: 0.1328 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2068 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0000e+00 - val_loss: 0.2003 - val_accuracy: 0.4127 - val_precision: 0.4127 - val_recall: 0.4127 - val_f1_score: 0.4932 - 77ms/epoch - 77ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1485 - accuracy: 0.4683 - precision: 0.4683 - recall: 0.4683 - f1_score: 0.5473 - val_loss: 0.2182 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4615 - 78ms/epoch - 78ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.4008 - precision: 0.4008 - recall: 0.4008 - f1_score: 0.5176 - val_loss: 0.1413 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.6792 - 80ms/epoch - 80ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1202 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.7761 - val_loss: 0.1130 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7879 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1282 - accuracy: 0.8413 - precision: 0.8413 - recall: 0.8413 - f1_score: 0.6875 - val_loss: 0.1072 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7500 - 81ms/epoch - 81ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1272 - accuracy: 0.8373 - precision: 0.8373 - recall: 0.8373 - f1_score: 0.6772 - val_loss: 0.1096 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 77ms/epoch - 77ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1099 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8153 - val_loss: 0.1282 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.7347 - 79ms/epoch - 79ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1034 - accuracy: 0.8413 - precision: 0.8413 - recall: 0.8413 - f1_score: 0.7980 - val_loss: 0.1434 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.6667 - 77ms/epoch - 77ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1055 - accuracy: 0.7619 - precision: 0.7619 - recall: 0.7619 - f1_score: 0.7297 - val_loss: 0.1248 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.7200 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0945 - accuracy: 0.8373 - precision: 0.8373 - recall: 0.8373 - f1_score: 0.7980 - val_loss: 0.0945 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 85ms/epoch - 85ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0834 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8750 - val_loss: 0.0770 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 79ms/epoch - 79ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0824 - accuracy: 0.9206 - precision: 0.9206 - recall: 0.9206 - f1_score: 0.8684 - val_loss: 0.0708 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 78ms/epoch - 78ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0751 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.8903 - val_loss: 0.0769 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0647 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8902 - val_loss: 0.0908 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 84ms/epoch - 84ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0647 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - f1_score: 0.8421 - val_loss: 0.0796 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8182 - 77ms/epoch - 77ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0578 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8696 - val_loss: 0.0563 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 79ms/epoch - 79ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0510 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9333 - val_loss: 0.0457 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 84ms/epoch - 84ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0511 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9231 - val_loss: 0.0468 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0435 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9448 - val_loss: 0.0578 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 79ms/epoch - 79ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0406 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.9091 - val_loss: 0.0587 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8571 - 84ms/epoch - 84ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0388 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8939 - val_loss: 0.0425 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0324 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9576 - val_loss: 0.0309 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 78ms/epoch - 78ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0317 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9630 - val_loss: 0.0290 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9630 - val_loss: 0.0347 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0244 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9756 - val_loss: 0.0389 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0240 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9643 - val_loss: 0.0306 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0200 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9818 - val_loss: 0.0216 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 81ms/epoch - 81ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0183 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - f1_score: 0.9753 - val_loss: 0.0188 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0172 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9814 - val_loss: 0.0208 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 81ms/epoch - 81ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0142 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9939 - val_loss: 0.0246 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0138 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - f1_score: 0.9878 - val_loss: 0.0207 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0118 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - f1_score: 0.9939 - val_loss: 0.0151 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 76ms/epoch - 76ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0103 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 86ms/epoch - 86ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0099 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 79ms/epoch - 79ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 79ms/epoch - 79ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0071 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9841 - val_precision: 0.9841 - val_recall: 0.9841 - val_f1_score: 0.9730 - 77ms/epoch - 77ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 76ms/epoch - 76ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 76ms/epoch - 76ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 77ms/epoch - 77ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0045 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 75ms/epoch - 75ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 73ms/epoch - 73ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0035 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 77ms/epoch - 77ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0031 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 80ms/epoch - 80ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 82ms/epoch - 82ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 81ms/epoch - 81ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 79ms/epoch - 79ms/step

🔍 Resultados no Teste:
Loss: 0.0329
Accuracy: 0.9559
Precision: 0.9559
Recall: 0.9559
F1 Score: 0.9091
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.9817106  0.01828947]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 481 | Acuracia_1: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_1: 0.0 
Precisao modelo Geral: 66.1157
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
481 481 481
(452, 30) (452, 30) (452, 30)
(452, 90) (452, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9894643  0.01053574]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 482 | Acuracia_2: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_2: 0.0 
Precisao modelo Geral: 66.3934
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
482 482 482
(453, 30) (453, 30) (453, 30)
(453, 90) (453, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9148256  0.08517437]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 483 | Acuracia_3: 0 | Contagem Geral: 20.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_3: 0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
483 483 483
(454, 30) (454, 30) (454, 30)
(454, 90) (454, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6462028 0.3537972]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 484 | Acuracia_4: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_4: 0.0 
Precisao modelo Geral: 66.129
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
484 484 484
(455, 30) (455, 30) (455, 30)
(455, 90) (455, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9767196  0.02328046]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 485 | Acuracia_5: 0 | Contagem Geral: 21.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_5: 0 
Precisao modelo Geral: 66.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
485 485 485
(456, 30) (456, 30) (456, 30)
(456, 90) (456, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9930011 0.0069989]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 486 | Acuracia_6: 1.0 | Contagem Geral: 21.0 
Ordem Natural: 31.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_6: 1.0 
Precisao modelo Geral: 65.873
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
486 486 486
(457, 30) (457, 30) (457, 30)
(457, 90) (457, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95968604 0.040314  ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 487 | Acuracia_7: 0.5 | Contagem Geral: 21.0 
Ordem Natural: 32.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_7: 0.5 
Precisao modelo Geral: 66.1417
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
487 487 487
(458, 30) (458, 30) (458, 30)
(458, 90) (458, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.91338456 0.08661544]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 488 | Acuracia_8: 0 | Contagem Geral: 21.0 
Ordem Natural: 32.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_8: 0 
Precisao modelo Geral: 65.625
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
488 488 488
(459, 30) (459, 30) (459, 30)
(459, 90) (459, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.84409195 0.15590806]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 489 | Acuracia_9: 0 | Contagem Geral: 21.0 
Ordem Natural: 33.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_9: 0 
Precisao modelo Geral: 65.1163
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
489 489 489
(460, 30) (460, 30) (460, 30)
(460, 90) (460, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98183316 0.01816683]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 490 | Acuracia_10: 0.0 | Contagem Geral: 21.0 
Ordem Natural: 34.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_10: 0.0 
Precisao modelo Geral: 65.3846
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
490 490 490
(461, 30) (461, 30) (461, 30)
(461, 90) (461, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9670252  0.03297477]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 491 | Acuracia_11: 0 | Contagem Geral: 21.0 
Ordem Natural: 34.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_11: 0 
Precisao modelo Geral: 64.8855
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
491 491 491
(462, 30) (462, 30) (462, 30)
(462, 90) (462, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89853764 0.10146235]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 492 | Acuracia_12: 0.0 | Contagem Geral: 21.0 
Ordem Natural: 35.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_12: 0.0 
Precisao modelo Geral: 64.3939
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
492 492 492
(463, 30) (463, 30) (463, 30)
(463, 90) (463, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9902636  0.00973638]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 493 | Acuracia_13: 0.0 | Contagem Geral: 21.0 
Ordem Natural: 36.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_13: 0.0 
Precisao modelo Geral: 63.9098
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
493 493 493
(464, 30) (464, 30) (464, 30)
(464, 90) (464, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9917611 0.0082389]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 494 | Acuracia_14: 0 | Contagem Geral: 21.0 
Ordem Natural: 37.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_14: 0 
Precisao modelo Geral: 64.1791
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
494 494 494
(465, 30) (465, 30) (465, 30)
(465, 90) (465, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95294565 0.04705438]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 495 | Acuracia_15: 0 | Contagem Geral: 21.0 
Ordem Natural: 37.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_15: 0 
Precisao modelo Geral: 64.4444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
495 495 495
(466, 30) (466, 30) (466, 30)
(466, 90) (466, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6968131 0.3031869]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 496 | Acuracia_16: 0.0 | Contagem Geral: 21.0 
Ordem Natural: 37.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_16: 0.0 
Precisao modelo Geral: 63.9706
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
496 496 496
(467, 30) (467, 30) (467, 30)
(467, 90) (467, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7820564  0.21794364]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 497 | Acuracia_17: 0.0 | Contagem Geral: 22.0 
Ordem Natural: 37.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.087 | Acuracia_17: 0.25 
Precisao modelo Geral: 64.2336
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
497 497 497
(468, 30) (468, 30) (468, 30)
(468, 90) (468, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98437226 0.01562766]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 498 | Acuracia_18: 1.0 | Contagem Geral: 23.0 
Ordem Natural: 38.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.087 | Acuracia_18: 1.0 
Precisao modelo Geral: 64.4928
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
498 498 498
(469, 30) (469, 30) (469, 30)
(469, 90) (469, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.966697   0.03330299]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 499 | Acuracia_19: 0 | Contagem Geral: 23.0 
Ordem Natural: 38.0
Entrada -> /home/darkcover/.pyenv/versions/3.10.17/lib/python3.10/tkinter/__init__.py:839: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  func(*args)
📈 Histórico de desempenho salvo em 'historico_janelas.csv'
