/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
Insera a entrada até onde o modelo deve ser carregado --> ------------------------------------------------------------------------
Número da Entrada - 0 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 1 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 2 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 24.83
------------------------------------------------------------------------
Número da Entrada - 3 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.25
------------------------------------------------------------------------
Número da Entrada - 4 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.55
------------------------------------------------------------------------
Número da Entrada - 5 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 6 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.52
------------------------------------------------------------------------
Número da Entrada - 7 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 8 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.57
------------------------------------------------------------------------
Número da Entrada - 9 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 10 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 11 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.16
------------------------------------------------------------------------
Número da Entrada - 12 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 13 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 14 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 15 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 16 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.88
------------------------------------------------------------------------
Número da Entrada - 17 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 18 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 19 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 20 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.8
------------------------------------------------------------------------
Número da Entrada - 21 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.48
------------------------------------------------------------------------
Número da Entrada - 22 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 23 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 24 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 25 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 26 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.5
------------------------------------------------------------------------
Número da Entrada - 27 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.32
------------------------------------------------------------------------
Número da Entrada - 28 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 29 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.45
------------------------------------------------------------------------
Número da Entrada - 30 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.95
------------------------------------------------------------------------
Número da Entrada - 31 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.7
------------------------------------------------------------------------
Número da Entrada - 32 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.78
------------------------------------------------------------------------
Número da Entrada - 33 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 34 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.04
------------------------------------------------------------------------
Número da Entrada - 35 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 36 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 37 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 38 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 39 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 40 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.44
------------------------------------------------------------------------
Número da Entrada - 41 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 42 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 43 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 44 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 45 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 46 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 47 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.96
------------------------------------------------------------------------
Número da Entrada - 48 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.21
------------------------------------------------------------------------
Número da Entrada - 49 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.19
------------------------------------------------------------------------
Número da Entrada - 50 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.51
------------------------------------------------------------------------
Número da Entrada - 51 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 52 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 53 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 54 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 55 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 56 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 57 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 58 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 59 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.79
------------------------------------------------------------------------
Número da Entrada - 60 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.18
------------------------------------------------------------------------
Número da Entrada - 61 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.79
------------------------------------------------------------------------
Número da Entrada - 62 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.75
------------------------------------------------------------------------
Número da Entrada - 63 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.8
------------------------------------------------------------------------
Número da Entrada - 64 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 65 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 66 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.47
------------------------------------------------------------------------
Número da Entrada - 67 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 68 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.93
------------------------------------------------------------------------
Número da Entrada - 69 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.55
------------------------------------------------------------------------
Número da Entrada - 70 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 71 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.54
------------------------------------------------------------------------
Número da Entrada - 72 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.13
------------------------------------------------------------------------
Número da Entrada - 73 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.2
------------------------------------------------------------------------
Número da Entrada - 74 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 75 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.95
------------------------------------------------------------------------
Número da Entrada - 76 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 77 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.84
------------------------------------------------------------------------
Número da Entrada - 78 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.73
------------------------------------------------------------------------
Número da Entrada - 79 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.87
------------------------------------------------------------------------
Número da Entrada - 80 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 81 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.07
------------------------------------------------------------------------
Número da Entrada - 82 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 83 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 84 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.17
------------------------------------------------------------------------
Número da Entrada - 85 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 86 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 87 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.8
------------------------------------------------------------------------
Número da Entrada - 88 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 89 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 93.91
------------------------------------------------------------------------
Número da Entrada - 90 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.17
------------------------------------------------------------------------
Número da Entrada - 91 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 92 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 93 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.29
------------------------------------------------------------------------
Número da Entrada - 94 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.85
------------------------------------------------------------------------
Número da Entrada - 95 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 547.44
------------------------------------------------------------------------
Número da Entrada - 96 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.5
------------------------------------------------------------------------
Número da Entrada - 97 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 98 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 99 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.76
------------------------------------------------------------------------
Número da Entrada - 100 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 101 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.49
------------------------------------------------------------------------
Número da Entrada - 102 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 103 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.64
------------------------------------------------------------------------
Número da Entrada - 104 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.51
------------------------------------------------------------------------
Número da Entrada - 105 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 106 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.96
------------------------------------------------------------------------
Número da Entrada - 107 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 108 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.51
------------------------------------------------------------------------
Número da Entrada - 109 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 21.63
------------------------------------------------------------------------
Número da Entrada - 110 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 27.5
------------------------------------------------------------------------
Número da Entrada - 111 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 112 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 29.87
------------------------------------------------------------------------
Número da Entrada - 113 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.69
------------------------------------------------------------------------
Número da Entrada - 114 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.92
------------------------------------------------------------------------
Número da Entrada - 115 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 116 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 117 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.42
------------------------------------------------------------------------
Número da Entrada - 118 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.27
------------------------------------------------------------------------
Número da Entrada - 119 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.4
------------------------------------------------------------------------
Número da Entrada - 120 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 121 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.24
------------------------------------------------------------------------
Número da Entrada - 122 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 123 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 124 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.62
------------------------------------------------------------------------
Número da Entrada - 125 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.44
------------------------------------------------------------------------
Número da Entrada - 126 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.61
------------------------------------------------------------------------
Número da Entrada - 127 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 128 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 129 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 130 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 131 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.28
------------------------------------------------------------------------
Número da Entrada - 132 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 133 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.9
------------------------------------------------------------------------
Número da Entrada - 134 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.99
------------------------------------------------------------------------
Número da Entrada - 135 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 136 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.14
------------------------------------------------------------------------
Número da Entrada - 137 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 138 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.75
------------------------------------------------------------------------
Número da Entrada - 139 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.59
------------------------------------------------------------------------
Número da Entrada - 140 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.53
------------------------------------------------------------------------
Número da Entrada - 141 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 142 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 143 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.56
------------------------------------------------------------------------
Número da Entrada - 144 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 145 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.92
------------------------------------------------------------------------
Número da Entrada - 146 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 147 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 148 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.37
------------------------------------------------------------------------
Número da Entrada - 149 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.19
------------------------------------------------------------------------
Número da Entrada - 150 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.0
------------------------------------------------------------------------
Número da Entrada - 151 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.12
------------------------------------------------------------------------
Número da Entrada - 152 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.8
------------------------------------------------------------------------
Número da Entrada - 153 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.74
------------------------------------------------------------------------
Número da Entrada - 154 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 155 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 156 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 157 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 158 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.5
------------------------------------------------------------------------
Número da Entrada - 159 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 160 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 161 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.61
------------------------------------------------------------------------
Número da Entrada - 162 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 163 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 164 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.05
------------------------------------------------------------------------
Número da Entrada - 165 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 35.4
------------------------------------------------------------------------
Número da Entrada - 166 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.12
------------------------------------------------------------------------
Número da Entrada - 167 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.84
------------------------------------------------------------------------
Número da Entrada - 168 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 57.77
------------------------------------------------------------------------
Número da Entrada - 169 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 170 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.28
------------------------------------------------------------------------
Número da Entrada - 171 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 172 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 173 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.24
------------------------------------------------------------------------
Número da Entrada - 174 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 175 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 176 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 177 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 178 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 179 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.18
------------------------------------------------------------------------
Número da Entrada - 180 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.48
------------------------------------------------------------------------
Número da Entrada - 181 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 182 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 183 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 184 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 185 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.72
------------------------------------------------------------------------
Número da Entrada - 186 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.56
------------------------------------------------------------------------
Número da Entrada - 187 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 188 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.09
------------------------------------------------------------------------
Número da Entrada - 189 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 190 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 191 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.09
------------------------------------------------------------------------
Número da Entrada - 192 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.68
------------------------------------------------------------------------
Número da Entrada - 193 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 194 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 195 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.41
------------------------------------------------------------------------
Número da Entrada - 196 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 197 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 198 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 199 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 200 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 201 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.99
------------------------------------------------------------------------
Número da Entrada - 202 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.68
------------------------------------------------------------------------
Número da Entrada - 203 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.22
------------------------------------------------------------------------
Número da Entrada - 204 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 205 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.42
------------------------------------------------------------------------
Número da Entrada - 206 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 207 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.93
------------------------------------------------------------------------
Número da Entrada - 208 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 209 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.27
------------------------------------------------------------------------
Número da Entrada - 210 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.59
------------------------------------------------------------------------
Número da Entrada - 211 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.74
------------------------------------------------------------------------
Número da Entrada - 212 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.89
------------------------------------------------------------------------
Número da Entrada - 213 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 214 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 215 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.06
------------------------------------------------------------------------
Número da Entrada - 216 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.53
------------------------------------------------------------------------
Número da Entrada - 217 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 218 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 219 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 220 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.71
------------------------------------------------------------------------
Número da Entrada - 221 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 18.79
------------------------------------------------------------------------
Número da Entrada - 222 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.14
------------------------------------------------------------------------
Número da Entrada - 223 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 224 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 225 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.4
------------------------------------------------------------------------
Número da Entrada - 226 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.57
------------------------------------------------------------------------
Número da Entrada - 227 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 228 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 229 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 230 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.4
------------------------------------------------------------------------
Número da Entrada - 231 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.29
------------------------------------------------------------------------
Número da Entrada - 232 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.34
------------------------------------------------------------------------
Número da Entrada - 233 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 234 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.44
------------------------------------------------------------------------
Número da Entrada - 235 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.72
------------------------------------------------------------------------
Número da Entrada - 236 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 237 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 238 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.39
------------------------------------------------------------------------
Número da Entrada - 239 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.88
------------------------------------------------------------------------
Número da Entrada - 240 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.09
------------------------------------------------------------------------
Número da Entrada - 241 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.48
------------------------------------------------------------------------
Número da Entrada - 242 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.78
------------------------------------------------------------------------
Número da Entrada - 243 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 244 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 245 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 246 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.79
------------------------------------------------------------------------
Número da Entrada - 247 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.34
------------------------------------------------------------------------
Número da Entrada - 248 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 249 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 250 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.03
------------------------------------------------------------------------
Número da Entrada - 251 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 252 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 253 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.67
------------------------------------------------------------------------
Número da Entrada - 254 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 255 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 256 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 257 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.58
------------------------------------------------------------------------
Número da Entrada - 258 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 259 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 260 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 261 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 262 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 263 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 264 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 265 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 266 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 267 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.66
------------------------------------------------------------------------
Número da Entrada - 268 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 67.78
------------------------------------------------------------------------
Número da Entrada - 269 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 270 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 9.12
------------------------------------------------------------------------
Número da Entrada - 271 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.2
------------------------------------------------------------------------
Número da Entrada - 272 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.56
------------------------------------------------------------------------
Número da Entrada - 273 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 274 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 275 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 276 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.31
------------------------------------------------------------------------
Número da Entrada - 277 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.3
------------------------------------------------------------------------
Número da Entrada - 278 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 279 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 280 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 281 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 282 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 283 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.92
------------------------------------------------------------------------
Número da Entrada - 284 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.08
------------------------------------------------------------------------
Número da Entrada - 285 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.5
------------------------------------------------------------------------
Número da Entrada - 286 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 287 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.45
------------------------------------------------------------------------
Número da Entrada - 288 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.23
------------------------------------------------------------------------
Número da Entrada - 289 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.44
------------------------------------------------------------------------
Número da Entrada - 290 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 291 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 292 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 293 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.39
------------------------------------------------------------------------
Número da Entrada - 294 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.45
------------------------------------------------------------------------
Número da Entrada - 295 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 296 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.16
------------------------------------------------------------------------
Número da Entrada - 297 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 298 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 299 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 36.82
------------------------------------------------------------------------
Número da Entrada - 300 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.49
------------------------------------------------------------------------
Número da Entrada - 301 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.82
------------------------------------------------------------------------
Número da Entrada - 302 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.8
------------------------------------------------------------------------
Número da Entrada - 303 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 304 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 305 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.65
------------------------------------------------------------------------
Número da Entrada - 306 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 307 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 308 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 309 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.81
------------------------------------------------------------------------
Número da Entrada - 310 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 311 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 312 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 313 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 314 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 315 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 316 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 317 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 318 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 319 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 320 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.49
------------------------------------------------------------------------
Número da Entrada - 321 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 12.09
------------------------------------------------------------------------
Número da Entrada - 322 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 68.2
------------------------------------------------------------------------
Número da Entrada - 323 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 324 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 325 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 326 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 78.5
------------------------------------------------------------------------
Número da Entrada - 327 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 328 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.26
------------------------------------------------------------------------
Número da Entrada - 329 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 330 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 331 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 332 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.18
------------------------------------------------------------------------
Número da Entrada - 333 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 334 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 335 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.27
------------------------------------------------------------------------
Número da Entrada - 336 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 337 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 338 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.0
------------------------------------------------------------------------
Número da Entrada - 339 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.79
------------------------------------------------------------------------
Número da Entrada - 340 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 341 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 342 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 343 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 344 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.27
------------------------------------------------------------------------
Número da Entrada - 345 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 346 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.95
------------------------------------------------------------------------
Número da Entrada - 347 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.94
------------------------------------------------------------------------
Número da Entrada - 348 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 62.98
------------------------------------------------------------------------
Número da Entrada - 349 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 62.98
------------------------------------------------------------------------
Número da Entrada - 350 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.84
------------------------------------------------------------------------
Número da Entrada - 351 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 352 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.66
------------------------------------------------------------------------
Número da Entrada - 353 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.67
------------------------------------------------------------------------
Número da Entrada - 354 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 224.59
------------------------------------------------------------------------
Número da Entrada - 355 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 356 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 357 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.96
------------------------------------------------------------------------
Número da Entrada - 358 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 359 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 360 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
************************************************************
Carregando dados ...
360 360 360
(331, 30) (331, 30) (331, 30)
(331, 90) (331, 30)
Matrix_30: [(331, 90), (331, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1638 - accuracy: 0.6522 - precision: 0.6522 - recall: 0.6522 - f1_score: 0.5294 - val_loss: 0.1987 - val_accuracy: 0.2979 - val_precision: 0.2979 - val_recall: 0.2979 - val_f1_score: 0.4590 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1619 - accuracy: 0.3696 - precision: 0.3696 - recall: 0.3696 - f1_score: 0.5043 - val_loss: 0.1331 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.6364 - 65ms/epoch - 65ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1459 - accuracy: 0.8261 - precision: 0.8261 - recall: 0.8261 - f1_score: 0.6667 - val_loss: 0.1269 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.6364 - 67ms/epoch - 67ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1395 - accuracy: 0.8315 - precision: 0.8315 - recall: 0.8315 - f1_score: 0.6804 - val_loss: 0.1381 - val_accuracy: 0.7660 - val_precision: 0.7660 - val_recall: 0.7660 - val_f1_score: 0.6857 - 72ms/epoch - 72ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1246 - accuracy: 0.8370 - precision: 0.8370 - recall: 0.8370 - f1_score: 0.7857 - val_loss: 0.1510 - val_accuracy: 0.7447 - val_precision: 0.7447 - val_recall: 0.7447 - val_f1_score: 0.7000 - 65ms/epoch - 65ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1223 - accuracy: 0.7391 - precision: 0.7391 - recall: 0.7391 - f1_score: 0.7143 - val_loss: 0.1328 - val_accuracy: 0.7447 - val_precision: 0.7447 - val_recall: 0.7447 - val_f1_score: 0.6667 - 66ms/epoch - 66ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1110 - accuracy: 0.8152 - precision: 0.8152 - recall: 0.8152 - f1_score: 0.7792 - val_loss: 0.1063 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.6667 - 65ms/epoch - 65ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1038 - accuracy: 0.9130 - precision: 0.9130 - recall: 0.9130 - f1_score: 0.8596 - val_loss: 0.0989 - val_accuracy: 0.8511 - val_precision: 0.8511 - val_recall: 0.8511 - val_f1_score: 0.6957 - 74ms/epoch - 74ms/step
Epoch 9/50
1/1 - 0s - loss: 0.0986 - accuracy: 0.8967 - precision: 0.8967 - recall: 0.8967 - f1_score: 0.8257 - val_loss: 0.1041 - val_accuracy: 0.8085 - val_precision: 0.8085 - val_recall: 0.8085 - val_f1_score: 0.7097 - 65ms/epoch - 65ms/step
Epoch 10/50
1/1 - 0s - loss: 0.0889 - accuracy: 0.9185 - precision: 0.9185 - recall: 0.9185 - f1_score: 0.8855 - val_loss: 0.1104 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.7647 - 65ms/epoch - 65ms/step
Epoch 11/50
1/1 - 0s - loss: 0.0858 - accuracy: 0.8533 - precision: 0.8533 - recall: 0.8533 - f1_score: 0.8163 - val_loss: 0.0941 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.7500 - 69ms/epoch - 69ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0768 - accuracy: 0.9239 - precision: 0.9239 - recall: 0.9239 - f1_score: 0.8939 - val_loss: 0.0793 - val_accuracy: 0.9149 - val_precision: 0.9149 - val_recall: 0.9149 - val_f1_score: 0.8462 - 67ms/epoch - 67ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0730 - accuracy: 0.9348 - precision: 0.9348 - recall: 0.9348 - f1_score: 0.9000 - val_loss: 0.0753 - val_accuracy: 0.9149 - val_precision: 0.9149 - val_recall: 0.9149 - val_f1_score: 0.8462 - 66ms/epoch - 66ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0670 - accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - f1_score: 0.9180 - val_loss: 0.0797 - val_accuracy: 0.8511 - val_precision: 0.8511 - val_recall: 0.8511 - val_f1_score: 0.7742 - 73ms/epoch - 73ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0614 - accuracy: 0.9402 - precision: 0.9402 - recall: 0.9402 - f1_score: 0.9160 - val_loss: 0.0797 - val_accuracy: 0.8298 - val_precision: 0.8298 - val_recall: 0.8298 - val_f1_score: 0.7500 - 66ms/epoch - 66ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0583 - accuracy: 0.9348 - precision: 0.9348 - recall: 0.9348 - f1_score: 0.9091 - val_loss: 0.0663 - val_accuracy: 0.9149 - val_precision: 0.9149 - val_recall: 0.9149 - val_f1_score: 0.8571 - 68ms/epoch - 68ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0521 - accuracy: 0.9565 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9375 - val_loss: 0.0575 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 80ms/epoch - 80ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0498 - accuracy: 0.9565 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9355 - val_loss: 0.0558 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 66ms/epoch - 66ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0446 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - f1_score: 0.9440 - val_loss: 0.0598 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.9032 - 67ms/epoch - 67ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0417 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - f1_score: 0.9449 - val_loss: 0.0567 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.9032 - 66ms/epoch - 66ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0384 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - f1_score: 0.9449 - val_loss: 0.0468 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 80ms/epoch - 80ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0345 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0421 - val_accuracy: 0.9362 - val_precision: 0.9362 - val_recall: 0.9362 - val_f1_score: 0.8889 - 65ms/epoch - 65ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0323 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9672 - val_loss: 0.0431 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0285 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0455 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0267 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9677 - val_loss: 0.0395 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 70ms/epoch - 70ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0233 - accuracy: 0.9891 - precision: 0.9891 - recall: 0.9891 - f1_score: 0.9836 - val_loss: 0.0323 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 73ms/epoch - 73ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0216 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9917 - val_loss: 0.0314 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 68ms/epoch - 68ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0190 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9917 - val_loss: 0.0346 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 109ms/epoch - 109ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0174 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9917 - val_loss: 0.0323 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 75ms/epoch - 75ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0156 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9917 - val_loss: 0.0261 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 73ms/epoch - 73ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0139 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 80ms/epoch - 80ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0102 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0089 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0080 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 72ms/epoch - 72ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0072 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 65ms/epoch - 65ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0057 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 65ms/epoch - 65ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0044 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 70ms/epoch - 70ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 66ms/epoch - 66ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 68ms/epoch - 68ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0030 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 75ms/epoch - 75ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 73ms/epoch - 73ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 69ms/epoch - 69ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_f1_score: 0.9655 - 67ms/epoch - 67ms/step

🔍 Resultados no Teste:
Loss: 0.0136
Accuracy: 0.9800
Precision: 0.9800
Recall: 0.9800
F1 Score: 0.9677
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
360 360 360
(331, 30) (331, 30) (331, 30)
(331, 90) (331, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 131ms/step
[[0.75927866 0.24072127]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 361 | Acuracia_0: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 0.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
361 361 361
(332, 30) (332, 30) (332, 30)
(332, 90) (332, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97937554 0.02062442]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 362 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
362 362 362
(333, 30) (333, 30) (333, 30)
(333, 90) (333, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9866932  0.01330677]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 363 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
363 363 363
(334, 30) (334, 30) (334, 30)
(334, 90) (334, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99803084 0.00196917]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 364 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 12.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
364 364 364
(335, 30) (335, 30) (335, 30)
(335, 90) (335, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
[[0.9972596  0.00274034]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 365 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 1.0
Entrada: 3.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 40.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
365 365 365
(336, 30) (336, 30) (336, 30)
(336, 90) (336, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98366195 0.01633803]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 366 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 2.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
366 366 366
(337, 30) (337, 30) (337, 30)
(337, 90) (337, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9677308  0.03226918]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 367 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 2.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 42.8571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
367 367 367
(338, 30) (338, 30) (338, 30)
(338, 90) (338, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9918139  0.00818611]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 368 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 3.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
368 368 368
(339, 30) (339, 30) (339, 30)
(339, 90) (339, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9637357  0.03626426]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 369 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 3.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
369 369 369
(340, 30) (340, 30) (340, 30)
(340, 90) (340, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9159233  0.08407672]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 370 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 3.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
370 370 370
(341, 30) (341, 30) (341, 30)
(341, 90) (341, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9937675  0.00623246]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 371 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 3.0
Entrada: 5.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 54.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
371 371 371
(342, 30) (342, 30) (342, 30)
(342, 90) (342, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9911322  0.00886775]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 372 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 4.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
372 372 372
(343, 30) (343, 30) (343, 30)
(343, 90) (343, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.97567695 0.024323  ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 373 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 4.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 61.5385
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
373 373 373
(344, 30) (344, 30) (344, 30)
(344, 90) (344, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9406494  0.05935057]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 374 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 4.0
Entrada: 20.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
374 374 374
(345, 30) (345, 30) (345, 30)
(345, 90) (345, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96734935 0.03265069]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 375 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 5.0
Entrada: 4.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 53.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
375 375 375
(346, 30) (346, 30) (346, 30)
(346, 90) (346, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7216424  0.27835754]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 376 | Acuracia_0: 0 | Contagem Geral: 1.0 
Ordem Natural: 6.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
376 376 376
(347, 30) (347, 30) (347, 30)
(347, 90) (347, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6026189 0.3973811]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 377 | Acuracia_0: 0 | Contagem Geral: 2.0 
Ordem Natural: 6.0
Entrada: 1.92
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 47.0588
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
377 377 377
(348, 30) (348, 30) (348, 30)
(348, 90) (348, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9950958  0.00490415]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 378 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 6.0
Entrada: 3.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 44.4444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
378 378 378
(349, 30) (349, 30) (349, 30)
(349, 90) (349, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9987936  0.00120637]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 379 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 7.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 47.3684
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
379 379 379
(350, 30) (350, 30) (350, 30)
(350, 90) (350, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.88530624 0.11469373]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 380 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 7.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
380 380 380
(351, 30) (351, 30) (351, 30)
(351, 90) (351, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9447739  0.05522605]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 381 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 7.0
Entrada: 1.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 52.381
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
381 381 381
(352, 30) (352, 30) (352, 30)
(352, 90) (352, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9600584 0.0399416]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 382 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 7.0
Entrada: 5.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
382 382 382
(353, 30) (353, 30) (353, 30)
(353, 90) (353, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9877065  0.01229355]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 383 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 8.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 52.1739
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
383 383 383
(354, 30) (354, 30) (354, 30)
(354, 90) (354, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99580574 0.00419426]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 384 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 8.0
Entrada: 3.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
384 384 384
(355, 30) (355, 30) (355, 30)
(355, 90) (355, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9575583  0.04244168]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 385 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 9.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 52.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
385 385 385
(356, 30) (356, 30) (356, 30)
(356, 90) (356, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.95889676 0.04110328]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 386 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 9.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 53.8462
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
386 386 386
(357, 30) (357, 30) (357, 30)
(357, 90) (357, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9715873  0.02841267]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 387 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 9.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
387 387 387
(358, 30) (358, 30) (358, 30)
(358, 90) (358, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9906059  0.00939411]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 388 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 9.0
Entrada: 514.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 53.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
388 388 388
(359, 30) (359, 30) (359, 30)
(359, 90) (359, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99040437 0.00959567]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 389 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 10.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.1724
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
389 389 389
(360, 30) (360, 30) (360, 30)
(360, 90) (360, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[[0.9851216  0.01487841]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 390 | Acuracia_0: 0 | Contagem Geral: 3.0 
Ordem Natural: 10.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_30: 0 
Precisao modelo Geral: 56.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
390 390 390
(361, 30) (361, 30) (361, 30)
(361, 90) (361, 30)
Matrix_30: [(361, 90), (361, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2067 - accuracy: 0.3582 - precision: 0.3582 - recall: 0.3582 - f1_score: 0.4819 - val_loss: 0.1641 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3179 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.0000e+00 - val_loss: 0.1506 - val_accuracy: 0.7255 - val_precision: 0.7255 - val_recall: 0.7255 - val_f1_score: 0.4167 - 68ms/epoch - 68ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.4444 - val_loss: 0.2644 - val_accuracy: 0.2549 - val_precision: 0.2549 - val_recall: 0.2549 - val_f1_score: 0.4062 - 66ms/epoch - 66ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.3532 - precision: 0.3532 - recall: 0.3532 - f1_score: 0.5113 - val_loss: 0.2849 - val_accuracy: 0.2549 - val_precision: 0.2549 - val_recall: 0.2549 - val_f1_score: 0.4062 - 67ms/epoch - 67ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1921 - accuracy: 0.3383 - precision: 0.3383 - recall: 0.3383 - f1_score: 0.5056 - val_loss: 0.2228 - val_accuracy: 0.2549 - val_precision: 0.2549 - val_recall: 0.2549 - val_f1_score: 0.4062 - 70ms/epoch - 70ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.3781 - precision: 0.3781 - recall: 0.3781 - f1_score: 0.5211 - val_loss: 0.1681 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.4898 - 66ms/epoch - 66ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1497 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.6224 - val_loss: 0.1397 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.7143 - 66ms/epoch - 66ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1539 - accuracy: 0.7811 - precision: 0.7811 - recall: 0.7811 - f1_score: 0.6452 - val_loss: 0.1297 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.6667 - 66ms/epoch - 66ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.7662 - precision: 0.7662 - recall: 0.7662 - f1_score: 0.5155 - val_loss: 0.1276 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.6316 - 69ms/epoch - 69ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.7512 - precision: 0.7512 - recall: 0.7512 - f1_score: 0.4681 - val_loss: 0.1306 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7500 - 66ms/epoch - 66ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1522 - accuracy: 0.7861 - precision: 0.7861 - recall: 0.7861 - f1_score: 0.6055 - val_loss: 0.1390 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 66ms/epoch - 66ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1428 - accuracy: 0.8159 - precision: 0.8159 - recall: 0.8159 - f1_score: 0.7299 - val_loss: 0.1533 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.5556 - 66ms/epoch - 66ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1381 - accuracy: 0.7463 - precision: 0.7463 - recall: 0.7463 - f1_score: 0.7086 - val_loss: 0.1688 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5106 - 71ms/epoch - 71ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1380 - accuracy: 0.6368 - precision: 0.6368 - recall: 0.6368 - f1_score: 0.6439 - val_loss: 0.1787 - val_accuracy: 0.4510 - val_precision: 0.4510 - val_recall: 0.4510 - val_f1_score: 0.4815 - 65ms/epoch - 65ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1385 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.6119 - val_loss: 0.1778 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.4906 - 66ms/epoch - 66ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1358 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.6233 - val_loss: 0.1656 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5106 - 66ms/epoch - 66ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1296 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.6667 - val_loss: 0.1474 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059 - val_f1_score: 0.5946 - 83ms/epoch - 83ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1229 - accuracy: 0.7910 - precision: 0.7910 - recall: 0.7910 - f1_score: 0.7529 - val_loss: 0.1303 - val_accuracy: 0.7843 - val_precision: 0.7843 - val_recall: 0.7843 - val_f1_score: 0.6452 - 66ms/epoch - 66ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1193 - accuracy: 0.8507 - precision: 0.8507 - recall: 0.8507 - f1_score: 0.7917 - val_loss: 0.1188 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7692 - 68ms/epoch - 68ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1181 - accuracy: 0.8557 - precision: 0.8557 - recall: 0.8557 - f1_score: 0.7786 - val_loss: 0.1136 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7692 - 70ms/epoch - 70ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1152 - accuracy: 0.8507 - precision: 0.8507 - recall: 0.8507 - f1_score: 0.7656 - val_loss: 0.1146 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.7143 - 71ms/epoch - 71ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1087 - accuracy: 0.8657 - precision: 0.8657 - recall: 0.8657 - f1_score: 0.8058 - val_loss: 0.1224 - val_accuracy: 0.7843 - val_precision: 0.7843 - val_recall: 0.7843 - val_f1_score: 0.6452 - 67ms/epoch - 67ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1027 - accuracy: 0.8507 - precision: 0.8507 - recall: 0.8507 - f1_score: 0.8052 - val_loss: 0.1342 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.6486 - 67ms/epoch - 67ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1004 - accuracy: 0.8209 - precision: 0.8209 - recall: 0.8209 - f1_score: 0.7831 - val_loss: 0.1399 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.6000 - 64ms/epoch - 64ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0990 - accuracy: 0.7960 - precision: 0.7960 - recall: 0.7960 - f1_score: 0.7630 - val_loss: 0.1318 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.6486 - 66ms/epoch - 66ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0942 - accuracy: 0.8209 - precision: 0.8209 - recall: 0.8209 - f1_score: 0.7857 - val_loss: 0.1147 - val_accuracy: 0.7843 - val_precision: 0.7843 - val_recall: 0.7843 - val_f1_score: 0.6452 - 66ms/epoch - 66ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0886 - accuracy: 0.8607 - precision: 0.8607 - recall: 0.8607 - f1_score: 0.8228 - val_loss: 0.1002 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.7143 - 67ms/epoch - 67ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0867 - accuracy: 0.8756 - precision: 0.8756 - recall: 0.8756 - f1_score: 0.8252 - val_loss: 0.0943 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.7143 - 66ms/epoch - 66ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0853 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - f1_score: 0.8345 - val_loss: 0.0964 - val_accuracy: 0.8431 - val_precision: 0.8431 - val_recall: 0.8431 - val_f1_score: 0.7143 - 67ms/epoch - 67ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0805 - accuracy: 0.8806 - precision: 0.8806 - recall: 0.8806 - f1_score: 0.8333 - val_loss: 0.1053 - val_accuracy: 0.8039 - val_precision: 0.8039 - val_recall: 0.8039 - val_f1_score: 0.6667 - 71ms/epoch - 71ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0766 - accuracy: 0.8806 - precision: 0.8806 - recall: 0.8806 - f1_score: 0.8462 - val_loss: 0.1133 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.7273 - 68ms/epoch - 68ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0754 - accuracy: 0.8607 - precision: 0.8607 - recall: 0.8607 - f1_score: 0.8272 - val_loss: 0.1098 - val_accuracy: 0.8039 - val_precision: 0.8039 - val_recall: 0.8039 - val_f1_score: 0.6875 - 67ms/epoch - 67ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0723 - accuracy: 0.8607 - precision: 0.8607 - recall: 0.8607 - f1_score: 0.8272 - val_loss: 0.0971 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.6897 - 66ms/epoch - 66ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0682 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8816 - val_loss: 0.0869 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 75ms/epoch - 75ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0666 - accuracy: 0.9154 - precision: 0.9154 - recall: 0.9154 - f1_score: 0.8828 - val_loss: 0.0840 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7692 - 66ms/epoch - 66ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0643 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - f1_score: 0.8873 - val_loss: 0.0874 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.6897 - 67ms/epoch - 67ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0604 - accuracy: 0.9254 - precision: 0.9254 - recall: 0.9254 - f1_score: 0.8980 - val_loss: 0.0935 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.6897 - 79ms/epoch - 79ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0582 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8816 - val_loss: 0.0937 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.6897 - 83ms/epoch - 83ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0561 - accuracy: 0.9154 - precision: 0.9154 - recall: 0.9154 - f1_score: 0.8889 - val_loss: 0.0854 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.6897 - 67ms/epoch - 67ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0526 - accuracy: 0.9353 - precision: 0.9353 - recall: 0.9353 - f1_score: 0.9116 - val_loss: 0.0760 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7692 - 67ms/epoch - 67ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0505 - accuracy: 0.9403 - precision: 0.9403 - recall: 0.9403 - f1_score: 0.9155 - val_loss: 0.0732 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.7692 - 66ms/epoch - 66ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0484 - accuracy: 0.9552 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9353 - val_loss: 0.0760 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 66ms/epoch - 66ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0452 - accuracy: 0.9453 - precision: 0.9453 - recall: 0.9453 - f1_score: 0.9241 - val_loss: 0.0797 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 65ms/epoch - 65ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9453 - precision: 0.9453 - recall: 0.9453 - f1_score: 0.9241 - val_loss: 0.0776 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 67ms/epoch - 67ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0410 - accuracy: 0.9453 - precision: 0.9453 - recall: 0.9453 - f1_score: 0.9241 - val_loss: 0.0706 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 66ms/epoch - 66ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0385 - accuracy: 0.9652 - precision: 0.9652 - recall: 0.9652 - f1_score: 0.9504 - val_loss: 0.0656 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8000 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0368 - accuracy: 0.9701 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9565 - val_loss: 0.0649 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0343 - accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - f1_score: 0.9640 - val_loss: 0.0667 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 66ms/epoch - 66ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0322 - accuracy: 0.9701 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9571 - val_loss: 0.0664 - val_accuracy: 0.8627 - val_precision: 0.8627 - val_recall: 0.8627 - val_f1_score: 0.7407 - 67ms/epoch - 67ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0305 - accuracy: 0.9652 - precision: 0.9652 - recall: 0.9652 - f1_score: 0.9504 - val_loss: 0.0620 - val_accuracy: 0.9020 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1_score: 0.8000 - 70ms/epoch - 70ms/step

🔍 Resultados no Teste:
Loss: 0.0571
Accuracy: 0.9083
Precision: 0.9083
Recall: 0.9083
F1 Score: 0.8611
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
390 390 390
(361, 30) (361, 30) (361, 30)
(361, 90) (361, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 91ms/step
[[0.8256525  0.17434745]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 391 | Acuracia_1: 0.0 | Contagem Geral: 3.0 
Ordem Natural: 10.0
Entrada: 2.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_1: 0.0 
Precisao modelo Geral: 58.0645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
391 391 391
(362, 30) (362, 30) (362, 30)
(362, 90) (362, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.64682615 0.3531739 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 392 | Acuracia_2: 0 | Contagem Geral: 3.0 
Ordem Natural: 10.0
Entrada: 7.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_2: 1.0 
Precisao modelo Geral: 59.375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
392 392 392
(363, 30) (363, 30) (363, 30)
(363, 90) (363, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5205913  0.47940865]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 393 | Acuracia_3: 0 | Contagem Geral: 4.0 
Ordem Natural: 11.0
Entrada: 2.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_3: 0.0 
Precisao modelo Geral: 57.5758
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
393 393 393
(364, 30) (364, 30) (364, 30)
(364, 90) (364, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.84897757 0.1510225 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 394 | Acuracia_4: 0 | Contagem Geral: 5.0 
Ordem Natural: 11.0
Entrada: 3.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_4: 0 
Precisao modelo Geral: 55.8824
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
394 394 394
(365, 30) (365, 30) (365, 30)
(365, 90) (365, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.89787066 0.10212935]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 395 | Acuracia_5: 0 | Contagem Geral: 5.0 
Ordem Natural: 12.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_5: 0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
395 395 395
(366, 30) (366, 30) (366, 30)
(366, 90) (366, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7928871  0.20711297]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 396 | Acuracia_6: 0 | Contagem Geral: 5.0 
Ordem Natural: 12.0
Entrada: 8.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_6: 1.0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
396 396 396
(367, 30) (367, 30) (367, 30)
(367, 90) (367, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.90337425 0.09662572]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 397 | Acuracia_7: 0 | Contagem Geral: 6.0 
Ordem Natural: 13.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_7: 0 
Precisao modelo Geral: 59.4595
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
397 397 397
(368, 30) (368, 30) (368, 30)
(368, 90) (368, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8140315  0.18596858]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 398 | Acuracia_8: 0 | Contagem Geral: 6.0 
Ordem Natural: 13.0
Entrada: 9.97
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_8: 0 
Precisao modelo Geral: 57.8947
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
398 398 398
(369, 30) (369, 30) (369, 30)
(369, 90) (369, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.74902356 0.2509764 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 399 | Acuracia_9: 0 | Contagem Geral: 6.0 
Ordem Natural: 14.0
Entrada: 2.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_9: 0.0 
Precisao modelo Geral: 56.4103
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
399 399 399
(370, 30) (370, 30) (370, 30)
(370, 90) (370, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6840741 0.3159259]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 400 | Acuracia_10: 0 | Contagem Geral: 7.0 
Ordem Natural: 14.0
Entrada: 8.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 37.5 | Acuracia_10: 1.0 
Precisao modelo Geral: 57.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
400 400 400
(371, 30) (371, 30) (371, 30)
(371, 90) (371, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9255534  0.07444662]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 401 | Acuracia_11: 0 | Contagem Geral: 8.0 
Ordem Natural: 15.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 37.5 | Acuracia_11: 0 
Precisao modelo Geral: 58.5366
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
401 401 401
(372, 30) (372, 30) (372, 30)
(372, 90) (372, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7140992  0.28590074]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 402 | Acuracia_12: 0 | Contagem Geral: 8.0 
Ordem Natural: 15.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_12: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
402 402 402
(373, 30) (373, 30) (373, 30)
(373, 90) (373, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.68832374 0.3116763 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 403 | Acuracia_13: 0 | Contagem Geral: 9.0 
Ordem Natural: 15.0
Entrada: 2.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_13: 0.0 
Precisao modelo Geral: 55.814
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
403 403 403
(374, 30) (374, 30) (374, 30)
(374, 90) (374, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9047544  0.09524561]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 404 | Acuracia_14: 0 | Contagem Geral: 10.0 
Ordem Natural: 15.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_14: 0 
Precisao modelo Geral: 56.8182
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
404 404 404
(375, 30) (375, 30) (375, 30)
(375, 90) (375, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8591759  0.14082403]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 405 | Acuracia_15: 0 | Contagem Geral: 10.0 
Ordem Natural: 15.0
Entrada: 1.9
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_15: 0 
Precisao modelo Geral: 57.7778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
405 405 405
(376, 30) (376, 30) (376, 30)
(376, 90) (376, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7545801  0.24541989]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 406 | Acuracia_16: 0.0 | Contagem Geral: 10.0 
Ordem Natural: 15.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_16: 0.0 
Precisao modelo Geral: 56.5217
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
406 406 406
(377, 30) (377, 30) (377, 30)
(377, 90) (377, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86843026 0.13156974]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 407 | Acuracia_17: 0.0 | Contagem Geral: 11.0 
Ordem Natural: 15.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_17: 0.0 
Precisao modelo Geral: 57.4468
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
407 407 407
(378, 30) (378, 30) (378, 30)
(378, 90) (378, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95306677 0.0469332 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 408 | Acuracia_18: 0 | Contagem Geral: 11.0 
Ordem Natural: 15.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_18: 0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
408 408 408
(379, 30) (379, 30) (379, 30)
(379, 90) (379, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8337978  0.16620216]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 409 | Acuracia_19: 0 | Contagem Geral: 11.0 
Ordem Natural: 15.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_19: 0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
409 409 409
(380, 30) (380, 30) (380, 30)
(380, 90) (380, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.61254495 0.38745502]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 410 | Acuracia_20: 0 | Contagem Geral: 11.0 
Ordem Natural: 16.0
Entrada: 2.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_20: 0.0 
Precisao modelo Geral: 56.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
410 410 410
(381, 30) (381, 30) (381, 30)
(381, 90) (381, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.74620265 0.25379732]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 411 | Acuracia_21: 0 | Contagem Geral: 12.0 
Ordem Natural: 16.0
Entrada: 12.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_21: 1.0 
Precisao modelo Geral: 56.8627
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
411 411 411
(382, 30) (382, 30) (382, 30)
(382, 90) (382, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.950605   0.04939496]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 412 | Acuracia_22: 0 | Contagem Geral: 13.0 
Ordem Natural: 17.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_22: 0 
Precisao modelo Geral: 57.6923
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
412 412 412
(383, 30) (383, 30) (383, 30)
(383, 90) (383, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8379222  0.16207777]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 413 | Acuracia_23: 0 | Contagem Geral: 13.0 
Ordem Natural: 17.0
Entrada: 2.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_23: 0 
Precisao modelo Geral: 58.4906
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
413 413 413
(384, 30) (384, 30) (384, 30)
(384, 90) (384, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.93536156 0.06463838]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 414 | Acuracia_24: 0 | Contagem Geral: 13.0 
Ordem Natural: 17.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_24: 0 
Precisao modelo Geral: 59.2593
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
414 414 414
(385, 30) (385, 30) (385, 30)
(385, 90) (385, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.77987295 0.22012706]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 415 | Acuracia_25: 0 | Contagem Geral: 13.0 
Ordem Natural: 17.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_25: 0.0 
Precisao modelo Geral: 58.1818
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
415 415 415
(386, 30) (386, 30) (386, 30)
(386, 90) (386, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.70509624 0.2949038 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 416 | Acuracia_26: 0 | Contagem Geral: 14.0 
Ordem Natural: 17.0
Entrada: 2.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_26: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
416 416 416
(387, 30) (387, 30) (387, 30)
(387, 90) (387, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.86546075 0.1345393 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 417 | Acuracia_27: 0 | Contagem Geral: 15.0 
Ordem Natural: 17.0
Entrada: 2.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_27: 0 
Precisao modelo Geral: 57.8947
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
417 417 417
(388, 30) (388, 30) (388, 30)
(388, 90) (388, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9682548  0.03174525]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 418 | Acuracia_28: 0 | Contagem Geral: 15.0 
Ordem Natural: 17.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_28: 0 
Precisao modelo Geral: 58.6207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
418 418 418
(389, 30) (389, 30) (389, 30)
(389, 90) (389, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8449958  0.15500423]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 419 | Acuracia_29: 0 | Contagem Geral: 15.0 
Ordem Natural: 17.0
Entrada: 10.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_29: 0 
Precisao modelo Geral: 57.6271
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
419 419 419
(390, 30) (390, 30) (390, 30)
(390, 90) (390, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.76145995 0.23854007]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 420 | Acuracia_0: 0 | Contagem Geral: 15.0 
Ordem Natural: 18.0
Entrada: 3.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_30: 1.0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
420 420 420
(391, 30) (391, 30) (391, 30)
(391, 90) (391, 30)
Matrix_30: [(391, 90), (391, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.3001 - accuracy: 0.6514 - precision: 0.6514 - recall: 0.6514 - f1_score: 0.0000e+00 - val_loss: 0.2619 - val_accuracy: 0.2364 - val_precision: 0.2364 - val_recall: 0.2364 - val_f1_score: 0.3636 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2086 - accuracy: 0.3716 - precision: 0.3716 - recall: 0.3716 - f1_score: 0.5090 - val_loss: 0.2936 - val_accuracy: 0.2727 - val_precision: 0.2727 - val_recall: 0.2727 - val_f1_score: 0.4286 - 66ms/epoch - 66ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2234 - accuracy: 0.3349 - precision: 0.3349 - recall: 0.3349 - f1_score: 0.4983 - val_loss: 0.2429 - val_accuracy: 0.2727 - val_precision: 0.2727 - val_recall: 0.2727 - val_f1_score: 0.4118 - 68ms/epoch - 68ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1921 - accuracy: 0.3578 - precision: 0.3578 - recall: 0.3578 - f1_score: 0.5070 - val_loss: 0.1951 - val_accuracy: 0.4182 - val_precision: 0.4182 - val_recall: 0.4182 - val_f1_score: 0.4483 - 66ms/epoch - 66ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.4679 - precision: 0.4679 - recall: 0.4679 - f1_score: 0.5323 - val_loss: 0.1660 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1_score: 0.4500 - 71ms/epoch - 71ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6606 - precision: 0.6606 - recall: 0.6606 - f1_score: 0.5698 - val_loss: 0.1508 - val_accuracy: 0.6909 - val_precision: 0.6909 - val_recall: 0.6909 - val_f1_score: 0.3200 - 69ms/epoch - 69ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.7431 - precision: 0.7431 - recall: 0.7431 - f1_score: 0.5333 - val_loss: 0.1450 - val_accuracy: 0.7455 - val_precision: 0.7455 - val_recall: 0.7455 - val_f1_score: 0.3636 - 68ms/epoch - 68ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.7431 - precision: 0.7431 - recall: 0.7431 - f1_score: 0.4400 - val_loss: 0.1436 - val_accuracy: 0.7818 - val_precision: 0.7818 - val_recall: 0.7818 - val_f1_score: 0.4545 - 67ms/epoch - 67ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1543 - accuracy: 0.7890 - precision: 0.7890 - recall: 0.7890 - f1_score: 0.5818 - val_loss: 0.1462 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.4828 - 71ms/epoch - 71ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1465 - accuracy: 0.8165 - precision: 0.8165 - recall: 0.8165 - f1_score: 0.6970 - val_loss: 0.1533 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.6154 - 67ms/epoch - 67ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1406 - accuracy: 0.8257 - precision: 0.8257 - recall: 0.8257 - f1_score: 0.7654 - val_loss: 0.1628 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 0.6000 - val_f1_score: 0.5417 - 68ms/epoch - 68ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1382 - accuracy: 0.7248 - precision: 0.7248 - recall: 0.7248 - f1_score: 0.6970 - val_loss: 0.1713 - val_accuracy: 0.4909 - val_precision: 0.4909 - val_recall: 0.4909 - val_f1_score: 0.5000 - 67ms/epoch - 67ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1374 - accuracy: 0.6376 - precision: 0.6376 - recall: 0.6376 - f1_score: 0.6457 - val_loss: 0.1736 - val_accuracy: 0.4727 - val_precision: 0.4727 - val_recall: 0.4727 - val_f1_score: 0.4912 - 69ms/epoch - 69ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1353 - accuracy: 0.6147 - precision: 0.6147 - recall: 0.6147 - f1_score: 0.6316 - val_loss: 0.1668 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5283 - 67ms/epoch - 67ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1302 - accuracy: 0.7018 - precision: 0.7018 - recall: 0.7018 - f1_score: 0.6890 - val_loss: 0.1538 - val_accuracy: 0.6182 - val_precision: 0.6182 - val_recall: 0.6182 - val_f1_score: 0.5714 - 68ms/epoch - 68ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1235 - accuracy: 0.7798 - precision: 0.7798 - recall: 0.7798 - f1_score: 0.7419 - val_loss: 0.1393 - val_accuracy: 0.7455 - val_precision: 0.7455 - val_recall: 0.7455 - val_f1_score: 0.6316 - 69ms/epoch - 69ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1180 - accuracy: 0.8578 - precision: 0.8578 - recall: 0.8578 - f1_score: 0.8075 - val_loss: 0.1276 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7273 - 68ms/epoch - 68ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1147 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.7838 - val_loss: 0.1204 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7333 - 67ms/epoch - 67ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1117 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - f1_score: 0.8085 - val_loss: 0.1174 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7500 - 67ms/epoch - 67ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1067 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - f1_score: 0.8112 - val_loss: 0.1184 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7273 - 67ms/epoch - 67ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1003 - accuracy: 0.8624 - precision: 0.8624 - recall: 0.8624 - f1_score: 0.8026 - val_loss: 0.1233 - val_accuracy: 0.7455 - val_precision: 0.7455 - val_recall: 0.7455 - val_f1_score: 0.6316 - 72ms/epoch - 72ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0954 - accuracy: 0.8716 - precision: 0.8716 - recall: 0.8716 - f1_score: 0.8293 - val_loss: 0.1282 - val_accuracy: 0.7818 - val_precision: 0.7818 - val_recall: 0.7818 - val_f1_score: 0.7000 - 66ms/epoch - 66ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0926 - accuracy: 0.8440 - precision: 0.8440 - recall: 0.8440 - f1_score: 0.8046 - val_loss: 0.1270 - val_accuracy: 0.7818 - val_precision: 0.7818 - val_recall: 0.7818 - val_f1_score: 0.7000 - 71ms/epoch - 71ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0893 - accuracy: 0.8440 - precision: 0.8440 - recall: 0.8440 - f1_score: 0.8046 - val_loss: 0.1181 - val_accuracy: 0.7818 - val_precision: 0.7818 - val_recall: 0.7818 - val_f1_score: 0.7000 - 67ms/epoch - 67ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0843 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - f1_score: 0.8383 - val_loss: 0.1065 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7429 - 67ms/epoch - 67ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0800 - accuracy: 0.8578 - precision: 0.8578 - recall: 0.8578 - f1_score: 0.8050 - val_loss: 0.0979 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7273 - 67ms/epoch - 67ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0776 - accuracy: 0.8853 - precision: 0.8853 - recall: 0.8853 - f1_score: 0.8322 - val_loss: 0.0936 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.7742 - 68ms/epoch - 68ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0747 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - f1_score: 0.8552 - val_loss: 0.0933 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7647 - 67ms/epoch - 67ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0702 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8421 - val_loss: 0.0960 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.8000 - 68ms/epoch - 68ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0666 - accuracy: 0.8991 - precision: 0.8991 - recall: 0.8991 - f1_score: 0.8642 - val_loss: 0.0979 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 68ms/epoch - 68ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0641 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - f1_score: 0.8727 - val_loss: 0.0941 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 70ms/epoch - 70ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0606 - accuracy: 0.9083 - precision: 0.9083 - recall: 0.9083 - f1_score: 0.8780 - val_loss: 0.0852 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.8000 - 72ms/epoch - 72ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0565 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - f1_score: 0.9000 - val_loss: 0.0769 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8485 - 70ms/epoch - 70ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0537 - accuracy: 0.9174 - precision: 0.9174 - recall: 0.9174 - f1_score: 0.8800 - val_loss: 0.0725 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8750 - 68ms/epoch - 68ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0510 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - f1_score: 0.8966 - val_loss: 0.0722 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8750 - 75ms/epoch - 75ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0474 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9139 - val_loss: 0.0746 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8485 - 68ms/epoch - 68ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0446 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9172 - val_loss: 0.0747 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8485 - 69ms/epoch - 69ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0423 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9172 - val_loss: 0.0693 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8750 - 68ms/epoch - 68ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0393 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - f1_score: 0.9351 - val_loss: 0.0624 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 86ms/epoch - 86ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0369 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - f1_score: 0.9200 - val_loss: 0.0586 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 67ms/epoch - 67ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0348 - accuracy: 0.9587 - precision: 0.9587 - recall: 0.9587 - f1_score: 0.9388 - val_loss: 0.0583 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 69ms/epoch - 69ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0321 - accuracy: 0.9633 - precision: 0.9633 - recall: 0.9633 - f1_score: 0.9459 - val_loss: 0.0596 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 67ms/epoch - 67ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0301 - accuracy: 0.9633 - precision: 0.9633 - recall: 0.9633 - f1_score: 0.9474 - val_loss: 0.0582 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 68ms/epoch - 68ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - f1_score: 0.9600 - val_loss: 0.0534 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 66ms/epoch - 66ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0259 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9796 - val_loss: 0.0488 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 69ms/epoch - 69ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0241 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - f1_score: 0.9655 - val_loss: 0.0468 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 66ms/epoch - 66ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9817 - precision: 0.9817 - recall: 0.9817 - f1_score: 0.9722 - val_loss: 0.0468 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 69ms/epoch - 69ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0205 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9796 - val_loss: 0.0469 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 165ms/epoch - 165ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0192 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9796 - val_loss: 0.0446 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 62ms/epoch - 62ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0177 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - f1_score: 0.9863 - val_loss: 0.0410 - val_accuracy: 0.9636 - val_precision: 0.9636 - val_recall: 0.9636 - val_f1_score: 0.9333 - 70ms/epoch - 70ms/step

🔍 Resultados no Teste:
Loss: 0.0566
Accuracy: 0.9068
Precision: 0.9068
Recall: 0.9068
F1 Score: 0.8493
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
420 420 420
(391, 30) (391, 30) (391, 30)
(391, 90) (391, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 89ms/step
[[0.88684475 0.11315527]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 421 | Acuracia_1: 0.0 | Contagem Geral: 16.0 
Ordem Natural: 19.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_1: 0.0 
Precisao modelo Geral: 59.0164
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
421 421 421
(392, 30) (392, 30) (392, 30)
(392, 90) (392, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.74511325 0.25488675]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 422 | Acuracia_2: 1.0 | Contagem Geral: 16.0 
Ordem Natural: 19.0
Entrada: 2.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_2: 0.5 
Precisao modelo Geral: 58.0645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
422 422 422
(393, 30) (393, 30) (393, 30)
(393, 90) (393, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8086408  0.19135919]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 423 | Acuracia_3: 0.0 | Contagem Geral: 17.0 
Ordem Natural: 19.0
Entrada: 1.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_3: 0.0 
Precisao modelo Geral: 58.7302
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
423 423 423
(394, 30) (394, 30) (394, 30)
(394, 90) (394, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8355334  0.16446666]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 424 | Acuracia_4: 0 | Contagem Geral: 17.0 
Ordem Natural: 19.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_4: 0 
Precisao modelo Geral: 59.375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
424 424 424
(395, 30) (395, 30) (395, 30)
(395, 90) (395, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87544894 0.12455107]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 425 | Acuracia_5: 0 | Contagem Geral: 17.0 
Ordem Natural: 19.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_5: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
425 425 425
(396, 30) (396, 30) (396, 30)
(396, 90) (396, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6731676  0.32683238]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 426 | Acuracia_6: 1.0 | Contagem Geral: 17.0 
Ordem Natural: 19.0
Entrada: 2736.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
426 426 426
(397, 30) (397, 30) (397, 30)
(397, 90) (397, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.65772957 0.34227046]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 427 | Acuracia_7: 0 | Contagem Geral: 18.0 
Ordem Natural: 20.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_7: 0.0 
Precisao modelo Geral: 59.7015
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
427 427 427
(398, 30) (398, 30) (398, 30)
(398, 90) (398, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6199095 0.3800905]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 428 | Acuracia_8: 0 | Contagem Geral: 19.0 
Ordem Natural: 20.0
Entrada: 234.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_8: 1.0 
Precisao modelo Geral: 60.2941
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
428 428 428
(399, 30) (399, 30) (399, 30)
(399, 90) (399, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8496047  0.15039527]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 429 | Acuracia_9: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 21.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_9: 0.0 
Precisao modelo Geral: 60.8696
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
429 429 429
(400, 30) (400, 30) (400, 30)
(400, 90) (400, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94976604 0.05023399]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 430 | Acuracia_10: 1.0 | Contagem Geral: 20.0 
Ordem Natural: 21.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_10: 1.0 
Precisao modelo Geral: 61.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
430 430 430
(401, 30) (401, 30) (401, 30)
(401, 90) (401, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8847171  0.11528286]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 431 | Acuracia_11: 0 | Contagem Geral: 20.0 
Ordem Natural: 21.0
Entrada: 2.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_11: 0 
Precisao modelo Geral: 61.9718
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
431 431 431
(402, 30) (402, 30) (402, 30)
(402, 90) (402, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87029815 0.12970187]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 432 | Acuracia_12: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 21.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_12: 0.0 
Precisao modelo Geral: 62.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
432 432 432
(403, 30) (403, 30) (403, 30)
(403, 90) (403, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.90662897 0.09337101]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 433 | Acuracia_13: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 21.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_13: 0.0 
Precisao modelo Geral: 61.6438
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
433 433 433
(404, 30) (404, 30) (404, 30)
(404, 90) (404, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8928728  0.10712721]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 434 | Acuracia_14: 0 | Contagem Geral: 20.0 
Ordem Natural: 22.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_14: 0 
Precisao modelo Geral: 62.1622
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
434 434 434
(405, 30) (405, 30) (405, 30)
(405, 90) (405, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8463322  0.15366772]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 435 | Acuracia_15: 0 | Contagem Geral: 20.0 
Ordem Natural: 22.0
Entrada: 7.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_15: 0 
Precisao modelo Geral: 61.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
435 435 435
(406, 30) (406, 30) (406, 30)
(406, 90) (406, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.91068566 0.08931434]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 436 | Acuracia_16: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 23.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 35.0 | Acuracia_16: 0.0 
Precisao modelo Geral: 61.8421
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
436 436 436
(407, 30) (407, 30) (407, 30)
(407, 90) (407, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.72195625 0.27804375]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 437 | Acuracia_17: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 23.0
Entrada: 11.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 38.0952 | Acuracia_17: 0.5 
Precisao modelo Geral: 62.3377
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
437 437 437
(408, 30) (408, 30) (408, 30)
(408, 90) (408, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7276611  0.27233896]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 438 | Acuracia_18: 0 | Contagem Geral: 21.0 
Ordem Natural: 24.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 36.3636 | Acuracia_18: 0.0 
Precisao modelo Geral: 61.5385
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
438 438 438
(409, 30) (409, 30) (409, 30)
(409, 90) (409, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5926025  0.40739754]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 439 | Acuracia_19: 0 | Contagem Geral: 22.0 
Ordem Natural: 24.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.7826 | Acuracia_19: 0.0 
Precisao modelo Geral: 60.7595
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
439 439 439
(410, 30) (410, 30) (410, 30)
(410, 90) (410, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.92653155 0.07346848]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 440 | Acuracia_20: 0.0 | Contagem Geral: 23.0 
Ordem Natural: 24.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.7826 | Acuracia_20: 0.0 
Precisao modelo Geral: 61.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
440 440 440
(411, 30) (411, 30) (411, 30)
(411, 90) (411, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.92436033 0.07563965]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 441 | Acuracia_21: 1.0 | Contagem Geral: 23.0 
Ordem Natural: 24.0
Entrada: 8.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.7826 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.4938
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
441 441 441
(412, 30) (412, 30) (412, 30)
(412, 90) (412, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8838635  0.11613647]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 442 | Acuracia_22: 0 | Contagem Geral: 23.0 
Ordem Natural: 25.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.7826 | Acuracia_22: 0 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
442 442 442
(413, 30) (413, 30) (413, 30)
(413, 90) (413, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8839013  0.11609868]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 443 | Acuracia_23: 0 | Contagem Geral: 23.0 
Ordem Natural: 25.0
Entrada: 2.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.7826 | Acuracia_23: 0 
Precisao modelo Geral: 61.4458
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
443 443 443
(414, 30) (414, 30) (414, 30)
(414, 90) (414, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7863542  0.21364585]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 444 | Acuracia_24: 0 | Contagem Geral: 23.0 
Ordem Natural: 25.0
Entrada: 2.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_24: 0.0 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
444 444 444
(415, 30) (415, 30) (415, 30)
(415, 90) (415, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.875977   0.12402305]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 445 | Acuracia_25: 0.0 | Contagem Geral: 24.0 
Ordem Natural: 25.0
Entrada: 18.7
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
445 445 445
(416, 30) (416, 30) (416, 30)
(416, 90) (416, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.962037   0.03796294]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 446 | Acuracia_26: 0.0 | Contagem Geral: 24.0 
Ordem Natural: 26.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_26: 0.0 
Precisao modelo Geral: 59.3023
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
446 446 446
(417, 30) (417, 30) (417, 30)
(417, 90) (417, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6563697 0.3436303]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 447 | Acuracia_27: 0 | Contagem Geral: 24.0 
Ordem Natural: 27.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.0 | Acuracia_27: 0.0 
Precisao modelo Geral: 58.6207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
447 447 447
(418, 30) (418, 30) (418, 30)
(418, 90) (418, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6536287  0.34637126]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 448 | Acuracia_28: 0 | Contagem Geral: 25.0 
Ordem Natural: 27.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_28: 0.0 
Precisao modelo Geral: 57.9545
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
448 448 448
(419, 30) (419, 30) (419, 30)
(419, 90) (419, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9511907  0.04880932]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 449 | Acuracia_29: 0 | Contagem Geral: 26.0 
Ordem Natural: 27.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_29: 0 
Precisao modelo Geral: 58.427
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
449 449 449
(420, 30) (420, 30) (420, 30)
(420, 90) (420, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9414003  0.05859972]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 450 | Acuracia_0: 1.0 | Contagem Geral: 26.0 
Ordem Natural: 27.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_30: 1.0 
Precisao modelo Geral: 58.8889
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
Matrix_30: [(421, 90), (421, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2019 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4667 - val_loss: 0.1640 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2696 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.0000e+00 - val_loss: 0.1603 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.3871 - 71ms/epoch - 71ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1791 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.2642 - val_loss: 0.2256 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.4324 - 69ms/epoch - 69ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1795 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.2513 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 67ms/epoch - 67ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1907 - accuracy: 0.3149 - precision: 0.3149 - recall: 0.3149 - f1_score: 0.4790 - val_loss: 0.2192 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.4267 - 70ms/epoch - 70ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.3191 - precision: 0.3191 - recall: 0.3191 - f1_score: 0.4805 - val_loss: 0.1834 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.4507 - 67ms/epoch - 67ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.4085 - precision: 0.4085 - recall: 0.4085 - f1_score: 0.5123 - val_loss: 0.1608 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.5532 - 72ms/epoch - 72ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1571 - accuracy: 0.7617 - precision: 0.7617 - recall: 0.7617 - f1_score: 0.6706 - val_loss: 0.1488 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.6429 - 70ms/epoch - 70ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1592 - accuracy: 0.7872 - precision: 0.7872 - recall: 0.7872 - f1_score: 0.5833 - val_loss: 0.1431 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.6400 - 68ms/epoch - 68ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1580 - accuracy: 0.7830 - precision: 0.7830 - recall: 0.7830 - f1_score: 0.5405 - val_loss: 0.1416 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.7586 - 69ms/epoch - 69ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1504 - accuracy: 0.8340 - precision: 0.8340 - recall: 0.8340 - f1_score: 0.6880 - val_loss: 0.1455 - val_accuracy: 0.8305 - val_precision: 0.8305 - val_recall: 0.8305 - val_f1_score: 0.7368 - 67ms/epoch - 67ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1391 - accuracy: 0.8340 - precision: 0.8340 - recall: 0.8340 - f1_score: 0.7484 - val_loss: 0.1582 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.5357 - 69ms/epoch - 69ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1325 - accuracy: 0.7404 - precision: 0.7404 - recall: 0.7404 - f1_score: 0.7024 - val_loss: 0.1748 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.5246 - 68ms/epoch - 68ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1341 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.5944 - val_loss: 0.1754 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.5161 - 69ms/epoch - 69ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1315 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.5992 - val_loss: 0.1560 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.5614 - 77ms/epoch - 77ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1211 - accuracy: 0.7064 - precision: 0.7064 - recall: 0.7064 - f1_score: 0.6791 - val_loss: 0.1337 - val_accuracy: 0.7966 - val_precision: 0.7966 - val_recall: 0.7966 - val_f1_score: 0.7143 - 67ms/epoch - 67ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1130 - accuracy: 0.8553 - precision: 0.8553 - recall: 0.8553 - f1_score: 0.8046 - val_loss: 0.1185 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7778 - 68ms/epoch - 68ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1105 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.8158 - val_loss: 0.1105 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8235 - 71ms/epoch - 71ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1079 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8310 - val_loss: 0.1078 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 68ms/epoch - 68ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1014 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - f1_score: 0.8421 - val_loss: 0.1116 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 66ms/epoch - 66ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0952 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - f1_score: 0.8364 - val_loss: 0.1189 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7805 - 69ms/epoch - 69ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0930 - accuracy: 0.8511 - precision: 0.8511 - recall: 0.8511 - f1_score: 0.8023 - val_loss: 0.1170 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7805 - 67ms/epoch - 67ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0895 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - f1_score: 0.8156 - val_loss: 0.1024 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7692 - 70ms/epoch - 70ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0824 - accuracy: 0.8936 - precision: 0.8936 - recall: 0.8936 - f1_score: 0.8485 - val_loss: 0.0873 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 74ms/epoch - 74ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0778 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8774 - val_loss: 0.0790 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 68ms/epoch - 68ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0752 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8784 - val_loss: 0.0769 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 74ms/epoch - 74ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0698 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9007 - val_loss: 0.0811 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 68ms/epoch - 68ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0649 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8820 - val_loss: 0.0858 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.7895 - 69ms/epoch - 69ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0628 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8795 - val_loss: 0.0798 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8108 - 67ms/epoch - 67ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0586 - accuracy: 0.9191 - precision: 0.9191 - recall: 0.9191 - f1_score: 0.8848 - val_loss: 0.0673 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 66ms/epoch - 66ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0540 - accuracy: 0.9362 - precision: 0.9362 - recall: 0.9362 - f1_score: 0.9045 - val_loss: 0.0591 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 67ms/epoch - 67ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0520 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9189 - val_loss: 0.0573 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 69ms/epoch - 69ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0482 - accuracy: 0.9532 - precision: 0.9532 - recall: 0.9532 - f1_score: 0.9262 - val_loss: 0.0610 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 67ms/epoch - 67ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0444 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9351 - val_loss: 0.0639 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 72ms/epoch - 72ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0426 - accuracy: 0.9489 - precision: 0.9489 - recall: 0.9489 - f1_score: 0.9241 - val_loss: 0.0577 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8571 - 69ms/epoch - 69ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0392 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9351 - val_loss: 0.0491 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 69ms/epoch - 69ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0365 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9530 - val_loss: 0.0453 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 75ms/epoch - 75ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9595 - val_loss: 0.0460 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 69ms/epoch - 69ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0318 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0489 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 69ms/epoch - 69ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0300 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9542 - val_loss: 0.0476 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 68ms/epoch - 68ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9745 - precision: 0.9745 - recall: 0.9745 - f1_score: 0.9605 - val_loss: 0.0416 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 68ms/epoch - 68ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0259 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9733 - val_loss: 0.0372 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 69ms/epoch - 69ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0246 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0362 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 68ms/epoch - 68ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0227 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0371 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 66ms/epoch - 66ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0209 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9799 - val_loss: 0.0369 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8824 - 68ms/epoch - 68ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0197 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0336 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9375 - 67ms/epoch - 67ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0181 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9867 - val_loss: 0.0303 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 67ms/epoch - 67ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0169 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0289 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 68ms/epoch - 68ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0156 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0285 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 75ms/epoch - 75ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0143 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9933 - val_loss: 0.0280 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9677 - 67ms/epoch - 67ms/step

🔍 Resultados no Teste:
Loss: 0.0495
Accuracy: 0.9134
Precision: 0.9134
Recall: 0.9134
F1 Score: 0.8736
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
450 450 450
(421, 30) (421, 30) (421, 30)
(421, 90) (421, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 88ms/step
[[0.91236234 0.08763769]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 451 | Acuracia_1: 0.0 | Contagem Geral: 26.0 
Ordem Natural: 27.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_1: 0.0 
Precisao modelo Geral: 59.3407
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
451 451 451
(422, 30) (422, 30) (422, 30)
(422, 90) (422, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8673516  0.13264845]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 452 | Acuracia_2: 0.5 | Contagem Geral: 26.0 
Ordem Natural: 27.0
Entrada: 5.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_2: 0.5 
Precisao modelo Geral: 58.6957
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
452 452 452
(423, 30) (423, 30) (423, 30)
(423, 90) (423, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.804295   0.19570501]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 453 | Acuracia_3: 0.0 | Contagem Geral: 26.0 
Ordem Natural: 28.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_3: 0.0 
Precisao modelo Geral: 59.1398
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
453 453 453
(424, 30) (424, 30) (424, 30)
(424, 90) (424, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7854121  0.21458793]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 454 | Acuracia_4: 0 | Contagem Geral: 26.0 
Ordem Natural: 28.0
Entrada: 5.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_4: 1.0 
Precisao modelo Geral: 59.5745
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
454 454 454
(425, 30) (425, 30) (425, 30)
(425, 90) (425, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8718808  0.12811914]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 455 | Acuracia_5: 0 | Contagem Geral: 27.0 
Ordem Natural: 29.0
Entrada: 1.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_5: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
455 455 455
(426, 30) (426, 30) (426, 30)
(426, 90) (426, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86005056 0.13994943]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 456 | Acuracia_6: 1.0 | Contagem Geral: 27.0 
Ordem Natural: 29.0
Entrada: 2.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.4167
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
456 456 456
(427, 30) (427, 30) (427, 30)
(427, 90) (427, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.775078   0.22492202]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 457 | Acuracia_7: 0.0 | Contagem Geral: 27.0 
Ordem Natural: 29.0
Entrada: 2.75
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_7: 0.0 
Precisao modelo Geral: 59.7938
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
457 457 457
(428, 30) (428, 30) (428, 30)
(428, 90) (428, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[[0.89141524 0.10858474]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 458 | Acuracia_8: 1.0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_8: 1.0 
Precisao modelo Geral: 60.2041
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
458 458 458
(429, 30) (429, 30) (429, 30)
(429, 90) (429, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8589373  0.14106262]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 459 | Acuracia_9: 0.0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_9: 0.0 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
459 459 459
(430, 30) (430, 30) (430, 30)
(430, 90) (430, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8773588  0.12264124]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 460 | Acuracia_10: 1.0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 2.91
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_10: 1.0 
Precisao modelo Geral: 61.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
460 460 460
(431, 30) (431, 30) (431, 30)
(431, 90) (431, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8612927  0.13870727]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 461 | Acuracia_11: 0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_11: 0 
Precisao modelo Geral: 61.3861
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
461 461 461
(432, 30) (432, 30) (432, 30)
(432, 90) (432, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87108475 0.12891525]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 462 | Acuracia_12: 0.0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.1429 | Acuracia_12: 0.0 
Precisao modelo Geral: 61.7647
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
462 462 462
(433, 30) (433, 30) (433, 30)
(433, 90) (433, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7890023  0.21099764]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 463 | Acuracia_13: 0.0 | Contagem Geral: 28.0 
Ordem Natural: 29.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_13: 0.0 
Precisao modelo Geral: 61.165
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
463 463 463
(434, 30) (434, 30) (434, 30)
(434, 90) (434, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.81570524 0.1842948 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 464 | Acuracia_14: 0 | Contagem Geral: 29.0 
Ordem Natural: 29.0
Entrada: 4.11
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_14: 0 
Precisao modelo Geral: 60.5769
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
464 464 464
(435, 30) (435, 30) (435, 30)
(435, 90) (435, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9344943 0.0655057]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 465 | Acuracia_15: 0 | Contagem Geral: 29.0 
Ordem Natural: 30.0
Entrada: 4.11
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_15: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
465 465 465
(436, 30) (436, 30) (436, 30)
(436, 90) (436, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.92394406 0.076056  ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 466 | Acuracia_16: 0.0 | Contagem Geral: 29.0 
Ordem Natural: 31.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.3774
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
466 466 466
(437, 30) (437, 30) (437, 30)
(437, 90) (437, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.88652647 0.11347352]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 467 | Acuracia_17: 0.5 | Contagem Geral: 29.0 
Ordem Natural: 31.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_17: 0.5 
Precisao modelo Geral: 60.7477
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
467 467 467
(438, 30) (438, 30) (438, 30)
(438, 90) (438, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7561148  0.24388528]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 468 | Acuracia_18: 0.0 | Contagem Geral: 29.0 
Ordem Natural: 31.0
Entrada: 1.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_18: 0.0 
Precisao modelo Geral: 60.1852
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
468 468 468
(439, 30) (439, 30) (439, 30)
(439, 90) (439, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.73821735 0.26178265]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 469 | Acuracia_19: 0.0 | Contagem Geral: 30.0 
Ordem Natural: 31.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_19: 0.0 
Precisao modelo Geral: 59.633
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
469 469 469
(440, 30) (440, 30) (440, 30)
(440, 90) (440, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8251451  0.17485487]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 470 | Acuracia_20: 0.0 | Contagem Geral: 31.0 
Ordem Natural: 31.0
Entrada: 3.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_20: 0.0 
Precisao modelo Geral: 59.0909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
470 470 470
(441, 30) (441, 30) (441, 30)
(441, 90) (441, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.84490395 0.15509602]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 471 | Acuracia_21: 1.0 | Contagem Geral: 31.0 
Ordem Natural: 32.0
Entrada: 3.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_21: 1.0 
Precisao modelo Geral: 58.5586
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
471 471 471
(442, 30) (442, 30) (442, 30)
(442, 90) (442, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7885264 0.2114736]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 472 | Acuracia_22: 0 | Contagem Geral: 31.0 
Ordem Natural: 33.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_22: 0.0 
Precisao modelo Geral: 58.0357
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
472 472 472
(443, 30) (443, 30) (443, 30)
(443, 90) (443, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6351448  0.36485517]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 473 | Acuracia_23: 0 | Contagem Geral: 32.0 
Ordem Natural: 33.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_23: 0.0 
Precisao modelo Geral: 57.5221
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
473 473 473
(444, 30) (444, 30) (444, 30)
(444, 90) (444, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.63232815 0.36767188]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 474 | Acuracia_24: 0.0 | Contagem Geral: 33.0 
Ordem Natural: 33.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.4706 | Acuracia_24: 0.0 
Precisao modelo Geral: 57.0175
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
474 474 474
(445, 30) (445, 30) (445, 30)
(445, 90) (445, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8976771  0.10232291]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 475 | Acuracia_25: 0.0 | Contagem Geral: 34.0 
Ordem Natural: 33.0
Entrada: 5.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.4706 | Acuracia_25: 0.0 
Precisao modelo Geral: 56.5217
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
475 475 475
(446, 30) (446, 30) (446, 30)
(446, 90) (446, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8900866  0.10991338]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 476 | Acuracia_26: 0.0 | Contagem Geral: 34.0 
Ordem Natural: 34.0
Entrada: 2.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.4706 | Acuracia_26: 0.0 
Precisao modelo Geral: 56.8966
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
476 476 476
(447, 30) (447, 30) (447, 30)
(447, 90) (447, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87567055 0.12432941]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 477 | Acuracia_27: 0.0 | Contagem Geral: 34.0 
Ordem Natural: 34.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.4706 | Acuracia_27: 0.0 
Precisao modelo Geral: 57.265
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
477 477 477
(448, 30) (448, 30) (448, 30)
(448, 90) (448, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8709033  0.12909667]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 478 | Acuracia_28: 0.0 | Contagem Geral: 34.0 
Ordem Natural: 34.0
Entrada: 1.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.4706 | Acuracia_28: 0.0 
Precisao modelo Geral: 57.6271
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
478 478 478
(449, 30) (449, 30) (449, 30)
(449, 90) (449, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.79433805 0.2056619 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 479 | Acuracia_29: 0 | Contagem Geral: 34.0 
Ordem Natural: 34.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.7143 | Acuracia_29: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
479 479 479
(450, 30) (450, 30) (450, 30)
(450, 90) (450, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6886414  0.31135854]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 480 | Acuracia_0: 1.0 | Contagem Geral: 35.0 
Ordem Natural: 34.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_30: 0.5 
Precisao modelo Geral: 56.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
Matrix_30: [(451, 90), (451, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1984 - accuracy: 0.5516 - precision: 0.5516 - recall: 0.5516 - f1_score: 0.2207 - val_loss: 0.4491 - val_accuracy: 0.2698 - val_precision: 0.2698 - val_recall: 0.2698 - val_f1_score: 0.4250 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3523 - accuracy: 0.3254 - precision: 0.3254 - recall: 0.3254 - f1_score: 0.4880 - val_loss: 0.2189 - val_accuracy: 0.4127 - val_precision: 0.4127 - val_recall: 0.4127 - val_f1_score: 0.4789 - 69ms/epoch - 69ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1876 - accuracy: 0.3889 - precision: 0.3889 - recall: 0.3889 - f1_score: 0.5064 - val_loss: 0.1320 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.4828 - 71ms/epoch - 71ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.6944 - precision: 0.6944 - recall: 0.6944 - f1_score: 0.2524 - val_loss: 0.1264 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.1111 - 69ms/epoch - 69ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2045 - accuracy: 0.6825 - precision: 0.6825 - recall: 0.6825 - f1_score: 0.0244 - val_loss: 0.1232 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.2105 - 69ms/epoch - 69ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1845 - accuracy: 0.6865 - precision: 0.6865 - recall: 0.6865 - f1_score: 0.0482 - val_loss: 0.1281 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.4545 - 68ms/epoch - 68ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - f1_score: 0.3889 - val_loss: 0.1462 - val_accuracy: 0.7302 - val_precision: 0.7302 - val_recall: 0.7302 - val_f1_score: 0.6531 - 70ms/epoch - 70ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1501 - accuracy: 0.7341 - precision: 0.7341 - recall: 0.7341 - f1_score: 0.6763 - val_loss: 0.1693 - val_accuracy: 0.6032 - val_precision: 0.6032 - val_recall: 0.6032 - val_f1_score: 0.5763 - 69ms/epoch - 69ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1546 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.5714 - val_loss: 0.1826 - val_accuracy: 0.5079 - val_precision: 0.5079 - val_recall: 0.5079 - val_f1_score: 0.5231 - 70ms/epoch - 70ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.4563 - precision: 0.4563 - recall: 0.4563 - f1_score: 0.5387 - val_loss: 0.1790 - val_accuracy: 0.5397 - val_precision: 0.5397 - val_recall: 0.5397 - val_f1_score: 0.5397 - 70ms/epoch - 70ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.5567 - val_loss: 0.1613 - val_accuracy: 0.6032 - val_precision: 0.6032 - val_recall: 0.6032 - val_f1_score: 0.5763 - 70ms/epoch - 70ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1425 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.6107 - val_loss: 0.1381 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.6538 - 70ms/epoch - 70ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1301 - accuracy: 0.7579 - precision: 0.7579 - recall: 0.7579 - f1_score: 0.7189 - val_loss: 0.1173 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7805 - 68ms/epoch - 68ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1232 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - f1_score: 0.7771 - val_loss: 0.1033 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7500 - 70ms/epoch - 70ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1231 - accuracy: 0.8373 - precision: 0.8373 - recall: 0.8373 - f1_score: 0.7133 - val_loss: 0.0963 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7097 - 69ms/epoch - 69ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1243 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.6565 - val_loss: 0.0936 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7097 - 70ms/epoch - 70ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1188 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - f1_score: 0.6667 - val_loss: 0.0956 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 68ms/epoch - 68ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1088 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.7643 - val_loss: 0.1037 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7727 - 72ms/epoch - 72ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1025 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - f1_score: 0.8043 - val_loss: 0.1145 - val_accuracy: 0.7937 - val_precision: 0.7937 - val_recall: 0.7937 - val_f1_score: 0.7234 - 68ms/epoch - 68ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1018 - accuracy: 0.8095 - precision: 0.8095 - recall: 0.8095 - f1_score: 0.7670 - val_loss: 0.1205 - val_accuracy: 0.7460 - val_precision: 0.7460 - val_recall: 0.7460 - val_f1_score: 0.6800 - 69ms/epoch - 69ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1019 - accuracy: 0.7817 - precision: 0.7817 - recall: 0.7817 - f1_score: 0.7418 - val_loss: 0.1161 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778 - val_f1_score: 0.7083 - 67ms/epoch - 67ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0978 - accuracy: 0.8056 - precision: 0.8056 - recall: 0.8056 - f1_score: 0.7633 - val_loss: 0.1028 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7391 - 71ms/epoch - 71ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0907 - accuracy: 0.8333 - precision: 0.8333 - recall: 0.8333 - f1_score: 0.7879 - val_loss: 0.0877 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 68ms/epoch - 68ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0858 - accuracy: 0.8611 - precision: 0.8611 - recall: 0.8611 - f1_score: 0.8066 - val_loss: 0.0770 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 74ms/epoch - 74ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0852 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8263 - val_loss: 0.0724 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8889 - 66ms/epoch - 66ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0844 - accuracy: 0.8690 - precision: 0.8690 - recall: 0.8690 - f1_score: 0.7925 - val_loss: 0.0731 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 74ms/epoch - 74ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0799 - accuracy: 0.8849 - precision: 0.8849 - recall: 0.8849 - f1_score: 0.8242 - val_loss: 0.0789 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 98ms/epoch - 98ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0756 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - f1_score: 0.8315 - val_loss: 0.0872 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7727 - 121ms/epoch - 121ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0748 - accuracy: 0.8690 - precision: 0.8690 - recall: 0.8690 - f1_score: 0.8254 - val_loss: 0.0907 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7556 - 99ms/epoch - 99ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0744 - accuracy: 0.8651 - precision: 0.8651 - recall: 0.8651 - f1_score: 0.8229 - val_loss: 0.0852 - val_accuracy: 0.8413 - val_precision: 0.8413 - val_recall: 0.8413 - val_f1_score: 0.7727 - 75ms/epoch - 75ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0711 - accuracy: 0.8690 - precision: 0.8690 - recall: 0.8690 - f1_score: 0.8254 - val_loss: 0.0746 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 70ms/epoch - 70ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0674 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - f1_score: 0.8427 - val_loss: 0.0655 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 72ms/epoch - 72ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0662 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9008 - f1_score: 0.8503 - val_loss: 0.0612 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8649 - 71ms/epoch - 71ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0656 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8606 - val_loss: 0.0616 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 70ms/epoch - 70ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0627 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8623 - val_loss: 0.0661 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 69ms/epoch - 69ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0598 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8736 - val_loss: 0.0714 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 69ms/epoch - 69ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0589 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8667 - val_loss: 0.0721 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 76ms/epoch - 76ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0577 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8667 - val_loss: 0.0666 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.8095 - 69ms/epoch - 69ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0549 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8764 - val_loss: 0.0587 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 77ms/epoch - 77ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0527 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8902 - val_loss: 0.0532 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 71ms/epoch - 71ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0517 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.8994 - val_loss: 0.0517 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 70ms/epoch - 70ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0499 - accuracy: 0.9325 - precision: 0.9325 - recall: 0.9325 - f1_score: 0.8994 - val_loss: 0.0538 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 69ms/epoch - 69ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0474 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8953 - val_loss: 0.0574 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 70ms/epoch - 70ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9143 - val_loss: 0.0586 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 90ms/epoch - 90ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0445 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9143 - val_loss: 0.0547 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 71ms/epoch - 71ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0424 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9143 - val_loss: 0.0485 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 69ms/epoch - 69ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0403 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9249 - val_loss: 0.0437 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 70ms/epoch - 70ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0389 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9112 - val_loss: 0.0418 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 72ms/epoch - 72ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0373 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9286 - val_loss: 0.0426 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8947 - 69ms/epoch - 69ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0352 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9294 - val_loss: 0.0445 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8718 - 70ms/epoch - 70ms/step

🔍 Resultados no Teste:
Loss: 0.0842
Accuracy: 0.8456
Precision: 0.8456
Recall: 0.8456
F1 Score: 0.7640
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
480 480 480
(451, 30) (451, 30) (451, 30)
(451, 90) (451, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 87ms/step
[[0.69311345 0.30688652]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 481 | Acuracia_1: 0.0 | Contagem Geral: 36.0 
Ordem Natural: 34.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.3243 | Acuracia_1: 0.0 
Precisao modelo Geral: 56.1983
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
481 481 481
(452, 30) (452, 30) (452, 30)
(452, 90) (452, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[[0.65910876 0.34089127]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 482 | Acuracia_2: 0.5 | Contagem Geral: 37.0 
Ordem Natural: 34.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.6842 | Acuracia_2: 0.3333 
Precisao modelo Geral: 55.7377
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
482 482 482
(453, 30) (453, 30) (453, 30)
(453, 90) (453, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6700772  0.32992285]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 483 | Acuracia_3: 0.0 | Contagem Geral: 38.0 
Ordem Natural: 34.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_3: 0.0 
Precisao modelo Geral: 55.2846
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
483 483 483
(454, 30) (454, 30) (454, 30)
(454, 90) (454, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9240622  0.07593777]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 484 | Acuracia_4: 1.0 | Contagem Geral: 39.0 
Ordem Natural: 34.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_4: 1.0 
Precisao modelo Geral: 54.8387
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
484 484 484
(455, 30) (455, 30) (455, 30)
(455, 90) (455, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9041578  0.09584222]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 485 | Acuracia_5: 0 | Contagem Geral: 39.0 
Ordem Natural: 35.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_5: 0 
Precisao modelo Geral: 55.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
485 485 485
(456, 30) (456, 30) (456, 30)
(456, 90) (456, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8677983  0.13220173]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 486 | Acuracia_6: 1.0 | Contagem Geral: 39.0 
Ordem Natural: 35.0
Entrada: 2.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_6: 1.0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
486 486 486
(457, 30) (457, 30) (457, 30)
(457, 90) (457, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8065465  0.19345354]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 487 | Acuracia_7: 0.0 | Contagem Geral: 39.0 
Ordem Natural: 35.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_7: 0.0 
Precisao modelo Geral: 55.9055
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
487 487 487
(458, 30) (458, 30) (458, 30)
(458, 90) (458, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8025581  0.19744185]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 488 | Acuracia_8: 1.0 | Contagem Geral: 39.0 
Ordem Natural: 35.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_8: 1.0 
Precisao modelo Geral: 56.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
488 488 488
(459, 30) (459, 30) (459, 30)
(459, 90) (459, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9050092  0.09499081]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 489 | Acuracia_9: 0.0 | Contagem Geral: 39.0 
Ordem Natural: 35.0
Entrada: 298.86
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_9: 0.0 
Precisao modelo Geral: 55.814
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
489 489 489
(460, 30) (460, 30) (460, 30)
(460, 90) (460, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.92626756 0.07373241]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 490 | Acuracia_10: 1.0 | Contagem Geral: 39.0 
Ordem Natural: 36.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_10: 1.0 
Precisao modelo Geral: 56.1538
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
490 490 490
(461, 30) (461, 30) (461, 30)
(461, 90) (461, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8611224  0.13887753]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 491 | Acuracia_11: 0 | Contagem Geral: 39.0 
Ordem Natural: 36.0
Entrada: 11.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_11: 0 
Precisao modelo Geral: 55.7252
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
491 491 491
(462, 30) (462, 30) (462, 30)
(462, 90) (462, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5186567  0.48134336]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 492 | Acuracia_12: 0.0 | Contagem Geral: 39.0 
Ordem Natural: 37.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.5 | Acuracia_12: 0.0 
Precisao modelo Geral: 55.303
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
492 492 492
(463, 30) (463, 30) (463, 30)
(463, 90) (463, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.47704336 0.5229566 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 493 | Acuracia_13: 0.0 | Contagem Geral: 40.0 
Ordem Natural: 37.0
Entrada: 3.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.3902 | Acuracia_13: 0.3333 
Precisao modelo Geral: 55.6391
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
493 493 493
(464, 30) (464, 30) (464, 30)
(464, 90) (464, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.77327734 0.22672264]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 494 | Acuracia_14: 0 | Contagem Geral: 41.0 
Ordem Natural: 38.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_14: 0.0 
Precisao modelo Geral: 55.2239
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
494 494 494
(465, 30) (465, 30) (465, 30)
(465, 90) (465, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.90576357 0.09423643]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 495 | Acuracia_15: 0 | Contagem Geral: 42.0 
Ordem Natural: 38.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_15: 0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
495 495 495
(466, 30) (466, 30) (466, 30)
(466, 90) (466, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8575009  0.14249907]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 496 | Acuracia_16: 0.0 | Contagem Geral: 42.0 
Ordem Natural: 38.0
Entrada: 3.99
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_16: 0.0 
Precisao modelo Geral: 55.1471
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
496 496 496
(467, 30) (467, 30) (467, 30)
(467, 90) (467, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7886511  0.21134889]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 497 | Acuracia_17: 0.5 | Contagem Geral: 42.0 
Ordem Natural: 39.0
Entrada: 2.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.2558 | Acuracia_17: 0.3333 
Precisao modelo Geral: 54.7445
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
497 497 497
(468, 30) (468, 30) (468, 30)
(468, 90) (468, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6871378  0.31286225]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 498 | Acuracia_18: 0.0 | Contagem Geral: 43.0 
Ordem Natural: 39.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_18: 0.0 
Precisao modelo Geral: 54.3478
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
498 498 498
(469, 30) (469, 30) (469, 30)
(469, 90) (469, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.803502  0.1964979]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 499 | Acuracia_19: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 39.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_19: 0.0 
Precisao modelo Geral: 54.6763
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
499 499 499
(470, 30) (470, 30) (470, 30)
(470, 90) (470, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.85681534 0.14318459]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 500 | Acuracia_20: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 39.0
Entrada: 8.28
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_20: 0.0 
Precisao modelo Geral: 54.2857
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
500 500 500
(471, 30) (471, 30) (471, 30)
(471, 90) (471, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
[[0.9093319  0.09066804]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 501 | Acuracia_21: 1.0 | Contagem Geral: 44.0 
Ordem Natural: 40.0
Entrada: 11.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_21: 1.0 
Precisao modelo Geral: 53.9007
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
501 501 501
(472, 30) (472, 30) (472, 30)
(472, 90) (472, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8462077  0.15379234]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 502 | Acuracia_22: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 41.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_22: 0.0 
Precisao modelo Geral: 54.2254
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
502 502 502
(473, 30) (473, 30) (473, 30)
(473, 90) (473, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.61586714 0.38413286]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 503 | Acuracia_23: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 41.0
Entrada: 12.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4444 | Acuracia_23: 0.5 
Precisao modelo Geral: 54.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
503 503 503
(474, 30) (474, 30) (474, 30)
(474, 90) (474, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.78005576 0.21994427]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 504 | Acuracia_24: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 42.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_24: 0.0 
Precisao modelo Geral: 54.1667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
504 504 504
(475, 30) (475, 30) (475, 30)
(475, 90) (475, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.88826597 0.111734  ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 505 | Acuracia_25: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 42.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_25: 0.0 
Precisao modelo Geral: 54.4828
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
505 505 505
(476, 30) (476, 30) (476, 30)
(476, 90) (476, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8254822  0.17451778]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 506 | Acuracia_26: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 42.0
Entrada: 2.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_26: 0.0 
Precisao modelo Geral: 54.7945
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
506 506 506
(477, 30) (477, 30) (477, 30)
(477, 90) (477, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.804018   0.19598192]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 507 | Acuracia_27: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 42.0
Entrada: 1.72
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_27: 0.0 
Precisao modelo Geral: 55.102
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
507 507 507
(478, 30) (478, 30) (478, 30)
(478, 90) (478, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8733134  0.12668653]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 508 | Acuracia_28: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 42.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_28: 0.0 
Precisao modelo Geral: 54.7297
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
508 508 508
(479, 30) (479, 30) (479, 30)
(479, 90) (479, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9059724  0.09402753]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 509 | Acuracia_29: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 43.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_29: 0.0 
Precisao modelo Geral: 55.0336
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
509 509 509
(480, 30) (480, 30) (480, 30)
(480, 90) (480, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94772834 0.05227169]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 510 | Acuracia_0: 0.5 | Contagem Geral: 46.0 
Ordem Natural: 43.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_30: 0.5 
Precisao modelo Geral: 55.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
510 510 510
(481, 30) (481, 30) (481, 30)
(481, 90) (481, 30)
Matrix_30: [(481, 90), (481, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1919 - accuracy: 0.3433 - precision: 0.3433 - recall: 0.3433 - f1_score: 0.4854 - val_loss: 0.1591 - val_accuracy: 0.6912 - val_precision: 0.6912 - val_recall: 0.6912 - val_f1_score: 0.0870 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2122 - accuracy: 0.6828 - precision: 0.6828 - recall: 0.6828 - f1_score: 0.0659 - val_loss: 0.1437 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.5143 - 70ms/epoch - 70ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.7463 - precision: 0.7463 - recall: 0.7463 - f1_score: 0.5000 - val_loss: 0.1670 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.5867 - 112ms/epoch - 112ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1487 - accuracy: 0.5709 - precision: 0.5709 - recall: 0.5709 - f1_score: 0.5907 - val_loss: 0.1892 - val_accuracy: 0.3676 - val_precision: 0.3676 - val_recall: 0.3676 - val_f1_score: 0.5057 - 104ms/epoch - 104ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.3955 - precision: 0.3955 - recall: 0.3955 - f1_score: 0.5120 - val_loss: 0.1769 - val_accuracy: 0.4853 - val_precision: 0.4853 - val_recall: 0.4853 - val_f1_score: 0.5570 - 70ms/epoch - 70ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1467 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - f1_score: 0.5556 - val_loss: 0.1507 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765 - val_f1_score: 0.6667 - 70ms/epoch - 70ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1331 - accuracy: 0.7090 - precision: 0.7090 - recall: 0.7090 - f1_score: 0.6829 - val_loss: 0.1300 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8462 - 71ms/epoch - 71ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1260 - accuracy: 0.8694 - precision: 0.8694 - recall: 0.8694 - f1_score: 0.8108 - val_loss: 0.1186 - val_accuracy: 0.8088 - val_precision: 0.8088 - val_recall: 0.8088 - val_f1_score: 0.6486 - 72ms/epoch - 72ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1244 - accuracy: 0.8694 - precision: 0.8694 - recall: 0.8694 - f1_score: 0.7651 - val_loss: 0.1122 - val_accuracy: 0.8088 - val_precision: 0.8088 - val_recall: 0.8088 - val_f1_score: 0.6486 - 71ms/epoch - 71ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1197 - accuracy: 0.8619 - precision: 0.8619 - recall: 0.8619 - f1_score: 0.7448 - val_loss: 0.1088 - val_accuracy: 0.8382 - val_precision: 0.8382 - val_recall: 0.8382 - val_f1_score: 0.7442 - 72ms/epoch - 72ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1095 - accuracy: 0.9030 - precision: 0.9030 - recall: 0.9030 - f1_score: 0.8395 - val_loss: 0.1105 - val_accuracy: 0.8676 - val_precision: 0.8676 - val_recall: 0.8676 - val_f1_score: 0.8302 - 71ms/epoch - 71ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1003 - accuracy: 0.8731 - precision: 0.8731 - recall: 0.8731 - f1_score: 0.8247 - val_loss: 0.1167 - val_accuracy: 0.8088 - val_precision: 0.8088 - val_recall: 0.8088 - val_f1_score: 0.7719 - 70ms/epoch - 70ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0967 - accuracy: 0.8284 - precision: 0.8284 - recall: 0.8284 - f1_score: 0.7850 - val_loss: 0.1159 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.7333 - 70ms/epoch - 70ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0926 - accuracy: 0.8209 - precision: 0.8209 - recall: 0.8209 - f1_score: 0.7778 - val_loss: 0.1020 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529 - val_f1_score: 0.8148 - 70ms/epoch - 70ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0837 - accuracy: 0.8657 - precision: 0.8657 - recall: 0.8657 - f1_score: 0.8218 - val_loss: 0.0866 - val_accuracy: 0.8676 - val_precision: 0.8676 - val_recall: 0.8676 - val_f1_score: 0.8085 - 71ms/epoch - 71ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0775 - accuracy: 0.8993 - precision: 0.8993 - recall: 0.8993 - f1_score: 0.8457 - val_loss: 0.0787 - val_accuracy: 0.8676 - val_precision: 0.8676 - val_recall: 0.8676 - val_f1_score: 0.7907 - 70ms/epoch - 70ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0756 - accuracy: 0.9254 - precision: 0.9254 - recall: 0.9254 - f1_score: 0.8810 - val_loss: 0.0756 - val_accuracy: 0.8676 - val_precision: 0.8676 - val_recall: 0.8676 - val_f1_score: 0.8000 - 72ms/epoch - 72ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0695 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.8605 - val_loss: 0.0783 - val_accuracy: 0.8971 - val_precision: 0.8971 - val_recall: 0.8971 - val_f1_score: 0.8571 - 69ms/epoch - 69ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0631 - accuracy: 0.9216 - precision: 0.9216 - recall: 0.9216 - f1_score: 0.8852 - val_loss: 0.0842 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529 - val_f1_score: 0.8077 - 71ms/epoch - 71ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0618 - accuracy: 0.8881 - precision: 0.8881 - recall: 0.8881 - f1_score: 0.8485 - val_loss: 0.0783 - val_accuracy: 0.8676 - val_precision: 0.8676 - val_recall: 0.8676 - val_f1_score: 0.8235 - 69ms/epoch - 69ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0573 - accuracy: 0.9030 - precision: 0.9030 - recall: 0.9030 - f1_score: 0.8660 - val_loss: 0.0653 - val_accuracy: 0.8971 - val_precision: 0.8971 - val_recall: 0.8971 - val_f1_score: 0.8511 - 71ms/epoch - 71ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0521 - accuracy: 0.9216 - precision: 0.9216 - recall: 0.9216 - f1_score: 0.8840 - val_loss: 0.0580 - val_accuracy: 0.9118 - val_precision: 0.9118 - val_recall: 0.9118 - val_f1_score: 0.8636 - 69ms/epoch - 69ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0509 - accuracy: 0.9291 - precision: 0.9291 - recall: 0.9291 - f1_score: 0.8889 - val_loss: 0.0553 - val_accuracy: 0.9118 - val_precision: 0.9118 - val_recall: 0.9118 - val_f1_score: 0.8636 - 72ms/epoch - 72ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0472 - accuracy: 0.9366 - precision: 0.9366 - recall: 0.9366 - f1_score: 0.9017 - val_loss: 0.0570 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9130 - 71ms/epoch - 71ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0432 - accuracy: 0.9328 - precision: 0.9328 - recall: 0.9328 - f1_score: 0.9011 - val_loss: 0.0597 - val_accuracy: 0.9118 - val_precision: 0.9118 - val_recall: 0.9118 - val_f1_score: 0.8750 - 72ms/epoch - 72ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0420 - accuracy: 0.9328 - precision: 0.9328 - recall: 0.9328 - f1_score: 0.9032 - val_loss: 0.0542 - val_accuracy: 0.9265 - val_precision: 0.9265 - val_recall: 0.9265 - val_f1_score: 0.8936 - 72ms/epoch - 72ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0387 - accuracy: 0.9403 - precision: 0.9403 - recall: 0.9403 - f1_score: 0.9130 - val_loss: 0.0453 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9130 - 71ms/epoch - 71ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0356 - accuracy: 0.9590 - precision: 0.9590 - recall: 0.9590 - f1_score: 0.9371 - val_loss: 0.0405 - val_accuracy: 0.9265 - val_precision: 0.9265 - val_recall: 0.9265 - val_f1_score: 0.8889 - 71ms/epoch - 71ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0344 - accuracy: 0.9739 - precision: 0.9739 - recall: 0.9739 - f1_score: 0.9591 - val_loss: 0.0387 - val_accuracy: 0.9412 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9130 - 69ms/epoch - 69ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0314 - accuracy: 0.9776 - precision: 0.9776 - recall: 0.9776 - f1_score: 0.9651 - val_loss: 0.0401 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 70ms/epoch - 70ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0290 - accuracy: 0.9627 - precision: 0.9627 - recall: 0.9627 - f1_score: 0.9432 - val_loss: 0.0407 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 68ms/epoch - 68ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0277 - accuracy: 0.9664 - precision: 0.9664 - recall: 0.9664 - f1_score: 0.9492 - val_loss: 0.0361 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 71ms/epoch - 71ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0252 - accuracy: 0.9776 - precision: 0.9776 - recall: 0.9776 - f1_score: 0.9651 - val_loss: 0.0305 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 73ms/epoch - 73ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0233 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9765 - val_loss: 0.0274 - val_accuracy: 0.9706 - val_precision: 0.9706 - val_recall: 0.9706 - val_f1_score: 0.9545 - 83ms/epoch - 83ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0221 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9765 - val_loss: 0.0266 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 74ms/epoch - 74ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0200 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9765 - val_loss: 0.0275 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0185 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - f1_score: 0.9884 - val_loss: 0.0275 - val_accuracy: 0.9559 - val_precision: 0.9559 - val_recall: 0.9559 - val_f1_score: 0.9362 - 72ms/epoch - 72ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - f1_score: 0.9884 - val_loss: 0.0245 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 71ms/epoch - 71ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0159 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - f1_score: 0.9884 - val_loss: 0.0211 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 79ms/epoch - 79ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0147 - accuracy: 0.9888 - precision: 0.9888 - recall: 0.9888 - f1_score: 0.9825 - val_loss: 0.0193 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 70ms/epoch - 70ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0140 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - f1_score: 0.9882 - val_loss: 0.0188 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 73ms/epoch - 73ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0128 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 72ms/epoch - 72ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 70ms/epoch - 70ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0112 - accuracy: 0.9963 - precision: 0.9963 - recall: 0.9963 - f1_score: 0.9942 - val_loss: 0.0175 - val_accuracy: 0.9853 - val_precision: 0.9853 - val_recall: 0.9853 - val_f1_score: 0.9778 - 70ms/epoch - 70ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0103 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 70ms/epoch - 70ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0095 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 68ms/epoch - 68ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0091 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 72ms/epoch - 72ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0084 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 71ms/epoch - 71ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0078 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 74ms/epoch - 74ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0074 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - 72ms/epoch - 72ms/step

🔍 Resultados no Teste:
Loss: 0.0636
Accuracy: 0.9172
Precision: 0.9172
Recall: 0.9172
F1 Score: 0.8571
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
510 510 510
(481, 30) (481, 30) (481, 30)
(481, 90) (481, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.97840905 0.02159096]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 511 | Acuracia_1: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 43.0
Entrada: 37.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_1: 0.0 
Precisao modelo Geral: 54.9669
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
511 511 511
(482, 30) (482, 30) (482, 30)
(482, 90) (482, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8002056  0.19979446]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 512 | Acuracia_2: 0.3333 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_2: 0.3333 
Precisao modelo Geral: 55.2632
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
512 512 512
(483, 30) (483, 30) (483, 30)
(483, 90) (483, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95705783 0.04294218]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 513 | Acuracia_3: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_3: 0.0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
513 513 513
(484, 30) (484, 30) (484, 30)
(484, 90) (484, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9936492  0.00635084]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 514 | Acuracia_4: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_4: 1.0 
Precisao modelo Geral: 55.8442
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
514 514 514
(485, 30) (485, 30) (485, 30)
(485, 90) (485, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98817    0.01183003]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 515 | Acuracia_5: 0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_5: 0 
Precisao modelo Geral: 56.129
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
515 515 515
(486, 30) (486, 30) (486, 30)
(486, 90) (486, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98191434 0.0180857 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 516 | Acuracia_6: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_6: 1.0 
Precisao modelo Geral: 56.4103
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
516 516 516
(487, 30) (487, 30) (487, 30)
(487, 90) (487, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8259725  0.17402749]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 517 | Acuracia_7: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_7: 0.0 
Precisao modelo Geral: 56.6879
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
517 517 517
(488, 30) (488, 30) (488, 30)
(488, 90) (488, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9598679  0.04013206]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 518 | Acuracia_8: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 2.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_8: 1.0 
Precisao modelo Geral: 56.962
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
518 518 518
(489, 30) (489, 30) (489, 30)
(489, 90) (489, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.956474   0.04352596]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 519 | Acuracia_9: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 44.0
Entrada: 6.97
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_9: 0.0 
Precisao modelo Geral: 56.6038
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
519 519 519
(490, 30) (490, 30) (490, 30)
(490, 90) (490, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98795575 0.01204425]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 520 | Acuracia_10: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 45.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_10: 1.0 
Precisao modelo Geral: 56.875
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
520 520 520
(491, 30) (491, 30) (491, 30)
(491, 90) (491, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99401146 0.00598855]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 521 | Acuracia_11: 0 | Contagem Geral: 46.0 
Ordem Natural: 45.0
Entrada: 22.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_11: 0 
Precisao modelo Geral: 56.5217
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
521 521 521
(492, 30) (492, 30) (492, 30)
(492, 90) (492, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9457075  0.05429252]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 522 | Acuracia_12: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 46.0
Entrada: 4.81
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_12: 0.0 
Precisao modelo Geral: 56.1728
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
522 522 522
(493, 30) (493, 30) (493, 30)
(493, 90) (493, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9752916  0.02470842]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 523 | Acuracia_13: 0.3333 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_13: 0.3333 
Precisao modelo Geral: 56.4417
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
523 523 523
(494, 30) (494, 30) (494, 30)
(494, 90) (494, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9282766  0.07172338]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 524 | Acuracia_14: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_14: 0.0 
Precisao modelo Geral: 56.7073
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
524 524 524
(495, 30) (495, 30) (495, 30)
(495, 90) (495, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9239749  0.07602512]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 525 | Acuracia_15: 0 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_15: 0 
Precisao modelo Geral: 56.9697
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
525 525 525
(496, 30) (496, 30) (496, 30)
(496, 90) (496, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9860744  0.01392556]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 526 | Acuracia_16: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_16: 0.0 
Precisao modelo Geral: 57.2289
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
526 526 526
(497, 30) (497, 30) (497, 30)
(497, 90) (497, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.969202   0.03079807]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 527 | Acuracia_17: 0.3333 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.913 | Acuracia_17: 0.3333 
Precisao modelo Geral: 57.485
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
527 527 527
(498, 30) (498, 30) (498, 30)
(498, 90) (498, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.76789504 0.23210499]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 528 | Acuracia_18: 0.0 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_18: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
528 528 528
(499, 30) (499, 30) (499, 30)
(499, 90) (499, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.92775935 0.07224064]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 529 | Acuracia_19: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_19: 0.0 
Precisao modelo Geral: 57.3964
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
529 529 529
(500, 30) (500, 30) (500, 30)
(500, 90) (500, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.957531   0.04246909]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 530 | Acuracia_20: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada: 5.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_20: 0.0 
Precisao modelo Geral: 57.0588
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
530 530 530
(501, 30) (501, 30) (501, 30)
(501, 90) (501, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95715564 0.04284431]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 531 | Acuracia_21: 1.0 | Contagem Geral: 47.0 
Ordem Natural: 48.0
Entrada: 3.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_21: 1.0 
Precisao modelo Geral: 56.7251
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
531 531 531
(502, 30) (502, 30) (502, 30)
(502, 90) (502, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9911479  0.00885211]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 532 | Acuracia_22: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 49.0
Entrada: 5.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_22: 0.0 
Precisao modelo Geral: 56.3953
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
532 532 532
(503, 30) (503, 30) (503, 30)
(503, 90) (503, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98344684 0.01655319]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 533 | Acuracia_23: 0.5 | Contagem Geral: 47.0 
Ordem Natural: 50.0
Entrada: 5.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_23: 0.5 
Precisao modelo Geral: 56.0694
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
533 533 533
(504, 30) (504, 30) (504, 30)
(504, 90) (504, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8943879 0.1056121]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 534 | Acuracia_24: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_24: 0.0 
Precisao modelo Geral: 56.3218
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
534 534 534
(505, 30) (505, 30) (505, 30)
(505, 90) (505, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9223597  0.07764031]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 535 | Acuracia_25: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 2.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_25: 0.0 
Precisao modelo Geral: 56.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
535 535 535
(506, 30) (506, 30) (506, 30)
(506, 90) (506, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9003348  0.09966526]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 536 | Acuracia_26: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_26: 0.0 
Precisao modelo Geral: 56.8182
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
536 536 536
(507, 30) (507, 30) (507, 30)
(507, 90) (507, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96435845 0.0356415 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 537 | Acuracia_27: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_27: 0.0 
Precisao modelo Geral: 57.0621
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
537 537 537
(508, 30) (508, 30) (508, 30)
(508, 90) (508, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9337838  0.06621612]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 538 | Acuracia_28: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_28: 0.0 
Precisao modelo Geral: 57.3034
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
538 538 538
(509, 30) (509, 30) (509, 30)
(509, 90) (509, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8583253  0.14167467]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 539 | Acuracia_29: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_29: 0.0 
Precisao modelo Geral: 57.5419
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
539 539 539
(510, 30) (510, 30) (510, 30)
(510, 90) (510, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9764608  0.02353916]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 540 | Acuracia_0: 0.5 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_30: 0.5 
Precisao modelo Geral: 57.7778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
540 540 540
(511, 30) (511, 30) (511, 30)
(511, 90) (511, 30)
Matrix_30: [(511, 90), (511, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1885 - accuracy: 0.5333 - precision: 0.5333 - recall: 0.5333 - f1_score: 0.2888 - val_loss: 0.2474 - val_accuracy: 0.3611 - val_precision: 0.3611 - val_recall: 0.3611 - val_f1_score: 0.5306 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2067 - accuracy: 0.3123 - precision: 0.3123 - recall: 0.3123 - f1_score: 0.4703 - val_loss: 0.1701 - val_accuracy: 0.5139 - val_precision: 0.5139 - val_recall: 0.5139 - val_f1_score: 0.5333 - 71ms/epoch - 71ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.5684 - precision: 0.5684 - recall: 0.5684 - f1_score: 0.5393 - val_loss: 0.1524 - val_accuracy: 0.6528 - val_precision: 0.6528 - val_recall: 0.6528 - val_f1_score: 0.0741 - 69ms/epoch - 69ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.7684 - precision: 0.7684 - recall: 0.7684 - f1_score: 0.4211 - val_loss: 0.1504 - val_accuracy: 0.6528 - val_precision: 0.6528 - val_recall: 0.6528 - val_f1_score: 0.0741 - 71ms/epoch - 71ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.7368 - precision: 0.7368 - recall: 0.7368 - f1_score: 0.2718 - val_loss: 0.1438 - val_accuracy: 0.6528 - val_precision: 0.6528 - val_recall: 0.6528 - val_f1_score: 0.0741 - 70ms/epoch - 70ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1469 - accuracy: 0.7754 - precision: 0.7754 - recall: 0.7754 - f1_score: 0.4921 - val_loss: 0.1446 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056 - val_f1_score: 0.7083 - 70ms/epoch - 70ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1366 - accuracy: 0.8175 - precision: 0.8175 - recall: 0.8175 - f1_score: 0.7292 - val_loss: 0.1536 - val_accuracy: 0.6806 - val_precision: 0.6806 - val_recall: 0.6806 - val_f1_score: 0.6933 - 70ms/epoch - 70ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1360 - accuracy: 0.7193 - precision: 0.7193 - recall: 0.7193 - f1_score: 0.6748 - val_loss: 0.1554 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389 - val_f1_score: 0.6667 - 71ms/epoch - 71ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1344 - accuracy: 0.6912 - precision: 0.6912 - recall: 0.6912 - f1_score: 0.6589 - val_loss: 0.1423 - val_accuracy: 0.7361 - val_precision: 0.7361 - val_recall: 0.7361 - val_f1_score: 0.7324 - 69ms/epoch - 69ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1250 - accuracy: 0.7649 - precision: 0.7649 - recall: 0.7649 - f1_score: 0.7149 - val_loss: 0.1245 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8302 - 71ms/epoch - 71ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1145 - accuracy: 0.8456 - precision: 0.8456 - recall: 0.8456 - f1_score: 0.7778 - val_loss: 0.1138 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8085 - 70ms/epoch - 70ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1100 - accuracy: 0.8982 - precision: 0.8982 - recall: 0.8982 - f1_score: 0.8221 - val_loss: 0.1090 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8000 - 72ms/epoch - 72ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1066 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - f1_score: 0.8235 - val_loss: 0.1021 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8085 - 72ms/epoch - 72ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0956 - accuracy: 0.9088 - precision: 0.9088 - recall: 0.9088 - f1_score: 0.8434 - val_loss: 0.0995 - val_accuracy: 0.8472 - val_precision: 0.8472 - val_recall: 0.8472 - val_f1_score: 0.7925 - 71ms/epoch - 71ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0860 - accuracy: 0.8947 - precision: 0.8947 - recall: 0.8947 - f1_score: 0.8454 - val_loss: 0.1027 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7931 - 72ms/epoch - 72ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0828 - accuracy: 0.8526 - precision: 0.8526 - recall: 0.8526 - f1_score: 0.8019 - val_loss: 0.0959 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7857 - 70ms/epoch - 70ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0747 - accuracy: 0.8702 - precision: 0.8702 - recall: 0.8702 - f1_score: 0.8213 - val_loss: 0.0858 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8235 - 70ms/epoch - 70ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0663 - accuracy: 0.9228 - precision: 0.9228 - recall: 0.9228 - f1_score: 0.8791 - val_loss: 0.0854 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8261 - 72ms/epoch - 72ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0652 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - f1_score: 0.9176 - val_loss: 0.0808 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8163 - 71ms/epoch - 71ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0579 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - f1_score: 0.9240 - val_loss: 0.0791 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8302 - 71ms/epoch - 71ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0531 - accuracy: 0.9263 - precision: 0.9263 - recall: 0.9263 - f1_score: 0.8901 - val_loss: 0.0796 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7857 - 72ms/epoch - 72ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0513 - accuracy: 0.9088 - precision: 0.9088 - recall: 0.9088 - f1_score: 0.8673 - val_loss: 0.0735 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8462 - 70ms/epoch - 70ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0447 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - f1_score: 0.9239 - val_loss: 0.0737 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8333 - 72ms/epoch - 72ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0426 - accuracy: 0.9614 - precision: 0.9614 - recall: 0.9614 - f1_score: 0.9364 - val_loss: 0.0729 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8333 - 70ms/epoch - 70ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0393 - accuracy: 0.9614 - precision: 0.9614 - recall: 0.9614 - f1_score: 0.9364 - val_loss: 0.0684 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8627 - 73ms/epoch - 73ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0344 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - f1_score: 0.9497 - val_loss: 0.0681 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8302 - 72ms/epoch - 72ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0333 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - f1_score: 0.9297 - val_loss: 0.0659 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8627 - 82ms/epoch - 82ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0289 - accuracy: 0.9754 - precision: 0.9754 - recall: 0.9754 - f1_score: 0.9609 - val_loss: 0.0681 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0264 - accuracy: 0.9719 - precision: 0.9719 - recall: 0.9719 - f1_score: 0.9540 - val_loss: 0.0690 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 72ms/epoch - 72ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0245 - accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860 - f1_score: 0.9767 - val_loss: 0.0631 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 71ms/epoch - 71ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0209 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - f1_score: 0.9714 - val_loss: 0.0599 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8800 - 73ms/epoch - 73ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0199 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - f1_score: 0.9888 - val_loss: 0.0588 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0173 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - f1_score: 0.9888 - val_loss: 0.0619 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0153 - accuracy: 0.9965 - precision: 0.9965 - recall: 0.9965 - f1_score: 0.9943 - val_loss: 0.0645 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8511 - 71ms/epoch - 71ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0143 - accuracy: 0.9965 - precision: 0.9965 - recall: 0.9965 - f1_score: 0.9943 - val_loss: 0.0588 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8750 - 72ms/epoch - 72ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0121 - accuracy: 0.9965 - precision: 0.9965 - recall: 0.9965 - f1_score: 0.9943 - val_loss: 0.0529 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 74ms/epoch - 74ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8571 - 71ms/epoch - 71ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0101 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8511 - 71ms/epoch - 71ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0085 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8511 - 71ms/epoch - 71ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0080 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8511 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0071 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9028 - val_precision: 0.9028 - val_recall: 0.9028 - val_f1_score: 0.8511 - 72ms/epoch - 72ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8750 - 72ms/epoch - 72ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0057 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8750 - 70ms/epoch - 70ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9306 - val_precision: 0.9306 - val_recall: 0.9306 - val_f1_score: 0.8936 - 73ms/epoch - 73ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0044 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8696 - 72ms/epoch - 72ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0042 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9306 - val_precision: 0.9306 - val_recall: 0.9306 - val_f1_score: 0.8936 - 71ms/epoch - 71ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9306 - val_precision: 0.9306 - val_recall: 0.9306 - val_f1_score: 0.8936 - 72ms/epoch - 72ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0034 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9306 - val_precision: 0.9306 - val_recall: 0.9306 - val_f1_score: 0.8936 - 72ms/epoch - 72ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444 - val_f1_score: 0.9167 - 71ms/epoch - 71ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0030 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9306 - val_precision: 0.9306 - val_recall: 0.9306 - val_f1_score: 0.8936 - 71ms/epoch - 71ms/step

🔍 Resultados no Teste:
Loss: 0.0449
Accuracy: 0.9351
Precision: 0.9351
Recall: 0.9351
F1 Score: 0.8837
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
540 540 540
(511, 30) (511, 30) (511, 30)
(511, 90) (511, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 87ms/step
[[0.9968725  0.00312756]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 541 | Acuracia_1: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 51.0
Entrada: 9.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_1: 0.0 
Precisao modelo Geral: 57.4586
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
541 541 541
(512, 30) (512, 30) (512, 30)
(512, 90) (512, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.988618   0.01138201]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 542 | Acuracia_2: 0.3333 | Contagem Geral: 47.0 
Ordem Natural: 52.0
Entrada: 2.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_2: 0.3333 
Precisao modelo Geral: 57.6923
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
542 542 542
(513, 30) (513, 30) (513, 30)
(513, 90) (513, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99142796 0.00857196]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 543 | Acuracia_3: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 52.0
Entrada: 11.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_3: 0.0 
Precisao modelo Geral: 57.377
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
543 543 543
(514, 30) (514, 30) (514, 30)
(514, 90) (514, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9651055  0.03489457]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 544 | Acuracia_4: 1.0 | Contagem Geral: 47.0 
Ordem Natural: 53.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_4: 1.0 
Precisao modelo Geral: 57.6087
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
544 544 544
(515, 30) (515, 30) (515, 30)
(515, 90) (515, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96628755 0.03371241]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 545 | Acuracia_5: 0 | Contagem Geral: 47.0 
Ordem Natural: 53.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_5: 0 
Precisao modelo Geral: 57.8378
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
545 545 545
(516, 30) (516, 30) (516, 30)
(516, 90) (516, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.929155   0.07084506]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 546 | Acuracia_6: 1.0 | Contagem Geral: 47.0 
Ordem Natural: 53.0
Entrada: 2.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.4043 | Acuracia_6: 1.0 
Precisao modelo Geral: 58.0645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
546 546 546
(517, 30) (517, 30) (517, 30)
(517, 90) (517, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.66915387 0.33084613]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 547 | Acuracia_7: 0.0 | Contagem Geral: 47.0 
Ordem Natural: 53.0
Entrada: 3.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_7: 0.3333 
Precisao modelo Geral: 58.2888
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
547 547 547
(518, 30) (518, 30) (518, 30)
(518, 90) (518, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.949746   0.05025395]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 548 | Acuracia_8: 1.0 | Contagem Geral: 48.0 
Ordem Natural: 54.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_8: 1.0 
Precisao modelo Geral: 58.5106
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
548 548 548
(519, 30) (519, 30) (519, 30)
(519, 90) (519, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8798061  0.12019387]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 549 | Acuracia_9: 0.0 | Contagem Geral: 48.0 
Ordem Natural: 54.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_9: 0.0 
Precisao modelo Geral: 58.7302
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
549 549 549
(520, 30) (520, 30) (520, 30)
(520, 90) (520, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.715935   0.28406504]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 550 | Acuracia_10: 1.0 | Contagem Geral: 48.0 
Ordem Natural: 54.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_10: 0.5 
Precisao modelo Geral: 58.4211
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
550 550 550
(521, 30) (521, 30) (521, 30)
(521, 90) (521, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9947351  0.00526488]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 551 | Acuracia_11: 0 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_11: 0 
Precisao modelo Geral: 58.6387
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
551 551 551
(522, 30) (522, 30) (522, 30)
(522, 90) (522, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99640864 0.00359132]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 552 | Acuracia_12: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 2.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_12: 0.0 
Precisao modelo Geral: 58.8542
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
552 552 552
(523, 30) (523, 30) (523, 30)
(523, 90) (523, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97784287 0.02215717]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 553 | Acuracia_13: 0.3333 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_13: 0.3333 
Precisao modelo Geral: 59.0674
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
553 553 553
(524, 30) (524, 30) (524, 30)
(524, 90) (524, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9812904 0.0187096]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 554 | Acuracia_14: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_14: 0.0 
Precisao modelo Geral: 59.2784
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
554 554 554
(525, 30) (525, 30) (525, 30)
(525, 90) (525, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9743935 0.0256065]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 555 | Acuracia_15: 0 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_15: 0 
Precisao modelo Geral: 59.4872
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
555 555 555
(526, 30) (526, 30) (526, 30)
(526, 90) (526, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9581511  0.04184892]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 556 | Acuracia_16: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 1.92
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.6939
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
556 556 556
(527, 30) (527, 30) (527, 30)
(527, 90) (527, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96288997 0.03710997]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 557 | Acuracia_17: 0.3333 | Contagem Geral: 49.0 
Ordem Natural: 54.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_17: 0.3333 
Precisao modelo Geral: 59.3909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
557 557 557
(528, 30) (528, 30) (528, 30)
(528, 90) (528, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.80929255 0.19070746]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 558 | Acuracia_18: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 55.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.4898 | Acuracia_18: 0.0 
Precisao modelo Geral: 59.596
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
558 558 558
(529, 30) (529, 30) (529, 30)
(529, 90) (529, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7962102  0.20378985]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 559 | Acuracia_19: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 55.0
Entrada: 2.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_19: 0.0 
Precisao modelo Geral: 59.2965
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
559 559 559
(530, 30) (530, 30) (530, 30)
(530, 90) (530, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89250946 0.10749058]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 560 | Acuracia_20: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 55.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_20: 0.0 
Precisao modelo Geral: 59.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
560 560 560
(531, 30) (531, 30) (531, 30)
(531, 90) (531, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.954295   0.04570502]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 561 | Acuracia_21: 1.0 | Contagem Geral: 50.0 
Ordem Natural: 55.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_21: 1.0 
Precisao modelo Geral: 59.7015
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
561 561 561
(532, 30) (532, 30) (532, 30)
(532, 90) (532, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9891432  0.01085673]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 562 | Acuracia_22: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 55.0
Entrada: 4.88
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_22: 0.0 
Precisao modelo Geral: 59.4059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
562 562 562
(533, 30) (533, 30) (533, 30)
(533, 90) (533, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98642933 0.01357062]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 563 | Acuracia_23: 0.5 | Contagem Geral: 50.0 
Ordem Natural: 56.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_23: 0.5 
Precisao modelo Geral: 59.6059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
563 563 563
(534, 30) (534, 30) (534, 30)
(534, 90) (534, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9746221  0.02537796]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 564 | Acuracia_24: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 56.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_24: 0.0 
Precisao modelo Geral: 59.8039
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
564 564 564
(535, 30) (535, 30) (535, 30)
(535, 90) (535, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9795442 0.0204558]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 565 | Acuracia_25: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 56.0
Entrada: 1.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
565 565 565
(536, 30) (536, 30) (536, 30)
(536, 90) (536, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9381192 0.0618808]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 566 | Acuracia_26: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 56.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_26: 0.0 
Precisao modelo Geral: 60.1942
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
566 566 566
(537, 30) (537, 30) (537, 30)
(537, 90) (537, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96986437 0.03013564]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 567 | Acuracia_27: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 56.0
Entrada: 16.68
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_27: 0.0 
Precisao modelo Geral: 59.9034
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
567 567 567
(538, 30) (538, 30) (538, 30)
(538, 90) (538, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.90968883 0.0903112 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 568 | Acuracia_28: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 57.0
Entrada: 17.41
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_28: 0.0 
Precisao modelo Geral: 59.6154
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
568 568 568
(539, 30) (539, 30) (539, 30)
(539, 90) (539, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.73136723 0.26863277]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 569 | Acuracia_29: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 58.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_29: 0.0 
Precisao modelo Geral: 59.3301
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
569 569 569
(540, 30) (540, 30) (540, 30)
(540, 90) (540, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.87996966 0.12003038]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 570 | Acuracia_0: 0.5 | Contagem Geral: 51.0 
Ordem Natural: 58.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.5294 | Acuracia_30: 0.5 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
570 570 570
(541, 30) (541, 30) (541, 30)
(541, 90) (541, 30)
Matrix_30: [(541, 90), (541, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1680 - accuracy: 0.4834 - precision: 0.4834 - recall: 0.4834 - f1_score: 0.4902 - val_loss: 0.2506 - val_accuracy: 0.6316 - val_precision: 0.6316 - val_recall: 0.6316 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2882 - accuracy: 0.6987 - precision: 0.6987 - recall: 0.6987 - f1_score: 0.0215 - val_loss: 0.1389 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_f1_score: 0.5238 - 75ms/epoch - 75ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1443 - accuracy: 0.7881 - precision: 0.7881 - recall: 0.7881 - f1_score: 0.6279 - val_loss: 0.2050 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.5545 - 73ms/epoch - 73ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.3444 - precision: 0.3444 - recall: 0.3444 - f1_score: 0.4817 - val_loss: 0.2321 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_f1_score: 0.5385 - 72ms/epoch - 72ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1902 - accuracy: 0.3079 - precision: 0.3079 - recall: 0.3079 - f1_score: 0.4682 - val_loss: 0.1982 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.5545 - 72ms/epoch - 72ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.3344 - precision: 0.3344 - recall: 0.3344 - f1_score: 0.4779 - val_loss: 0.1618 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_f1_score: 0.6364 - 71ms/epoch - 71ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1472 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - f1_score: 0.5590 - val_loss: 0.1411 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_f1_score: 0.7419 - 72ms/epoch - 72ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1381 - accuracy: 0.7517 - precision: 0.7517 - recall: 0.7517 - f1_score: 0.6835 - val_loss: 0.1339 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.5581 - 72ms/epoch - 72ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1392 - accuracy: 0.8311 - precision: 0.8311 - recall: 0.8311 - f1_score: 0.6871 - val_loss: 0.1335 - val_accuracy: 0.7237 - val_precision: 0.7237 - val_recall: 0.7237 - val_f1_score: 0.4000 - 71ms/epoch - 71ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1442 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - f1_score: 0.5821 - val_loss: 0.1341 - val_accuracy: 0.7105 - val_precision: 0.7105 - val_recall: 0.7105 - val_f1_score: 0.3529 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1469 - accuracy: 0.7881 - precision: 0.7881 - recall: 0.7881 - f1_score: 0.4921 - val_loss: 0.1327 - val_accuracy: 0.7237 - val_precision: 0.7237 - val_recall: 0.7237 - val_f1_score: 0.4000 - 72ms/epoch - 72ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1449 - accuracy: 0.7914 - precision: 0.7914 - recall: 0.7914 - f1_score: 0.5039 - val_loss: 0.1299 - val_accuracy: 0.7237 - val_precision: 0.7237 - val_recall: 0.7237 - val_f1_score: 0.4000 - 73ms/epoch - 73ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1394 - accuracy: 0.8212 - precision: 0.8212 - recall: 0.8212 - f1_score: 0.6029 - val_loss: 0.1280 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.6341 - 73ms/epoch - 73ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1333 - accuracy: 0.8510 - precision: 0.8510 - recall: 0.8510 - f1_score: 0.7097 - val_loss: 0.1288 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7059 - 73ms/epoch - 73ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1290 - accuracy: 0.8808 - precision: 0.8808 - recall: 0.8808 - f1_score: 0.8043 - val_loss: 0.1319 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7869 - 74ms/epoch - 74ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1268 - accuracy: 0.8444 - precision: 0.8444 - recall: 0.8444 - f1_score: 0.7793 - val_loss: 0.1353 - val_accuracy: 0.7632 - val_precision: 0.7632 - val_recall: 0.7632 - val_f1_score: 0.7353 - 72ms/epoch - 72ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1257 - accuracy: 0.8212 - precision: 0.8212 - recall: 0.8212 - f1_score: 0.7692 - val_loss: 0.1364 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_f1_score: 0.7778 - 72ms/epoch - 72ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1240 - accuracy: 0.7980 - precision: 0.7980 - recall: 0.7980 - f1_score: 0.7469 - val_loss: 0.1332 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_f1_score: 0.7778 - 73ms/epoch - 73ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1208 - accuracy: 0.8113 - precision: 0.8113 - recall: 0.8113 - f1_score: 0.7595 - val_loss: 0.1267 - val_accuracy: 0.7632 - val_precision: 0.7632 - val_recall: 0.7632 - val_f1_score: 0.7353 - 73ms/epoch - 73ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1163 - accuracy: 0.8477 - precision: 0.8477 - recall: 0.8477 - f1_score: 0.7946 - val_loss: 0.1193 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7797 - 72ms/epoch - 72ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1119 - accuracy: 0.8940 - precision: 0.8940 - recall: 0.8940 - f1_score: 0.8431 - val_loss: 0.1131 - val_accuracy: 0.8553 - val_precision: 0.8553 - val_recall: 0.8553 - val_f1_score: 0.8000 - 72ms/epoch - 72ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1088 - accuracy: 0.9205 - precision: 0.9205 - recall: 0.9205 - f1_score: 0.8723 - val_loss: 0.1092 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7600 - 71ms/epoch - 71ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1068 - accuracy: 0.9172 - precision: 0.9172 - recall: 0.9172 - f1_score: 0.8588 - val_loss: 0.1064 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7347 - 72ms/epoch - 72ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1043 - accuracy: 0.9040 - precision: 0.9040 - recall: 0.9040 - f1_score: 0.8324 - val_loss: 0.1039 - val_accuracy: 0.8553 - val_precision: 0.8553 - val_recall: 0.8553 - val_f1_score: 0.7843 - 80ms/epoch - 80ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1001 - accuracy: 0.9139 - precision: 0.9139 - recall: 0.9139 - f1_score: 0.8556 - val_loss: 0.1025 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7778 - 82ms/epoch - 82ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0956 - accuracy: 0.9238 - precision: 0.9238 - recall: 0.9238 - f1_score: 0.8796 - val_loss: 0.1030 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7797 - 73ms/epoch - 73ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0923 - accuracy: 0.9073 - precision: 0.9073 - recall: 0.9073 - f1_score: 0.8614 - val_loss: 0.1039 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7812 - 71ms/epoch - 71ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0899 - accuracy: 0.8974 - precision: 0.8974 - recall: 0.8974 - f1_score: 0.8502 - val_loss: 0.1023 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7812 - 72ms/epoch - 72ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0869 - accuracy: 0.8940 - precision: 0.8940 - recall: 0.8940 - f1_score: 0.8476 - val_loss: 0.0976 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7869 - 73ms/epoch - 73ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0828 - accuracy: 0.9040 - precision: 0.9040 - recall: 0.9040 - f1_score: 0.8585 - val_loss: 0.0920 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7500 - 72ms/epoch - 72ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0788 - accuracy: 0.9205 - precision: 0.9205 - recall: 0.9205 - f1_score: 0.8776 - val_loss: 0.0885 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7547 - 71ms/epoch - 71ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0761 - accuracy: 0.9205 - precision: 0.9205 - recall: 0.9205 - f1_score: 0.8737 - val_loss: 0.0867 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7547 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0735 - accuracy: 0.9172 - precision: 0.9172 - recall: 0.9172 - f1_score: 0.8677 - val_loss: 0.0852 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7547 - 79ms/epoch - 79ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0699 - accuracy: 0.9238 - precision: 0.9238 - recall: 0.9238 - f1_score: 0.8796 - val_loss: 0.0847 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7273 - 73ms/epoch - 73ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0664 - accuracy: 0.9238 - precision: 0.9238 - recall: 0.9238 - f1_score: 0.8821 - val_loss: 0.0854 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7541 - 73ms/epoch - 73ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0640 - accuracy: 0.9172 - precision: 0.9172 - recall: 0.9172 - f1_score: 0.8768 - val_loss: 0.0852 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7742 - 84ms/epoch - 84ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0617 - accuracy: 0.9139 - precision: 0.9139 - recall: 0.9139 - f1_score: 0.8738 - val_loss: 0.0830 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7541 - 73ms/epoch - 73ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0588 - accuracy: 0.9172 - precision: 0.9172 - recall: 0.9172 - f1_score: 0.8768 - val_loss: 0.0808 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7273 - 96ms/epoch - 96ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0561 - accuracy: 0.9272 - precision: 0.9272 - recall: 0.9272 - f1_score: 0.8878 - val_loss: 0.0803 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7407 - 119ms/epoch - 119ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0542 - accuracy: 0.9338 - precision: 0.9338 - recall: 0.9338 - f1_score: 0.8958 - val_loss: 0.0801 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7547 - 73ms/epoch - 73ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0519 - accuracy: 0.9338 - precision: 0.9338 - recall: 0.9338 - f1_score: 0.8958 - val_loss: 0.0796 - val_accuracy: 0.8026 - val_precision: 0.8026 - val_recall: 0.8026 - val_f1_score: 0.7273 - 73ms/epoch - 73ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0493 - accuracy: 0.9338 - precision: 0.9338 - recall: 0.9338 - f1_score: 0.8980 - val_loss: 0.0798 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7667 - 85ms/epoch - 85ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0474 - accuracy: 0.9305 - precision: 0.9305 - recall: 0.9305 - f1_score: 0.8934 - val_loss: 0.0799 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7667 - 73ms/epoch - 73ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0454 - accuracy: 0.9305 - precision: 0.9305 - recall: 0.9305 - f1_score: 0.8945 - val_loss: 0.0791 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7857 - 72ms/epoch - 72ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0430 - accuracy: 0.9437 - precision: 0.9437 - recall: 0.9437 - f1_score: 0.9119 - val_loss: 0.0790 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7857 - 72ms/epoch - 72ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0410 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - f1_score: 0.9312 - val_loss: 0.0792 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7778 - 73ms/epoch - 73ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0392 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - f1_score: 0.9305 - val_loss: 0.0785 - val_accuracy: 0.8289 - val_precision: 0.8289 - val_recall: 0.8289 - val_f1_score: 0.7636 - 76ms/epoch - 76ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0371 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - f1_score: 0.9305 - val_loss: 0.0777 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_f1_score: 0.7857 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0351 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - f1_score: 0.9312 - val_loss: 0.0774 - val_accuracy: 0.8553 - val_precision: 0.8553 - val_recall: 0.8553 - val_f1_score: 0.8070 - 72ms/epoch - 72ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0334 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - f1_score: 0.9312 - val_loss: 0.0769 - val_accuracy: 0.8553 - val_precision: 0.8553 - val_recall: 0.8553 - val_f1_score: 0.8070 - 73ms/epoch - 73ms/step

🔍 Resultados no Teste:
Loss: 0.0517
Accuracy: 0.9264
Precision: 0.9264
Recall: 0.9264
F1 Score: 0.8667
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
570 570 570
(541, 30) (541, 30) (541, 30)
(541, 90) (541, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 90ms/step
[[0.73524225 0.2647578 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 571 | Acuracia_1: 0.0 | Contagem Geral: 51.0 
Ordem Natural: 58.0
Entrada: 3.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_1: 0.3333 
Precisao modelo Geral: 59.7156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
571 571 571
(542, 30) (542, 30) (542, 30)
(542, 90) (542, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.80930907 0.19069101]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 572 | Acuracia_2: 0.3333 | Contagem Geral: 52.0 
Ordem Natural: 59.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_2: 0.3333 
Precisao modelo Geral: 59.9057
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
572 572 572
(543, 30) (543, 30) (543, 30)
(543, 90) (543, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8379507  0.16204932]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 573 | Acuracia_3: 0.0 | Contagem Geral: 52.0 
Ordem Natural: 59.0
Entrada: 17.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_3: 0.0 
Precisao modelo Geral: 59.6244
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
573 573 573
(544, 30) (544, 30) (544, 30)
(544, 90) (544, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6847878  0.31521225]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 574 | Acuracia_4: 1.0 | Contagem Geral: 52.0 
Ordem Natural: 60.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.5283 | Acuracia_4: 0.5 
Precisao modelo Geral: 59.3458
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
574 574 574
(545, 30) (545, 30) (545, 30)
(545, 90) (545, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6933135 0.3066865]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 575 | Acuracia_5: 0 | Contagem Geral: 53.0 
Ordem Natural: 60.0
Entrada: 4.54
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_5: 1.0 
Precisao modelo Geral: 59.5349
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
575 575 575
(546, 30) (546, 30) (546, 30)
(546, 90) (546, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8616091  0.13839096]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 576 | Acuracia_6: 1.0 | Contagem Geral: 54.0 
Ordem Natural: 61.0
Entrada: 11.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_6: 1.0 
Precisao modelo Geral: 59.2593
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
576 576 576
(547, 30) (547, 30) (547, 30)
(547, 90) (547, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9154372  0.08456279]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 577 | Acuracia_7: 0.3333 | Contagem Geral: 54.0 
Ordem Natural: 62.0
Entrada: 22.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_7: 0.3333 
Precisao modelo Geral: 58.9862
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
577 577 577
(548, 30) (548, 30) (548, 30)
(548, 90) (548, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.81153125 0.18846874]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 578 | Acuracia_8: 1.0 | Contagem Geral: 54.0 
Ordem Natural: 63.0
Entrada: 6.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_8: 1.0 
Precisao modelo Geral: 58.7156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
578 578 578
(549, 30) (549, 30) (549, 30)
(549, 90) (549, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.82874644 0.1712535 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 579 | Acuracia_9: 0.0 | Contagem Geral: 54.0 
Ordem Natural: 64.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_9: 0.0 
Precisao modelo Geral: 58.9041
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
579 579 579
(550, 30) (550, 30) (550, 30)
(550, 90) (550, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.92366225 0.07633781]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 580 | Acuracia_10: 0.5 | Contagem Geral: 54.0 
Ordem Natural: 64.0
Entrada: 1.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.0909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
580 580 580
(551, 30) (551, 30) (551, 30)
(551, 90) (551, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9341265  0.06587357]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 581 | Acuracia_11: 0 | Contagem Geral: 54.0 
Ordem Natural: 64.0
Entrada: 4.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_11: 0 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
581 581 581
(552, 30) (552, 30) (552, 30)
(552, 90) (552, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9581328  0.04186723]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 582 | Acuracia_12: 0.0 | Contagem Geral: 54.0 
Ordem Natural: 65.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.009
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
582 582 582
(553, 30) (553, 30) (553, 30)
(553, 90) (553, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.924011   0.07598896]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 583 | Acuracia_13: 0.3333 | Contagem Geral: 54.0 
Ordem Natural: 65.0
Entrada: 4.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.9259 | Acuracia_13: 0.3333 
Precisao modelo Geral: 58.7444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
583 583 583
(554, 30) (554, 30) (554, 30)
(554, 90) (554, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.75559473 0.24440527]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 584 | Acuracia_14: 0.0 | Contagem Geral: 54.0 
Ordem Natural: 66.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.4545 | Acuracia_14: 0.0 
Precisao modelo Geral: 58.4821
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
584 584 584
(555, 30) (555, 30) (555, 30)
(555, 90) (555, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7610019  0.23899812]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 585 | Acuracia_15: 0 | Contagem Geral: 55.0 
Ordem Natural: 66.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_15: 0.0 
Precisao modelo Geral: 58.2222
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
585 585 585
(556, 30) (556, 30) (556, 30)
(556, 90) (556, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.87759006 0.12240995]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 586 | Acuracia_16: 0.0 | Contagem Geral: 56.0 
Ordem Natural: 66.0
Entrada: 6.68
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_16: 0.0 
Precisao modelo Geral: 57.9646
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
586 586 586
(557, 30) (557, 30) (557, 30)
(557, 90) (557, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9642508  0.03574918]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 587 | Acuracia_17: 0.3333 | Contagem Geral: 56.0 
Ordem Natural: 67.0
Entrada: 2.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_17: 0.3333 
Precisao modelo Geral: 58.1498
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
587 587 587
(558, 30) (558, 30) (558, 30)
(558, 90) (558, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9115381 0.0884619]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 588 | Acuracia_18: 0.0 | Contagem Geral: 56.0 
Ordem Natural: 67.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_18: 0.0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
588 588 588
(559, 30) (559, 30) (559, 30)
(559, 90) (559, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7735521  0.22644787]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 589 | Acuracia_19: 0.0 | Contagem Geral: 56.0 
Ordem Natural: 67.0
Entrada: 1.57
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.5614 | Acuracia_19: 0.0 
Precisao modelo Geral: 58.0786
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
589 589 589
(560, 30) (560, 30) (560, 30)
(560, 90) (560, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.63408643 0.36591354]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 590 | Acuracia_20: 0.0 | Contagem Geral: 57.0 
Ordem Natural: 67.0
Entrada: 5.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_20: 0.5 
Precisao modelo Geral: 58.2609
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
590 590 590
(561, 30) (561, 30) (561, 30)
(561, 90) (561, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94137335 0.05862669]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 591 | Acuracia_21: 1.0 | Contagem Geral: 58.0 
Ordem Natural: 68.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_21: 1.0 
Precisao modelo Geral: 58.4416
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
591 591 591
(562, 30) (562, 30) (562, 30)
(562, 90) (562, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9863144  0.01368554]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 592 | Acuracia_22: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 68.0
Entrada: 4.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_22: 0.0 
Precisao modelo Geral: 58.1897
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
592 592 592
(563, 30) (563, 30) (563, 30)
(563, 90) (563, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9706454  0.02935456]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 593 | Acuracia_23: 0.5 | Contagem Geral: 58.0 
Ordem Natural: 69.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_23: 0.5 
Precisao modelo Geral: 58.3691
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
593 593 593
(564, 30) (564, 30) (564, 30)
(564, 90) (564, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.83482975 0.16517028]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 594 | Acuracia_24: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 69.0
Entrada: 4.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_24: 0.0 
Precisao modelo Geral: 58.1197
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
594 594 594
(565, 30) (565, 30) (565, 30)
(565, 90) (565, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.80160385 0.19839618]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 595 | Acuracia_25: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_25: 0.0 
Precisao modelo Geral: 58.2979
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
595 595 595
(566, 30) (566, 30) (566, 30)
(566, 90) (566, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8356487  0.16435122]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 596 | Acuracia_26: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_26: 0.0 
Precisao modelo Geral: 58.4746
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
596 596 596
(567, 30) (567, 30) (567, 30)
(567, 90) (567, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.92598456 0.07401547]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 597 | Acuracia_27: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_27: 0.0 
Precisao modelo Geral: 58.6498
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
597 597 597
(568, 30) (568, 30) (568, 30)
(568, 90) (568, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9170701  0.08292992]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 598 | Acuracia_28: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_28: 0.0 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
598 598 598
(569, 30) (569, 30) (569, 30)
(569, 90) (569, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.82386166 0.17613839]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 599 | Acuracia_29: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_29: 0.0 
Precisao modelo Geral: 58.9958
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
599 599 599
(570, 30) (570, 30) (570, 30)
(570, 90) (570, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8456201  0.15437993]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 600 | Acuracia_0: 0.5 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_30: 0.5 
Precisao modelo Geral: 59.1667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
600 600 600
(571, 30) (571, 30) (571, 30)
(571, 90) (571, 30)
Matrix_30: [(571, 90), (571, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1818 - accuracy: 0.4451 - precision: 0.4451 - recall: 0.4451 - f1_score: 0.4080 - val_loss: 0.1562 - val_accuracy: 0.6875 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1873 - accuracy: 0.6803 - precision: 0.6803 - recall: 0.6803 - f1_score: 0.0000e+00 - val_loss: 0.1610 - val_accuracy: 0.6500 - val_precision: 0.6500 - val_recall: 0.6500 - val_f1_score: 0.5484 - 74ms/epoch - 74ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1497 - accuracy: 0.7116 - precision: 0.7116 - recall: 0.7116 - f1_score: 0.6462 - val_loss: 0.2077 - val_accuracy: 0.3625 - val_precision: 0.3625 - val_recall: 0.3625 - val_f1_score: 0.4848 - 77ms/epoch - 77ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.4263 - precision: 0.4263 - recall: 0.4263 - f1_score: 0.5247 - val_loss: 0.1706 - val_accuracy: 0.5500 - val_precision: 0.5500 - val_recall: 0.5500 - val_f1_score: 0.5610 - 73ms/epoch - 73ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1384 - accuracy: 0.6050 - precision: 0.6050 - recall: 0.6050 - f1_score: 0.6135 - val_loss: 0.1360 - val_accuracy: 0.7750 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1_score: 0.5263 - 73ms/epoch - 73ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1269 - accuracy: 0.8746 - precision: 0.8746 - recall: 0.8746 - f1_score: 0.7959 - val_loss: 0.1306 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.3333 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1284 - accuracy: 0.8339 - precision: 0.8339 - recall: 0.8339 - f1_score: 0.6536 - val_loss: 0.1250 - val_accuracy: 0.7750 - val_precision: 0.7750 - val_recall: 0.7750 - val_f1_score: 0.5000 - 72ms/epoch - 72ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1147 - accuracy: 0.8840 - precision: 0.8840 - recall: 0.8840 - f1_score: 0.7933 - val_loss: 0.1307 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1_score: 0.7143 - 72ms/epoch - 72ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1039 - accuracy: 0.8621 - precision: 0.8621 - recall: 0.8621 - f1_score: 0.8136 - val_loss: 0.1448 - val_accuracy: 0.6875 - val_precision: 0.6875 - val_recall: 0.6875 - val_f1_score: 0.6479 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1035 - accuracy: 0.7900 - precision: 0.7900 - recall: 0.7900 - f1_score: 0.7509 - val_loss: 0.1326 - val_accuracy: 0.7625 - val_precision: 0.7625 - val_recall: 0.7625 - val_f1_score: 0.6984 - 72ms/epoch - 72ms/step
Epoch 11/50
1/1 - 0s - loss: 0.0944 - accuracy: 0.8182 - precision: 0.8182 - recall: 0.8182 - f1_score: 0.7698 - val_loss: 0.1120 - val_accuracy: 0.8500 - val_precision: 0.8500 - val_recall: 0.8500 - val_f1_score: 0.7500 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0850 - accuracy: 0.9122 - precision: 0.9122 - recall: 0.9122 - f1_score: 0.8654 - val_loss: 0.1061 - val_accuracy: 0.8250 - val_precision: 0.8250 - val_recall: 0.8250 - val_f1_score: 0.6500 - 76ms/epoch - 76ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0841 - accuracy: 0.9248 - precision: 0.9248 - recall: 0.9248 - f1_score: 0.8710 - val_loss: 0.1019 - val_accuracy: 0.8250 - val_precision: 0.8250 - val_recall: 0.8250 - val_f1_score: 0.6667 - 74ms/epoch - 74ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0768 - accuracy: 0.9248 - precision: 0.9248 - recall: 0.9248 - f1_score: 0.8763 - val_loss: 0.1025 - val_accuracy: 0.8375 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1_score: 0.7547 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0688 - accuracy: 0.9185 - precision: 0.9185 - recall: 0.9185 - f1_score: 0.8796 - val_loss: 0.1102 - val_accuracy: 0.8500 - val_precision: 0.8500 - val_recall: 0.8500 - val_f1_score: 0.7857 - 77ms/epoch - 77ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0684 - accuracy: 0.8871 - precision: 0.8871 - recall: 0.8871 - f1_score: 0.8475 - val_loss: 0.1011 - val_accuracy: 0.8375 - val_precision: 0.8375 - val_recall: 0.8375 - val_f1_score: 0.7636 - 73ms/epoch - 73ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0616 - accuracy: 0.8997 - precision: 0.8997 - recall: 0.8997 - f1_score: 0.8596 - val_loss: 0.0898 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.7917 - 73ms/epoch - 73ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0556 - accuracy: 0.9530 - precision: 0.9530 - recall: 0.9530 - f1_score: 0.9268 - val_loss: 0.0884 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8000 - 74ms/epoch - 74ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0546 - accuracy: 0.9436 - precision: 0.9436 - recall: 0.9436 - f1_score: 0.9082 - val_loss: 0.0843 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.7917 - 75ms/epoch - 75ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0487 - accuracy: 0.9592 - precision: 0.9592 - recall: 0.9592 - f1_score: 0.9353 - val_loss: 0.0841 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8077 - 74ms/epoch - 74ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0448 - accuracy: 0.9436 - precision: 0.9436 - recall: 0.9436 - f1_score: 0.9159 - val_loss: 0.0858 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8077 - 75ms/epoch - 75ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0438 - accuracy: 0.9373 - precision: 0.9373 - recall: 0.9373 - f1_score: 0.9091 - val_loss: 0.0784 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8163 - 73ms/epoch - 73ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0387 - accuracy: 0.9561 - precision: 0.9561 - recall: 0.9561 - f1_score: 0.9333 - val_loss: 0.0758 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 73ms/epoch - 73ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0364 - accuracy: 0.9592 - precision: 0.9592 - recall: 0.9592 - f1_score: 0.9353 - val_loss: 0.0756 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.7826 - 75ms/epoch - 75ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9655 - precision: 0.9655 - recall: 0.9655 - f1_score: 0.9447 - val_loss: 0.0720 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 74ms/epoch - 74ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0304 - accuracy: 0.9687 - precision: 0.9687 - recall: 0.9687 - f1_score: 0.9510 - val_loss: 0.0722 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0290 - accuracy: 0.9718 - precision: 0.9718 - recall: 0.9718 - f1_score: 0.9573 - val_loss: 0.0707 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8571 - 72ms/epoch - 72ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0270 - accuracy: 0.9749 - precision: 0.9749 - recall: 0.9749 - f1_score: 0.9619 - val_loss: 0.0678 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 81ms/epoch - 81ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0237 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - f1_score: 0.9854 - val_loss: 0.0693 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 70ms/epoch - 70ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0227 - accuracy: 0.9843 - precision: 0.9843 - recall: 0.9843 - f1_score: 0.9751 - val_loss: 0.0679 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 81ms/epoch - 81ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0206 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875 - f1_score: 0.9802 - val_loss: 0.0645 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0183 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - f1_score: 0.9902 - val_loss: 0.0636 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - f1_score: 0.9854 - val_loss: 0.0622 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8571 - 84ms/epoch - 84ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0157 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - f1_score: 0.9902 - val_loss: 0.0630 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8333 - 74ms/epoch - 74ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0141 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - f1_score: 0.9902 - val_loss: 0.0652 - val_accuracy: 0.8875 - val_precision: 0.8875 - val_recall: 0.8875 - val_f1_score: 0.8085 - 74ms/epoch - 74ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0134 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - f1_score: 0.9951 - val_loss: 0.0624 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8333 - 77ms/epoch - 77ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0118 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - f1_score: 0.9951 - val_loss: 0.0593 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8333 - 72ms/epoch - 72ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0109 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - f1_score: 0.9902 - val_loss: 0.0582 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8333 - 72ms/epoch - 72ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0103 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - f1_score: 0.9902 - val_loss: 0.0584 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8333 - 73ms/epoch - 73ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0091 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 73ms/epoch - 73ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0084 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 72ms/epoch - 72ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 72ms/epoch - 72ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0070 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 72ms/epoch - 72ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0065 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 79ms/epoch - 79ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 72ms/epoch - 72ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 73ms/epoch - 73ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8261 - 72ms/epoch - 72ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 74ms/epoch - 74ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 74ms/epoch - 74ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9125 - val_precision: 0.9125 - val_recall: 0.9125 - val_f1_score: 0.8511 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0322
Accuracy: 0.9535
Precision: 0.9535
Recall: 0.9535
F1 Score: 0.9184
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
600 600 600
(571, 30) (571, 30) (571, 30)
(571, 90) (571, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 92ms/step
[[0.9540955 0.0459045]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 601 | Acuracia_1: 0.3333 | Contagem Geral: 58.0 
Ordem Natural: 70.0
Entrada: 3.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_1: 0.3333 
Precisao modelo Geral: 58.9212
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
601 601 601
(572, 30) (572, 30) (572, 30)
(572, 90) (572, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.981264   0.01873597]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 602 | Acuracia_2: 0.3333 | Contagem Geral: 58.0 
Ordem Natural: 71.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_2: 0.3333 
Precisao modelo Geral: 59.0909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
602 602 602
(573, 30) (573, 30) (573, 30)
(573, 90) (573, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99104893 0.00895106]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 603 | Acuracia_3: 0.0 | Contagem Geral: 58.0 
Ordem Natural: 71.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_3: 0.0 
Precisao modelo Geral: 59.2593
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
603 603 603
(574, 30) (574, 30) (574, 30)
(574, 90) (574, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93355596 0.06644405]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 604 | Acuracia_4: 0.5 | Contagem Geral: 58.0 
Ordem Natural: 71.0
Entrada: 83.81
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8621 | Acuracia_4: 0.5 
Precisao modelo Geral: 59.0164
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
604 604 604
(575, 30) (575, 30) (575, 30)
(575, 90) (575, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.78483284 0.2151672 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 605 | Acuracia_5: 1.0 | Contagem Geral: 58.0 
Ordem Natural: 72.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.4237 | Acuracia_5: 0.5 
Precisao modelo Geral: 58.7755
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
605 605 605
(576, 30) (576, 30) (576, 30)
(576, 90) (576, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.84107023 0.15892977]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 606 | Acuracia_6: 1.0 | Contagem Geral: 59.0 
Ordem Natural: 72.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.4237 | Acuracia_6: 1.0 
Precisao modelo Geral: 58.9431
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
606 606 606
(577, 30) (577, 30) (577, 30)
(577, 90) (577, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9910652  0.00893479]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 607 | Acuracia_7: 0.3333 | Contagem Geral: 59.0 
Ordem Natural: 72.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.4237 | Acuracia_7: 0.3333 
Precisao modelo Geral: 59.1093
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
607 607 607
(578, 30) (578, 30) (578, 30)
(578, 90) (578, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9451928  0.05480719]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 608 | Acuracia_8: 1.0 | Contagem Geral: 59.0 
Ordem Natural: 72.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.4237 | Acuracia_8: 1.0 
Precisao modelo Geral: 59.2742
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
608 608 608
(579, 30) (579, 30) (579, 30)
(579, 90) (579, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.60302156 0.39697844]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 609 | Acuracia_9: 0.0 | Contagem Geral: 59.0 
Ordem Natural: 72.0
Entrada: 3.99
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_9: 0.5 
Precisao modelo Geral: 59.4378
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
609 609 609
(580, 30) (580, 30) (580, 30)
(580, 90) (580, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9025374  0.09746258]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 610 | Acuracia_10: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 73.0
Entrada: 9.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
610 610 610
(581, 30) (581, 30) (581, 30)
(581, 90) (581, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94011253 0.05988752]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 611 | Acuracia_11: 0 | Contagem Geral: 60.0 
Ordem Natural: 74.0
Entrada: 6.97
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_11: 0 
Precisao modelo Geral: 58.9641
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
611 611 611
(582, 30) (582, 30) (582, 30)
(582, 90) (582, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9705685  0.02943151]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 612 | Acuracia_12: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 2.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.127
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
612 612 612
(583, 30) (583, 30) (583, 30)
(583, 90) (583, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97994    0.02005997]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 613 | Acuracia_13: 0.3333 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_13: 0.3333 
Precisao modelo Geral: 59.2885
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
613 613 613
(584, 30) (584, 30) (584, 30)
(584, 90) (584, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.886296   0.11370404]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 614 | Acuracia_14: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 1.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_14: 0.0 
Precisao modelo Geral: 59.4488
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
614 614 614
(585, 30) (585, 30) (585, 30)
(585, 90) (585, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9566567  0.04334324]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 615 | Acuracia_15: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 2.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_15: 0.0 
Precisao modelo Geral: 59.6078
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
615 615 615
(586, 30) (586, 30) (586, 30)
(586, 90) (586, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9917231  0.00827685]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 616 | Acuracia_16: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.7656
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
616 616 616
(587, 30) (587, 30) (587, 30)
(587, 90) (587, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8949249  0.10507514]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 617 | Acuracia_17: 0.3333 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_17: 0.3333 
Precisao modelo Geral: 59.9222
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
617 617 617
(588, 30) (588, 30) (588, 30)
(588, 90) (588, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.86421263 0.13578738]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 618 | Acuracia_18: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_18: 0.0 
Precisao modelo Geral: 60.0775
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
618 618 618
(589, 30) (589, 30) (589, 30)
(589, 90) (589, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97900015 0.02099982]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 619 | Acuracia_19: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 75.0
Entrada: 5.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_19: 0.0 
Precisao modelo Geral: 59.8456
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
619 619 619
(590, 30) (590, 30) (590, 30)
(590, 90) (590, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9467224  0.05327762]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 620 | Acuracia_20: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 76.0
Entrada: 3.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_20: 0.5 
Precisao modelo Geral: 59.6154
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
620 620 620
(591, 30) (591, 30) (591, 30)
(591, 90) (591, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9210707  0.07892932]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 621 | Acuracia_21: 1.0 | Contagem Geral: 60.0 
Ordem Natural: 77.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_21: 1.0 
Precisao modelo Geral: 59.7701
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
621 621 621
(592, 30) (592, 30) (592, 30)
(592, 90) (592, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9598219  0.04017814]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 622 | Acuracia_22: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 77.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_22: 0.0 
Precisao modelo Geral: 59.9237
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
622 622 622
(593, 30) (593, 30) (593, 30)
(593, 90) (593, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9419965  0.05800354]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 623 | Acuracia_23: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 77.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_23: 0.5 
Precisao modelo Geral: 60.076
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
623 623 623
(594, 30) (594, 30) (594, 30)
(594, 90) (594, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98859733 0.01140266]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 624 | Acuracia_24: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 77.0
Entrada: 6.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_24: 0.0 
Precisao modelo Geral: 59.8485
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
624 624 624
(595, 30) (595, 30) (595, 30)
(595, 90) (595, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9809467  0.01905327]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 625 | Acuracia_25: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 78.0
Entrada: 2.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
625 625 625
(596, 30) (596, 30) (596, 30)
(596, 90) (596, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97685003 0.02314992]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 626 | Acuracia_26: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 78.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_26: 0.0 
Precisao modelo Geral: 60.1504
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
626 626 626
(597, 30) (597, 30) (597, 30)
(597, 90) (597, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9530223  0.04697776]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 627 | Acuracia_27: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 78.0
Entrada: 2.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.2996
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
627 627 627
(598, 30) (598, 30) (598, 30)
(598, 90) (598, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9313283  0.06867176]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 628 | Acuracia_28: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 78.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.4478
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
628 628 628
(599, 30) (599, 30) (599, 30)
(599, 90) (599, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94725615 0.05274386]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 629 | Acuracia_29: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 78.0
Entrada: 4.81
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.223
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
629 629 629
(600, 30) (600, 30) (600, 30)
(600, 90) (600, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97369087 0.02630911]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 630 | Acuracia_0: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 79.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.3704
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
630 630 630
(601, 30) (601, 30) (601, 30)
(601, 90) (601, 30)
Matrix_30: [(601, 90), (601, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1825 - accuracy: 0.4435 - precision: 0.4435 - recall: 0.4435 - f1_score: 0.4484 - val_loss: 0.1417 - val_accuracy: 0.6905 - val_precision: 0.6905 - val_recall: 0.6905 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1783 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.2698 - val_loss: 0.1582 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.5946 - 74ms/epoch - 74ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1405 - accuracy: 0.6815 - precision: 0.6815 - recall: 0.6815 - f1_score: 0.6397 - val_loss: 0.2012 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.5208 - 74ms/epoch - 74ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1462 - accuracy: 0.5060 - precision: 0.5060 - recall: 0.5060 - f1_score: 0.5632 - val_loss: 0.1699 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.5412 - 77ms/epoch - 77ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1285 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.6446 - val_loss: 0.1296 - val_accuracy: 0.7976 - val_precision: 0.7976 - val_recall: 0.7976 - val_f1_score: 0.7119 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1146 - accuracy: 0.8720 - precision: 0.8720 - recall: 0.8720 - f1_score: 0.8106 - val_loss: 0.1158 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.6500 - 76ms/epoch - 76ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1165 - accuracy: 0.8601 - precision: 0.8601 - recall: 0.8601 - f1_score: 0.7513 - val_loss: 0.1125 - val_accuracy: 0.8452 - val_precision: 0.8452 - val_recall: 0.8452 - val_f1_score: 0.7111 - 73ms/epoch - 73ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1067 - accuracy: 0.8780 - precision: 0.8780 - recall: 0.8780 - f1_score: 0.7940 - val_loss: 0.1204 - val_accuracy: 0.7976 - val_precision: 0.7976 - val_recall: 0.7976 - val_f1_score: 0.7119 - 74ms/epoch - 74ms/step
Epoch 9/50
1/1 - 0s - loss: 0.0940 - accuracy: 0.8720 - precision: 0.8720 - recall: 0.8720 - f1_score: 0.8170 - val_loss: 0.1418 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.6765 - 73ms/epoch - 73ms/step
Epoch 10/50
1/1 - 0s - loss: 0.0937 - accuracy: 0.8244 - precision: 0.8244 - recall: 0.8244 - f1_score: 0.7807 - val_loss: 0.1411 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.6866 - 73ms/epoch - 73ms/step
Epoch 11/50
1/1 - 0s - loss: 0.0892 - accuracy: 0.8363 - precision: 0.8363 - recall: 0.8363 - f1_score: 0.7940 - val_loss: 0.1153 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7241 - 75ms/epoch - 75ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0780 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - f1_score: 0.8347 - val_loss: 0.0978 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7308 - 75ms/epoch - 75ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0755 - accuracy: 0.9226 - precision: 0.9226 - recall: 0.9226 - f1_score: 0.8785 - val_loss: 0.0937 - val_accuracy: 0.8452 - val_precision: 0.8452 - val_recall: 0.8452 - val_f1_score: 0.7347 - 82ms/epoch - 82ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0730 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8857 - val_loss: 0.0960 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7143 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0640 - accuracy: 0.9226 - precision: 0.9226 - recall: 0.9226 - f1_score: 0.8807 - val_loss: 0.1096 - val_accuracy: 0.7976 - val_precision: 0.7976 - val_recall: 0.7976 - val_f1_score: 0.7119 - 83ms/epoch - 83ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0607 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.8958 - f1_score: 0.8560 - val_loss: 0.1159 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.7000 - 73ms/epoch - 73ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0591 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8502 - val_loss: 0.1011 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7241 - 76ms/epoch - 76ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0522 - accuracy: 0.9226 - precision: 0.9226 - recall: 0.9226 - f1_score: 0.8879 - val_loss: 0.0881 - val_accuracy: 0.8214 - val_precision: 0.8214 - val_recall: 0.8214 - val_f1_score: 0.7273 - 76ms/epoch - 76ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0496 - accuracy: 0.9464 - precision: 0.9464 - recall: 0.9464 - f1_score: 0.9151 - val_loss: 0.0855 - val_accuracy: 0.8690 - val_precision: 0.8690 - val_recall: 0.8690 - val_f1_score: 0.7843 - 76ms/epoch - 76ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0480 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9048 - val_loss: 0.0877 - val_accuracy: 0.8214 - val_precision: 0.8214 - val_recall: 0.8214 - val_f1_score: 0.7273 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0422 - accuracy: 0.9464 - precision: 0.9464 - recall: 0.9464 - f1_score: 0.9159 - val_loss: 0.0977 - val_accuracy: 0.8214 - val_precision: 0.8214 - val_recall: 0.8214 - val_f1_score: 0.7368 - 73ms/epoch - 73ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0402 - accuracy: 0.9435 - precision: 0.9435 - recall: 0.9435 - f1_score: 0.9177 - val_loss: 0.0990 - val_accuracy: 0.8214 - val_precision: 0.8214 - val_recall: 0.8214 - val_f1_score: 0.7368 - 72ms/epoch - 72ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0380 - accuracy: 0.9435 - precision: 0.9435 - recall: 0.9435 - f1_score: 0.9177 - val_loss: 0.0867 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7500 - 73ms/epoch - 73ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0332 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - f1_score: 0.9502 - val_loss: 0.0801 - val_accuracy: 0.8690 - val_precision: 0.8690 - val_recall: 0.8690 - val_f1_score: 0.7843 - 75ms/epoch - 75ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0319 - accuracy: 0.9613 - precision: 0.9613 - recall: 0.9613 - f1_score: 0.9378 - val_loss: 0.0792 - val_accuracy: 0.8690 - val_precision: 0.8690 - val_recall: 0.8690 - val_f1_score: 0.7843 - 75ms/epoch - 75ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0293 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9528 - val_loss: 0.0817 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7778 - 78ms/epoch - 78ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0257 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - f1_score: 0.9725 - val_loss: 0.0874 - val_accuracy: 0.8452 - val_precision: 0.8452 - val_recall: 0.8452 - val_f1_score: 0.7636 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0247 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9640 - val_loss: 0.0833 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7778 - 75ms/epoch - 75ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0219 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9817 - val_loss: 0.0768 - val_accuracy: 0.8929 - val_precision: 0.8929 - val_recall: 0.8929 - val_f1_score: 0.8235 - 77ms/epoch - 77ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0195 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1_score: 0.9815 - val_loss: 0.0759 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 81ms/epoch - 81ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0186 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9767 - val_loss: 0.0751 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0161 - accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - f1_score: 0.9862 - val_loss: 0.0763 - val_accuracy: 0.8929 - val_precision: 0.8929 - val_recall: 0.8929 - val_f1_score: 0.8235 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0145 - accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - f1_score: 0.9862 - val_loss: 0.0770 - val_accuracy: 0.8929 - val_precision: 0.8929 - val_recall: 0.8929 - val_f1_score: 0.8235 - 74ms/epoch - 74ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0136 - accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - f1_score: 0.9862 - val_loss: 0.0737 - val_accuracy: 0.8929 - val_precision: 0.8929 - val_recall: 0.8929 - val_f1_score: 0.8235 - 72ms/epoch - 72ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0118 - accuracy: 0.9940 - precision: 0.9940 - recall: 0.9940 - f1_score: 0.9907 - val_loss: 0.0729 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0109 - accuracy: 0.9940 - precision: 0.9940 - recall: 0.9940 - f1_score: 0.9907 - val_loss: 0.0733 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0101 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - f1_score: 0.9953 - val_loss: 0.0712 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 84ms/epoch - 84ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0088 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - f1_score: 0.9953 - val_loss: 0.0701 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 122ms/epoch - 122ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0081 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - f1_score: 0.9953 - val_loss: 0.0696 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 97ms/epoch - 97ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0075 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - f1_score: 0.9953 - val_loss: 0.0690 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0065 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 85ms/epoch - 85ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0056 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 73ms/epoch - 73ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 73ms/epoch - 73ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167 - val_f1_score: 0.8571 - 74ms/epoch - 74ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 71ms/epoch - 71ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0035 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.8810 - val_precision: 0.8810 - val_recall: 0.8810 - val_f1_score: 0.7826 - 79ms/epoch - 79ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0033 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.8810 - val_precision: 0.8810 - val_recall: 0.8810 - val_f1_score: 0.7826 - 88ms/epoch - 88ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0031 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step

🔍 Resultados no Teste:
Loss: 0.0325
Accuracy: 0.9503
Precision: 0.9503
Recall: 0.9503
F1 Score: 0.9143
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
630 630 630
(601, 30) (601, 30) (601, 30)
(601, 90) (601, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 88ms/step
[[0.9808177  0.01918232]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 631 | Acuracia_1: 0.3333 | Contagem Geral: 60.0 
Ordem Natural: 79.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_1: 0.3333 
Precisao modelo Geral: 60.5166
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
631 631 631
(602, 30) (602, 30) (602, 30)
(602, 90) (602, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.86783785 0.13216215]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 632 | Acuracia_2: 0.3333 | Contagem Geral: 60.0 
Ordem Natural: 79.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_2: 0.3333 
Precisao modelo Geral: 60.6618
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
632 632 632
(603, 30) (603, 30) (603, 30)
(603, 90) (603, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98725665 0.01274337]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 633 | Acuracia_3: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 79.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.8059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
633 633 633
(604, 30) (604, 30) (604, 30)
(604, 90) (604, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99737144 0.00262856]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 634 | Acuracia_4: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 79.0
Entrada: 3.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_4: 0.5 
Precisao modelo Geral: 60.5839
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
634 634 634
(605, 30) (605, 30) (605, 30)
(605, 90) (605, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97535986 0.02464007]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 635 | Acuracia_5: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 80.0
Entrada: 9.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_5: 0.5 
Precisao modelo Geral: 60.3636
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
635 635 635
(606, 30) (606, 30) (606, 30)
(606, 90) (606, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9647796  0.03522038]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 636 | Acuracia_6: 1.0 | Contagem Geral: 60.0 
Ordem Natural: 81.0
Entrada: 3.66
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.1449
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
636 636 636
(607, 30) (607, 30) (607, 30)
(607, 90) (607, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9532681  0.04673187]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 637 | Acuracia_7: 0.3333 | Contagem Geral: 60.0 
Ordem Natural: 82.0
Entrada: 3.99
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.6667 | Acuracia_7: 0.3333 
Precisao modelo Geral: 59.9278
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
637 637 637
(608, 30) (608, 30) (608, 30)
(608, 90) (608, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.69864833 0.30135164]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 638 | Acuracia_8: 1.0 | Contagem Geral: 60.0 
Ordem Natural: 83.0
Entrada: 2.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_8: 0.5 
Precisao modelo Geral: 59.7122
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
638 638 638
(609, 30) (609, 30) (609, 30)
(609, 90) (609, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89526683 0.10473319]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 639 | Acuracia_9: 0.5 | Contagem Geral: 61.0 
Ordem Natural: 83.0
Entrada: 4.11
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_9: 0.5 
Precisao modelo Geral: 59.4982
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
639 639 639
(610, 30) (610, 30) (610, 30)
(610, 90) (610, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9752739  0.02472613]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 640 | Acuracia_10: 0.5 | Contagem Geral: 61.0 
Ordem Natural: 84.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.6429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
640 640 640
(611, 30) (611, 30) (611, 30)
(611, 90) (611, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99217176 0.00782827]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 641 | Acuracia_11: 0 | Contagem Geral: 61.0 
Ordem Natural: 84.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_11: 0 
Precisao modelo Geral: 59.7865
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
641 641 641
(612, 30) (612, 30) (612, 30)
(612, 90) (612, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9771444  0.02285563]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 642 | Acuracia_12: 0.0 | Contagem Geral: 61.0 
Ordem Natural: 84.0
Entrada: 5.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.5745
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
642 642 642
(613, 30) (613, 30) (613, 30)
(613, 90) (613, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97433585 0.02566418]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 643 | Acuracia_13: 0.3333 | Contagem Geral: 61.0 
Ordem Natural: 85.0
Entrada: 2.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_13: 0.3333 
Precisao modelo Geral: 59.7173
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
643 643 643
(614, 30) (614, 30) (614, 30)
(614, 90) (614, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9953389  0.00466113]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 644 | Acuracia_14: 0.0 | Contagem Geral: 61.0 
Ordem Natural: 85.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_14: 0.0 
Precisao modelo Geral: 59.8592
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
644 644 644
(615, 30) (615, 30) (615, 30)
(615, 90) (615, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99244726 0.00755269]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 645 | Acuracia_15: 0.0 | Contagem Geral: 61.0 
Ordem Natural: 85.0
Entrada: 14.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_15: 0.0 
Precisao modelo Geral: 59.6491
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
645 645 645
(616, 30) (616, 30) (616, 30)
(616, 90) (616, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.88519174 0.11480829]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 646 | Acuracia_16: 0.0 | Contagem Geral: 61.0 
Ordem Natural: 86.0
Entrada: 8.28
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.2295 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.4406
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
646 646 646
(617, 30) (617, 30) (617, 30)
(617, 90) (617, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.54204494 0.4579551 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 647 | Acuracia_17: 0.3333 | Contagem Geral: 61.0 
Ordem Natural: 87.0
Entrada: 3.66
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.4194 | Acuracia_17: 0.5 
Precisao modelo Geral: 59.5819
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
647 647 647
(618, 30) (618, 30) (618, 30)
(618, 90) (618, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.79772395 0.20227602]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 648 | Acuracia_18: 0.0 | Contagem Geral: 62.0 
Ordem Natural: 88.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.9841 | Acuracia_18: 0.0 
Precisao modelo Geral: 59.375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
648 648 648
(619, 30) (619, 30) (619, 30)
(619, 90) (619, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9952289  0.00477112]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 649 | Acuracia_19: 0.0 | Contagem Geral: 63.0 
Ordem Natural: 88.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.9841 | Acuracia_19: 0.0 
Precisao modelo Geral: 59.5156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
649 649 649
(620, 30) (620, 30) (620, 30)
(620, 90) (620, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99679923 0.00320075]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 650 | Acuracia_20: 0.5 | Contagem Geral: 63.0 
Ordem Natural: 88.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.9841 | Acuracia_20: 0.5 
Precisao modelo Geral: 59.6552
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
650 650 650
(621, 30) (621, 30) (621, 30)
(621, 90) (621, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.931658   0.06834192]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 651 | Acuracia_21: 1.0 | Contagem Geral: 63.0 
Ordem Natural: 88.0
Entrada: 1.92
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.9841 | Acuracia_21: 1.0 
Precisao modelo Geral: 59.7938
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
651 651 651
(622, 30) (622, 30) (622, 30)
(622, 90) (622, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.660895   0.33910495]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 652 | Acuracia_22: 0.0 | Contagem Geral: 63.0 
Ordem Natural: 88.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_22: 0.0 
Precisao modelo Geral: 59.589
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
652 652 652
(623, 30) (623, 30) (623, 30)
(623, 90) (623, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97839624 0.02160372]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 653 | Acuracia_23: 0.5 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_23: 0.5 
Precisao modelo Geral: 59.727
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
653 653 653
(624, 30) (624, 30) (624, 30)
(624, 90) (624, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9977016  0.00229838]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 654 | Acuracia_24: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_24: 0.0 
Precisao modelo Geral: 59.8639
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
654 654 654
(625, 30) (625, 30) (625, 30)
(625, 90) (625, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9878649  0.01213509]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 655 | Acuracia_25: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 2.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
655 655 655
(626, 30) (626, 30) (626, 30)
(626, 90) (626, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9636354  0.03636464]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 656 | Acuracia_26: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_26: 0.0 
Precisao modelo Geral: 60.1351
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
656 656 656
(627, 30) (627, 30) (627, 30)
(627, 90) (627, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.88412917 0.11587077]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 657 | Acuracia_27: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 2.56
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.2694
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
657 657 657
(628, 30) (628, 30) (628, 30)
(628, 90) (628, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.95120645 0.04879351]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 658 | Acuracia_28: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.4027
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
658 658 658
(629, 30) (629, 30) (629, 30)
(629, 90) (629, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99305785 0.00694213]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 659 | Acuracia_29: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 2.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.5351
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
659 659 659
(630, 30) (630, 30) (630, 30)
(630, 90) (630, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9904875 0.0095125]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 660 | Acuracia_0: 0.5 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 2.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
660 660 660
(631, 30) (631, 30) (631, 30)
(631, 90) (631, 30)
Matrix_30: [(631, 90), (631, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1918 - accuracy: 0.3267 - precision: 0.3267 - recall: 0.3267 - f1_score: 0.3844 - val_loss: 0.1480 - val_accuracy: 0.7191 - val_precision: 0.7191 - val_recall: 0.7191 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2028 - accuracy: 0.6818 - precision: 0.6818 - recall: 0.6818 - f1_score: 0.0000e+00 - val_loss: 0.1669 - val_accuracy: 0.6180 - val_precision: 0.6180 - val_recall: 0.6180 - val_f1_score: 0.5750 - 75ms/epoch - 75ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1566 - accuracy: 0.6818 - precision: 0.6818 - recall: 0.6818 - f1_score: 0.6216 - val_loss: 0.2342 - val_accuracy: 0.2921 - val_precision: 0.2921 - val_recall: 0.2921 - val_f1_score: 0.4425 - 74ms/epoch - 74ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1716 - accuracy: 0.3324 - precision: 0.3324 - recall: 0.3324 - f1_score: 0.4880 - val_loss: 0.2069 - val_accuracy: 0.3146 - val_precision: 0.3146 - val_recall: 0.3146 - val_f1_score: 0.4505 - 74ms/epoch - 74ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.3892 - precision: 0.3892 - recall: 0.3892 - f1_score: 0.5080 - val_loss: 0.1631 - val_accuracy: 0.6292 - val_precision: 0.6292 - val_recall: 0.6292 - val_f1_score: 0.5823 - 75ms/epoch - 75ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1412 - accuracy: 0.7585 - precision: 0.7585 - recall: 0.7585 - f1_score: 0.7176 - val_loss: 0.1401 - val_accuracy: 0.8539 - val_precision: 0.8539 - val_recall: 0.8539 - val_f1_score: 0.6829 - 77ms/epoch - 77ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1393 - accuracy: 0.8580 - precision: 0.8580 - recall: 0.8580 - f1_score: 0.7475 - val_loss: 0.1309 - val_accuracy: 0.8090 - val_precision: 0.8090 - val_recall: 0.8090 - val_f1_score: 0.4848 - 75ms/epoch - 75ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1389 - accuracy: 0.8352 - precision: 0.8352 - recall: 0.8352 - f1_score: 0.6588 - val_loss: 0.1269 - val_accuracy: 0.8427 - val_precision: 0.8427 - val_recall: 0.8427 - val_f1_score: 0.6111 - 74ms/epoch - 74ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.8693 - precision: 0.8693 - recall: 0.8693 - f1_score: 0.7527 - val_loss: 0.1286 - val_accuracy: 0.8989 - val_precision: 0.8989 - val_recall: 0.8989 - val_f1_score: 0.8163 - 75ms/epoch - 75ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1187 - accuracy: 0.9148 - precision: 0.9148 - recall: 0.9148 - f1_score: 0.8649 - val_loss: 0.1415 - val_accuracy: 0.7528 - val_precision: 0.7528 - val_recall: 0.7528 - val_f1_score: 0.6765 - 74ms/epoch - 74ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1115 - accuracy: 0.8466 - precision: 0.8466 - recall: 0.8466 - f1_score: 0.8015 - val_loss: 0.1552 - val_accuracy: 0.6292 - val_precision: 0.6292 - val_recall: 0.6292 - val_f1_score: 0.5926 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1102 - accuracy: 0.7642 - precision: 0.7642 - recall: 0.7642 - f1_score: 0.7279 - val_loss: 0.1453 - val_accuracy: 0.7191 - val_precision: 0.7191 - val_recall: 0.7191 - val_f1_score: 0.6575 - 77ms/epoch - 77ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1024 - accuracy: 0.7983 - precision: 0.7983 - recall: 0.7983 - f1_score: 0.7577 - val_loss: 0.1195 - val_accuracy: 0.8315 - val_precision: 0.8315 - val_recall: 0.8315 - val_f1_score: 0.7458 - 75ms/epoch - 75ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0913 - accuracy: 0.9091 - precision: 0.9091 - recall: 0.9091 - f1_score: 0.8720 - val_loss: 0.1000 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0871 - accuracy: 0.9290 - precision: 0.9290 - recall: 0.9290 - f1_score: 0.8858 - val_loss: 0.0919 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8182 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0842 - accuracy: 0.9318 - precision: 0.9318 - recall: 0.9318 - f1_score: 0.8868 - val_loss: 0.0900 - val_accuracy: 0.8989 - val_precision: 0.8989 - val_recall: 0.8989 - val_f1_score: 0.8163 - 88ms/epoch - 88ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0751 - accuracy: 0.9347 - precision: 0.9347 - recall: 0.9347 - f1_score: 0.8969 - val_loss: 0.0986 - val_accuracy: 0.8652 - val_precision: 0.8652 - val_recall: 0.8652 - val_f1_score: 0.7857 - 103ms/epoch - 103ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0693 - accuracy: 0.9148 - precision: 0.9148 - recall: 0.9148 - f1_score: 0.8780 - val_loss: 0.1076 - val_accuracy: 0.7978 - val_precision: 0.7978 - val_recall: 0.7978 - val_f1_score: 0.7187 - 124ms/epoch - 124ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0680 - accuracy: 0.8835 - precision: 0.8835 - recall: 0.8835 - f1_score: 0.8417 - val_loss: 0.0940 - val_accuracy: 0.8764 - val_precision: 0.8764 - val_recall: 0.8764 - val_f1_score: 0.8000 - 73ms/epoch - 73ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0608 - accuracy: 0.9091 - precision: 0.9091 - recall: 0.9091 - f1_score: 0.8710 - val_loss: 0.0755 - val_accuracy: 0.8876 - val_precision: 0.8876 - val_recall: 0.8876 - val_f1_score: 0.8077 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0553 - accuracy: 0.9460 - precision: 0.9460 - recall: 0.9460 - f1_score: 0.9163 - val_loss: 0.0683 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8333 - 74ms/epoch - 74ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0538 - accuracy: 0.9517 - precision: 0.9517 - recall: 0.9517 - f1_score: 0.9224 - val_loss: 0.0678 - val_accuracy: 0.8989 - val_precision: 0.8989 - val_recall: 0.8989 - val_f1_score: 0.8235 - 75ms/epoch - 75ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0479 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9327 - val_loss: 0.0755 - val_accuracy: 0.8989 - val_precision: 0.8989 - val_recall: 0.8989 - val_f1_score: 0.8302 - 80ms/epoch - 80ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0438 - accuracy: 0.9460 - precision: 0.9460 - recall: 0.9460 - f1_score: 0.9191 - val_loss: 0.0820 - val_accuracy: 0.8876 - val_precision: 0.8876 - val_recall: 0.8876 - val_f1_score: 0.8214 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0426 - accuracy: 0.9347 - precision: 0.9347 - recall: 0.9347 - f1_score: 0.9046 - val_loss: 0.0711 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8519 - 83ms/epoch - 83ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0377 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9356 - val_loss: 0.0589 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8400 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0350 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - f1_score: 0.9554 - val_loss: 0.0553 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8400 - 76ms/epoch - 76ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0338 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - f1_score: 0.9550 - val_loss: 0.0568 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8627 - 74ms/epoch - 74ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0297 - accuracy: 0.9744 - precision: 0.9744 - recall: 0.9744 - f1_score: 0.9596 - val_loss: 0.0645 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 74ms/epoch - 74ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - f1_score: 0.9442 - val_loss: 0.0651 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 77ms/epoch - 77ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0265 - accuracy: 0.9659 - precision: 0.9659 - recall: 0.9659 - f1_score: 0.9487 - val_loss: 0.0554 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8627 - 91ms/epoch - 91ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0234 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9732 - val_loss: 0.0496 - val_accuracy: 0.9326 - val_precision: 0.9326 - val_recall: 0.9326 - val_f1_score: 0.8800 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9727 - val_loss: 0.0491 - val_accuracy: 0.9326 - val_precision: 0.9326 - val_recall: 0.9326 - val_f1_score: 0.8800 - 74ms/epoch - 74ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0204 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9727 - val_loss: 0.0531 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8462 - 72ms/epoch - 72ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0181 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 76ms/epoch - 76ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0173 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9956 - val_loss: 0.0543 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 73ms/epoch - 73ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0154 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9956 - val_loss: 0.0481 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8462 - 82ms/epoch - 82ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0139 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9956 - val_loss: 0.0464 - val_accuracy: 0.9326 - val_precision: 0.9326 - val_recall: 0.9326 - val_f1_score: 0.8800 - 90ms/epoch - 90ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0132 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9955 - val_loss: 0.0477 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8627 - 79ms/epoch - 79ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0116 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8462 - 75ms/epoch - 75ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0108 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9956 - val_loss: 0.0537 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8462 - 75ms/epoch - 75ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0101 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1_score: 0.9956 - val_loss: 0.0498 - val_accuracy: 0.9101 - val_precision: 0.9101 - val_recall: 0.9101 - val_f1_score: 0.8462 - 75ms/epoch - 75ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0090 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8627 - 159ms/epoch - 159ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0084 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8571 - 91ms/epoch - 91ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8627 - 74ms/epoch - 74ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0071 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 75ms/epoch - 75ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0068 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8679 - 106ms/epoch - 106ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0063 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8571 - 94ms/epoch - 94ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0057 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8571 - 98ms/epoch - 98ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0054 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9213 - val_precision: 0.9213 - val_recall: 0.9213 - val_f1_score: 0.8571 - 108ms/epoch - 108ms/step

🔍 Resultados no Teste:
Loss: 0.0343
Accuracy: 0.9421
Precision: 0.9421
Recall: 0.9421
F1 Score: 0.9009
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
660 660 660
(631, 30) (631, 30) (631, 30)
(631, 90) (631, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.9565677 0.0434323]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 661 | Acuracia_1: 0.3333 | Contagem Geral: 64.0 
Ordem Natural: 88.0
Entrada: 1265.03
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5625 | Acuracia_1: 0.3333 
Precisao modelo Geral: 60.4651
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
661 661 661
(632, 30) (632, 30) (632, 30)
(632, 90) (632, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.76092285 0.23907714]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 662 | Acuracia_2: 0.3333 | Contagem Geral: 64.0 
Ordem Natural: 89.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_2: 0.25 
Precisao modelo Geral: 60.2649
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
662 662 662
(633, 30) (633, 30) (633, 30)
(633, 90) (633, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8694605  0.13053949]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 663 | Acuracia_3: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 2.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.396
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
663 663 663
(634, 30) (634, 30) (634, 30)
(634, 90) (634, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9597812  0.04021878]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 664 | Acuracia_4: 0.5 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_4: 0.5 
Precisao modelo Geral: 60.5263
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
664 664 664
(635, 30) (635, 30) (635, 30)
(635, 90) (635, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.9570174  0.04298253]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 665 | Acuracia_5: 0.5 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 2.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_5: 0.5 
Precisao modelo Geral: 60.6557
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
665 665 665
(636, 30) (636, 30) (636, 30)
(636, 90) (636, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9463535 0.0536465]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 666 | Acuracia_6: 1.0 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 2.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.7843
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
666 666 666
(637, 30) (637, 30) (637, 30)
(637, 90) (637, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9616108  0.03838918]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 667 | Acuracia_7: 0.3333 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.9121
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
667 667 667
(638, 30) (638, 30) (638, 30)
(638, 90) (638, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9593199  0.04068005]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 668 | Acuracia_8: 0.5 | Contagem Geral: 65.0 
Ordem Natural: 89.0
Entrada: 9.28
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_8: 0.5 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
668 668 668
(639, 30) (639, 30) (639, 30)
(639, 90) (639, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9529203  0.04707967]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 669 | Acuracia_9: 0.5 | Contagem Geral: 65.0 
Ordem Natural: 90.0
Entrada: 4.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.5178
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
669 669 669
(640, 30) (640, 30) (640, 30)
(640, 90) (640, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.8899527  0.11004727]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 670 | Acuracia_10: 0.5 | Contagem Geral: 65.0 
Ordem Natural: 91.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.3226
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
670 670 670
(641, 30) (641, 30) (641, 30)
(641, 90) (641, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97092295 0.02907705]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 671 | Acuracia_11: 0 | Contagem Geral: 65.0 
Ordem Natural: 92.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_11: 0 
Precisao modelo Geral: 60.4502
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
671 671 671
(642, 30) (642, 30) (642, 30)
(642, 90) (642, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9706186  0.02938143]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 672 | Acuracia_12: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 92.0
Entrada: 37.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.1538 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.2564
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
672 672 672
(643, 30) (643, 30) (643, 30)
(643, 90) (643, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.73019904 0.269801  ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 673 | Acuracia_13: 0.3333 | Contagem Geral: 65.0 
Ordem Natural: 93.0
Entrada: 8.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_13: 0.5 
Precisao modelo Geral: 60.3834
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
673 673 673
(644, 30) (644, 30) (644, 30)
(644, 90) (644, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.84788567 0.15211432]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 674 | Acuracia_14: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 94.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.5096
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
674 674 674
(645, 30) (645, 30) (645, 30)
(645, 90) (645, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95165354 0.04834647]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 675 | Acuracia_15: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 94.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.6349
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
675 675 675
(646, 30) (646, 30) (646, 30)
(646, 90) (646, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9885443  0.01145571]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 676 | Acuracia_16: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 94.0
Entrada: 28.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.443
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
676 676 676
(647, 30) (647, 30) (647, 30)
(647, 90) (647, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97956836 0.02043164]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 677 | Acuracia_17: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 95.0
Entrada: 5.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_17: 0.5 
Precisao modelo Geral: 60.2524
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
677 677 677
(648, 30) (648, 30) (648, 30)
(648, 90) (648, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9847551  0.01524492]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 678 | Acuracia_18: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 96.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_18: 0.0 
Precisao modelo Geral: 60.3774
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
678 678 678
(649, 30) (649, 30) (649, 30)
(649, 90) (649, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9707506  0.02924947]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 679 | Acuracia_19: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 96.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_19: 0.0 
Precisao modelo Geral: 60.5016
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
679 679 679
(650, 30) (650, 30) (650, 30)
(650, 90) (650, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98003286 0.0199671 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 680 | Acuracia_20: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 96.0
Entrada: 2.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_20: 0.5 
Precisao modelo Geral: 60.625
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
680 680 680
(651, 30) (651, 30) (651, 30)
(651, 90) (651, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9879874  0.01201259]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 681 | Acuracia_21: 1.0 | Contagem Geral: 66.0 
Ordem Natural: 96.0
Entrada: 3.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.4361
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
681 681 681
(652, 30) (652, 30) (652, 30)
(652, 90) (652, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9927907  0.00720924]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 682 | Acuracia_22: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 97.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_22: 0.0 
Precisao modelo Geral: 60.559
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
682 682 682
(653, 30) (653, 30) (653, 30)
(653, 90) (653, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9724726 0.0275274]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 683 | Acuracia_23: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 97.0
Entrada: 10.86
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_23: 0.5 
Precisao modelo Geral: 60.3715
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
683 683 683
(654, 30) (654, 30) (654, 30)
(654, 90) (654, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9731549  0.02684508]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 684 | Acuracia_24: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 98.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_24: 0.0 
Precisao modelo Geral: 60.4938
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
684 684 684
(655, 30) (655, 30) (655, 30)
(655, 90) (655, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
[[0.9903143  0.00968571]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 685 | Acuracia_25: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 98.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.6154
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
685 685 685
(656, 30) (656, 30) (656, 30)
(656, 90) (656, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9978496  0.00215039]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 686 | Acuracia_26: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 98.0
Entrada: 1.9
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_26: 0.0 
Precisao modelo Geral: 60.7362
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
686 686 686
(657, 30) (657, 30) (657, 30)
(657, 90) (657, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9682463  0.03175367]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 687 | Acuracia_27: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 98.0
Entrada: 3.99
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.5505
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
687 687 687
(658, 30) (658, 30) (658, 30)
(658, 90) (658, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9515541  0.04844593]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 688 | Acuracia_28: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 99.0
Entrada: 2.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.6707
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
688 688 688
(659, 30) (659, 30) (659, 30)
(659, 90) (659, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9391333  0.06086672]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 689 | Acuracia_29: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 99.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.7903
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
689 689 689
(660, 30) (660, 30) (660, 30)
(660, 90) (660, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.998071   0.00192901]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 690 | Acuracia_0: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 99.0
Entrada: 15.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
690 690 690
(661, 30) (661, 30) (661, 30)
(661, 90) (661, 30)
Matrix_30: [(661, 90), (661, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2038 - accuracy: 0.3008 - precision: 0.3008 - recall: 0.3008 - f1_score: 0.3582 - val_loss: 0.1440 - val_accuracy: 0.7527 - val_precision: 0.7527 - val_recall: 0.7527 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2002 - accuracy: 0.6802 - precision: 0.6802 - recall: 0.6802 - f1_score: 0.0167 - val_loss: 0.2224 - val_accuracy: 0.2473 - val_precision: 0.2473 - val_recall: 0.2473 - val_f1_score: 0.3966 - 76ms/epoch - 76ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1705 - accuracy: 0.3550 - precision: 0.3550 - recall: 0.3550 - f1_score: 0.5000 - val_loss: 0.2371 - val_accuracy: 0.2473 - val_precision: 0.2473 - val_recall: 0.2473 - val_f1_score: 0.3966 - 76ms/epoch - 76ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.3496 - precision: 0.3496 - recall: 0.3496 - f1_score: 0.4979 - val_loss: 0.1755 - val_accuracy: 0.5269 - val_precision: 0.5269 - val_recall: 0.5269 - val_f1_score: 0.4884 - 81ms/epoch - 81ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1433 - accuracy: 0.6504 - precision: 0.6504 - recall: 0.6504 - f1_score: 0.6407 - val_loss: 0.1370 - val_accuracy: 0.8280 - val_precision: 0.8280 - val_recall: 0.8280 - val_f1_score: 0.6000 - 78ms/epoch - 78ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1405 - accuracy: 0.8428 - precision: 0.8428 - recall: 0.8428 - f1_score: 0.7212 - val_loss: 0.1267 - val_accuracy: 0.8172 - val_precision: 0.8172 - val_recall: 0.8172 - val_f1_score: 0.5143 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1390 - accuracy: 0.8482 - precision: 0.8482 - recall: 0.8482 - f1_score: 0.7053 - val_loss: 0.1309 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.6818 - 74ms/epoch - 74ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1253 - accuracy: 0.8618 - precision: 0.8618 - recall: 0.8618 - f1_score: 0.7773 - val_loss: 0.1502 - val_accuracy: 0.7204 - val_precision: 0.7204 - val_recall: 0.7204 - val_f1_score: 0.6286 - 76ms/epoch - 76ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1177 - accuracy: 0.8022 - precision: 0.8022 - recall: 0.8022 - f1_score: 0.7525 - val_loss: 0.1682 - val_accuracy: 0.5699 - val_precision: 0.5699 - val_recall: 0.5699 - val_f1_score: 0.5349 - 74ms/epoch - 74ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1179 - accuracy: 0.7046 - precision: 0.7046 - recall: 0.7046 - f1_score: 0.6804 - val_loss: 0.1557 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_f1_score: 0.5714 - 77ms/epoch - 77ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1096 - accuracy: 0.7615 - precision: 0.7615 - recall: 0.7615 - f1_score: 0.7215 - val_loss: 0.1246 - val_accuracy: 0.8602 - val_precision: 0.8602 - val_recall: 0.8602 - val_f1_score: 0.7719 - 81ms/epoch - 81ms/step
Epoch 12/50
1/1 - 0s - loss: 0.0989 - accuracy: 0.8726 - precision: 0.8726 - recall: 0.8726 - f1_score: 0.8213 - val_loss: 0.1039 - val_accuracy: 0.8710 - val_precision: 0.8710 - val_recall: 0.8710 - val_f1_score: 0.7391 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0976 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - f1_score: 0.8210 - val_loss: 0.0989 - val_accuracy: 0.8602 - val_precision: 0.8602 - val_recall: 0.8602 - val_f1_score: 0.7234 - 76ms/epoch - 76ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0929 - accuracy: 0.8970 - precision: 0.8970 - recall: 0.8970 - f1_score: 0.8333 - val_loss: 0.1077 - val_accuracy: 0.8710 - val_precision: 0.8710 - val_recall: 0.8710 - val_f1_score: 0.7778 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0834 - accuracy: 0.8835 - precision: 0.8835 - recall: 0.8835 - f1_score: 0.8314 - val_loss: 0.1270 - val_accuracy: 0.8065 - val_precision: 0.8065 - val_recall: 0.8065 - val_f1_score: 0.7097 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0825 - accuracy: 0.8428 - precision: 0.8428 - recall: 0.8428 - f1_score: 0.7958 - val_loss: 0.1242 - val_accuracy: 0.8065 - val_precision: 0.8065 - val_recall: 0.8065 - val_f1_score: 0.7097 - 75ms/epoch - 75ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0787 - accuracy: 0.8455 - precision: 0.8455 - recall: 0.8455 - f1_score: 0.8000 - val_loss: 0.0987 - val_accuracy: 0.8710 - val_precision: 0.8710 - val_recall: 0.8710 - val_f1_score: 0.7778 - 77ms/epoch - 77ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0712 - accuracy: 0.8862 - precision: 0.8862 - recall: 0.8862 - f1_score: 0.8359 - val_loss: 0.0833 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7755 - 94ms/epoch - 94ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0714 - accuracy: 0.9160 - precision: 0.9160 - recall: 0.9160 - f1_score: 0.8681 - val_loss: 0.0838 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8000 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0664 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8619 - val_loss: 0.0989 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.7500 - 81ms/epoch - 81ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0622 - accuracy: 0.8862 - precision: 0.8862 - recall: 0.8862 - f1_score: 0.8421 - val_loss: 0.1080 - val_accuracy: 0.8387 - val_precision: 0.8387 - val_recall: 0.8387 - val_f1_score: 0.7458 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0615 - accuracy: 0.8726 - precision: 0.8726 - recall: 0.8726 - f1_score: 0.8291 - val_loss: 0.0915 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.7500 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0556 - accuracy: 0.9133 - precision: 0.9133 - recall: 0.9133 - f1_score: 0.8750 - val_loss: 0.0769 - val_accuracy: 0.9032 - val_precision: 0.9032 - val_recall: 0.9032 - val_f1_score: 0.8235 - 79ms/epoch - 79ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0547 - accuracy: 0.9268 - precision: 0.9268 - recall: 0.9268 - f1_score: 0.8870 - val_loss: 0.0769 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8077 - 78ms/epoch - 78ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0516 - accuracy: 0.9295 - precision: 0.9295 - recall: 0.9295 - f1_score: 0.8917 - val_loss: 0.0897 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.7500 - 81ms/epoch - 81ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0481 - accuracy: 0.9214 - precision: 0.9214 - recall: 0.9214 - f1_score: 0.8863 - val_loss: 0.0978 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.7500 - 86ms/epoch - 86ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0473 - accuracy: 0.9051 - precision: 0.9051 - recall: 0.9051 - f1_score: 0.8659 - val_loss: 0.0842 - val_accuracy: 0.8495 - val_precision: 0.8495 - val_recall: 0.8495 - val_f1_score: 0.7500 - 87ms/epoch - 87ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0430 - accuracy: 0.9377 - precision: 0.9377 - recall: 0.9377 - f1_score: 0.9076 - val_loss: 0.0712 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8077 - 79ms/epoch - 79ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0418 - accuracy: 0.9431 - precision: 0.9431 - recall: 0.9431 - f1_score: 0.9121 - val_loss: 0.0717 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8077 - 75ms/epoch - 75ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0389 - accuracy: 0.9485 - precision: 0.9485 - recall: 0.9485 - f1_score: 0.9212 - val_loss: 0.0825 - val_accuracy: 0.8710 - val_precision: 0.8710 - val_recall: 0.8710 - val_f1_score: 0.7778 - 86ms/epoch - 86ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0366 - accuracy: 0.9485 - precision: 0.9485 - recall: 0.9485 - f1_score: 0.9231 - val_loss: 0.0848 - val_accuracy: 0.8602 - val_precision: 0.8602 - val_recall: 0.8602 - val_f1_score: 0.7636 - 78ms/epoch - 78ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0352 - accuracy: 0.9512 - precision: 0.9512 - recall: 0.9512 - f1_score: 0.9280 - val_loss: 0.0707 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7925 - 80ms/epoch - 80ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0321 - accuracy: 0.9593 - precision: 0.9593 - recall: 0.9593 - f1_score: 0.9383 - val_loss: 0.0621 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8000 - 85ms/epoch - 85ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0313 - accuracy: 0.9648 - precision: 0.9648 - recall: 0.9648 - f1_score: 0.9451 - val_loss: 0.0652 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7843 - 110ms/epoch - 110ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0285 - accuracy: 0.9675 - precision: 0.9675 - recall: 0.9675 - f1_score: 0.9500 - val_loss: 0.0738 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7925 - 97ms/epoch - 97ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0273 - accuracy: 0.9729 - precision: 0.9729 - recall: 0.9729 - f1_score: 0.9593 - val_loss: 0.0691 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7925 - 162ms/epoch - 162ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0253 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9551 - val_loss: 0.0577 - val_accuracy: 0.8925 - val_precision: 0.8925 - val_recall: 0.8925 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0237 - accuracy: 0.9864 - precision: 0.9864 - recall: 0.9864 - f1_score: 0.9789 - val_loss: 0.0548 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8333 - 75ms/epoch - 75ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0225 - accuracy: 0.9892 - precision: 0.9892 - recall: 0.9892 - f1_score: 0.9832 - val_loss: 0.0602 - val_accuracy: 0.8710 - val_precision: 0.8710 - val_recall: 0.8710 - val_f1_score: 0.7692 - 78ms/epoch - 78ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0207 - accuracy: 0.9919 - precision: 0.9919 - recall: 0.9919 - f1_score: 0.9874 - val_loss: 0.0635 - val_accuracy: 0.8817 - val_precision: 0.8817 - val_recall: 0.8817 - val_f1_score: 0.7925 - 91ms/epoch - 91ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0199 - accuracy: 0.9892 - precision: 0.9892 - recall: 0.9892 - f1_score: 0.9835 - val_loss: 0.0558 - val_accuracy: 0.9032 - val_precision: 0.9032 - val_recall: 0.9032 - val_f1_score: 0.8163 - 82ms/epoch - 82ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0182 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9917 - val_loss: 0.0496 - val_accuracy: 0.9247 - val_precision: 0.9247 - val_recall: 0.9247 - val_f1_score: 0.8511 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9915 - val_loss: 0.0506 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8333 - 77ms/epoch - 77ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0161 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9032 - val_precision: 0.9032 - val_recall: 0.9032 - val_f1_score: 0.8235 - 80ms/epoch - 80ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0153 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - f1_score: 0.9958 - val_loss: 0.0540 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8400 - 76ms/epoch - 76ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0144 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8261 - 77ms/epoch - 77ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0134 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8261 - 76ms/epoch - 76ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0128 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9140 - val_precision: 0.9140 - val_recall: 0.9140 - val_f1_score: 0.8333 - 76ms/epoch - 76ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9247 - val_precision: 0.9247 - val_recall: 0.9247 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9247 - val_precision: 0.9247 - val_recall: 0.9247 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0383
Accuracy: 0.9447
Precision: 0.9447
Recall: 0.9447
F1 Score: 0.9091
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
690 690 690
(661, 30) (661, 30) (661, 30)
(661, 90) (661, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 88ms/step
[[0.9669835  0.03301646]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 691 | Acuracia_1: 0.3333 | Contagem Geral: 66.0 
Ordem Natural: 100.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_1: 0.3333 
Precisao modelo Geral: 60.7251
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
691 691 691
(662, 30) (662, 30) (662, 30)
(662, 90) (662, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.99188316 0.00811685]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 692 | Acuracia_2: 0.25 | Contagem Geral: 66.0 
Ordem Natural: 100.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_2: 0.25 
Precisao modelo Geral: 60.8434
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
692 692 692
(663, 30) (663, 30) (663, 30)
(663, 90) (663, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98556316 0.01443681]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 693 | Acuracia_3: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 100.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.961
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
693 693 693
(664, 30) (664, 30) (664, 30)
(664, 90) (664, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8899394 0.1100606]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 694 | Acuracia_4: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 100.0
Entrada: 29.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_4: 0.5 
Precisao modelo Geral: 60.7784
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
694 694 694
(665, 30) (665, 30) (665, 30)
(665, 90) (665, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.86110073 0.13889927]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 695 | Acuracia_5: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 101.0
Entrada: 39.3
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_5: 0.5 
Precisao modelo Geral: 60.597
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
695 695 695
(666, 30) (666, 30) (666, 30)
(666, 90) (666, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8874861  0.11251389]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 696 | Acuracia_6: 1.0 | Contagem Geral: 66.0 
Ordem Natural: 102.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
696 696 696
(667, 30) (667, 30) (667, 30)
(667, 90) (667, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9352462  0.06475379]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 697 | Acuracia_7: 0.3333 | Contagem Geral: 66.0 
Ordem Natural: 102.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.8309
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
697 697 697
(668, 30) (668, 30) (668, 30)
(668, 90) (668, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.83417875 0.16582127]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 698 | Acuracia_8: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 102.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_8: 0.5 
Precisao modelo Geral: 60.9467
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
698 698 698
(669, 30) (669, 30) (669, 30)
(669, 90) (669, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8821113 0.1178887]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 699 | Acuracia_9: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 102.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_9: 0.5 
Precisao modelo Geral: 61.0619
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
699 699 699
(670, 30) (670, 30) (670, 30)
(670, 90) (670, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.67290485 0.32709515]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 700 | Acuracia_10: 0.5 | Contagem Geral: 66.0 
Ordem Natural: 102.0
Entrada: 5.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_10: 0.6667 
Precisao modelo Geral: 61.1765
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
700 700 700
(671, 30) (671, 30) (671, 30)
(671, 90) (671, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.42331335 0.5766867 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 701 | Acuracia_11: 0 | Contagem Geral: 67.0 
Ordem Natural: 103.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_11: 0.0 
Precisao modelo Geral: 60.9971
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
701 701 701
(672, 30) (672, 30) (672, 30)
(672, 90) (672, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97748125 0.02251874]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 702 | Acuracia_12: 0.0 | Contagem Geral: 68.0 
Ordem Natural: 103.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_12: 0.0 
Precisao modelo Geral: 61.1111
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
702 702 702
(673, 30) (673, 30) (673, 30)
(673, 90) (673, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9857817  0.01421833]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 703 | Acuracia_13: 0.5 | Contagem Geral: 68.0 
Ordem Natural: 103.0
Entrada: 4.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_13: 0.5 
Precisao modelo Geral: 60.9329
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
703 703 703
(674, 30) (674, 30) (674, 30)
(674, 90) (674, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6658674  0.33413258]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 704 | Acuracia_14: 0.0 | Contagem Geral: 68.0 
Ordem Natural: 104.0
Entrada: 2.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5362 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.7558
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
704 704 704
(675, 30) (675, 30) (675, 30)
(675, 90) (675, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6381829  0.36181712]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 705 | Acuracia_15: 0.0 | Contagem Geral: 69.0 
Ordem Natural: 104.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.5797
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
705 705 705
(676, 30) (676, 30) (676, 30)
(676, 90) (676, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8810378  0.11896225]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 706 | Acuracia_16: 0.0 | Contagem Geral: 70.0 
Ordem Natural: 104.0
Entrada: 1.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.6936
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
706 706 706
(677, 30) (677, 30) (677, 30)
(677, 90) (677, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9846538  0.01534619]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 707 | Acuracia_17: 0.5 | Contagem Geral: 70.0 
Ordem Natural: 104.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_17: 0.5 
Precisao modelo Geral: 60.8069
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
707 707 707
(678, 30) (678, 30) (678, 30)
(678, 90) (678, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9690981 0.0309019]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 708 | Acuracia_18: 0.0 | Contagem Geral: 70.0 
Ordem Natural: 104.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_18: 0.0 
Precisao modelo Geral: 60.9195
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
708 708 708
(679, 30) (679, 30) (679, 30)
(679, 90) (679, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.87837154 0.12162844]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 709 | Acuracia_19: 0.0 | Contagem Geral: 70.0 
Ordem Natural: 104.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_19: 0.0 
Precisao modelo Geral: 60.745
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
709 709 709
(680, 30) (680, 30) (680, 30)
(680, 90) (680, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8970014  0.10299865]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 710 | Acuracia_20: 0.5 | Contagem Geral: 70.0 
Ordem Natural: 105.0
Entrada: 3.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_20: 0.5 
Precisao modelo Geral: 60.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
710 710 710
(681, 30) (681, 30) (681, 30)
(681, 90) (681, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.60565317 0.39434686]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 711 | Acuracia_21: 1.0 | Contagem Geral: 70.0 
Ordem Natural: 106.0
Entrada: 103.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.6838
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
711 711 711
(682, 30) (682, 30) (682, 30)
(682, 90) (682, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8780014 0.1219986]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 712 | Acuracia_22: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 107.0
Entrada: 8.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_22: 0.0 
Precisao modelo Geral: 60.5114
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
712 712 712
(683, 30) (683, 30) (683, 30)
(683, 90) (683, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9727199  0.02728006]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 713 | Acuracia_23: 0.5 | Contagem Geral: 71.0 
Ordem Natural: 108.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_23: 0.5 
Precisao modelo Geral: 60.6232
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
713 713 713
(684, 30) (684, 30) (684, 30)
(684, 90) (684, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.97514534 0.02485461]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 714 | Acuracia_24: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 108.0
Entrada: 2.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_24: 0.0 
Precisao modelo Geral: 60.7345
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
714 714 714
(685, 30) (685, 30) (685, 30)
(685, 90) (685, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.928951   0.07104892]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 715 | Acuracia_25: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 108.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.8451
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
715 715 715
(686, 30) (686, 30) (686, 30)
(686, 90) (686, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9122052  0.08779482]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 716 | Acuracia_26: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 108.0
Entrada: 3.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_26: 0.0 
Precisao modelo Geral: 60.6742
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
716 716 716
(687, 30) (687, 30) (687, 30)
(687, 90) (687, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.88615733 0.11384271]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 717 | Acuracia_27: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 109.0
Entrada: 2.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.7843
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
717 717 717
(688, 30) (688, 30) (688, 30)
(688, 90) (688, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.5792846  0.42071536]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 718 | Acuracia_28: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 109.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.6145
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
718 718 718
(689, 30) (689, 30) (689, 30)
(689, 90) (689, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8747608  0.12523924]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 719 | Acuracia_29: 0.0 | Contagem Geral: 72.0 
Ordem Natural: 109.0
Entrada: 8.89
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.4457
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
719 719 719
(690, 30) (690, 30) (690, 30)
(690, 90) (690, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9705874 0.0294126]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 720 | Acuracia_0: 0.5 | Contagem Geral: 72.0 
Ordem Natural: 110.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
720 720 720
(691, 30) (691, 30) (691, 30)
(691, 90) (691, 30)
Matrix_30: [(691, 90), (691, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2569 - accuracy: 0.6658 - precision: 0.6658 - recall: 0.6658 - f1_score: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.2887 - val_precision: 0.2887 - val_recall: 0.2887 - val_f1_score: 0.4390 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2397 - accuracy: 0.3135 - precision: 0.3135 - recall: 0.3135 - f1_score: 0.4773 - val_loss: 0.2552 - val_accuracy: 0.2887 - val_precision: 0.2887 - val_recall: 0.2887 - val_f1_score: 0.4390 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2074 - accuracy: 0.3135 - precision: 0.3135 - recall: 0.3135 - f1_score: 0.4752 - val_loss: 0.1946 - val_accuracy: 0.3608 - val_precision: 0.3608 - val_recall: 0.3608 - val_f1_score: 0.4259 - 80ms/epoch - 80ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.3990 - precision: 0.3990 - recall: 0.3990 - f1_score: 0.4821 - val_loss: 0.1613 - val_accuracy: 0.6186 - val_precision: 0.6186 - val_recall: 0.6186 - val_f1_score: 0.3729 - 78ms/epoch - 78ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6347 - precision: 0.6347 - recall: 0.6347 - f1_score: 0.4835 - val_loss: 0.1450 - val_accuracy: 0.7732 - val_precision: 0.7732 - val_recall: 0.7732 - val_f1_score: 0.4211 - 76ms/epoch - 76ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.7642 - precision: 0.7642 - recall: 0.7642 - f1_score: 0.4916 - val_loss: 0.1373 - val_accuracy: 0.7732 - val_precision: 0.7732 - val_recall: 0.7732 - val_f1_score: 0.4211 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.7850 - precision: 0.7850 - recall: 0.7850 - f1_score: 0.5464 - val_loss: 0.1363 - val_accuracy: 0.8763 - val_precision: 0.8763 - val_recall: 0.8763 - val_f1_score: 0.7600 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1433 - accuracy: 0.7979 - precision: 0.7979 - recall: 0.7979 - f1_score: 0.6549 - val_loss: 0.1425 - val_accuracy: 0.8247 - val_precision: 0.8247 - val_recall: 0.8247 - val_f1_score: 0.7213 - 77ms/epoch - 77ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1348 - accuracy: 0.7798 - precision: 0.7798 - recall: 0.7798 - f1_score: 0.7176 - val_loss: 0.1513 - val_accuracy: 0.7216 - val_precision: 0.7216 - val_recall: 0.7216 - val_f1_score: 0.6667 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.7306 - precision: 0.7306 - recall: 0.7306 - f1_score: 0.6959 - val_loss: 0.1520 - val_accuracy: 0.7010 - val_precision: 0.7010 - val_recall: 0.7010 - val_f1_score: 0.6506 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1268 - accuracy: 0.7332 - precision: 0.7332 - recall: 0.7332 - f1_score: 0.7032 - val_loss: 0.1400 - val_accuracy: 0.7423 - val_precision: 0.7423 - val_recall: 0.7423 - val_f1_score: 0.6753 - 78ms/epoch - 78ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1189 - accuracy: 0.7694 - precision: 0.7694 - recall: 0.7694 - f1_score: 0.7311 - val_loss: 0.1222 - val_accuracy: 0.8866 - val_precision: 0.8866 - val_recall: 0.8866 - val_f1_score: 0.8197 - 79ms/epoch - 79ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1107 - accuracy: 0.8290 - precision: 0.8290 - recall: 0.8290 - f1_score: 0.7692 - val_loss: 0.1072 - val_accuracy: 0.9175 - val_precision: 0.9175 - val_recall: 0.9175 - val_f1_score: 0.8462 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1059 - accuracy: 0.8705 - precision: 0.8705 - recall: 0.8705 - f1_score: 0.7967 - val_loss: 0.0988 - val_accuracy: 0.9175 - val_precision: 0.9175 - val_recall: 0.9175 - val_f1_score: 0.8400 - 79ms/epoch - 79ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1019 - accuracy: 0.8886 - precision: 0.8886 - recall: 0.8886 - f1_score: 0.8155 - val_loss: 0.0966 - val_accuracy: 0.8969 - val_precision: 0.8969 - val_recall: 0.8969 - val_f1_score: 0.8148 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0950 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - f1_score: 0.8299 - val_loss: 0.0999 - val_accuracy: 0.8866 - val_precision: 0.8866 - val_recall: 0.8866 - val_f1_score: 0.8136 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0884 - accuracy: 0.8756 - precision: 0.8756 - recall: 0.8756 - f1_score: 0.8235 - val_loss: 0.1060 - val_accuracy: 0.8454 - val_precision: 0.8454 - val_recall: 0.8454 - val_f1_score: 0.7692 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0850 - accuracy: 0.8756 - precision: 0.8756 - recall: 0.8756 - f1_score: 0.8298 - val_loss: 0.1054 - val_accuracy: 0.8454 - val_precision: 0.8454 - val_recall: 0.8454 - val_f1_score: 0.7692 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0812 - accuracy: 0.8679 - precision: 0.8679 - recall: 0.8679 - f1_score: 0.8211 - val_loss: 0.0938 - val_accuracy: 0.8763 - val_precision: 0.8763 - val_recall: 0.8763 - val_f1_score: 0.8065 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0748 - accuracy: 0.8808 - precision: 0.8808 - recall: 0.8808 - f1_score: 0.8321 - val_loss: 0.0804 - val_accuracy: 0.8969 - val_precision: 0.8969 - val_recall: 0.8969 - val_f1_score: 0.8276 - 80ms/epoch - 80ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0704 - accuracy: 0.9093 - precision: 0.9093 - recall: 0.9093 - f1_score: 0.8638 - val_loss: 0.0733 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_f1_score: 0.8364 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0682 - accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.8790 - val_loss: 0.0724 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_f1_score: 0.8421 - 79ms/epoch - 79ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0635 - accuracy: 0.9249 - precision: 0.9249 - recall: 0.9249 - f1_score: 0.8845 - val_loss: 0.0769 - val_accuracy: 0.8866 - val_precision: 0.8866 - val_recall: 0.8866 - val_f1_score: 0.8197 - 77ms/epoch - 77ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0591 - accuracy: 0.9145 - precision: 0.9145 - recall: 0.9145 - f1_score: 0.8726 - val_loss: 0.0814 - val_accuracy: 0.8866 - val_precision: 0.8866 - val_recall: 0.8866 - val_f1_score: 0.8197 - 78ms/epoch - 78ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0569 - accuracy: 0.9041 - precision: 0.9041 - recall: 0.9041 - f1_score: 0.8614 - val_loss: 0.0772 - val_accuracy: 0.8866 - val_precision: 0.8866 - val_recall: 0.8866 - val_f1_score: 0.8197 - 80ms/epoch - 80ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0532 - accuracy: 0.9171 - precision: 0.9171 - recall: 0.9171 - f1_score: 0.8779 - val_loss: 0.0677 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_f1_score: 0.8475 - 78ms/epoch - 78ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0492 - accuracy: 0.9326 - precision: 0.9326 - recall: 0.9326 - f1_score: 0.8968 - val_loss: 0.0612 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8772 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0470 - accuracy: 0.9482 - precision: 0.9482 - recall: 0.9482 - f1_score: 0.9174 - val_loss: 0.0597 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8772 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0441 - accuracy: 0.9508 - precision: 0.9508 - recall: 0.9508 - f1_score: 0.9212 - val_loss: 0.0624 - val_accuracy: 0.9175 - val_precision: 0.9175 - val_recall: 0.9175 - val_f1_score: 0.8621 - 78ms/epoch - 78ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0408 - accuracy: 0.9508 - precision: 0.9508 - recall: 0.9508 - f1_score: 0.9237 - val_loss: 0.0664 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_f1_score: 0.8475 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0388 - accuracy: 0.9534 - precision: 0.9534 - recall: 0.9534 - f1_score: 0.9291 - val_loss: 0.0649 - val_accuracy: 0.8969 - val_precision: 0.8969 - val_recall: 0.8969 - val_f1_score: 0.8333 - 79ms/epoch - 79ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0363 - accuracy: 0.9534 - precision: 0.9534 - recall: 0.9534 - f1_score: 0.9291 - val_loss: 0.0584 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8772 - 82ms/epoch - 82ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0333 - accuracy: 0.9715 - precision: 0.9715 - recall: 0.9715 - f1_score: 0.9547 - val_loss: 0.0535 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 79ms/epoch - 79ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0314 - accuracy: 0.9689 - precision: 0.9689 - recall: 0.9689 - f1_score: 0.9500 - val_loss: 0.0525 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_f1_score: 0.8889 - 78ms/epoch - 78ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0292 - accuracy: 0.9715 - precision: 0.9715 - recall: 0.9715 - f1_score: 0.9544 - val_loss: 0.0549 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8772 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0268 - accuracy: 0.9741 - precision: 0.9741 - recall: 0.9741 - f1_score: 0.9590 - val_loss: 0.0580 - val_accuracy: 0.9175 - val_precision: 0.9175 - val_recall: 0.9175 - val_f1_score: 0.8621 - 79ms/epoch - 79ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0253 - accuracy: 0.9845 - precision: 0.9845 - recall: 0.9845 - f1_score: 0.9758 - val_loss: 0.0568 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_f1_score: 0.8929 - 87ms/epoch - 87ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0235 - accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - f1_score: 0.9837 - val_loss: 0.0524 - val_accuracy: 0.9485 - val_precision: 0.9485 - val_recall: 0.9485 - val_f1_score: 0.9091 - 82ms/epoch - 82ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0216 - accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - f1_score: 0.9835 - val_loss: 0.0496 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_f1_score: 0.8889 - 82ms/epoch - 82ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0204 - accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - f1_score: 0.9835 - val_loss: 0.0495 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_f1_score: 0.8889 - 79ms/epoch - 79ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0189 - accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - f1_score: 0.9835 - val_loss: 0.0514 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 78ms/epoch - 78ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0175 - accuracy: 0.9948 - precision: 0.9948 - recall: 0.9948 - f1_score: 0.9918 - val_loss: 0.0530 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_f1_score: 0.8929 - 78ms/epoch - 78ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0166 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0518 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0153 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0497 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 103ms/epoch - 103ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0142 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0490 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 87ms/epoch - 87ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0134 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0495 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 80ms/epoch - 80ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0124 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0508 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0116 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0515 - val_accuracy: 0.9278 - val_precision: 0.9278 - val_recall: 0.9278 - val_f1_score: 0.8727 - 79ms/epoch - 79ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0108 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0506 - val_accuracy: 0.9175 - val_precision: 0.9175 - val_recall: 0.9175 - val_f1_score: 0.8519 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0100 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - f1_score: 0.9959 - val_loss: 0.0498 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_f1_score: 0.8302 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0371
Accuracy: 0.9231
Precision: 0.9231
Recall: 0.9231
F1 Score: 0.8730
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
720 720 720
(691, 30) (691, 30) (691, 30)
(691, 90) (691, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 89ms/step
[[0.9427345  0.05726549]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 721 | Acuracia_1: 0.3333 | Contagem Geral: 72.0 
Ordem Natural: 110.0
Entrada: 2.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_1: 0.3333 
Precisao modelo Geral: 60.6648
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
721 721 721
(692, 30) (692, 30) (692, 30)
(692, 90) (692, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.37115473 0.6288453 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 722 | Acuracia_2: 0.25 | Contagem Geral: 72.0 
Ordem Natural: 110.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_2: 0.2 
Precisao modelo Geral: 60.4972
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
722 722 722
(693, 30) (693, 30) (693, 30)
(693, 90) (693, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.27492195 0.72507805]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 723 | Acuracia_3: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 110.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.027 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.3306
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
723 723 723
(694, 30) (694, 30) (694, 30)
(694, 90) (694, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.95757926 0.04242069]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 724 | Acuracia_4: 0.5 | Contagem Geral: 74.0 
Ordem Natural: 110.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.027 | Acuracia_4: 0.5 
Precisao modelo Geral: 60.4396
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
724 724 724
(695, 30) (695, 30) (695, 30)
(695, 90) (695, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98834115 0.01165879]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 725 | Acuracia_5: 0.5 | Contagem Geral: 74.0 
Ordem Natural: 110.0
Entrada: 15.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.027 | Acuracia_5: 0.5 
Precisao modelo Geral: 60.274
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
725 725 725
(696, 30) (696, 30) (696, 30)
(696, 90) (696, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94628197 0.05371807]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 726 | Acuracia_6: 1.0 | Contagem Geral: 74.0 
Ordem Natural: 111.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.027 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.3825
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
726 726 726
(697, 30) (697, 30) (697, 30)
(697, 90) (697, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.8712428  0.12875715]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 727 | Acuracia_7: 0.3333 | Contagem Geral: 74.0 
Ordem Natural: 111.0
Entrada: 5.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.027 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.218
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
727 727 727
(698, 30) (698, 30) (698, 30)
(698, 90) (698, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.599009   0.40099105]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 728 | Acuracia_8: 0.5 | Contagem Geral: 74.0 
Ordem Natural: 112.0
Entrada: 4.48
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.3261
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
728 728 728
(699, 30) (699, 30) (699, 30)
(699, 90) (699, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.90674996 0.09324996]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 729 | Acuracia_9: 0.5 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.57
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.4336
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
729 729 729
(700, 30) (700, 30) (700, 30)
(700, 90) (700, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9036417  0.09635831]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 730 | Acuracia_10: 0.6667 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_10: 0.6667 
Precisao modelo Geral: 60.5405
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
730 730 730
(701, 30) (701, 30) (701, 30)
(701, 90) (701, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.8513189  0.14868104]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 731 | Acuracia_11: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_11: 0.0 
Precisao modelo Geral: 60.6469
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
731 731 731
(702, 30) (702, 30) (702, 30)
(702, 90) (702, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 38ms/step
[[0.9456157  0.05438427]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 732 | Acuracia_12: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.7527
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
732 732 732
(703, 30) (703, 30) (703, 30)
(703, 90) (703, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9604874  0.03951255]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 733 | Acuracia_13: 0.5 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_13: 0.5 
Precisao modelo Geral: 60.8579
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
733 733 733
(704, 30) (704, 30) (704, 30)
(704, 90) (704, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9454445  0.05455543]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 734 | Acuracia_14: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 2.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.9626
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
734 734 734
(705, 30) (705, 30) (705, 30)
(705, 90) (705, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.84414285 0.15585718]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 735 | Acuracia_15: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 2.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_15: 0.0 
Precisao modelo Geral: 61.0667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
735 735 735
(706, 30) (706, 30) (706, 30)
(706, 90) (706, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8208505  0.17914945]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 736 | Acuracia_16: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_16: 0.0 
Precisao modelo Geral: 61.1702
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
736 736 736
(707, 30) (707, 30) (707, 30)
(707, 90) (707, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93212134 0.06787866]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 737 | Acuracia_17: 0.5 | Contagem Geral: 75.0 
Ordem Natural: 113.0
Entrada: 3.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_17: 0.5 
Precisao modelo Geral: 61.008
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
737 737 737
(708, 30) (708, 30) (708, 30)
(708, 90) (708, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.8588881  0.14111188]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 738 | Acuracia_18: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 114.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_18: 0.0 
Precisao modelo Geral: 61.1111
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
738 738 738
(709, 30) (709, 30) (709, 30)
(709, 90) (709, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.57320964 0.42679033]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 739 | Acuracia_19: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 114.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6316 | Acuracia_19: 0.0 
Precisao modelo Geral: 60.9499
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
739 739 739
(710, 30) (710, 30) (710, 30)
(710, 90) (710, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7709863  0.22901367]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 740 | Acuracia_20: 0.5 | Contagem Geral: 76.0 
Ordem Natural: 114.0
Entrada: 1.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_20: 0.3333 
Precisao modelo Geral: 60.7895
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
740 740 740
(711, 30) (711, 30) (711, 30)
(711, 90) (711, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.93282336 0.06717662]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 741 | Acuracia_21: 1.0 | Contagem Geral: 77.0 
Ordem Natural: 114.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.8924
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
741 741 741
(712, 30) (712, 30) (712, 30)
(712, 90) (712, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9502322  0.04976776]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 742 | Acuracia_22: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 114.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_22: 0.0 
Precisao modelo Geral: 60.9948
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
742 742 742
(713, 30) (713, 30) (713, 30)
(713, 90) (713, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8599952  0.14000487]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 743 | Acuracia_23: 0.5 | Contagem Geral: 77.0 
Ordem Natural: 114.0
Entrada: 2.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.2727 | Acuracia_23: 0.5 
Precisao modelo Geral: 61.0966
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
743 743 743
(714, 30) (714, 30) (714, 30)
(714, 90) (714, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.5979448 0.4020552]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 744 | Acuracia_24: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 114.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.9231 | Acuracia_24: 0.0 
Precisao modelo Geral: 60.9375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
744 744 744
(715, 30) (715, 30) (715, 30)
(715, 90) (715, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6926177  0.30738235]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 745 | Acuracia_25: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 114.0
Entrada: 2.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.5823 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.7792
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
745 745 745
(716, 30) (716, 30) (716, 30)
(716, 90) (716, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6544676  0.34553248]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 746 | Acuracia_26: 0.0 | Contagem Geral: 79.0 
Ordem Natural: 114.0
Entrada: 4.41
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_26: 0.5 
Precisao modelo Geral: 60.8808
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
746 746 746
(717, 30) (717, 30) (717, 30)
(717, 90) (717, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.8024109  0.19758911]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 747 | Acuracia_27: 0.0 | Contagem Geral: 80.0 
Ordem Natural: 115.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.9819
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
747 747 747
(718, 30) (718, 30) (718, 30)
(718, 90) (718, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95268404 0.04731597]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 748 | Acuracia_28: 0.0 | Contagem Geral: 80.0 
Ordem Natural: 115.0
Entrada: 3.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.8247
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
748 748 748
(719, 30) (719, 30) (719, 30)
(719, 90) (719, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96150994 0.03849006]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 749 | Acuracia_29: 0.0 | Contagem Geral: 80.0 
Ordem Natural: 116.0
Entrada: 3.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.6684
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
749 749 749
(720, 30) (720, 30) (720, 30)
(720, 90) (720, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9512947  0.04870529]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 750 | Acuracia_0: 0.5 | Contagem Geral: 80.0 
Ordem Natural: 117.0
Entrada: 4.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.5128
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
750 750 750
(721, 30) (721, 30) (721, 30)
(721, 90) (721, 30)
Matrix_30: [(721, 90), (721, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1843 - accuracy: 0.5087 - precision: 0.5087 - recall: 0.5087 - f1_score: 0.3734 - val_loss: 0.3216 - val_accuracy: 0.2970 - val_precision: 0.2970 - val_recall: 0.2970 - val_f1_score: 0.4580 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2437 - accuracy: 0.3127 - precision: 0.3127 - recall: 0.3127 - f1_score: 0.4764 - val_loss: 0.1591 - val_accuracy: 0.6634 - val_precision: 0.6634 - val_recall: 0.6634 - val_f1_score: 0.5405 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1530 - accuracy: 0.7022 - precision: 0.7022 - recall: 0.7022 - f1_score: 0.6078 - val_loss: 0.1395 - val_accuracy: 0.7030 - val_precision: 0.7030 - val_recall: 0.7030 - val_f1_score: 0.0000e+00 - 74ms/epoch - 74ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1914 - accuracy: 0.6973 - precision: 0.6973 - recall: 0.6973 - f1_score: 0.0615 - val_loss: 0.1323 - val_accuracy: 0.7327 - val_precision: 0.7327 - val_recall: 0.7327 - val_f1_score: 0.1818 - 82ms/epoch - 82ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.7295 - precision: 0.7295 - recall: 0.7295 - f1_score: 0.2378 - val_loss: 0.1378 - val_accuracy: 0.8317 - val_precision: 0.8317 - val_recall: 0.8317 - val_f1_score: 0.6909 - 80ms/epoch - 80ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1389 - accuracy: 0.8561 - precision: 0.8561 - recall: 0.8561 - f1_score: 0.7521 - val_loss: 0.1674 - val_accuracy: 0.4950 - val_precision: 0.4950 - val_recall: 0.4950 - val_f1_score: 0.5405 - 75ms/epoch - 75ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.5484 - precision: 0.5484 - recall: 0.5484 - f1_score: 0.5787 - val_loss: 0.1869 - val_accuracy: 0.3663 - val_precision: 0.3663 - val_recall: 0.3663 - val_f1_score: 0.4839 - 76ms/epoch - 76ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1505 - accuracy: 0.4194 - precision: 0.4194 - recall: 0.4194 - f1_score: 0.5185 - val_loss: 0.1756 - val_accuracy: 0.4356 - val_precision: 0.4356 - val_recall: 0.4356 - val_f1_score: 0.5128 - 75ms/epoch - 75ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1426 - accuracy: 0.4814 - precision: 0.4814 - recall: 0.4814 - f1_score: 0.5447 - val_loss: 0.1490 - val_accuracy: 0.6931 - val_precision: 0.6931 - val_recall: 0.6931 - val_f1_score: 0.6593 - 77ms/epoch - 77ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1281 - accuracy: 0.7270 - precision: 0.7270 - recall: 0.7270 - f1_score: 0.6944 - val_loss: 0.1263 - val_accuracy: 0.8911 - val_precision: 0.8911 - val_recall: 0.8911 - val_f1_score: 0.8254 - 76ms/epoch - 76ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1202 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.8958 - f1_score: 0.8359 - val_loss: 0.1139 - val_accuracy: 0.9109 - val_precision: 0.9109 - val_recall: 0.9109 - val_f1_score: 0.8302 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1204 - accuracy: 0.9007 - precision: 0.9007 - recall: 0.9007 - f1_score: 0.8214 - val_loss: 0.1081 - val_accuracy: 0.8713 - val_precision: 0.8713 - val_recall: 0.8713 - val_f1_score: 0.7234 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1206 - accuracy: 0.8784 - precision: 0.8784 - recall: 0.8784 - f1_score: 0.7656 - val_loss: 0.1045 - val_accuracy: 0.8812 - val_precision: 0.8812 - val_recall: 0.8812 - val_f1_score: 0.7500 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1147 - accuracy: 0.9032 - precision: 0.9032 - recall: 0.9032 - f1_score: 0.8219 - val_loss: 0.1034 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208 - val_f1_score: 0.8621 - 78ms/epoch - 78ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1051 - accuracy: 0.9305 - precision: 0.9305 - recall: 0.9305 - f1_score: 0.8803 - val_loss: 0.1066 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8852 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0978 - accuracy: 0.9355 - precision: 0.9355 - recall: 0.9355 - f1_score: 0.8984 - val_loss: 0.1127 - val_accuracy: 0.8911 - val_precision: 0.8911 - val_recall: 0.8911 - val_f1_score: 0.8406 - 78ms/epoch - 78ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0950 - accuracy: 0.9007 - precision: 0.9007 - recall: 0.9007 - f1_score: 0.8582 - val_loss: 0.1156 - val_accuracy: 0.8515 - val_precision: 0.8515 - val_recall: 0.8515 - val_f1_score: 0.7945 - 76ms/epoch - 76ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0930 - accuracy: 0.8536 - precision: 0.8536 - recall: 0.8536 - f1_score: 0.8078 - val_loss: 0.1092 - val_accuracy: 0.8812 - val_precision: 0.8812 - val_recall: 0.8812 - val_f1_score: 0.8286 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0876 - accuracy: 0.8834 - precision: 0.8834 - recall: 0.8834 - f1_score: 0.8407 - val_loss: 0.0953 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8923 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0796 - accuracy: 0.9305 - precision: 0.9305 - recall: 0.9305 - f1_score: 0.8963 - val_loss: 0.0814 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0739 - accuracy: 0.9479 - precision: 0.9479 - recall: 0.9479 - f1_score: 0.9150 - val_loss: 0.0727 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208 - val_f1_score: 0.8621 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0717 - accuracy: 0.9504 - precision: 0.9504 - recall: 0.9504 - f1_score: 0.9167 - val_loss: 0.0679 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208 - val_f1_score: 0.8571 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0682 - accuracy: 0.9504 - precision: 0.9504 - recall: 0.9504 - f1_score: 0.9167 - val_loss: 0.0659 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9000 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0616 - accuracy: 0.9504 - precision: 0.9504 - recall: 0.9504 - f1_score: 0.9167 - val_loss: 0.0680 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9206 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0561 - accuracy: 0.9578 - precision: 0.9578 - recall: 0.9578 - f1_score: 0.9328 - val_loss: 0.0721 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208 - val_f1_score: 0.8788 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0540 - accuracy: 0.9529 - precision: 0.9529 - recall: 0.9529 - f1_score: 0.9283 - val_loss: 0.0705 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208 - val_f1_score: 0.8788 - 93ms/epoch - 93ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0510 - accuracy: 0.9529 - precision: 0.9529 - recall: 0.9529 - f1_score: 0.9283 - val_loss: 0.0618 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9206 - 75ms/epoch - 75ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0459 - accuracy: 0.9628 - precision: 0.9628 - recall: 0.9628 - f1_score: 0.9416 - val_loss: 0.0530 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9180 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0429 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9516 - val_loss: 0.0488 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9180 - 79ms/epoch - 79ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0417 - accuracy: 0.9677 - precision: 0.9677 - recall: 0.9677 - f1_score: 0.9474 - val_loss: 0.0475 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9180 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0384 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9516 - val_loss: 0.0495 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0351 - accuracy: 0.9752 - precision: 0.9752 - recall: 0.9752 - f1_score: 0.9603 - val_loss: 0.0532 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9062 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0339 - accuracy: 0.9677 - precision: 0.9677 - recall: 0.9677 - f1_score: 0.9498 - val_loss: 0.0525 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9062 - 82ms/epoch - 82ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0322 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9538 - val_loss: 0.0466 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8889 - 76ms/epoch - 76ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0292 - accuracy: 0.9777 - precision: 0.9777 - recall: 0.9777 - f1_score: 0.9644 - val_loss: 0.0415 - val_accuracy: 0.9604 - val_precision: 0.9604 - val_recall: 0.9604 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0278 - accuracy: 0.9801 - precision: 0.9801 - recall: 0.9801 - f1_score: 0.9680 - val_loss: 0.0395 - val_accuracy: 0.9604 - val_precision: 0.9604 - val_recall: 0.9604 - val_f1_score: 0.9333 - 85ms/epoch - 85ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0269 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - f1_score: 0.9719 - val_loss: 0.0400 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9180 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0247 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - f1_score: 0.9719 - val_loss: 0.0428 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 83ms/epoch - 83ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0231 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9762 - val_loss: 0.0452 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9062 - 74ms/epoch - 74ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9764 - val_loss: 0.0432 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8889 - 82ms/epoch - 82ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0209 - accuracy: 0.9876 - precision: 0.9876 - recall: 0.9876 - f1_score: 0.9802 - val_loss: 0.0392 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8889 - 148ms/epoch - 148ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0195 - accuracy: 0.9876 - precision: 0.9876 - recall: 0.9876 - f1_score: 0.9801 - val_loss: 0.0370 - val_accuracy: 0.9505 - val_precision: 0.9505 - val_recall: 0.9505 - val_f1_score: 0.9180 - 91ms/epoch - 91ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0189 - accuracy: 0.9901 - precision: 0.9901 - recall: 0.9901 - f1_score: 0.9839 - val_loss: 0.0369 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0178 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - f1_score: 0.9880 - val_loss: 0.0385 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0166 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - f1_score: 0.9880 - val_loss: 0.0408 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8889 - 77ms/epoch - 77ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0160 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - f1_score: 0.9960 - val_loss: 0.0408 - val_accuracy: 0.9307 - val_precision: 0.9307 - val_recall: 0.9307 - val_f1_score: 0.8889 - 79ms/epoch - 79ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0152 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - f1_score: 0.9960 - val_loss: 0.0384 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0142 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 77ms/epoch - 77ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0136 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 85ms/epoch - 85ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0131 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9406 - val_precision: 0.9406 - val_recall: 0.9406 - val_f1_score: 0.9032 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0317
Accuracy: 0.9724
Precision: 0.9724
Recall: 0.9724
F1 Score: 0.9552
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
750 750 750
(721, 30) (721, 30) (721, 30)
(721, 90) (721, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 89ms/step
[[0.9288857  0.07111434]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 751 | Acuracia_1: 0.3333 | Contagem Geral: 80.0 
Ordem Natural: 118.0
Entrada: 3.66
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_1: 0.3333 
Precisao modelo Geral: 60.3581
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
751 751 751
(722, 30) (722, 30) (722, 30)
(722, 90) (722, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89295435 0.10704559]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 752 | Acuracia_2: 0.2 | Contagem Geral: 80.0 
Ordem Natural: 119.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5 | Acuracia_2: 0.2 
Precisao modelo Geral: 60.4592
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
752 752 752
(723, 30) (723, 30) (723, 30)
(723, 90) (723, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.59301823 0.4069817 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 753 | Acuracia_3: 0.0 | Contagem Geral: 80.0 
Ordem Natural: 119.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1605 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.3053
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
753 753 753
(724, 30) (724, 30) (724, 30)
(724, 90) (724, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7883105  0.21168943]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 754 | Acuracia_4: 0.5 | Contagem Geral: 81.0 
Ordem Natural: 119.0
Entrada: 4.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0488 | Acuracia_4: 0.6667 
Precisao modelo Geral: 60.4061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
754 754 754
(725, 30) (725, 30) (725, 30)
(725, 90) (725, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.88466597 0.11533405]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 755 | Acuracia_5: 0.5 | Contagem Geral: 82.0 
Ordem Natural: 120.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0488 | Acuracia_5: 0.5 
Precisao modelo Geral: 60.5063
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
755 755 755
(726, 30) (726, 30) (726, 30)
(726, 90) (726, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5659789  0.43402112]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 756 | Acuracia_6: 1.0 | Contagem Geral: 82.0 
Ordem Natural: 120.0
Entrada: 4.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
756 756 756
(727, 30) (727, 30) (727, 30)
(727, 90) (727, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.93134403 0.06865603]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 757 | Acuracia_7: 0.3333 | Contagem Geral: 83.0 
Ordem Natural: 121.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.7053
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
757 757 757
(728, 30) (728, 30) (728, 30)
(728, 90) (728, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96740884 0.03259113]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 758 | Acuracia_8: 0.6667 | Contagem Geral: 83.0 
Ordem Natural: 121.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.804
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
758 758 758
(729, 30) (729, 30) (729, 30)
(729, 90) (729, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.9051251  0.09487489]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 759 | Acuracia_9: 0.5 | Contagem Geral: 83.0 
Ordem Natural: 121.0
Entrada: 1.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.9023
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
759 759 759
(730, 30) (730, 30) (730, 30)
(730, 90) (730, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9121186  0.08788139]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 760 | Acuracia_10: 0.6667 | Contagem Geral: 83.0 
Ordem Natural: 121.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_10: 0.6667 
Precisao modelo Geral: 61.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
760 760 760
(731, 30) (731, 30) (731, 30)
(731, 90) (731, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90303713 0.09696289]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 761 | Acuracia_11: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 121.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_11: 0.0 
Precisao modelo Geral: 60.8479
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
761 761 761
(732, 30) (732, 30) (732, 30)
(732, 90) (732, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.88285434 0.11714573]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 762 | Acuracia_12: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 122.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.9453
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
762 762 762
(733, 30) (733, 30) (733, 30)
(733, 90) (733, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8915985  0.10840151]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 763 | Acuracia_13: 0.5 | Contagem Geral: 83.0 
Ordem Natural: 122.0
Entrada: 17.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_13: 0.5 
Precisao modelo Geral: 60.794
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
763 763 763
(734, 30) (734, 30) (734, 30)
(734, 90) (734, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8725512  0.12744875]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 764 | Acuracia_14: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 123.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.8911
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
764 764 764
(735, 30) (735, 30) (735, 30)
(735, 90) (735, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.83335    0.16664992]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 765 | Acuracia_15: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 123.0
Entrada: 31.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.7407
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
765 765 765
(736, 30) (736, 30) (736, 30)
(736, 90) (736, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9573499  0.04265015]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 766 | Acuracia_16: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 124.0
Entrada: 1.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.8374
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
766 766 766
(737, 30) (737, 30) (737, 30)
(737, 90) (737, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9720256 0.0279744]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 767 | Acuracia_17: 0.5 | Contagem Geral: 83.0 
Ordem Natural: 124.0
Entrada: 2.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_17: 0.5 
Precisao modelo Geral: 60.9337
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
767 767 767
(738, 30) (738, 30) (738, 30)
(738, 90) (738, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9492743  0.05072564]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 768 | Acuracia_18: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 124.0
Entrada: 2.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_18: 0.0 
Precisao modelo Geral: 61.0294
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
768 768 768
(739, 30) (739, 30) (739, 30)
(739, 90) (739, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9630167  0.03698332]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 769 | Acuracia_19: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 124.0
Entrada: 10.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_19: 0.0 
Precisao modelo Geral: 60.8802
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
769 769 769
(740, 30) (740, 30) (740, 30)
(740, 90) (740, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9769444  0.02305566]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 770 | Acuracia_20: 0.3333 | Contagem Geral: 83.0 
Ordem Natural: 125.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_20: 0.3333 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
770 770 770
(741, 30) (741, 30) (741, 30)
(741, 90) (741, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.964803   0.03519698]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 771 | Acuracia_21: 1.0 | Contagem Geral: 83.0 
Ordem Natural: 125.0
Entrada: 2.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_21: 1.0 
Precisao modelo Geral: 61.0706
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
771 771 771
(742, 30) (742, 30) (742, 30)
(742, 90) (742, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9274345  0.07256544]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 772 | Acuracia_22: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 125.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9157 | Acuracia_22: 0.0 
Precisao modelo Geral: 61.165
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
772 772 772
(743, 30) (743, 30) (743, 30)
(743, 90) (743, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7811089 0.2188911]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 773 | Acuracia_23: 0.5 | Contagem Geral: 83.0 
Ordem Natural: 125.0
Entrada: 5.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7619 | Acuracia_23: 0.6667 
Precisao modelo Geral: 61.2591
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
773 773 773
(744, 30) (744, 30) (744, 30)
(744, 90) (744, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6901521  0.30984783]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 774 | Acuracia_24: 0.0 | Contagem Geral: 84.0 
Ordem Natural: 126.0
Entrada: 3.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_24: 0.2 
Precisao modelo Geral: 61.3527
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
774 774 774
(745, 30) (745, 30) (745, 30)
(745, 90) (745, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9064226  0.09357736]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 775 | Acuracia_25: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 127.0
Entrada: 12.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_25: 0.0 
Precisao modelo Geral: 61.2048
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
775 775 775
(746, 30) (746, 30) (746, 30)
(746, 90) (746, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9121306  0.08786934]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 776 | Acuracia_26: 0.5 | Contagem Geral: 85.0 
Ordem Natural: 128.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_26: 0.5 
Precisao modelo Geral: 61.2981
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
776 776 776
(747, 30) (747, 30) (747, 30)
(747, 90) (747, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.8198039  0.18019608]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 777 | Acuracia_27: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 128.0
Entrada: 7.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_27: 0.0 
Precisao modelo Geral: 61.1511
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
777 777 777
(748, 30) (748, 30) (748, 30)
(748, 90) (748, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.84904087 0.15095913]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 778 | Acuracia_28: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 129.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_28: 0.0 
Precisao modelo Geral: 61.244
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
778 778 778
(749, 30) (749, 30) (749, 30)
(749, 90) (749, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.87332094 0.12667914]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 779 | Acuracia_29: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 129.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_29: 0.0 
Precisao modelo Geral: 61.3365
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
779 779 779
(750, 30) (750, 30) (750, 30)
(750, 90) (750, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95168084 0.04831919]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 780 | Acuracia_0: 0.5 | Contagem Geral: 85.0 
Ordem Natural: 129.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5882 | Acuracia_30: 0.5 
Precisao modelo Geral: 61.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
780 780 780
(751, 30) (751, 30) (751, 30)
(751, 90) (751, 30)
Matrix_30: [(751, 90), (751, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2214 - accuracy: 0.3690 - precision: 0.3690 - recall: 0.3690 - f1_score: 0.4603 - val_loss: 0.2337 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.5160 - accuracy: 0.6857 - precision: 0.6857 - recall: 0.6857 - f1_score: 0.0000e+00 - val_loss: 0.1562 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.0625 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2149 - accuracy: 0.6833 - precision: 0.6833 - recall: 0.6833 - f1_score: 0.1192 - val_loss: 0.2997 - val_accuracy: 0.2762 - val_precision: 0.2762 - val_recall: 0.2762 - val_f1_score: 0.4154 - 76ms/epoch - 76ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2103 - accuracy: 0.3476 - precision: 0.3476 - recall: 0.3476 - f1_score: 0.4888 - val_loss: 0.4166 - val_accuracy: 0.2571 - val_precision: 0.2571 - val_recall: 0.2571 - val_f1_score: 0.4091 - 77ms/epoch - 77ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2812 - accuracy: 0.3167 - precision: 0.3167 - recall: 0.3167 - f1_score: 0.4791 - val_loss: 0.3697 - val_accuracy: 0.2571 - val_precision: 0.2571 - val_recall: 0.2571 - val_f1_score: 0.4091 - 78ms/epoch - 78ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2520 - accuracy: 0.3167 - precision: 0.3167 - recall: 0.3167 - f1_score: 0.4791 - val_loss: 0.2705 - val_accuracy: 0.2667 - val_precision: 0.2667 - val_recall: 0.2667 - val_f1_score: 0.4122 - 81ms/epoch - 81ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1940 - accuracy: 0.3405 - precision: 0.3405 - recall: 0.3405 - f1_score: 0.4861 - val_loss: 0.1927 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.4000 - val_f1_score: 0.4324 - 79ms/epoch - 79ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.5598 - val_loss: 0.1541 - val_accuracy: 0.6857 - val_precision: 0.6857 - val_recall: 0.6857 - val_f1_score: 0.3529 - 79ms/epoch - 79ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.7452 - precision: 0.7452 - recall: 0.7452 - f1_score: 0.5244 - val_loss: 0.1412 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714 - val_f1_score: 0.2000 - 76ms/epoch - 76ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1741 - accuracy: 0.7048 - precision: 0.7048 - recall: 0.7048 - f1_score: 0.1143 - val_loss: 0.1381 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1838 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.0299 - val_loss: 0.1369 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429 - val_f1_score: 0.0000e+00 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.0299 - val_loss: 0.1367 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714 - val_f1_score: 0.2000 - 77ms/epoch - 77ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1716 - accuracy: 0.7000 - precision: 0.7000 - recall: 0.7000 - f1_score: 0.0870 - val_loss: 0.1393 - val_accuracy: 0.7810 - val_precision: 0.7810 - val_recall: 0.7810 - val_f1_score: 0.3030 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.7762 - precision: 0.7762 - recall: 0.7762 - f1_score: 0.4598 - val_loss: 0.1463 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.4681 - 80ms/epoch - 80ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1481 - accuracy: 0.8238 - precision: 0.8238 - recall: 0.8238 - f1_score: 0.6810 - val_loss: 0.1580 - val_accuracy: 0.6952 - val_precision: 0.6952 - val_recall: 0.6952 - val_f1_score: 0.5789 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1428 - accuracy: 0.7714 - precision: 0.7714 - recall: 0.7714 - f1_score: 0.7019 - val_loss: 0.1723 - val_accuracy: 0.5429 - val_precision: 0.5429 - val_recall: 0.5429 - val_f1_score: 0.5000 - 78ms/epoch - 78ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1425 - accuracy: 0.6357 - precision: 0.6357 - recall: 0.6357 - f1_score: 0.6222 - val_loss: 0.1850 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571 - val_f1_score: 0.4865 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1445 - accuracy: 0.5405 - precision: 0.5405 - recall: 0.5405 - f1_score: 0.5740 - val_loss: 0.1915 - val_accuracy: 0.3714 - val_precision: 0.3714 - val_recall: 0.3714 - val_f1_score: 0.4500 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1451 - accuracy: 0.5024 - precision: 0.5024 - recall: 0.5024 - f1_score: 0.5563 - val_loss: 0.1890 - val_accuracy: 0.3905 - val_precision: 0.3905 - val_recall: 0.3905 - val_f1_score: 0.4576 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.5214 - precision: 0.5214 - recall: 0.5214 - f1_score: 0.5659 - val_loss: 0.1781 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857 - val_f1_score: 0.4906 - 79ms/epoch - 79ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1354 - accuracy: 0.6143 - precision: 0.6143 - recall: 0.6143 - f1_score: 0.6179 - val_loss: 0.1622 - val_accuracy: 0.5905 - val_precision: 0.5905 - val_recall: 0.5905 - val_f1_score: 0.5376 - 84ms/epoch - 84ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1278 - accuracy: 0.7190 - precision: 0.7190 - recall: 0.7190 - f1_score: 0.6862 - val_loss: 0.1460 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1_score: 0.6866 - 80ms/epoch - 80ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1218 - accuracy: 0.8167 - precision: 0.8167 - recall: 0.8167 - f1_score: 0.7601 - val_loss: 0.1334 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.6552 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1180 - accuracy: 0.8738 - precision: 0.8738 - recall: 0.8738 - f1_score: 0.8059 - val_loss: 0.1251 - val_accuracy: 0.8190 - val_precision: 0.8190 - val_recall: 0.8190 - val_f1_score: 0.6275 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1148 - accuracy: 0.8786 - precision: 0.8786 - recall: 0.8786 - f1_score: 0.8016 - val_loss: 0.1210 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286 - val_f1_score: 0.6538 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1107 - accuracy: 0.8857 - precision: 0.8857 - recall: 0.8857 - f1_score: 0.8125 - val_loss: 0.1204 - val_accuracy: 0.8476 - val_precision: 0.8476 - val_recall: 0.8476 - val_f1_score: 0.7143 - 77ms/epoch - 77ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1054 - accuracy: 0.8976 - precision: 0.8976 - recall: 0.8976 - f1_score: 0.8390 - val_loss: 0.1231 - val_accuracy: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_f1_score: 0.7667 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1007 - accuracy: 0.8738 - precision: 0.8738 - recall: 0.8738 - f1_score: 0.8191 - val_loss: 0.1263 - val_accuracy: 0.8190 - val_precision: 0.8190 - val_recall: 0.8190 - val_f1_score: 0.7246 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0975 - accuracy: 0.8548 - precision: 0.8548 - recall: 0.8548 - f1_score: 0.8051 - val_loss: 0.1245 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.7143 - 82ms/epoch - 82ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0942 - accuracy: 0.8524 - precision: 0.8524 - recall: 0.8524 - f1_score: 0.8025 - val_loss: 0.1156 - val_accuracy: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_f1_score: 0.7812 - 88ms/epoch - 88ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0896 - accuracy: 0.8690 - precision: 0.8690 - recall: 0.8690 - f1_score: 0.8185 - val_loss: 0.1043 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857 - val_f1_score: 0.7857 - 79ms/epoch - 79ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0856 - accuracy: 0.8952 - precision: 0.8952 - recall: 0.8952 - f1_score: 0.8429 - val_loss: 0.0958 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8000 - 78ms/epoch - 78ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0828 - accuracy: 0.9190 - precision: 0.9190 - recall: 0.9190 - f1_score: 0.8731 - val_loss: 0.0917 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8000 - 87ms/epoch - 87ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0796 - accuracy: 0.9262 - precision: 0.9262 - recall: 0.9262 - f1_score: 0.8839 - val_loss: 0.0916 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857 - val_f1_score: 0.7931 - 78ms/epoch - 78ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0758 - accuracy: 0.9095 - precision: 0.9095 - recall: 0.9095 - f1_score: 0.8633 - val_loss: 0.0938 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857 - val_f1_score: 0.8000 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0731 - accuracy: 0.8952 - precision: 0.8952 - recall: 0.8952 - f1_score: 0.8472 - val_loss: 0.0938 - val_accuracy: 0.8762 - val_precision: 0.8762 - val_recall: 0.8762 - val_f1_score: 0.7869 - 84ms/epoch - 84ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0709 - accuracy: 0.9000 - precision: 0.9000 - recall: 0.9000 - f1_score: 0.8552 - val_loss: 0.0882 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857 - val_f1_score: 0.8000 - 92ms/epoch - 92ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0678 - accuracy: 0.9000 - precision: 0.9000 - recall: 0.9000 - f1_score: 0.8542 - val_loss: 0.0802 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8276 - 77ms/epoch - 77ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0650 - accuracy: 0.9190 - precision: 0.9190 - recall: 0.9190 - f1_score: 0.8768 - val_loss: 0.0747 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143 - val_f1_score: 0.8421 - 77ms/epoch - 77ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0631 - accuracy: 0.9310 - precision: 0.9310 - recall: 0.9310 - f1_score: 0.8914 - val_loss: 0.0730 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143 - val_f1_score: 0.8421 - 75ms/epoch - 75ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0607 - accuracy: 0.9357 - precision: 0.9357 - recall: 0.9357 - f1_score: 0.8996 - val_loss: 0.0743 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8276 - 75ms/epoch - 75ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0581 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - f1_score: 0.8913 - val_loss: 0.0762 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8136 - 78ms/epoch - 78ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0563 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8763 - val_loss: 0.0746 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8136 - 80ms/epoch - 80ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0543 - accuracy: 0.9190 - precision: 0.9190 - recall: 0.9190 - f1_score: 0.8794 - val_loss: 0.0699 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8276 - 77ms/epoch - 77ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0520 - accuracy: 0.9381 - precision: 0.9381 - recall: 0.9381 - f1_score: 0.9051 - val_loss: 0.0658 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8214 - 87ms/epoch - 87ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0503 - accuracy: 0.9452 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9151 - val_loss: 0.0644 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8214 - 76ms/epoch - 76ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0485 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - f1_score: 0.9185 - val_loss: 0.0656 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8214 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0465 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - f1_score: 0.9191 - val_loss: 0.0675 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8070 - 76ms/epoch - 76ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0450 - accuracy: 0.9429 - precision: 0.9429 - recall: 0.9429 - f1_score: 0.9130 - val_loss: 0.0670 - val_accuracy: 0.8952 - val_precision: 0.8952 - val_recall: 0.8952 - val_f1_score: 0.8070 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - f1_score: 0.9203 - val_loss: 0.0640 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8214 - 81ms/epoch - 81ms/step

🔍 Resultados no Teste:
Loss: 0.0574
Accuracy: 0.9292
Precision: 0.9292
Recall: 0.9292
F1 Score: 0.8961
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
780 780 780
(751, 30) (751, 30) (751, 30)
(751, 90) (751, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.7710402 0.2289598]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 781 | Acuracia_1: 0.3333 | Contagem Geral: 85.0 
Ordem Natural: 129.0
Entrada: 3.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.3953 | Acuracia_1: 0.5 
Precisao modelo Geral: 61.5202
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
781 781 781
(752, 30) (752, 30) (752, 30)
(752, 90) (752, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6587849 0.3412151]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 782 | Acuracia_2: 0.2 | Contagem Geral: 86.0 
Ordem Natural: 130.0
Entrada: 2.56
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_2: 0.1667 
Precisao modelo Geral: 61.3744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
782 782 782
(753, 30) (753, 30) (753, 30)
(753, 90) (753, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.71955884 0.2804412 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 783 | Acuracia_3: 0.0 | Contagem Geral: 87.0 
Ordem Natural: 130.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.6818 | Acuracia_3: 0.0 
Precisao modelo Geral: 61.2293
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
783 783 783
(754, 30) (754, 30) (754, 30)
(754, 90) (754, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.64335144 0.3566486 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 784 | Acuracia_4: 0.6667 | Contagem Geral: 88.0 
Ordem Natural: 130.0
Entrada: 5.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4607 | Acuracia_4: 0.75 
Precisao modelo Geral: 61.3208
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
784 784 784
(755, 30) (755, 30) (755, 30)
(755, 90) (755, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.684706 0.315294]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 785 | Acuracia_5: 0.5 | Contagem Geral: 89.0 
Ordem Natural: 131.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_5: 0.3333 
Precisao modelo Geral: 61.1765
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
785 785 785
(756, 30) (756, 30) (756, 30)
(756, 90) (756, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.85111463 0.14888535]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 786 | Acuracia_6: 1.0 | Contagem Geral: 90.0 
Ordem Natural: 131.0
Entrada: 11.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_6: 1.0 
Precisao modelo Geral: 61.0329
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
786 786 786
(757, 30) (757, 30) (757, 30)
(757, 90) (757, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86734456 0.13265547]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 787 | Acuracia_7: 0.3333 | Contagem Geral: 90.0 
Ordem Natural: 132.0
Entrada: 7.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.8899
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
787 787 787
(758, 30) (758, 30) (758, 30)
(758, 90) (758, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.85987556 0.14012441]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 788 | Acuracia_8: 0.6667 | Contagem Geral: 90.0 
Ordem Natural: 133.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.7477
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
788 788 788
(759, 30) (759, 30) (759, 30)
(759, 90) (759, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.74603593 0.25396404]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 789 | Acuracia_9: 0.5 | Contagem Geral: 90.0 
Ordem Natural: 134.0
Entrada: 3.94
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.8681 | Acuracia_9: 0.6667 
Precisao modelo Geral: 60.8392
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
789 789 789
(760, 30) (760, 30) (760, 30)
(760, 90) (760, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.7791115 0.2208885]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 790 | Acuracia_10: 0.6667 | Contagem Geral: 91.0 
Ordem Natural: 135.0
Entrada: 2.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5217 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.6977
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
790 790 790
(761, 30) (761, 30) (761, 30)
(761, 90) (761, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.54532754 0.45467252]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 791 | Acuracia_11: 0.0 | Contagem Geral: 92.0 
Ordem Natural: 135.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1828 | Acuracia_11: 0.0 
Precisao modelo Geral: 60.5568
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
791 791 791
(762, 30) (762, 30) (762, 30)
(762, 90) (762, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.47776133 0.5222386 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 792 | Acuracia_12: 0.0 | Contagem Geral: 93.0 
Ordem Natural: 135.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.8511 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.4167
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
792 792 792
(763, 30) (763, 30) (763, 30)
(763, 90) (763, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6140177 0.3859823]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 793 | Acuracia_13: 0.5 | Contagem Geral: 94.0 
Ordem Natural: 135.0
Entrada: 11.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.5081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
793 793 793
(764, 30) (764, 30) (764, 30)
(764, 90) (764, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.81327677 0.18672323]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 794 | Acuracia_14: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 136.0
Entrada: 6.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.3687
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
794 794 794
(765, 30) (765, 30) (765, 30)
(765, 90) (765, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8603671  0.13963287]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 795 | Acuracia_15: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 137.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.4598
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
795 795 795
(766, 30) (766, 30) (766, 30)
(766, 90) (766, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7433692 0.2566308]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 796 | Acuracia_16: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 137.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.3211
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
796 796 796
(767, 30) (767, 30) (767, 30)
(767, 90) (767, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.44555068 0.5544493 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 797 | Acuracia_17: 0.5 | Contagem Geral: 96.0 
Ordem Natural: 137.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.9278 | Acuracia_17: 0.4 
Precisao modelo Geral: 60.1831
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
797 797 797
(768, 30) (768, 30) (768, 30)
(768, 90) (768, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.64795834 0.35204166]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 798 | Acuracia_18: 0.0 | Contagem Geral: 97.0 
Ordem Natural: 137.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.6327 | Acuracia_18: 0.1667 
Precisao modelo Geral: 60.274
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
798 798 798
(769, 30) (769, 30) (769, 30)
(769, 90) (769, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.77457154 0.2254285 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 799 | Acuracia_19: 0.0 | Contagem Geral: 98.0 
Ordem Natural: 138.0
Entrada: 3.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.3232 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.3645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
799 799 799
(770, 30) (770, 30) (770, 30)
(770, 90) (770, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7975258  0.20247412]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 800 | Acuracia_20: 0.3333 | Contagem Geral: 99.0 
Ordem Natural: 139.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.0 | Acuracia_20: 0.25 
Precisao modelo Geral: 60.2273
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
800 800 800
(771, 30) (771, 30) (771, 30)
(771, 90) (771, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.5885917  0.41140828]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 801 | Acuracia_21: 1.0 | Contagem Geral: 100.0 
Ordem Natural: 139.0
Entrada: 5.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.6733 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.3175
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
801 801 801
(772, 30) (772, 30) (772, 30)
(772, 90) (772, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6230852 0.3769148]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 802 | Acuracia_22: 0.0 | Contagem Geral: 101.0 
Ordem Natural: 140.0
Entrada: 5.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_22: 0.3333 
Precisao modelo Geral: 60.4072
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
802 802 802
(773, 30) (773, 30) (773, 30)
(773, 90) (773, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5589428  0.44105724]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 803 | Acuracia_23: 0.6667 | Contagem Geral: 102.0 
Ordem Natural: 141.0
Entrada: 7.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9806 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.4966
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
803 803 803
(774, 30) (774, 30) (774, 30)
(774, 90) (774, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7048795  0.29512045]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 804 | Acuracia_24: 0.2 | Contagem Geral: 103.0 
Ordem Natural: 142.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6538 | Acuracia_24: 0.1667 
Precisao modelo Geral: 60.3604
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
804 804 804
(775, 30) (775, 30) (775, 30)
(775, 90) (775, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6307035 0.3692965]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 805 | Acuracia_25: 0.0 | Contagem Geral: 104.0 
Ordem Natural: 142.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.2247
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
805 805 805
(776, 30) (776, 30) (776, 30)
(776, 90) (776, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.63590044 0.36409956]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 806 | Acuracia_26: 0.5 | Contagem Geral: 105.0 
Ordem Natural: 142.0
Entrada: 8.28
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9623 | Acuracia_26: 0.6667 
Precisao modelo Geral: 60.3139
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
806 806 806
(777, 30) (777, 30) (777, 30)
(777, 90) (777, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.88854605 0.1114539 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 807 | Acuracia_27: 0.0 | Contagem Geral: 106.0 
Ordem Natural: 143.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9623 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.4027
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
807 807 807
(778, 30) (778, 30) (778, 30)
(778, 90) (778, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87437505 0.12562495]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 808 | Acuracia_28: 0.0 | Contagem Geral: 106.0 
Ordem Natural: 143.0
Entrada: 2.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9623 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.4911
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
808 808 808
(779, 30) (779, 30) (779, 30)
(779, 90) (779, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.7576294  0.24237062]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 809 | Acuracia_29: 0.0 | Contagem Geral: 106.0 
Ordem Natural: 143.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6449 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.3563
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
809 809 809
(780, 30) (780, 30) (780, 30)
(780, 90) (780, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.69001585 0.30998415]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 810 | Acuracia_0: 0.5 | Contagem Geral: 107.0 
Ordem Natural: 143.0
Entrada: 14.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_30: 0.6667 
Precisao modelo Geral: 60.4444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
810 810 810
(781, 30) (781, 30) (781, 30)
(781, 90) (781, 30)
Matrix_30: [(781, 90), (781, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2351 - accuracy: 0.3142 - precision: 0.3142 - recall: 0.3142 - f1_score: 0.4745 - val_loss: 0.1605 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2343 - accuracy: 0.6720 - precision: 0.6720 - recall: 0.6720 - f1_score: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.7182 - val_precision: 0.7182 - val_recall: 0.7182 - val_f1_score: 0.0606 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2028 - accuracy: 0.6743 - precision: 0.6743 - recall: 0.6743 - f1_score: 0.0274 - val_loss: 0.1611 - val_accuracy: 0.7182 - val_precision: 0.7182 - val_recall: 0.7182 - val_f1_score: 0.5373 - 79ms/epoch - 79ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1711 - accuracy: 0.6284 - precision: 0.6284 - recall: 0.6284 - f1_score: 0.4255 - val_loss: 0.1904 - val_accuracy: 0.3727 - val_precision: 0.3727 - val_recall: 0.3727 - val_f1_score: 0.4202 - 79ms/epoch - 79ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1705 - accuracy: 0.4106 - precision: 0.4106 - recall: 0.4106 - f1_score: 0.5029 - val_loss: 0.2050 - val_accuracy: 0.3000 - val_precision: 0.3000 - val_recall: 0.3000 - val_f1_score: 0.4211 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1739 - accuracy: 0.3509 - precision: 0.3509 - recall: 0.3509 - f1_score: 0.4901 - val_loss: 0.1927 - val_accuracy: 0.3364 - val_precision: 0.3364 - val_recall: 0.3364 - val_f1_score: 0.4341 - 76ms/epoch - 76ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.3807 - precision: 0.3807 - recall: 0.3807 - f1_score: 0.5018 - val_loss: 0.1709 - val_accuracy: 0.4727 - val_precision: 0.4727 - val_recall: 0.4727 - val_f1_score: 0.4727 - 77ms/epoch - 77ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.5390 - precision: 0.5390 - recall: 0.5390 - f1_score: 0.5696 - val_loss: 0.1528 - val_accuracy: 0.7364 - val_precision: 0.7364 - val_recall: 0.7364 - val_f1_score: 0.6329 - 77ms/epoch - 77ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1476 - accuracy: 0.7798 - precision: 0.7798 - recall: 0.7798 - f1_score: 0.7073 - val_loss: 0.1419 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7187 - 76ms/epoch - 76ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1455 - accuracy: 0.8372 - precision: 0.8372 - recall: 0.8372 - f1_score: 0.7300 - val_loss: 0.1368 - val_accuracy: 0.8273 - val_precision: 0.8273 - val_recall: 0.8273 - val_f1_score: 0.6984 - 81ms/epoch - 81ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1427 - accuracy: 0.8509 - precision: 0.8509 - recall: 0.8509 - f1_score: 0.7390 - val_loss: 0.1366 - val_accuracy: 0.8364 - val_precision: 0.8364 - val_recall: 0.8364 - val_f1_score: 0.7273 - 82ms/epoch - 82ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1372 - accuracy: 0.8670 - precision: 0.8670 - recall: 0.8670 - f1_score: 0.7786 - val_loss: 0.1410 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1_score: 0.7105 - 79ms/epoch - 79ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1312 - accuracy: 0.8509 - precision: 0.8509 - recall: 0.8509 - f1_score: 0.7869 - val_loss: 0.1477 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.6512 - 79ms/epoch - 79ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1272 - accuracy: 0.7775 - precision: 0.7775 - recall: 0.7775 - f1_score: 0.7283 - val_loss: 0.1497 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.6591 - 79ms/epoch - 79ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1235 - accuracy: 0.7546 - precision: 0.7546 - recall: 0.7546 - f1_score: 0.7147 - val_loss: 0.1416 - val_accuracy: 0.7545 - val_precision: 0.7545 - val_recall: 0.7545 - val_f1_score: 0.6747 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1172 - accuracy: 0.8028 - precision: 0.8028 - recall: 0.8028 - f1_score: 0.7543 - val_loss: 0.1267 - val_accuracy: 0.8091 - val_precision: 0.8091 - val_recall: 0.8091 - val_f1_score: 0.7273 - 79ms/epoch - 79ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1098 - accuracy: 0.8784 - precision: 0.8784 - recall: 0.8784 - f1_score: 0.8274 - val_loss: 0.1123 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8000 - 81ms/epoch - 81ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1047 - accuracy: 0.9014 - precision: 0.9014 - recall: 0.9014 - f1_score: 0.8436 - val_loss: 0.1033 - val_accuracy: 0.8909 - val_precision: 0.8909 - val_recall: 0.8909 - val_f1_score: 0.8125 - 83ms/epoch - 83ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1000 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8550 - val_loss: 0.1010 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8308 - 79ms/epoch - 79ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0928 - accuracy: 0.9060 - precision: 0.9060 - recall: 0.9060 - f1_score: 0.8520 - val_loss: 0.1047 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0868 - accuracy: 0.8945 - precision: 0.8945 - recall: 0.8945 - f1_score: 0.8477 - val_loss: 0.1069 - val_accuracy: 0.8455 - val_precision: 0.8455 - val_recall: 0.8455 - val_f1_score: 0.7671 - 79ms/epoch - 79ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0832 - accuracy: 0.8739 - precision: 0.8739 - recall: 0.8739 - f1_score: 0.8265 - val_loss: 0.0978 - val_accuracy: 0.8545 - val_precision: 0.8545 - val_recall: 0.8545 - val_f1_score: 0.7778 - 77ms/epoch - 77ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0774 - accuracy: 0.8968 - precision: 0.8968 - recall: 0.8968 - f1_score: 0.8534 - val_loss: 0.0838 - val_accuracy: 0.8909 - val_precision: 0.8909 - val_recall: 0.8909 - val_f1_score: 0.8182 - 78ms/epoch - 78ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0724 - accuracy: 0.9060 - precision: 0.9060 - recall: 0.9060 - f1_score: 0.8551 - val_loss: 0.0758 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8308 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0696 - accuracy: 0.9197 - precision: 0.9197 - recall: 0.9197 - f1_score: 0.8727 - val_loss: 0.0760 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8060 - 78ms/epoch - 78ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0647 - accuracy: 0.9197 - precision: 0.9197 - recall: 0.9197 - f1_score: 0.8772 - val_loss: 0.0809 - val_accuracy: 0.8455 - val_precision: 0.8455 - val_recall: 0.8455 - val_f1_score: 0.7606 - 90ms/epoch - 90ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0615 - accuracy: 0.9083 - precision: 0.9083 - recall: 0.9083 - f1_score: 0.8667 - val_loss: 0.0805 - val_accuracy: 0.8455 - val_precision: 0.8455 - val_recall: 0.8455 - val_f1_score: 0.7606 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0588 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - f1_score: 0.8609 - val_loss: 0.0718 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.7941 - 86ms/epoch - 86ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0548 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - f1_score: 0.8904 - val_loss: 0.0644 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8060 - 90ms/epoch - 90ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0527 - accuracy: 0.9358 - precision: 0.9358 - recall: 0.9358 - f1_score: 0.8993 - val_loss: 0.0635 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.7879 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0496 - accuracy: 0.9335 - precision: 0.9335 - recall: 0.9335 - f1_score: 0.8968 - val_loss: 0.0674 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8060 - 78ms/epoch - 78ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0467 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - f1_score: 0.8958 - val_loss: 0.0692 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8060 - 81ms/epoch - 81ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0447 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - f1_score: 0.8966 - val_loss: 0.0639 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8060 - 88ms/epoch - 88ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0417 - accuracy: 0.9358 - precision: 0.9358 - recall: 0.9358 - f1_score: 0.9021 - val_loss: 0.0583 - val_accuracy: 0.8909 - val_precision: 0.8909 - val_recall: 0.8909 - val_f1_score: 0.8125 - 76ms/epoch - 76ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0397 - accuracy: 0.9495 - precision: 0.9495 - recall: 0.9495 - f1_score: 0.9203 - val_loss: 0.0577 - val_accuracy: 0.8909 - val_precision: 0.8909 - val_recall: 0.8909 - val_f1_score: 0.8125 - 79ms/epoch - 79ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0374 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - f1_score: 0.9304 - val_loss: 0.0611 - val_accuracy: 0.8727 - val_precision: 0.8727 - val_recall: 0.8727 - val_f1_score: 0.7879 - 150ms/epoch - 150ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0351 - accuracy: 0.9518 - precision: 0.9518 - recall: 0.9518 - f1_score: 0.9242 - val_loss: 0.0628 - val_accuracy: 0.8636 - val_precision: 0.8636 - val_recall: 0.8636 - val_f1_score: 0.7761 - 93ms/epoch - 93ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0335 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - f1_score: 0.9324 - val_loss: 0.0590 - val_accuracy: 0.8818 - val_precision: 0.8818 - val_recall: 0.8818 - val_f1_score: 0.8000 - 80ms/epoch - 80ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0312 - accuracy: 0.9610 - precision: 0.9610 - recall: 0.9610 - f1_score: 0.9386 - val_loss: 0.0551 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8254 - 77ms/epoch - 77ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0297 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - f1_score: 0.9559 - val_loss: 0.0548 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8254 - 86ms/epoch - 86ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0279 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - f1_score: 0.9559 - val_loss: 0.0570 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8254 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0262 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - f1_score: 0.9559 - val_loss: 0.0574 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_f1_score: 0.8254 - 78ms/epoch - 78ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0249 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - f1_score: 0.9635 - val_loss: 0.0539 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8387 - 77ms/epoch - 77ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0233 - accuracy: 0.9748 - precision: 0.9748 - recall: 0.9748 - f1_score: 0.9594 - val_loss: 0.0512 - val_accuracy: 0.9182 - val_precision: 0.9182 - val_recall: 0.9182 - val_f1_score: 0.8525 - 76ms/epoch - 76ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0222 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - f1_score: 0.9630 - val_loss: 0.0509 - val_accuracy: 0.9182 - val_precision: 0.9182 - val_recall: 0.9182 - val_f1_score: 0.8525 - 78ms/epoch - 78ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0208 - accuracy: 0.9794 - precision: 0.9794 - recall: 0.9794 - f1_score: 0.9668 - val_loss: 0.0521 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8387 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0197 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1_score: 0.9781 - val_loss: 0.0514 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8710 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0188 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - f1_score: 0.9855 - val_loss: 0.0487 - val_accuracy: 0.9182 - val_precision: 0.9182 - val_recall: 0.9182 - val_f1_score: 0.8525 - 77ms/epoch - 77ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0177 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - f1_score: 0.9855 - val_loss: 0.0469 - val_accuracy: 0.9182 - val_precision: 0.9182 - val_recall: 0.9182 - val_f1_score: 0.8525 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0169 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954 - f1_score: 0.9927 - val_loss: 0.0467 - val_accuracy: 0.9273 - val_precision: 0.9273 - val_recall: 0.9273 - val_f1_score: 0.8710 - 77ms/epoch - 77ms/step

🔍 Resultados no Teste:
Loss: 0.0380
Accuracy: 0.9489
Precision: 0.9489
Recall: 0.9489
F1 Score: 0.9259
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
810 810 810
(781, 30) (781, 30) (781, 30)
(781, 90) (781, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.9639364 0.0360636]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 811 | Acuracia_1: 0.5 | Contagem Geral: 108.0 
Ordem Natural: 144.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_1: 0.5 
Precisao modelo Geral: 60.5322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
811 811 811
(782, 30) (782, 30) (782, 30)
(782, 90) (782, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.91372794 0.08627204]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 812 | Acuracia_2: 0.1667 | Contagem Geral: 108.0 
Ordem Natural: 144.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_2: 0.1667 
Precisao modelo Geral: 60.6195
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
812 812 812
(783, 30) (783, 30) (783, 30)
(783, 90) (783, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9761737  0.02382633]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 813 | Acuracia_3: 0.0 | Contagem Geral: 108.0 
Ordem Natural: 144.0
Entrada: 3.94
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.4857
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
813 813 813
(784, 30) (784, 30) (784, 30)
(784, 90) (784, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94733226 0.05266774]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 814 | Acuracia_4: 0.75 | Contagem Geral: 108.0 
Ordem Natural: 145.0
Entrada: 3.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_4: 0.75 
Precisao modelo Geral: 60.3524
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
814 814 814
(785, 30) (785, 30) (785, 30)
(785, 90) (785, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.87893146 0.12106859]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 815 | Acuracia_5: 0.3333 | Contagem Geral: 108.0 
Ordem Natural: 146.0
Entrada: 27.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.2198
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
815 815 815
(786, 30) (786, 30) (786, 30)
(786, 90) (786, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.96627456 0.03372544]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 816 | Acuracia_6: 1.0 | Contagem Geral: 108.0 
Ordem Natural: 147.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.307
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
816 816 816
(787, 30) (787, 30) (787, 30)
(787, 90) (787, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9121107 0.0878893]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 817 | Acuracia_7: 0.3333 | Contagem Geral: 108.0 
Ordem Natural: 147.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.3939
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
817 817 817
(788, 30) (788, 30) (788, 30)
(788, 90) (788, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96685255 0.0331474 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 818 | Acuracia_8: 0.6667 | Contagem Geral: 108.0 
Ordem Natural: 147.0
Entrada: 18.43
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.262
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
818 818 818
(789, 30) (789, 30) (789, 30)
(789, 90) (789, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9934263  0.00657363]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 819 | Acuracia_9: 0.6667 | Contagem Geral: 108.0 
Ordem Natural: 148.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_9: 0.6667 
Precisao modelo Geral: 60.3486
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
819 819 819
(790, 30) (790, 30) (790, 30)
(790, 90) (790, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94697577 0.05302417]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 820 | Acuracia_10: 0.5 | Contagem Geral: 108.0 
Ordem Natural: 148.0
Entrada: 2.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2593 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.4348
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
820 820 820
(791, 30) (791, 30) (791, 30)
(791, 90) (791, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.6560259 0.3439741]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 821 | Acuracia_11: 0.0 | Contagem Geral: 108.0 
Ordem Natural: 148.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.8624 | Acuracia_11: 0.3333 
Precisao modelo Geral: 60.5206
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
821 821 821
(792, 30) (792, 30) (792, 30)
(792, 90) (792, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 32ms/step
[[0.84728    0.15271991]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 822 | Acuracia_12: 0.0 | Contagem Geral: 109.0 
Ordem Natural: 149.0
Entrada: 2.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.8624 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
822 822 822
(793, 30) (793, 30) (793, 30)
(793, 90) (793, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 39ms/step
[[0.9905787  0.00942131]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 823 | Acuracia_13: 0.6 | Contagem Geral: 109.0 
Ordem Natural: 149.0
Entrada: 2.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.8624 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.6911
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
823 823 823
(794, 30) (794, 30) (794, 30)
(794, 90) (794, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99425656 0.00574342]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 824 | Acuracia_14: 0.0 | Contagem Geral: 109.0 
Ordem Natural: 149.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.8624 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.7759
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
824 824 824
(795, 30) (795, 30) (795, 30)
(795, 90) (795, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9008399  0.09916005]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 825 | Acuracia_15: 0.0 | Contagem Geral: 109.0 
Ordem Natural: 149.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.8624 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.8602
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
825 825 825
(796, 30) (796, 30) (796, 30)
(796, 90) (796, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7593291  0.24067095]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 826 | Acuracia_16: 0.0 | Contagem Geral: 109.0 
Ordem Natural: 149.0
Entrada: 1.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.7296
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
826 826 826
(797, 30) (797, 30) (797, 30)
(797, 90) (797, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9242313  0.07576867]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 827 | Acuracia_17: 0.4 | Contagem Geral: 110.0 
Ordem Natural: 149.0
Entrada: 3.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_17: 0.4 
Precisao modelo Geral: 60.5996
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
827 827 827
(798, 30) (798, 30) (798, 30)
(798, 90) (798, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97702754 0.02297241]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 828 | Acuracia_18: 0.1667 | Contagem Geral: 110.0 
Ordem Natural: 150.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_18: 0.1667 
Precisao modelo Geral: 60.6838
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
828 828 828
(799, 30) (799, 30) (799, 30)
(799, 90) (799, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8605651  0.13943484]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 829 | Acuracia_19: 0.1667 | Contagem Geral: 110.0 
Ordem Natural: 150.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.7676
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
829 829 829
(800, 30) (800, 30) (800, 30)
(800, 90) (800, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.80049866 0.1995013 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 830 | Acuracia_20: 0.25 | Contagem Geral: 110.0 
Ordem Natural: 150.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_20: 0.25 
Precisao modelo Geral: 60.8511
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
830 830 830
(801, 30) (801, 30) (801, 30)
(801, 90) (801, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94213575 0.05786426]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 831 | Acuracia_21: 1.0 | Contagem Geral: 110.0 
Ordem Natural: 150.0
Entrada: 24.88
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_21: 1.0 
Precisao modelo Geral: 60.7219
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
831 831 831
(802, 30) (802, 30) (802, 30)
(802, 90) (802, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9693527  0.03064728]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 832 | Acuracia_22: 0.3333 | Contagem Geral: 110.0 
Ordem Natural: 151.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_22: 0.3333 
Precisao modelo Geral: 60.8051
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
832 832 832
(803, 30) (803, 30) (803, 30)
(803, 90) (803, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9844067  0.01559325]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 833 | Acuracia_23: 0.75 | Contagem Geral: 110.0 
Ordem Natural: 151.0
Entrada: 39.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.6765
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
833 833 833
(804, 30) (804, 30) (804, 30)
(804, 90) (804, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.90627396 0.09372602]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 834 | Acuracia_24: 0.1667 | Contagem Geral: 110.0 
Ordem Natural: 152.0
Entrada: 11.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_24: 0.1667 
Precisao modelo Geral: 60.5485
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
834 834 834
(805, 30) (805, 30) (805, 30)
(805, 90) (805, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9790077  0.02099233]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 835 | Acuracia_25: 0.0 | Contagem Geral: 110.0 
Ordem Natural: 153.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.6316
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
835 835 835
(806, 30) (806, 30) (806, 30)
(806, 90) (806, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98724604 0.01275394]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 836 | Acuracia_26: 0.6667 | Contagem Geral: 110.0 
Ordem Natural: 153.0
Entrada: 2.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_26: 0.6667 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
836 836 836
(807, 30) (807, 30) (807, 30)
(807, 90) (807, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.84817487 0.15182516]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 837 | Acuracia_27: 0.0 | Contagem Geral: 110.0 
Ordem Natural: 153.0
Entrada: 1.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.5455 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.7966
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
837 837 837
(808, 30) (808, 30) (808, 30)
(808, 90) (808, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6758881  0.32411197]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 838 | Acuracia_28: 0.0 | Contagem Geral: 110.0 
Ordem Natural: 153.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2342 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.6695
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
838 838 838
(809, 30) (809, 30) (809, 30)
(809, 90) (809, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94198877 0.05801126]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 839 | Acuracia_29: 0.0 | Contagem Geral: 111.0 
Ordem Natural: 153.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2342 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.7516
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
839 839 839
(810, 30) (810, 30) (810, 30)
(810, 90) (810, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9817011  0.01829898]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 840 | Acuracia_0: 0.6667 | Contagem Geral: 111.0 
Ordem Natural: 153.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2342 | Acuracia_30: 0.6667 
Precisao modelo Geral: 60.8333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
840 840 840
(811, 30) (811, 30) (811, 30)
(811, 90) (811, 30)
Matrix_30: [(811, 90), (811, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1916 - accuracy: 0.3201 - precision: 0.3201 - recall: 0.3201 - f1_score: 0.4744 - val_loss: 0.1450 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_f1_score: 0.1500 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2005 - accuracy: 0.6932 - precision: 0.6932 - recall: 0.6932 - f1_score: 0.0142 - val_loss: 0.1365 - val_accuracy: 0.7632 - val_precision: 0.7632 - val_recall: 0.7632 - val_f1_score: 0.4706 - 81ms/epoch - 81ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.7152 - precision: 0.7152 - recall: 0.7152 - f1_score: 0.1783 - val_loss: 0.1463 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_f1_score: 0.6905 - 77ms/epoch - 77ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1432 - accuracy: 0.7837 - precision: 0.7837 - recall: 0.7837 - f1_score: 0.6899 - val_loss: 0.1758 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_f1_score: 0.5714 - 80ms/epoch - 80ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1475 - accuracy: 0.5364 - precision: 0.5364 - recall: 0.5364 - f1_score: 0.5697 - val_loss: 0.1888 - val_accuracy: 0.4474 - val_precision: 0.4474 - val_recall: 0.4474 - val_f1_score: 0.5333 - 81ms/epoch - 81ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.4393 - precision: 0.4393 - recall: 0.4393 - f1_score: 0.5226 - val_loss: 0.1726 - val_accuracy: 0.5526 - val_precision: 0.5526 - val_recall: 0.5526 - val_f1_score: 0.5854 - 78ms/epoch - 78ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1405 - accuracy: 0.5717 - precision: 0.5717 - recall: 0.5717 - f1_score: 0.5890 - val_loss: 0.1457 - val_accuracy: 0.7456 - val_precision: 0.7456 - val_recall: 0.7456 - val_f1_score: 0.7010 - 77ms/epoch - 77ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1272 - accuracy: 0.7815 - precision: 0.7815 - recall: 0.7815 - f1_score: 0.7273 - val_loss: 0.1248 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7595 - 80ms/epoch - 80ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1217 - accuracy: 0.8455 - precision: 0.8455 - recall: 0.8455 - f1_score: 0.7651 - val_loss: 0.1132 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7324 - 86ms/epoch - 86ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1215 - accuracy: 0.8698 - precision: 0.8698 - recall: 0.8698 - f1_score: 0.7704 - val_loss: 0.1077 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7246 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1174 - accuracy: 0.8720 - precision: 0.8720 - recall: 0.8720 - f1_score: 0.7698 - val_loss: 0.1071 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7397 - 79ms/epoch - 79ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1074 - accuracy: 0.8631 - precision: 0.8631 - recall: 0.8631 - f1_score: 0.7801 - val_loss: 0.1136 - val_accuracy: 0.8509 - val_precision: 0.8509 - val_recall: 0.8509 - val_f1_score: 0.7952 - 84ms/epoch - 84ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1000 - accuracy: 0.8499 - precision: 0.8499 - recall: 0.8499 - f1_score: 0.7821 - val_loss: 0.1233 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.7865 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0988 - accuracy: 0.8411 - precision: 0.8411 - recall: 0.8411 - f1_score: 0.7857 - val_loss: 0.1249 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_f1_score: 0.7692 - 82ms/epoch - 82ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0966 - accuracy: 0.8278 - precision: 0.8278 - recall: 0.8278 - f1_score: 0.7733 - val_loss: 0.1133 - val_accuracy: 0.8509 - val_precision: 0.8509 - val_recall: 0.8509 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0898 - accuracy: 0.8477 - precision: 0.8477 - recall: 0.8477 - f1_score: 0.7890 - val_loss: 0.0978 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_f1_score: 0.8052 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0844 - accuracy: 0.8764 - precision: 0.8764 - recall: 0.8764 - f1_score: 0.8133 - val_loss: 0.0886 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_f1_score: 0.7778 - 78ms/epoch - 78ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0846 - accuracy: 0.8808 - precision: 0.8808 - recall: 0.8808 - f1_score: 0.8085 - val_loss: 0.0863 - val_accuracy: 0.8509 - val_precision: 0.8509 - val_recall: 0.8509 - val_f1_score: 0.7671 - 80ms/epoch - 80ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0812 - accuracy: 0.8830 - precision: 0.8830 - recall: 0.8830 - f1_score: 0.8140 - val_loss: 0.0895 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_f1_score: 0.7895 - 83ms/epoch - 83ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0756 - accuracy: 0.8852 - precision: 0.8852 - recall: 0.8852 - f1_score: 0.8255 - val_loss: 0.0970 - val_accuracy: 0.8509 - val_precision: 0.8509 - val_recall: 0.8509 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0736 - accuracy: 0.8764 - precision: 0.8764 - recall: 0.8764 - f1_score: 0.8228 - val_loss: 0.1005 - val_accuracy: 0.8509 - val_precision: 0.8509 - val_recall: 0.8509 - val_f1_score: 0.8046 - 82ms/epoch - 82ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0727 - accuracy: 0.8764 - precision: 0.8764 - recall: 0.8764 - f1_score: 0.8261 - val_loss: 0.0937 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_f1_score: 0.8095 - 92ms/epoch - 92ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0687 - accuracy: 0.8830 - precision: 0.8830 - recall: 0.8830 - f1_score: 0.8307 - val_loss: 0.0828 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_f1_score: 0.8158 - 82ms/epoch - 82ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0650 - accuracy: 0.8962 - precision: 0.8962 - recall: 0.8962 - f1_score: 0.8439 - val_loss: 0.0756 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_f1_score: 0.7945 - 77ms/epoch - 77ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0639 - accuracy: 0.9117 - precision: 0.9117 - recall: 0.9117 - f1_score: 0.8601 - val_loss: 0.0736 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_f1_score: 0.8056 - 81ms/epoch - 81ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0615 - accuracy: 0.9117 - precision: 0.9117 - recall: 0.9117 - f1_score: 0.8601 - val_loss: 0.0758 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_f1_score: 0.8000 - 86ms/epoch - 86ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0575 - accuracy: 0.9073 - precision: 0.9073 - recall: 0.9073 - f1_score: 0.8581 - val_loss: 0.0806 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_f1_score: 0.8101 - 81ms/epoch - 81ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0555 - accuracy: 0.9051 - precision: 0.9051 - recall: 0.9051 - f1_score: 0.8599 - val_loss: 0.0813 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_f1_score: 0.8250 - 80ms/epoch - 80ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0537 - accuracy: 0.9117 - precision: 0.9117 - recall: 0.9117 - f1_score: 0.8710 - val_loss: 0.0751 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_f1_score: 0.7949 - 80ms/epoch - 80ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0503 - accuracy: 0.9139 - precision: 0.9139 - recall: 0.9139 - f1_score: 0.8713 - val_loss: 0.0679 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 77ms/epoch - 77ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0481 - accuracy: 0.9338 - precision: 0.9338 - recall: 0.9338 - f1_score: 0.8951 - val_loss: 0.0648 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 80ms/epoch - 80ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0465 - accuracy: 0.9404 - precision: 0.9404 - recall: 0.9404 - f1_score: 0.9046 - val_loss: 0.0655 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 93ms/epoch - 93ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0433 - accuracy: 0.9448 - precision: 0.9448 - recall: 0.9448 - f1_score: 0.9129 - val_loss: 0.0687 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_f1_score: 0.8000 - 91ms/epoch - 91ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0412 - accuracy: 0.9448 - precision: 0.9448 - recall: 0.9448 - f1_score: 0.9147 - val_loss: 0.0694 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_f1_score: 0.8205 - 88ms/epoch - 88ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0395 - accuracy: 0.9448 - precision: 0.9448 - recall: 0.9448 - f1_score: 0.9153 - val_loss: 0.0650 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 80ms/epoch - 80ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0368 - accuracy: 0.9492 - precision: 0.9492 - recall: 0.9492 - f1_score: 0.9210 - val_loss: 0.0599 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 80ms/epoch - 80ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9691 - precision: 0.9691 - recall: 0.9691 - f1_score: 0.9500 - val_loss: 0.0576 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0332 - accuracy: 0.9735 - precision: 0.9735 - recall: 0.9735 - f1_score: 0.9568 - val_loss: 0.0575 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8219 - 78ms/epoch - 78ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0308 - accuracy: 0.9757 - precision: 0.9757 - recall: 0.9757 - f1_score: 0.9606 - val_loss: 0.0591 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8267 - 79ms/epoch - 79ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0290 - accuracy: 0.9713 - precision: 0.9713 - recall: 0.9713 - f1_score: 0.9537 - val_loss: 0.0590 - val_accuracy: 0.8947 - val_precision: 0.8947 - val_recall: 0.8947 - val_f1_score: 0.8421 - 82ms/epoch - 82ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0275 - accuracy: 0.9757 - precision: 0.9757 - recall: 0.9757 - f1_score: 0.9611 - val_loss: 0.0555 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860 - val_f1_score: 0.8267 - 78ms/epoch - 78ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0254 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - f1_score: 0.9643 - val_loss: 0.0521 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_f1_score: 0.8571 - 77ms/epoch - 77ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0240 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - f1_score: 0.9640 - val_loss: 0.0505 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_f1_score: 0.8571 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0226 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - f1_score: 0.9640 - val_loss: 0.0504 - val_accuracy: 0.9211 - val_precision: 0.9211 - val_recall: 0.9211 - val_f1_score: 0.8732 - 86ms/epoch - 86ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0209 - accuracy: 0.9845 - precision: 0.9845 - recall: 0.9845 - f1_score: 0.9751 - val_loss: 0.0507 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_f1_score: 0.8649 - 91ms/epoch - 91ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0198 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - f1_score: 0.9789 - val_loss: 0.0492 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_f1_score: 0.8649 - 79ms/epoch - 79ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0185 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - f1_score: 0.9789 - val_loss: 0.0465 - val_accuracy: 0.9386 - val_precision: 0.9386 - val_recall: 0.9386 - val_f1_score: 0.9014 - 79ms/epoch - 79ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0172 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9912 - f1_score: 0.9857 - val_loss: 0.0450 - val_accuracy: 0.9386 - val_precision: 0.9386 - val_recall: 0.9386 - val_f1_score: 0.9014 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0163 - accuracy: 0.9934 - precision: 0.9934 - recall: 0.9934 - f1_score: 0.9892 - val_loss: 0.0445 - val_accuracy: 0.9386 - val_precision: 0.9386 - val_recall: 0.9386 - val_f1_score: 0.9014 - 79ms/epoch - 79ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0151 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9912 - f1_score: 0.9857 - val_loss: 0.0446 - val_accuracy: 0.9211 - val_precision: 0.9211 - val_recall: 0.9211 - val_f1_score: 0.8767 - 100ms/epoch - 100ms/step

🔍 Resultados no Teste:
Loss: 0.0451
Accuracy: 0.9385
Precision: 0.9385
Recall: 0.9385
F1 Score: 0.9057
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
840 840 840
(811, 30) (811, 30) (811, 30)
(811, 90) (811, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 91ms/step
[[0.83837354 0.16162644]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 841 | Acuracia_1: 0.5 | Contagem Geral: 111.0 
Ordem Natural: 153.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 34.2342 | Acuracia_1: 0.5 
Precisao modelo Geral: 60.9148
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
841 841 841
(812, 30) (812, 30) (812, 30)
(812, 90) (812, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.71176296 0.28823695]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 842 | Acuracia_2: 0.1667 | Contagem Geral: 111.0 
Ordem Natural: 153.0
Entrada: 2.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_2: 0.1429 
Precisao modelo Geral: 60.7884
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
842 842 842
(813, 30) (813, 30) (813, 30)
(813, 90) (813, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8498404  0.15015955]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 843 | Acuracia_3: 0.0 | Contagem Geral: 112.0 
Ordem Natural: 153.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.8696
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
843 843 843
(814, 30) (814, 30) (814, 30)
(814, 90) (814, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9175903  0.08240965]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 844 | Acuracia_4: 0.75 | Contagem Geral: 112.0 
Ordem Natural: 153.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_4: 0.75 
Precisao modelo Geral: 60.9504
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
844 844 844
(815, 30) (815, 30) (815, 30)
(815, 90) (815, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9291241  0.07087592]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 845 | Acuracia_5: 0.3333 | Contagem Geral: 112.0 
Ordem Natural: 153.0
Entrada: 5.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.8247
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
845 845 845
(816, 30) (816, 30) (816, 30)
(816, 90) (816, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.804083   0.19591695]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 846 | Acuracia_6: 1.0 | Contagem Geral: 112.0 
Ordem Natural: 154.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.9053
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
846 846 846
(817, 30) (817, 30) (817, 30)
(817, 90) (817, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9666695  0.03333053]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 847 | Acuracia_7: 0.3333 | Contagem Geral: 112.0 
Ordem Natural: 154.0
Entrada: 3.66
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.7803
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
847 847 847
(818, 30) (818, 30) (818, 30)
(818, 90) (818, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9684623  0.03153772]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 848 | Acuracia_8: 0.6667 | Contagem Geral: 112.0 
Ordem Natural: 155.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.9286 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.8607
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
848 848 848
(819, 30) (819, 30) (819, 30)
(819, 90) (819, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7955059  0.20449409]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 849 | Acuracia_9: 0.6667 | Contagem Geral: 112.0 
Ordem Natural: 155.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.7362
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
849 849 849
(820, 30) (820, 30) (820, 30)
(820, 90) (820, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.81099904 0.18900104]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 850 | Acuracia_10: 0.5 | Contagem Geral: 113.0 
Ordem Natural: 155.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.8163
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
850 850 850
(821, 30) (821, 30) (821, 30)
(821, 90) (821, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.90203005 0.09796999]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 851 | Acuracia_11: 0.3333 | Contagem Geral: 113.0 
Ordem Natural: 155.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_11: 0.3333 
Precisao modelo Geral: 60.8961
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
851 851 851
(822, 30) (822, 30) (822, 30)
(822, 90) (822, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8846453  0.11535469]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 852 | Acuracia_12: 0.0 | Contagem Geral: 113.0 
Ordem Natural: 155.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
852 852 852
(823, 30) (823, 30) (823, 30)
(823, 90) (823, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.92438215 0.07561781]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 853 | Acuracia_13: 0.6 | Contagem Geral: 113.0 
Ordem Natural: 155.0
Entrada: 4.41
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.8519
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
853 853 853
(824, 30) (824, 30) (824, 30)
(824, 90) (824, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.85254604 0.14745395]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 854 | Acuracia_14: 0.0 | Contagem Geral: 113.0 
Ordem Natural: 156.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.6283 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.9312
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
854 854 854
(825, 30) (825, 30) (825, 30)
(825, 90) (825, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.6449165  0.35508347]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 855 | Acuracia_15: 0.0 | Contagem Geral: 113.0 
Ordem Natural: 156.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.8081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
855 855 855
(826, 30) (826, 30) (826, 30)
(826, 90) (826, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8975959  0.10240407]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 856 | Acuracia_16: 0.0 | Contagem Geral: 114.0 
Ordem Natural: 156.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.8871
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
856 856 856
(827, 30) (827, 30) (827, 30)
(827, 90) (827, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9427753  0.05722474]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 857 | Acuracia_17: 0.4 | Contagem Geral: 114.0 
Ordem Natural: 156.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_17: 0.4 
Precisao modelo Geral: 60.9658
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
857 857 857
(828, 30) (828, 30) (828, 30)
(828, 90) (828, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8266331  0.17336692]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 858 | Acuracia_18: 0.1667 | Contagem Geral: 114.0 
Ordem Natural: 156.0
Entrada: 14.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_18: 0.1667 
Precisao modelo Geral: 60.8434
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
858 858 858
(829, 30) (829, 30) (829, 30)
(829, 90) (829, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8375732  0.16242683]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 859 | Acuracia_19: 0.1667 | Contagem Geral: 114.0 
Ordem Natural: 157.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.9218
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
859 859 859
(830, 30) (830, 30) (830, 30)
(830, 90) (830, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9536519 0.0463481]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 860 | Acuracia_20: 0.25 | Contagem Geral: 114.0 
Ordem Natural: 157.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_20: 0.25 
Precisao modelo Geral: 61.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
860 860 860
(831, 30) (831, 30) (831, 30)
(831, 90) (831, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.79193336 0.20806666]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 861 | Acuracia_21: 1.0 | Contagem Geral: 114.0 
Ordem Natural: 157.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0435 | Acuracia_21: 0.75 
Precisao modelo Geral: 60.8782
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
861 861 861
(832, 30) (832, 30) (832, 30)
(832, 90) (832, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.5340484 0.4659516]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 862 | Acuracia_22: 0.3333 | Contagem Geral: 115.0 
Ordem Natural: 157.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_22: 0.25 
Precisao modelo Geral: 60.757
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
862 862 862
(833, 30) (833, 30) (833, 30)
(833, 90) (833, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9250887  0.07491132]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 863 | Acuracia_23: 0.75 | Contagem Geral: 116.0 
Ordem Natural: 157.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.835
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
863 863 863
(834, 30) (834, 30) (834, 30)
(834, 90) (834, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.91611725 0.08388273]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 864 | Acuracia_24: 0.1667 | Contagem Geral: 116.0 
Ordem Natural: 157.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_24: 0.1667 
Precisao modelo Geral: 60.9127
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
864 864 864
(835, 30) (835, 30) (835, 30)
(835, 90) (835, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8639293  0.13607077]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 865 | Acuracia_25: 0.0 | Contagem Geral: 116.0 
Ordem Natural: 157.0
Entrada: 2.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.9901
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
865 865 865
(836, 30) (836, 30) (836, 30)
(836, 90) (836, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90976053 0.09023945]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 866 | Acuracia_26: 0.6667 | Contagem Geral: 116.0 
Ordem Natural: 157.0
Entrada: 6.78
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_26: 0.6667 
Precisao modelo Geral: 60.8696
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
866 866 866
(837, 30) (837, 30) (837, 30)
(837, 90) (837, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94807154 0.05192842]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 867 | Acuracia_27: 0.0 | Contagem Geral: 116.0 
Ordem Natural: 158.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.9467
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
867 867 867
(838, 30) (838, 30) (838, 30)
(838, 90) (838, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9398863  0.06011375]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 868 | Acuracia_28: 0.0 | Contagem Geral: 116.0 
Ordem Natural: 158.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7586 | Acuracia_28: 0.0 
Precisao modelo Geral: 61.0236
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
868 868 868
(839, 30) (839, 30) (839, 30)
(839, 90) (839, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.73383594 0.266164  ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 869 | Acuracia_29: 0.0 | Contagem Geral: 116.0 
Ordem Natural: 158.0
Entrada: 1.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.9037
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
869 869 869
(840, 30) (840, 30) (840, 30)
(840, 90) (840, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8564758  0.14352427]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 870 | Acuracia_0: 0.6667 | Contagem Geral: 117.0 
Ordem Natural: 158.0
Entrada: 9.97
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_30: 0.6667 
Precisao modelo Geral: 60.7843
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
870 870 870
(841, 30) (841, 30) (841, 30)
(841, 90) (841, 30)
Matrix_30: [(841, 90), (841, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1822 - accuracy: 0.7000 - precision: 0.7000 - recall: 0.7000 - f1_score: 0.2460 - val_loss: 0.3396 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.4675 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2566 - accuracy: 0.3064 - precision: 0.3064 - recall: 0.3064 - f1_score: 0.4691 - val_loss: 0.2285 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.4737 - 79ms/epoch - 79ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1842 - accuracy: 0.3362 - precision: 0.3362 - recall: 0.3362 - f1_score: 0.4800 - val_loss: 0.1474 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.6591 - 79ms/epoch - 79ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1468 - accuracy: 0.7128 - precision: 0.7128 - recall: 0.7128 - f1_score: 0.6419 - val_loss: 0.1256 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.2857 - 79ms/epoch - 79ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.7362 - precision: 0.7362 - recall: 0.7362 - f1_score: 0.2530 - val_loss: 0.1231 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.2000 - 79ms/epoch - 79ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.7191 - precision: 0.7191 - recall: 0.7191 - f1_score: 0.1538 - val_loss: 0.1209 - val_accuracy: 0.8051 - val_precision: 0.8051 - val_recall: 0.8051 - val_f1_score: 0.5306 - 79ms/epoch - 79ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1488 - accuracy: 0.7596 - precision: 0.7596 - recall: 0.7596 - f1_score: 0.3616 - val_loss: 0.1264 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7273 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1378 - accuracy: 0.8872 - precision: 0.8872 - recall: 0.8872 - f1_score: 0.7938 - val_loss: 0.1371 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_f1_score: 0.7750 - 81ms/epoch - 81ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1353 - accuracy: 0.8255 - precision: 0.8255 - recall: 0.8255 - f1_score: 0.7657 - val_loss: 0.1468 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.7200 - 81ms/epoch - 81ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1361 - accuracy: 0.7170 - precision: 0.7170 - recall: 0.7170 - f1_score: 0.6826 - val_loss: 0.1500 - val_accuracy: 0.6695 - val_precision: 0.6695 - val_recall: 0.6695 - val_f1_score: 0.6486 - 80ms/epoch - 80ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1355 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.6384 - val_loss: 0.1446 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.7059 - 78ms/epoch - 78ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.7021 - precision: 0.7021 - recall: 0.7021 - f1_score: 0.6714 - val_loss: 0.1308 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.8140 - 80ms/epoch - 80ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1236 - accuracy: 0.8149 - precision: 0.8149 - recall: 0.8149 - f1_score: 0.7629 - val_loss: 0.1141 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8333 - 86ms/epoch - 86ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1169 - accuracy: 0.9213 - precision: 0.9213 - recall: 0.9213 - f1_score: 0.8746 - val_loss: 0.1017 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8182 - 80ms/epoch - 80ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1148 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8372 - val_loss: 0.0961 - val_accuracy: 0.8898 - val_precision: 0.8898 - val_recall: 0.8898 - val_f1_score: 0.7937 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1119 - accuracy: 0.9043 - precision: 0.9043 - recall: 0.9043 - f1_score: 0.8207 - val_loss: 0.0938 - val_accuracy: 0.8898 - val_precision: 0.8898 - val_recall: 0.8898 - val_f1_score: 0.8060 - 78ms/epoch - 78ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1035 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - f1_score: 0.8667 - val_loss: 0.0964 - val_accuracy: 0.9068 - val_precision: 0.9068 - val_recall: 0.9068 - val_f1_score: 0.8533 - 83ms/epoch - 83ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0956 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - f1_score: 0.8667 - val_loss: 0.1024 - val_accuracy: 0.8898 - val_precision: 0.8898 - val_recall: 0.8898 - val_f1_score: 0.8395 - 82ms/epoch - 82ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0926 - accuracy: 0.8872 - precision: 0.8872 - recall: 0.8872 - f1_score: 0.8399 - val_loss: 0.1009 - val_accuracy: 0.8898 - val_precision: 0.8898 - val_recall: 0.8898 - val_f1_score: 0.8434 - 80ms/epoch - 80ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0886 - accuracy: 0.8787 - precision: 0.8787 - recall: 0.8787 - f1_score: 0.8299 - val_loss: 0.0875 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.8718 - 80ms/epoch - 80ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0803 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - f1_score: 0.8599 - val_loss: 0.0728 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9041 - 84ms/epoch - 84ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0745 - accuracy: 0.9383 - precision: 0.9383 - recall: 0.9383 - f1_score: 0.8997 - val_loss: 0.0651 - val_accuracy: 0.9068 - val_precision: 0.9068 - val_recall: 0.9068 - val_f1_score: 0.8358 - 82ms/epoch - 82ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0720 - accuracy: 0.9383 - precision: 0.9383 - recall: 0.9383 - f1_score: 0.8953 - val_loss: 0.0617 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.8857 - 81ms/epoch - 81ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0655 - accuracy: 0.9468 - precision: 0.9468 - recall: 0.9468 - f1_score: 0.9117 - val_loss: 0.0630 - val_accuracy: 0.9237 - val_precision: 0.9237 - val_recall: 0.9237 - val_f1_score: 0.8800 - 81ms/epoch - 81ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0595 - accuracy: 0.9447 - precision: 0.9447 - recall: 0.9447 - f1_score: 0.9116 - val_loss: 0.0651 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9091 - 79ms/epoch - 79ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0569 - accuracy: 0.9255 - precision: 0.9255 - recall: 0.9255 - f1_score: 0.8882 - val_loss: 0.0579 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9067 - 78ms/epoch - 78ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0517 - accuracy: 0.9426 - precision: 0.9426 - recall: 0.9426 - f1_score: 0.9109 - val_loss: 0.0469 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9041 - 78ms/epoch - 78ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0471 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - f1_score: 0.9366 - val_loss: 0.0418 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_f1_score: 0.9296 - 92ms/epoch - 92ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0456 - accuracy: 0.9638 - precision: 0.9638 - recall: 0.9638 - f1_score: 0.9382 - val_loss: 0.0404 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9041 - 80ms/epoch - 80ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0411 - accuracy: 0.9681 - precision: 0.9681 - recall: 0.9681 - f1_score: 0.9462 - val_loss: 0.0428 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0383 - accuracy: 0.9596 - precision: 0.9596 - recall: 0.9596 - f1_score: 0.9360 - val_loss: 0.0432 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_f1_score: 0.9333 - 116ms/epoch - 116ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0368 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - f1_score: 0.9333 - val_loss: 0.0370 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_f1_score: 0.9333 - 103ms/epoch - 103ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0332 - accuracy: 0.9766 - precision: 0.9766 - recall: 0.9766 - f1_score: 0.9622 - val_loss: 0.0319 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_f1_score: 0.9315 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0317 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - f1_score: 0.9716 - val_loss: 0.0301 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9444 - 83ms/epoch - 83ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0300 - accuracy: 0.9809 - precision: 0.9809 - recall: 0.9809 - f1_score: 0.9680 - val_loss: 0.0306 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9459 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0273 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9790 - val_loss: 0.0325 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9459 - 80ms/epoch - 80ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0264 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - f1_score: 0.9658 - val_loss: 0.0304 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9459 - 77ms/epoch - 77ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0246 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9758 - val_loss: 0.0263 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 79ms/epoch - 79ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0228 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9789 - val_loss: 0.0244 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 88ms/epoch - 88ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0221 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9789 - val_loss: 0.0242 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0204 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9754 - val_loss: 0.0255 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0194 - accuracy: 0.9809 - precision: 0.9809 - recall: 0.9809 - f1_score: 0.9691 - val_loss: 0.0256 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9459 - 82ms/epoch - 82ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0186 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9761 - val_loss: 0.0231 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0173 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9758 - val_loss: 0.0215 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9722 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0167 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9789 - val_loss: 0.0211 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_f1_score: 0.9722 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0159 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9789 - val_loss: 0.0218 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0150 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9862 - val_loss: 0.0225 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9459 - 80ms/epoch - 80ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0146 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - f1_score: 0.9795 - val_loss: 0.0215 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 83ms/epoch - 83ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0138 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - f1_score: 0.9862 - val_loss: 0.0202 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_f1_score: 0.9589 - 80ms/epoch - 80ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0132 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - f1_score: 0.9931 - val_loss: 0.0197 - val_accuracy: 0.9661 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1_score: 0.9444 - 78ms/epoch - 78ms/step

🔍 Resultados no Teste:
Loss: 0.0350
Accuracy: 0.9565
Precision: 0.9565
Recall: 0.9565
F1 Score: 0.9325
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
870 870 870
(841, 30) (841, 30) (841, 30)
(841, 90) (841, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 90ms/step
[[0.9840693  0.01593075]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 871 | Acuracia_1: 0.5 | Contagem Geral: 117.0 
Ordem Natural: 159.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_1: 0.5 
Precisao modelo Geral: 60.8611
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
871 871 871
(842, 30) (842, 30) (842, 30)
(842, 90) (842, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9434595  0.05654044]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 872 | Acuracia_2: 0.1429 | Contagem Geral: 117.0 
Ordem Natural: 159.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_2: 0.1429 
Precisao modelo Geral: 60.9375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
872 872 872
(843, 30) (843, 30) (843, 30)
(843, 90) (843, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8598233  0.14017674]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 873 | Acuracia_3: 0.0 | Contagem Geral: 117.0 
Ordem Natural: 159.0
Entrada: 1.12
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_3: 0.0 
Precisao modelo Geral: 61.0136
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
873 873 873
(844, 30) (844, 30) (844, 30)
(844, 90) (844, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9224786  0.07752143]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 874 | Acuracia_4: 0.75 | Contagem Geral: 117.0 
Ordem Natural: 159.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_4: 0.75 
Precisao modelo Geral: 60.8949
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
874 874 874
(845, 30) (845, 30) (845, 30)
(845, 90) (845, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9725866  0.02741336]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 875 | Acuracia_5: 0.3333 | Contagem Geral: 117.0 
Ordem Natural: 160.0
Entrada: 7.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.7767
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
875 875 875
(846, 30) (846, 30) (846, 30)
(846, 90) (846, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96997213 0.03002787]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 876 | Acuracia_6: 1.0 | Contagem Geral: 117.0 
Ordem Natural: 161.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.8527
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
876 876 876
(847, 30) (847, 30) (847, 30)
(847, 90) (847, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93956274 0.06043728]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 877 | Acuracia_7: 0.3333 | Contagem Geral: 117.0 
Ordem Natural: 161.0
Entrada: 4.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.735
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
877 877 877
(848, 30) (848, 30) (848, 30)
(848, 90) (848, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97925436 0.02074566]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 878 | Acuracia_8: 0.6667 | Contagem Geral: 117.0 
Ordem Natural: 162.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.8108
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
878 878 878
(849, 30) (849, 30) (849, 30)
(849, 90) (849, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9855188  0.01448123]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 879 | Acuracia_9: 0.5 | Contagem Geral: 117.0 
Ordem Natural: 162.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.8863
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
879 879 879
(850, 30) (850, 30) (850, 30)
(850, 90) (850, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.94625187 0.05374816]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 880 | Acuracia_10: 0.5 | Contagem Geral: 117.0 
Ordem Natural: 162.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.4786 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.9615
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
880 880 880
(851, 30) (851, 30) (851, 30)
(851, 90) (851, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7652236  0.23477638]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 881 | Acuracia_11: 0.3333 | Contagem Geral: 117.0 
Ordem Natural: 162.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_11: 0.25 
Precisao modelo Geral: 60.8445
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
881 881 881
(852, 30) (852, 30) (852, 30)
(852, 90) (852, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9609637  0.03903632]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 882 | Acuracia_12: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 162.0
Entrada: 5.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.728
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
882 882 882
(853, 30) (853, 30) (853, 30)
(853, 90) (853, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9937211 0.0062789]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 883 | Acuracia_13: 0.6 | Contagem Geral: 118.0 
Ordem Natural: 163.0
Entrada: 4.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.6119
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
883 883 883
(854, 30) (854, 30) (854, 30)
(854, 90) (854, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.988497   0.01150297]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 884 | Acuracia_14: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 164.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.687
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
884 884 884
(855, 30) (855, 30) (855, 30)
(855, 90) (855, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.92533994 0.07466004]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 885 | Acuracia_15: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 164.0
Entrada: 10.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
885 885 885
(856, 30) (856, 30) (856, 30)
(856, 90) (856, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8344619  0.16553807]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 886 | Acuracia_16: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.6464
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
886 886 886
(857, 30) (857, 30) (857, 30)
(857, 90) (857, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98916954 0.01083038]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 887 | Acuracia_17: 0.4 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_17: 0.4 
Precisao modelo Geral: 60.7211
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
887 887 887
(858, 30) (858, 30) (858, 30)
(858, 90) (858, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9937463  0.00625376]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 888 | Acuracia_18: 0.1667 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_18: 0.1667 
Precisao modelo Geral: 60.7955
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
888 888 888
(859, 30) (859, 30) (859, 30)
(859, 90) (859, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9733471 0.0266529]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 889 | Acuracia_19: 0.1667 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 2.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.8696
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
889 889 889
(860, 30) (860, 30) (860, 30)
(860, 90) (860, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.98366123 0.01633877]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 890 | Acuracia_20: 0.25 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_20: 0.25 
Precisao modelo Geral: 60.9434
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
890 890 890
(861, 30) (861, 30) (861, 30)
(861, 90) (861, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9777098  0.02229019]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 891 | Acuracia_21: 0.75 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_21: 0.75 
Precisao modelo Geral: 61.0169
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
891 891 891
(862, 30) (862, 30) (862, 30)
(862, 90) (862, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9397735  0.06022652]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 892 | Acuracia_22: 0.25 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 1.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_22: 0.25 
Precisao modelo Geral: 61.0902
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
892 892 892
(863, 30) (863, 30) (863, 30)
(863, 90) (863, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.84956765 0.1504324 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 893 | Acuracia_23: 0.75 | Contagem Geral: 118.0 
Ordem Natural: 165.0
Entrada: 4.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
893 893 893
(864, 30) (864, 30) (864, 30)
(864, 90) (864, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.91039884 0.08960111]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 894 | Acuracia_24: 0.1667 | Contagem Geral: 118.0 
Ordem Natural: 166.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_24: 0.1667 
Precisao modelo Geral: 61.0487
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
894 894 894
(865, 30) (865, 30) (865, 30)
(865, 90) (865, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9948909  0.00510912]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 895 | Acuracia_25: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 166.0
Entrada: 2.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_25: 0.0 
Precisao modelo Geral: 61.1215
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
895 895 895
(866, 30) (866, 30) (866, 30)
(866, 90) (866, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9901973  0.00980273]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 896 | Acuracia_26: 0.6667 | Contagem Geral: 118.0 
Ordem Natural: 166.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_26: 0.6667 
Precisao modelo Geral: 61.194
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
896 896 896
(867, 30) (867, 30) (867, 30)
(867, 90) (867, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94461894 0.05538108]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 897 | Acuracia_27: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 166.0
Entrada: 5.24
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_27: 0.0 
Precisao modelo Geral: 61.0801
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
897 897 897
(868, 30) (868, 30) (868, 30)
(868, 90) (868, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9618374  0.03816259]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 898 | Acuracia_28: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 167.0
Entrada: 7.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.9665
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
898 898 898
(869, 30) (869, 30) (869, 30)
(869, 90) (869, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.989499   0.01050104]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 899 | Acuracia_29: 0.0 | Contagem Geral: 118.0 
Ordem Natural: 168.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_29: 0.0 
Precisao modelo Geral: 61.039
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
899 899 899
(870, 30) (870, 30) (870, 30)
(870, 90) (870, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9822334  0.01776662]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 900 | Acuracia_0: 0.6667 | Contagem Geral: 118.0 
Ordem Natural: 168.0
Entrada: 8.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2034 | Acuracia_30: 0.6667 
Precisao modelo Geral: 60.9259
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
900 900 900
(871, 30) (871, 30) (871, 30)
(871, 90) (871, 30)
Matrix_30: [(871, 90), (871, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1833 - accuracy: 0.3080 - precision: 0.3080 - recall: 0.3080 - f1_score: 0.4693 - val_loss: 0.1564 - val_accuracy: 0.6803 - val_precision: 0.6803 - val_recall: 0.6803 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2012 - accuracy: 0.6940 - precision: 0.6940 - recall: 0.6940 - f1_score: 0.0000e+00 - val_loss: 0.1566 - val_accuracy: 0.6803 - val_precision: 0.6803 - val_recall: 0.6803 - val_f1_score: 0.2909 - 79ms/epoch - 79ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.7023 - precision: 0.7023 - recall: 0.7023 - f1_score: 0.1899 - val_loss: 0.1722 - val_accuracy: 0.5082 - val_precision: 0.5082 - val_recall: 0.5082 - val_f1_score: 0.5455 - 83ms/epoch - 83ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1614 - accuracy: 0.4908 - precision: 0.4908 - recall: 0.4908 - f1_score: 0.5321 - val_loss: 0.1839 - val_accuracy: 0.4016 - val_precision: 0.4016 - val_recall: 0.4016 - val_f1_score: 0.5166 - 81ms/epoch - 81ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1637 - accuracy: 0.3758 - precision: 0.3758 - recall: 0.3758 - f1_score: 0.4950 - val_loss: 0.1755 - val_accuracy: 0.4672 - val_precision: 0.4672 - val_recall: 0.4672 - val_f1_score: 0.5455 - 82ms/epoch - 82ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.4168 - precision: 0.4168 - recall: 0.4168 - f1_score: 0.5120 - val_loss: 0.1605 - val_accuracy: 0.6557 - val_precision: 0.6557 - val_recall: 0.6557 - val_f1_score: 0.6379 - 81ms/epoch - 81ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1537 - accuracy: 0.6632 - precision: 0.6632 - recall: 0.6632 - f1_score: 0.6388 - val_loss: 0.1499 - val_accuracy: 0.8197 - val_precision: 0.8197 - val_recall: 0.8197 - val_f1_score: 0.7179 - 83ms/epoch - 83ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.8316 - precision: 0.8316 - recall: 0.8316 - f1_score: 0.7192 - val_loss: 0.1447 - val_accuracy: 0.8443 - val_precision: 0.8443 - val_recall: 0.8443 - val_f1_score: 0.7397 - 81ms/epoch - 81ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1486 - accuracy: 0.8419 - precision: 0.8419 - recall: 0.8419 - f1_score: 0.7179 - val_loss: 0.1430 - val_accuracy: 0.8361 - val_precision: 0.8361 - val_recall: 0.8361 - val_f1_score: 0.7500 - 80ms/epoch - 80ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.8337 - precision: 0.8337 - recall: 0.8337 - f1_score: 0.7553 - val_loss: 0.1451 - val_accuracy: 0.7295 - val_precision: 0.7295 - val_recall: 0.7295 - val_f1_score: 0.6857 - 84ms/epoch - 84ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1366 - accuracy: 0.7659 - precision: 0.7659 - recall: 0.7659 - f1_score: 0.7107 - val_loss: 0.1475 - val_accuracy: 0.7131 - val_precision: 0.7131 - val_recall: 0.7131 - val_f1_score: 0.6847 - 83ms/epoch - 83ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1332 - accuracy: 0.7372 - precision: 0.7372 - recall: 0.7372 - f1_score: 0.6952 - val_loss: 0.1404 - val_accuracy: 0.7377 - val_precision: 0.7377 - val_recall: 0.7377 - val_f1_score: 0.6981 - 81ms/epoch - 81ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1275 - accuracy: 0.7598 - precision: 0.7598 - recall: 0.7598 - f1_score: 0.7111 - val_loss: 0.1261 - val_accuracy: 0.8115 - val_precision: 0.8115 - val_recall: 0.8115 - val_f1_score: 0.7473 - 82ms/epoch - 82ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1207 - accuracy: 0.8460 - precision: 0.8460 - recall: 0.8460 - f1_score: 0.7801 - val_loss: 0.1154 - val_accuracy: 0.8443 - val_precision: 0.8443 - val_recall: 0.8443 - val_f1_score: 0.7532 - 82ms/epoch - 82ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1160 - accuracy: 0.8604 - precision: 0.8604 - recall: 0.8604 - f1_score: 0.7821 - val_loss: 0.1112 - val_accuracy: 0.8525 - val_precision: 0.8525 - val_recall: 0.8525 - val_f1_score: 0.7750 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1092 - accuracy: 0.8624 - precision: 0.8624 - recall: 0.8624 - f1_score: 0.7913 - val_loss: 0.1128 - val_accuracy: 0.8443 - val_precision: 0.8443 - val_recall: 0.8443 - val_f1_score: 0.7865 - 84ms/epoch - 84ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1032 - accuracy: 0.8522 - precision: 0.8522 - recall: 0.8522 - f1_score: 0.7919 - val_loss: 0.1088 - val_accuracy: 0.8525 - val_precision: 0.8525 - val_recall: 0.8525 - val_f1_score: 0.8000 - 90ms/epoch - 90ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0980 - accuracy: 0.8522 - precision: 0.8522 - recall: 0.8522 - f1_score: 0.7943 - val_loss: 0.0945 - val_accuracy: 0.8525 - val_precision: 0.8525 - val_recall: 0.8525 - val_f1_score: 0.7857 - 82ms/epoch - 82ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0910 - accuracy: 0.8747 - precision: 0.8747 - recall: 0.8747 - f1_score: 0.8100 - val_loss: 0.0858 - val_accuracy: 0.8607 - val_precision: 0.8607 - val_recall: 0.8607 - val_f1_score: 0.7792 - 82ms/epoch - 82ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0864 - accuracy: 0.8891 - precision: 0.8891 - recall: 0.8891 - f1_score: 0.8235 - val_loss: 0.0843 - val_accuracy: 0.8525 - val_precision: 0.8525 - val_recall: 0.8525 - val_f1_score: 0.7805 - 85ms/epoch - 85ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0791 - accuracy: 0.8891 - precision: 0.8891 - recall: 0.8891 - f1_score: 0.8323 - val_loss: 0.0843 - val_accuracy: 0.8689 - val_precision: 0.8689 - val_recall: 0.8689 - val_f1_score: 0.8095 - 82ms/epoch - 82ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0747 - accuracy: 0.8830 - precision: 0.8830 - recall: 0.8830 - f1_score: 0.8288 - val_loss: 0.0737 - val_accuracy: 0.8607 - val_precision: 0.8607 - val_recall: 0.8607 - val_f1_score: 0.7901 - 81ms/epoch - 81ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0691 - accuracy: 0.9014 - precision: 0.9014 - recall: 0.9014 - f1_score: 0.8471 - val_loss: 0.0685 - val_accuracy: 0.8852 - val_precision: 0.8852 - val_recall: 0.8852 - val_f1_score: 0.8250 - 81ms/epoch - 81ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0654 - accuracy: 0.9138 - precision: 0.9138 - recall: 0.9138 - f1_score: 0.8627 - val_loss: 0.0713 - val_accuracy: 0.8852 - val_precision: 0.8852 - val_recall: 0.8852 - val_f1_score: 0.8372 - 80ms/epoch - 80ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0619 - accuracy: 0.8932 - precision: 0.8932 - recall: 0.8932 - f1_score: 0.8434 - val_loss: 0.0632 - val_accuracy: 0.8852 - val_precision: 0.8852 - val_recall: 0.8852 - val_f1_score: 0.8293 - 79ms/epoch - 79ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0572 - accuracy: 0.9158 - precision: 0.9158 - recall: 0.9158 - f1_score: 0.8698 - val_loss: 0.0574 - val_accuracy: 0.9016 - val_precision: 0.9016 - val_recall: 0.9016 - val_f1_score: 0.8500 - 80ms/epoch - 80ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0547 - accuracy: 0.9240 - precision: 0.9240 - recall: 0.9240 - f1_score: 0.8779 - val_loss: 0.0599 - val_accuracy: 0.8934 - val_precision: 0.8934 - val_recall: 0.8934 - val_f1_score: 0.8471 - 82ms/epoch - 82ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0511 - accuracy: 0.9199 - precision: 0.9199 - recall: 0.9199 - f1_score: 0.8785 - val_loss: 0.0547 - val_accuracy: 0.9180 - val_precision: 0.9180 - val_recall: 0.9180 - val_f1_score: 0.8750 - 92ms/epoch - 92ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0474 - accuracy: 0.9322 - precision: 0.9322 - recall: 0.9322 - f1_score: 0.8946 - val_loss: 0.0491 - val_accuracy: 0.9016 - val_precision: 0.9016 - val_recall: 0.9016 - val_f1_score: 0.8462 - 82ms/epoch - 82ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0455 - accuracy: 0.9446 - precision: 0.9446 - recall: 0.9446 - f1_score: 0.9103 - val_loss: 0.0506 - val_accuracy: 0.9262 - val_precision: 0.9262 - val_recall: 0.9262 - val_f1_score: 0.8889 - 81ms/epoch - 81ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0421 - accuracy: 0.9384 - precision: 0.9384 - recall: 0.9384 - f1_score: 0.9045 - val_loss: 0.0482 - val_accuracy: 0.9262 - val_precision: 0.9262 - val_recall: 0.9262 - val_f1_score: 0.8889 - 81ms/epoch - 81ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0396 - accuracy: 0.9425 - precision: 0.9425 - recall: 0.9425 - f1_score: 0.9108 - val_loss: 0.0429 - val_accuracy: 0.9262 - val_precision: 0.9262 - val_recall: 0.9262 - val_f1_score: 0.8831 - 81ms/epoch - 81ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0377 - accuracy: 0.9507 - precision: 0.9507 - recall: 0.9507 - f1_score: 0.9195 - val_loss: 0.0431 - val_accuracy: 0.9262 - val_precision: 0.9262 - val_recall: 0.9262 - val_f1_score: 0.8889 - 82ms/epoch - 82ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0347 - accuracy: 0.9569 - precision: 0.9569 - recall: 0.9569 - f1_score: 0.9316 - val_loss: 0.0427 - val_accuracy: 0.9262 - val_precision: 0.9262 - val_recall: 0.9262 - val_f1_score: 0.8889 - 90ms/epoch - 90ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0330 - accuracy: 0.9589 - precision: 0.9589 - recall: 0.9589 - f1_score: 0.9355 - val_loss: 0.0379 - val_accuracy: 0.9344 - val_precision: 0.9344 - val_recall: 0.9344 - val_f1_score: 0.8974 - 81ms/epoch - 81ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0310 - accuracy: 0.9713 - precision: 0.9713 - recall: 0.9713 - f1_score: 0.9533 - val_loss: 0.0372 - val_accuracy: 0.9426 - val_precision: 0.9426 - val_recall: 0.9426 - val_f1_score: 0.9114 - 82ms/epoch - 82ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0288 - accuracy: 0.9733 - precision: 0.9733 - recall: 0.9733 - f1_score: 0.9571 - val_loss: 0.0376 - val_accuracy: 0.9426 - val_precision: 0.9426 - val_recall: 0.9426 - val_f1_score: 0.9114 - 84ms/epoch - 84ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0274 - accuracy: 0.9651 - precision: 0.9651 - recall: 0.9651 - f1_score: 0.9446 - val_loss: 0.0337 - val_accuracy: 0.9508 - val_precision: 0.9508 - val_recall: 0.9508 - val_f1_score: 0.9231 - 84ms/epoch - 84ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0256 - accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - f1_score: 0.9732 - val_loss: 0.0324 - val_accuracy: 0.9508 - val_precision: 0.9508 - val_recall: 0.9508 - val_f1_score: 0.9231 - 93ms/epoch - 93ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0240 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9877 - f1_score: 0.9797 - val_loss: 0.0328 - val_accuracy: 0.9344 - val_precision: 0.9344 - val_recall: 0.9344 - val_f1_score: 0.9000 - 80ms/epoch - 80ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0229 - accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - f1_score: 0.9733 - val_loss: 0.0301 - val_accuracy: 0.9508 - val_precision: 0.9508 - val_recall: 0.9508 - val_f1_score: 0.9231 - 82ms/epoch - 82ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0213 - accuracy: 0.9918 - precision: 0.9918 - recall: 0.9918 - f1_score: 0.9865 - val_loss: 0.0287 - val_accuracy: 0.9590 - val_precision: 0.9590 - val_recall: 0.9590 - val_f1_score: 0.9351 - 83ms/epoch - 83ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0203 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9898 - val_loss: 0.0287 - val_accuracy: 0.9590 - val_precision: 0.9590 - val_recall: 0.9590 - val_f1_score: 0.9367 - 80ms/epoch - 80ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0191 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9899 - val_loss: 0.0272 - val_accuracy: 0.9672 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1_score: 0.9487 - 86ms/epoch - 86ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0180 - accuracy: 0.9959 - precision: 0.9959 - recall: 0.9959 - f1_score: 0.9932 - val_loss: 0.0259 - val_accuracy: 0.9672 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0172 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9898 - val_loss: 0.0256 - val_accuracy: 0.9836 - val_precision: 0.9836 - val_recall: 0.9836 - val_f1_score: 0.9744 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0161 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9899 - val_loss: 0.0252 - val_accuracy: 0.9836 - val_precision: 0.9836 - val_recall: 0.9836 - val_f1_score: 0.9744 - 83ms/epoch - 83ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0154 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9899 - val_loss: 0.0239 - val_accuracy: 0.9672 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1_score: 0.9474 - 82ms/epoch - 82ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0146 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - f1_score: 0.9899 - val_loss: 0.0236 - val_accuracy: 0.9836 - val_precision: 0.9836 - val_recall: 0.9836 - val_f1_score: 0.9744 - 81ms/epoch - 81ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0138 - accuracy: 0.9959 - precision: 0.9959 - recall: 0.9959 - f1_score: 0.9933 - val_loss: 0.0237 - val_accuracy: 0.9754 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1_score: 0.9620 - 90ms/epoch - 90ms/step

🔍 Resultados no Teste:
Loss: 0.0379
Accuracy: 0.9389
Precision: 0.9389
Recall: 0.9389
F1 Score: 0.9036
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
900 900 900
(871, 30) (871, 30) (871, 30)
(871, 90) (871, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 87ms/step
[[0.76661325 0.23338677]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 901 | Acuracia_1: 0.5 | Contagem Geral: 118.0 
Ordem Natural: 169.0
Entrada: 10.26
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_1: 0.6 
Precisao modelo Geral: 60.9982
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
901 901 901
(872, 30) (872, 30) (872, 30)
(872, 90) (872, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8754143  0.12458568]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 902 | Acuracia_2: 0.1429 | Contagem Geral: 119.0 
Ordem Natural: 170.0
Entrada: 3.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_2: 0.1429 
Precisao modelo Geral: 60.8856
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
902 902 902
(873, 30) (873, 30) (873, 30)
(873, 90) (873, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89169043 0.10830954]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 903 | Acuracia_3: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 171.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.9576
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
903 903 903
(874, 30) (874, 30) (874, 30)
(874, 90) (874, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.88667846 0.11332148]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 904 | Acuracia_4: 0.75 | Contagem Geral: 119.0 
Ordem Natural: 171.0
Entrada: 3.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_4: 0.75 
Precisao modelo Geral: 60.8456
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
904 904 904
(875, 30) (875, 30) (875, 30)
(875, 90) (875, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9521085  0.04789148]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 905 | Acuracia_5: 0.3333 | Contagem Geral: 119.0 
Ordem Natural: 172.0
Entrada: 3.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.7339
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
905 905 905
(876, 30) (876, 30) (876, 30)
(876, 90) (876, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9824461  0.01755387]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 906 | Acuracia_6: 1.0 | Contagem Geral: 119.0 
Ordem Natural: 173.0
Entrada: 2.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.8059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
906 906 906
(877, 30) (877, 30) (877, 30)
(877, 90) (877, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9844282  0.01557178]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 907 | Acuracia_7: 0.3333 | Contagem Geral: 119.0 
Ordem Natural: 173.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.8775
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
907 907 907
(878, 30) (878, 30) (878, 30)
(878, 90) (878, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.91361785 0.08638212]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 908 | Acuracia_8: 0.6667 | Contagem Geral: 119.0 
Ordem Natural: 173.0
Entrada: 4.88
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.7664
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
908 908 908
(879, 30) (879, 30) (879, 30)
(879, 90) (879, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.86872417 0.13127585]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 909 | Acuracia_9: 0.5 | Contagem Geral: 119.0 
Ordem Natural: 174.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_9: 0.5 
Precisao modelo Geral: 60.8379
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
909 909 909
(880, 30) (880, 30) (880, 30)
(880, 90) (880, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89550596 0.10449403]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 910 | Acuracia_10: 0.5 | Contagem Geral: 119.0 
Ordem Natural: 174.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.9091
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
910 910 910
(881, 30) (881, 30) (881, 30)
(881, 90) (881, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9666335  0.03336649]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 911 | Acuracia_11: 0.25 | Contagem Geral: 119.0 
Ordem Natural: 174.0
Entrada: 42.21
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_11: 0.25 
Precisao modelo Geral: 60.7985
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
911 911 911
(882, 30) (882, 30) (882, 30)
(882, 90) (882, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95798093 0.04201907]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 912 | Acuracia_12: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 175.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.8696
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
912 912 912
(883, 30) (883, 30) (883, 30)
(883, 90) (883, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9719729  0.02802715]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 913 | Acuracia_13: 0.6 | Contagem Geral: 119.0 
Ordem Natural: 175.0
Entrada: 10.26
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.7595
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
913 913 913
(884, 30) (884, 30) (884, 30)
(884, 90) (884, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9868896  0.01311039]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 914 | Acuracia_14: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 176.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.8303
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
914 914 914
(885, 30) (885, 30) (885, 30)
(885, 90) (885, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9794658  0.02053424]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 915 | Acuracia_15: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 176.0
Entrada: 8.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.7207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
915 915 915
(886, 30) (886, 30) (886, 30)
(886, 90) (886, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95243126 0.04756877]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 916 | Acuracia_16: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 177.0
Entrada: 1.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.7914
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
916 916 916
(887, 30) (887, 30) (887, 30)
(887, 90) (887, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9753945  0.02460556]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 917 | Acuracia_17: 0.4 | Contagem Geral: 119.0 
Ordem Natural: 177.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_17: 0.4 
Precisao modelo Geral: 60.8618
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
917 917 917
(888, 30) (888, 30) (888, 30)
(888, 90) (888, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96893275 0.03106728]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 918 | Acuracia_18: 0.1667 | Contagem Geral: 119.0 
Ordem Natural: 177.0
Entrada: 2.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_18: 0.1667 
Precisao modelo Geral: 60.9319
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
918 918 918
(889, 30) (889, 30) (889, 30)
(889, 90) (889, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9302028  0.06979715]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 919 | Acuracia_19: 0.1667 | Contagem Geral: 119.0 
Ordem Natural: 177.0
Entrada: 3.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.8229
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
919 919 919
(890, 30) (890, 30) (890, 30)
(890, 90) (890, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94917107 0.05082886]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 920 | Acuracia_20: 0.25 | Contagem Geral: 119.0 
Ordem Natural: 178.0
Entrada: 7.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_20: 0.25 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
920 920 920
(891, 30) (891, 30) (891, 30)
(891, 90) (891, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.94077224 0.0592278 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 921 | Acuracia_21: 0.75 | Contagem Geral: 119.0 
Ordem Natural: 179.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_21: 0.75 
Precisao modelo Geral: 60.7843
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
921 921 921
(892, 30) (892, 30) (892, 30)
(892, 90) (892, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9757505  0.02424956]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 922 | Acuracia_22: 0.25 | Contagem Geral: 119.0 
Ordem Natural: 179.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_22: 0.25 
Precisao modelo Geral: 60.8541
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
922 922 922
(893, 30) (893, 30) (893, 30)
(893, 90) (893, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.97987694 0.0201231 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 923 | Acuracia_23: 0.75 | Contagem Geral: 119.0 
Ordem Natural: 179.0
Entrada: 14.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.746
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
923 923 923
(894, 30) (894, 30) (894, 30)
(894, 90) (894, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9487445  0.05125552]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 924 | Acuracia_24: 0.1667 | Contagem Geral: 119.0 
Ordem Natural: 180.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_24: 0.1667 
Precisao modelo Geral: 60.8156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
924 924 924
(895, 30) (895, 30) (895, 30)
(895, 90) (895, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9077833  0.09221665]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 925 | Acuracia_25: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 180.0
Entrada: 3.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.708
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
925 925 925
(896, 30) (896, 30) (896, 30)
(896, 90) (896, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90371275 0.09628724]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 926 | Acuracia_26: 0.6667 | Contagem Geral: 119.0 
Ordem Natural: 181.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_26: 0.6667 
Precisao modelo Geral: 60.7774
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
926 926 926
(897, 30) (897, 30) (897, 30)
(897, 90) (897, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8618914  0.13810863]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 927 | Acuracia_27: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 181.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.8466
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
927 927 927
(898, 30) (898, 30) (898, 30)
(898, 90) (898, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.92446434 0.07553566]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 928 | Acuracia_28: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 181.0
Entrada: 3.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.7394
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
928 928 928
(899, 30) (899, 30) (899, 30)
(899, 90) (899, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9171271  0.08287297]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 929 | Acuracia_29: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 182.0
Entrada: 2.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.8084
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
929 929 929
(900, 30) (900, 30) (900, 30)
(900, 90) (900, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.87189    0.12810996]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 930 | Acuracia_0: 0.6667 | Contagem Geral: 119.0 
Ordem Natural: 182.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_30: 0.6667 
Precisao modelo Geral: 60.8772
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
930 930 930
(901, 30) (901, 30) (901, 30)
(901, 90) (901, 30)
Matrix_30: [(901, 90), (901, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1763 - accuracy: 0.3988 - precision: 0.3988 - recall: 0.3988 - f1_score: 0.4560 - val_loss: 0.1612 - val_accuracy: 0.7063 - val_precision: 0.7063 - val_recall: 0.7063 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2524 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.0000e+00 - val_loss: 0.1515 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.6452 - 80ms/epoch - 80ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1501 - accuracy: 0.7421 - precision: 0.7421 - recall: 0.7421 - f1_score: 0.6448 - val_loss: 0.2294 - val_accuracy: 0.3016 - val_precision: 0.3016 - val_recall: 0.3016 - val_f1_score: 0.4568 - 85ms/epoch - 85ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1804 - accuracy: 0.3135 - precision: 0.3135 - recall: 0.3135 - f1_score: 0.4742 - val_loss: 0.2283 - val_accuracy: 0.2937 - val_precision: 0.2937 - val_recall: 0.2937 - val_f1_score: 0.4540 - 83ms/epoch - 83ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1795 - accuracy: 0.3115 - precision: 0.3115 - recall: 0.3115 - f1_score: 0.4734 - val_loss: 0.1816 - val_accuracy: 0.3651 - val_precision: 0.3651 - val_recall: 0.3651 - val_f1_score: 0.4805 - 82ms/epoch - 82ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.3770 - precision: 0.3770 - recall: 0.3770 - f1_score: 0.4984 - val_loss: 0.1434 - val_accuracy: 0.8254 - val_precision: 0.8254 - val_recall: 0.8254 - val_f1_score: 0.7317 - 79ms/epoch - 79ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1449 - accuracy: 0.8155 - precision: 0.8155 - recall: 0.8155 - f1_score: 0.7224 - val_loss: 0.1291 - val_accuracy: 0.7698 - val_precision: 0.7698 - val_recall: 0.7698 - val_f1_score: 0.4082 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1544 - accuracy: 0.7718 - precision: 0.7718 - recall: 0.7718 - f1_score: 0.4162 - val_loss: 0.1261 - val_accuracy: 0.7540 - val_precision: 0.7540 - val_recall: 0.7540 - val_f1_score: 0.3404 - 79ms/epoch - 79ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1542 - accuracy: 0.7599 - precision: 0.7599 - recall: 0.7599 - f1_score: 0.3665 - val_loss: 0.1261 - val_accuracy: 0.8492 - val_precision: 0.8492 - val_recall: 0.8492 - val_f1_score: 0.6780 - 81ms/epoch - 81ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1423 - accuracy: 0.8413 - precision: 0.8413 - recall: 0.8413 - f1_score: 0.6721 - val_loss: 0.1324 - val_accuracy: 0.8492 - val_precision: 0.8492 - val_recall: 0.8492 - val_f1_score: 0.7595 - 83ms/epoch - 83ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1322 - accuracy: 0.8770 - precision: 0.8770 - recall: 0.8770 - f1_score: 0.8086 - val_loss: 0.1451 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.7115 - 83ms/epoch - 83ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1300 - accuracy: 0.7560 - precision: 0.7560 - recall: 0.7560 - f1_score: 0.7119 - val_loss: 0.1552 - val_accuracy: 0.6270 - val_precision: 0.6270 - val_recall: 0.6270 - val_f1_score: 0.6116 - 81ms/epoch - 81ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1311 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.6250 - val_loss: 0.1497 - val_accuracy: 0.6746 - val_precision: 0.6746 - val_recall: 0.6746 - val_f1_score: 0.6435 - 91ms/epoch - 91ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1261 - accuracy: 0.6806 - precision: 0.6806 - recall: 0.6806 - f1_score: 0.6582 - val_loss: 0.1299 - val_accuracy: 0.8175 - val_precision: 0.8175 - val_recall: 0.8175 - val_f1_score: 0.7629 - 83ms/epoch - 83ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1150 - accuracy: 0.8333 - precision: 0.8333 - recall: 0.8333 - f1_score: 0.7835 - val_loss: 0.1083 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7895 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1073 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - f1_score: 0.8562 - val_loss: 0.0961 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.7812 - 81ms/epoch - 81ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1071 - accuracy: 0.9067 - precision: 0.9067 - recall: 0.9067 - f1_score: 0.8374 - val_loss: 0.0912 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8125 - 87ms/epoch - 87ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1022 - accuracy: 0.9048 - precision: 0.9048 - recall: 0.9048 - f1_score: 0.8345 - val_loss: 0.0909 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8108 - 81ms/epoch - 81ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0921 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8590 - val_loss: 0.0976 - val_accuracy: 0.8651 - val_precision: 0.8651 - val_recall: 0.8651 - val_f1_score: 0.8000 - 85ms/epoch - 85ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0876 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - f1_score: 0.8400 - val_loss: 0.1021 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.8000 - 88ms/epoch - 88ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0865 - accuracy: 0.8532 - precision: 0.8532 - recall: 0.8532 - f1_score: 0.8032 - val_loss: 0.0917 - val_accuracy: 0.8810 - val_precision: 0.8810 - val_recall: 0.8810 - val_f1_score: 0.8235 - 82ms/epoch - 82ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0802 - accuracy: 0.8869 - precision: 0.8869 - recall: 0.8869 - f1_score: 0.8376 - val_loss: 0.0767 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571 - val_f1_score: 0.7692 - 81ms/epoch - 81ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0752 - accuracy: 0.9187 - precision: 0.9187 - recall: 0.9187 - f1_score: 0.8731 - val_loss: 0.0701 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_f1_score: 0.8169 - 81ms/epoch - 81ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0743 - accuracy: 0.9127 - precision: 0.9127 - recall: 0.9127 - f1_score: 0.8553 - val_loss: 0.0687 - val_accuracy: 0.8730 - val_precision: 0.8730 - val_recall: 0.8730 - val_f1_score: 0.7895 - 86ms/epoch - 86ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0686 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - f1_score: 0.8833 - val_loss: 0.0725 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8293 - 82ms/epoch - 82ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0649 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8743 - val_loss: 0.0749 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_f1_score: 0.8471 - 82ms/epoch - 82ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0637 - accuracy: 0.9067 - precision: 0.9067 - recall: 0.9067 - f1_score: 0.8638 - val_loss: 0.0679 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8333 - 81ms/epoch - 81ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0596 - accuracy: 0.9167 - precision: 0.9167 - recall: 0.9167 - f1_score: 0.8765 - val_loss: 0.0590 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_f1_score: 0.8267 - 81ms/epoch - 81ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0566 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8820 - val_loss: 0.0548 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8333 - 82ms/epoch - 82ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0556 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.8981 - val_loss: 0.0538 - val_accuracy: 0.9048 - val_precision: 0.9048 - val_recall: 0.9048 - val_f1_score: 0.8378 - 80ms/epoch - 80ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0523 - accuracy: 0.9345 - precision: 0.9345 - recall: 0.9345 - f1_score: 0.8959 - val_loss: 0.0562 - val_accuracy: 0.9127 - val_precision: 0.9127 - val_recall: 0.9127 - val_f1_score: 0.8608 - 85ms/epoch - 85ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0498 - accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - f1_score: 0.8862 - val_loss: 0.0576 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8780 - 87ms/epoch - 87ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0486 - accuracy: 0.9306 - precision: 0.9306 - recall: 0.9306 - f1_score: 0.8961 - val_loss: 0.0526 - val_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286 - val_f1_score: 0.8831 - 82ms/epoch - 82ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9345 - precision: 0.9345 - recall: 0.9345 - f1_score: 0.9009 - val_loss: 0.0467 - val_accuracy: 0.9206 - val_precision: 0.9206 - val_recall: 0.9206 - val_f1_score: 0.8684 - 80ms/epoch - 80ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0439 - accuracy: 0.9504 - precision: 0.9504 - recall: 0.9504 - f1_score: 0.9216 - val_loss: 0.0443 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444 - val_f1_score: 0.9041 - 169ms/epoch - 169ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0425 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9295 - val_loss: 0.0444 - val_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286 - val_f1_score: 0.8800 - 81ms/epoch - 81ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0397 - accuracy: 0.9583 - precision: 0.9583 - recall: 0.9583 - f1_score: 0.9338 - val_loss: 0.0463 - val_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286 - val_f1_score: 0.8861 - 82ms/epoch - 82ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0381 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - f1_score: 0.9202 - val_loss: 0.0453 - val_accuracy: 0.9365 - val_precision: 0.9365 - val_recall: 0.9365 - val_f1_score: 0.8974 - 84ms/epoch - 84ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0364 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - f1_score: 0.9259 - val_loss: 0.0413 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9211 - 81ms/epoch - 81ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0343 - accuracy: 0.9623 - precision: 0.9623 - recall: 0.9623 - f1_score: 0.9404 - val_loss: 0.0389 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9167 - 82ms/epoch - 82ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0330 - accuracy: 0.9702 - precision: 0.9702 - recall: 0.9702 - f1_score: 0.9518 - val_loss: 0.0385 - val_accuracy: 0.9603 - val_precision: 0.9603 - val_recall: 0.9603 - val_f1_score: 0.9333 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0310 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9494 - val_loss: 0.0396 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9211 - 90ms/epoch - 90ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0295 - accuracy: 0.9663 - precision: 0.9663 - recall: 0.9663 - f1_score: 0.9470 - val_loss: 0.0391 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9211 - 85ms/epoch - 85ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0282 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - f1_score: 0.9441 - val_loss: 0.0363 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9211 - 82ms/epoch - 82ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0264 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9560 - val_loss: 0.0342 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 82ms/epoch - 82ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0252 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - f1_score: 0.9618 - val_loss: 0.0336 - val_accuracy: 0.9603 - val_precision: 0.9603 - val_recall: 0.9603 - val_f1_score: 0.9333 - 81ms/epoch - 81ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0237 - accuracy: 0.9782 - precision: 0.9782 - recall: 0.9782 - f1_score: 0.9651 - val_loss: 0.0342 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9211 - 83ms/epoch - 83ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0224 - accuracy: 0.9742 - precision: 0.9742 - recall: 0.9742 - f1_score: 0.9592 - val_loss: 0.0337 - val_accuracy: 0.9603 - val_precision: 0.9603 - val_recall: 0.9603 - val_f1_score: 0.9351 - 80ms/epoch - 80ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0214 - accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - f1_score: 0.9562 - val_loss: 0.0316 - val_accuracy: 0.9603 - val_precision: 0.9603 - val_recall: 0.9603 - val_f1_score: 0.9333 - 83ms/epoch - 83ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0201 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - f1_score: 0.9714 - val_loss: 0.0304 - val_accuracy: 0.9524 - val_precision: 0.9524 - val_recall: 0.9524 - val_f1_score: 0.9189 - 86ms/epoch - 86ms/step

🔍 Resultados no Teste:
Loss: 0.0546
Accuracy: 0.9151
Precision: 0.9151
Recall: 0.9151
F1 Score: 0.8701
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
930 930 930
(901, 30) (901, 30) (901, 30)
(901, 90) (901, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 88ms/step
[[0.8982761  0.10172386]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 931 | Acuracia_1: 0.6 | Contagem Geral: 119.0 
Ordem Natural: 182.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_1: 0.6 
Precisao modelo Geral: 60.9457
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
931 931 931
(902, 30) (902, 30) (902, 30)
(902, 90) (902, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.83438796 0.16561197]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 932 | Acuracia_2: 0.1429 | Contagem Geral: 119.0 
Ordem Natural: 182.0
Entrada: 5.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_2: 0.1429 
Precisao modelo Geral: 60.8392
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
932 932 932
(903, 30) (903, 30) (903, 30)
(903, 90) (903, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89713854 0.10286146]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 933 | Acuracia_3: 0.0 | Contagem Geral: 119.0 
Ordem Natural: 183.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_3: 0.0 
Precisao modelo Geral: 60.9075
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
933 933 933
(904, 30) (904, 30) (904, 30)
(904, 90) (904, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9220675  0.07793252]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 934 | Acuracia_4: 0.75 | Contagem Geral: 119.0 
Ordem Natural: 183.0
Entrada: 6.87
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_4: 0.75 
Precisao modelo Geral: 60.8014
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
934 934 934
(905, 30) (905, 30) (905, 30)
(905, 90) (905, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9158799  0.08412007]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 935 | Acuracia_5: 0.3333 | Contagem Geral: 119.0 
Ordem Natural: 184.0
Entrada: 10.71
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.6957
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
935 935 935
(906, 30) (906, 30) (906, 30)
(906, 90) (906, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8842156  0.11578442]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 936 | Acuracia_6: 1.0 | Contagem Geral: 119.0 
Ordem Natural: 185.0
Entrada: 3.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.5903
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
936 936 936
(907, 30) (907, 30) (907, 30)
(907, 90) (907, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9175765  0.08242355]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 937 | Acuracia_7: 0.3333 | Contagem Geral: 119.0 
Ordem Natural: 186.0
Entrada: 12.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.4853
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
937 937 937
(908, 30) (908, 30) (908, 30)
(908, 90) (908, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96670824 0.03329169]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 938 | Acuracia_8: 0.6667 | Contagem Geral: 119.0 
Ordem Natural: 187.0
Entrada: 2.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.7731 | Acuracia_8: 0.6667 
Precisao modelo Geral: 60.5536
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
938 938 938
(909, 30) (909, 30) (909, 30)
(909, 90) (909, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.70927185 0.29072815]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 939 | Acuracia_9: 0.5 | Contagem Geral: 119.0 
Ordem Natural: 187.0
Entrada: 1.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_9: 0.4 
Precisao modelo Geral: 60.4491
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
939 939 939
(910, 30) (910, 30) (910, 30)
(910, 90) (910, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9192824  0.08071763]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 940 | Acuracia_10: 0.5 | Contagem Geral: 120.0 
Ordem Natural: 187.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_10: 0.5 
Precisao modelo Geral: 60.5172
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
940 940 940
(911, 30) (911, 30) (911, 30)
(911, 90) (911, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8556028  0.14439723]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 941 | Acuracia_11: 0.25 | Contagem Geral: 120.0 
Ordem Natural: 187.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_11: 0.25 
Precisao modelo Geral: 60.5852
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
941 941 941
(912, 30) (912, 30) (912, 30)
(912, 90) (912, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87466055 0.12533945]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 942 | Acuracia_12: 0.0 | Contagem Geral: 120.0 
Ordem Natural: 187.0
Entrada: 1.72
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_12: 0.0 
Precisao modelo Geral: 60.6529
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
942 942 942
(913, 30) (913, 30) (913, 30)
(913, 90) (913, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86458683 0.13541313]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 943 | Acuracia_13: 0.6 | Contagem Geral: 120.0 
Ordem Natural: 187.0
Entrada: 90.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_13: 0.6 
Precisao modelo Geral: 60.5489
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
943 943 943
(914, 30) (914, 30) (914, 30)
(914, 90) (914, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.95792043 0.04207955]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 944 | Acuracia_14: 0.0 | Contagem Geral: 120.0 
Ordem Natural: 188.0
Entrada: 6.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_14: 0.0 
Precisao modelo Geral: 60.4452
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
944 944 944
(915, 30) (915, 30) (915, 30)
(915, 90) (915, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9921108  0.00788918]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 945 | Acuracia_15: 0.0 | Contagem Geral: 120.0 
Ordem Natural: 189.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_15: 0.0 
Precisao modelo Geral: 60.5128
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
945 945 945
(916, 30) (916, 30) (916, 30)
(916, 90) (916, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.89594334 0.10405663]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 946 | Acuracia_16: 0.0 | Contagem Geral: 120.0 
Ordem Natural: 189.0
Entrada: 1.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5 | Acuracia_16: 0.0 
Precisao modelo Geral: 60.5802
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
946 946 946
(917, 30) (917, 30) (917, 30)
(917, 90) (917, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.63611084 0.36388916]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 947 | Acuracia_17: 0.4 | Contagem Geral: 120.0 
Ordem Natural: 189.0
Entrada: 1.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.2314 | Acuracia_17: 0.3333 
Precisao modelo Geral: 60.477
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
947 947 947
(918, 30) (918, 30) (918, 30)
(918, 90) (918, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.71148825 0.28851172]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 948 | Acuracia_18: 0.1667 | Contagem Geral: 121.0 
Ordem Natural: 189.0
Entrada: 1.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.9672 | Acuracia_18: 0.1429 
Precisao modelo Geral: 60.3741
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
948 948 948
(919, 30) (919, 30) (919, 30)
(919, 90) (919, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9766118  0.02338825]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 949 | Acuracia_19: 0.1667 | Contagem Geral: 122.0 
Ordem Natural: 189.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.9672 | Acuracia_19: 0.1667 
Precisao modelo Geral: 60.4414
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
949 949 949
(920, 30) (920, 30) (920, 30)
(920, 90) (920, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9631593  0.03684074]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 950 | Acuracia_20: 0.25 | Contagem Geral: 122.0 
Ordem Natural: 189.0
Entrada: 5.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.9672 | Acuracia_20: 0.25 
Precisao modelo Geral: 60.339
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
950 950 950
(921, 30) (921, 30) (921, 30)
(921, 90) (921, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.58882076 0.4111793 ]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 951 | Acuracia_21: 0.75 | Contagem Geral: 122.0 
Ordem Natural: 190.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_21: 0.6 
Precisao modelo Geral: 60.2369
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
951 951 951
(922, 30) (922, 30) (922, 30)
(922, 90) (922, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9454434  0.05455664]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 952 | Acuracia_22: 0.25 | Contagem Geral: 123.0 
Ordem Natural: 190.0
Entrada: 1.92
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_22: 0.25 
Precisao modelo Geral: 60.3041
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
952 952 952
(923, 30) (923, 30) (923, 30)
(923, 90) (923, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.90248746 0.09751257]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 953 | Acuracia_23: 0.75 | Contagem Geral: 123.0 
Ordem Natural: 190.0
Entrada: 3.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_23: 0.75 
Precisao modelo Geral: 60.2024
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
953 953 953
(924, 30) (924, 30) (924, 30)
(924, 90) (924, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8964639  0.10353613]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 954 | Acuracia_24: 0.1667 | Contagem Geral: 123.0 
Ordem Natural: 191.0
Entrada: 1.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_24: 0.1667 
Precisao modelo Geral: 60.2694
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
954 954 954
(925, 30) (925, 30) (925, 30)
(925, 90) (925, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9372064  0.06279358]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 955 | Acuracia_25: 0.0 | Contagem Geral: 123.0 
Ordem Natural: 191.0
Entrada: 3.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.1681
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
955 955 955
(926, 30) (926, 30) (926, 30)
(926, 90) (926, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.91016966 0.08983037]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 956 | Acuracia_26: 0.6667 | Contagem Geral: 123.0 
Ordem Natural: 192.0
Entrada: 1.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_26: 0.6667 
Precisao modelo Geral: 60.2349
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
956 956 956
(927, 30) (927, 30) (927, 30)
(927, 90) (927, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9714793  0.02852072]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 957 | Acuracia_27: 0.0 | Contagem Geral: 123.0 
Ordem Natural: 192.0
Entrada: 1.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.3015
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
957 957 957
(928, 30) (928, 30) (928, 30)
(928, 90) (928, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.9813184  0.01868164]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 958 | Acuracia_28: 0.0 | Contagem Geral: 123.0 
Ordem Natural: 192.0
Entrada: 9.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.2007
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
958 958 958
(929, 30) (929, 30) (929, 30)
(929, 90) (929, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90914303 0.09085698]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 959 | Acuracia_29: 0.0 | Contagem Geral: 123.0 
Ordem Natural: 193.0
Entrada: 45.99
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.7073 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.1002
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
959 959 959
(930, 30) (930, 30) (930, 30)
(930, 90) (930, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.5543273 0.4456727]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 960 | Acuracia_0: 0.6667 | Contagem Geral: 123.0 
Ordem Natural: 194.0
Entrada: 2.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4516 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
960 960 960
(931, 30) (931, 30) (931, 30)
(931, 90) (931, 30)
Matrix_30: [(931, 90), (931, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1977 - accuracy: 0.6712 - precision: 0.6712 - recall: 0.6712 - f1_score: 0.1320 - val_loss: 0.3638 - val_accuracy: 0.3206 - val_precision: 0.3206 - val_recall: 0.3206 - val_f1_score: 0.4855 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2771 - accuracy: 0.3058 - precision: 0.3058 - recall: 0.3058 - f1_score: 0.4683 - val_loss: 0.2155 - val_accuracy: 0.3206 - val_precision: 0.3206 - val_recall: 0.3206 - val_f1_score: 0.4855 - 82ms/epoch - 82ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1808 - accuracy: 0.3231 - precision: 0.3231 - recall: 0.3231 - f1_score: 0.4746 - val_loss: 0.1492 - val_accuracy: 0.6947 - val_precision: 0.6947 - val_recall: 0.6947 - val_f1_score: 0.2000 - 87ms/epoch - 87ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.7115 - precision: 0.7115 - recall: 0.7115 - f1_score: 0.1758 - val_loss: 0.1457 - val_accuracy: 0.6794 - val_precision: 0.6794 - val_recall: 0.6794 - val_f1_score: 0.0000e+00 - 84ms/epoch - 84ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1860 - accuracy: 0.6981 - precision: 0.6981 - recall: 0.6981 - f1_score: 0.0248 - val_loss: 0.1414 - val_accuracy: 0.6870 - val_precision: 0.6870 - val_recall: 0.6870 - val_f1_score: 0.0465 - 81ms/epoch - 81ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.7058 - precision: 0.7058 - recall: 0.7058 - f1_score: 0.0727 - val_loss: 0.1413 - val_accuracy: 0.7328 - val_precision: 0.7328 - val_recall: 0.7328 - val_f1_score: 0.3860 - 82ms/epoch - 82ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.7673 - precision: 0.7673 - recall: 0.7673 - f1_score: 0.4211 - val_loss: 0.1507 - val_accuracy: 0.7939 - val_precision: 0.7939 - val_recall: 0.7939 - val_f1_score: 0.6966 - 82ms/epoch - 82ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1467 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - f1_score: 0.7029 - val_loss: 0.1659 - val_accuracy: 0.6107 - val_precision: 0.6107 - val_recall: 0.6107 - val_f1_score: 0.6165 - 82ms/epoch - 82ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1478 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - f1_score: 0.6055 - val_loss: 0.1765 - val_accuracy: 0.4580 - val_precision: 0.4580 - val_recall: 0.4580 - val_f1_score: 0.5359 - 83ms/epoch - 83ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1507 - accuracy: 0.5077 - precision: 0.5077 - recall: 0.5077 - f1_score: 0.5540 - val_loss: 0.1751 - val_accuracy: 0.4733 - val_precision: 0.4733 - val_recall: 0.4733 - val_f1_score: 0.5430 - 85ms/epoch - 85ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1487 - accuracy: 0.5135 - precision: 0.5135 - recall: 0.5135 - f1_score: 0.5569 - val_loss: 0.1642 - val_accuracy: 0.5802 - val_precision: 0.5802 - val_recall: 0.5802 - val_f1_score: 0.5985 - 84ms/epoch - 84ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1425 - accuracy: 0.6231 - precision: 0.6231 - recall: 0.6231 - f1_score: 0.6172 - val_loss: 0.1500 - val_accuracy: 0.7710 - val_precision: 0.7710 - val_recall: 0.7710 - val_f1_score: 0.7222 - 88ms/epoch - 88ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1359 - accuracy: 0.7635 - precision: 0.7635 - recall: 0.7635 - f1_score: 0.7133 - val_loss: 0.1375 - val_accuracy: 0.8168 - val_precision: 0.8168 - val_recall: 0.8168 - val_f1_score: 0.7333 - 84ms/epoch - 84ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1318 - accuracy: 0.8558 - precision: 0.8558 - recall: 0.8558 - f1_score: 0.7887 - val_loss: 0.1289 - val_accuracy: 0.8473 - val_precision: 0.8473 - val_recall: 0.8473 - val_f1_score: 0.7619 - 83ms/epoch - 83ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1302 - accuracy: 0.8712 - precision: 0.8712 - recall: 0.8712 - f1_score: 0.7818 - val_loss: 0.1233 - val_accuracy: 0.8321 - val_precision: 0.8321 - val_recall: 0.8321 - val_f1_score: 0.7179 - 84ms/epoch - 84ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1290 - accuracy: 0.8442 - precision: 0.8442 - recall: 0.8442 - f1_score: 0.7117 - val_loss: 0.1195 - val_accuracy: 0.8321 - val_precision: 0.8321 - val_recall: 0.8321 - val_f1_score: 0.7179 - 82ms/epoch - 82ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1258 - accuracy: 0.8519 - precision: 0.8519 - recall: 0.8519 - f1_score: 0.7279 - val_loss: 0.1169 - val_accuracy: 0.8397 - val_precision: 0.8397 - val_recall: 0.8397 - val_f1_score: 0.7342 - 83ms/epoch - 83ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1201 - accuracy: 0.8731 - precision: 0.8731 - recall: 0.8731 - f1_score: 0.7785 - val_loss: 0.1159 - val_accuracy: 0.8397 - val_precision: 0.8397 - val_recall: 0.8397 - val_f1_score: 0.7586 - 83ms/epoch - 83ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1136 - accuracy: 0.8904 - precision: 0.8904 - recall: 0.8904 - f1_score: 0.8267 - val_loss: 0.1169 - val_accuracy: 0.8244 - val_precision: 0.8244 - val_recall: 0.8244 - val_f1_score: 0.7527 - 82ms/epoch - 82ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1083 - accuracy: 0.8692 - precision: 0.8692 - recall: 0.8692 - f1_score: 0.8101 - val_loss: 0.1175 - val_accuracy: 0.8321 - val_precision: 0.8321 - val_recall: 0.8321 - val_f1_score: 0.7708 - 82ms/epoch - 82ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1042 - accuracy: 0.8538 - precision: 0.8538 - recall: 0.8538 - f1_score: 0.7979 - val_loss: 0.1142 - val_accuracy: 0.8473 - val_precision: 0.8473 - val_recall: 0.8473 - val_f1_score: 0.7959 - 87ms/epoch - 87ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0996 - accuracy: 0.8500 - precision: 0.8500 - recall: 0.8500 - f1_score: 0.7947 - val_loss: 0.1058 - val_accuracy: 0.8244 - val_precision: 0.8244 - val_recall: 0.8244 - val_f1_score: 0.7579 - 102ms/epoch - 102ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0937 - accuracy: 0.8731 - precision: 0.8731 - recall: 0.8731 - f1_score: 0.8177 - val_loss: 0.0951 - val_accuracy: 0.8550 - val_precision: 0.8550 - val_recall: 0.8550 - val_f1_score: 0.7865 - 106ms/epoch - 106ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0884 - accuracy: 0.8923 - precision: 0.8923 - recall: 0.8923 - f1_score: 0.8363 - val_loss: 0.0869 - val_accuracy: 0.8550 - val_precision: 0.8550 - val_recall: 0.8550 - val_f1_score: 0.7654 - 84ms/epoch - 84ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0852 - accuracy: 0.9058 - precision: 0.9058 - recall: 0.9058 - f1_score: 0.8502 - val_loss: 0.0829 - val_accuracy: 0.8626 - val_precision: 0.8626 - val_recall: 0.8626 - val_f1_score: 0.7805 - 82ms/epoch - 82ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0806 - accuracy: 0.9096 - precision: 0.9096 - recall: 0.9096 - f1_score: 0.8571 - val_loss: 0.0829 - val_accuracy: 0.8702 - val_precision: 0.8702 - val_recall: 0.8702 - val_f1_score: 0.8090 - 83ms/epoch - 83ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0749 - accuracy: 0.9019 - precision: 0.9019 - recall: 0.9019 - f1_score: 0.8504 - val_loss: 0.0857 - val_accuracy: 0.8550 - val_precision: 0.8550 - val_recall: 0.8550 - val_f1_score: 0.8000 - 84ms/epoch - 84ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0716 - accuracy: 0.8904 - precision: 0.8904 - recall: 0.8904 - f1_score: 0.8385 - val_loss: 0.0834 - val_accuracy: 0.8626 - val_precision: 0.8626 - val_recall: 0.8626 - val_f1_score: 0.8085 - 83ms/epoch - 83ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0682 - accuracy: 0.8942 - precision: 0.8942 - recall: 0.8942 - f1_score: 0.8442 - val_loss: 0.0734 - val_accuracy: 0.8779 - val_precision: 0.8779 - val_recall: 0.8779 - val_f1_score: 0.8222 - 83ms/epoch - 83ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0634 - accuracy: 0.8981 - precision: 0.8981 - recall: 0.8981 - f1_score: 0.8455 - val_loss: 0.0655 - val_accuracy: 0.8931 - val_precision: 0.8931 - val_recall: 0.8931 - val_f1_score: 0.8333 - 84ms/epoch - 84ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0611 - accuracy: 0.9154 - precision: 0.9154 - recall: 0.9154 - f1_score: 0.8659 - val_loss: 0.0630 - val_accuracy: 0.9008 - val_precision: 0.9008 - val_recall: 0.9008 - val_f1_score: 0.8506 - 83ms/epoch - 83ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0578 - accuracy: 0.9212 - precision: 0.9212 - recall: 0.9212 - f1_score: 0.8746 - val_loss: 0.0651 - val_accuracy: 0.8931 - val_precision: 0.8931 - val_recall: 0.8931 - val_f1_score: 0.8444 - 84ms/epoch - 84ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0543 - accuracy: 0.9077 - precision: 0.9077 - recall: 0.9077 - f1_score: 0.8596 - val_loss: 0.0667 - val_accuracy: 0.8702 - val_precision: 0.8702 - val_recall: 0.8702 - val_f1_score: 0.8211 - 84ms/epoch - 84ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0525 - accuracy: 0.9077 - precision: 0.9077 - recall: 0.9077 - f1_score: 0.8629 - val_loss: 0.0597 - val_accuracy: 0.9008 - val_precision: 0.9008 - val_recall: 0.9008 - val_f1_score: 0.8539 - 86ms/epoch - 86ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0489 - accuracy: 0.9192 - precision: 0.9192 - recall: 0.9192 - f1_score: 0.8757 - val_loss: 0.0532 - val_accuracy: 0.9160 - val_precision: 0.9160 - val_recall: 0.9160 - val_f1_score: 0.8736 - 82ms/epoch - 82ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0470 - accuracy: 0.9346 - precision: 0.9346 - recall: 0.9346 - f1_score: 0.8951 - val_loss: 0.0513 - val_accuracy: 0.9160 - val_precision: 0.9160 - val_recall: 0.9160 - val_f1_score: 0.8736 - 85ms/epoch - 85ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0444 - accuracy: 0.9365 - precision: 0.9365 - recall: 0.9365 - f1_score: 0.8985 - val_loss: 0.0531 - val_accuracy: 0.8931 - val_precision: 0.8931 - val_recall: 0.8931 - val_f1_score: 0.8444 - 85ms/epoch - 85ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0418 - accuracy: 0.9423 - precision: 0.9423 - recall: 0.9423 - f1_score: 0.9102 - val_loss: 0.0533 - val_accuracy: 0.8855 - val_precision: 0.8855 - val_recall: 0.8855 - val_f1_score: 0.8352 - 82ms/epoch - 82ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0401 - accuracy: 0.9442 - precision: 0.9442 - recall: 0.9442 - f1_score: 0.9139 - val_loss: 0.0476 - val_accuracy: 0.9160 - val_precision: 0.9160 - val_recall: 0.9160 - val_f1_score: 0.8736 - 84ms/epoch - 84ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0373 - accuracy: 0.9462 - precision: 0.9462 - recall: 0.9462 - f1_score: 0.9157 - val_loss: 0.0435 - val_accuracy: 0.9389 - val_precision: 0.9389 - val_recall: 0.9389 - val_f1_score: 0.9048 - 81ms/epoch - 81ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0357 - accuracy: 0.9538 - precision: 0.9538 - recall: 0.9538 - f1_score: 0.9259 - val_loss: 0.0427 - val_accuracy: 0.9313 - val_precision: 0.9313 - val_recall: 0.9313 - val_f1_score: 0.8941 - 83ms/epoch - 83ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0333 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - f1_score: 0.9297 - val_loss: 0.0440 - val_accuracy: 0.9160 - val_precision: 0.9160 - val_recall: 0.9160 - val_f1_score: 0.8736 - 83ms/epoch - 83ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0315 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - f1_score: 0.9305 - val_loss: 0.0421 - val_accuracy: 0.9389 - val_precision: 0.9389 - val_recall: 0.9389 - val_f1_score: 0.9070 - 81ms/epoch - 81ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0296 - accuracy: 0.9577 - precision: 0.9577 - recall: 0.9577 - f1_score: 0.9333 - val_loss: 0.0378 - val_accuracy: 0.9313 - val_precision: 0.9313 - val_recall: 0.9313 - val_f1_score: 0.8916 - 82ms/epoch - 82ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0275 - accuracy: 0.9731 - precision: 0.9731 - recall: 0.9731 - f1_score: 0.9562 - val_loss: 0.0357 - val_accuracy: 0.9313 - val_precision: 0.9313 - val_recall: 0.9313 - val_f1_score: 0.8916 - 81ms/epoch - 81ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0261 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - f1_score: 0.9592 - val_loss: 0.0357 - val_accuracy: 0.9389 - val_precision: 0.9389 - val_recall: 0.9389 - val_f1_score: 0.9048 - 94ms/epoch - 94ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0241 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - f1_score: 0.9657 - val_loss: 0.0360 - val_accuracy: 0.9618 - val_precision: 0.9618 - val_recall: 0.9618 - val_f1_score: 0.9425 - 85ms/epoch - 85ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0230 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9808 - f1_score: 0.9691 - val_loss: 0.0333 - val_accuracy: 0.9618 - val_precision: 0.9618 - val_recall: 0.9618 - val_f1_score: 0.9412 - 81ms/epoch - 81ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0213 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9808 - f1_score: 0.9689 - val_loss: 0.0310 - val_accuracy: 0.9466 - val_precision: 0.9466 - val_recall: 0.9466 - val_f1_score: 0.9157 - 83ms/epoch - 83ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0202 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - f1_score: 0.9655 - val_loss: 0.0302 - val_accuracy: 0.9542 - val_precision: 0.9542 - val_recall: 0.9542 - val_f1_score: 0.9286 - 85ms/epoch - 85ms/step

🔍 Resultados no Teste:
Loss: 0.0578
Accuracy: 0.9143
Precision: 0.9143
Recall: 0.9143
F1 Score: 0.8681
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
960 960 960
(931, 30) (931, 30) (931, 30)
(931, 90) (931, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 88ms/step
[[0.7843272  0.21567276]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 961 | Acuracia_1: 0.6 | Contagem Geral: 124.0 
Ordem Natural: 194.0
Entrada: 2.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.2 | Acuracia_1: 0.5 
Precisao modelo Geral: 59.9002
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
961 961 961
(932, 30) (932, 30) (932, 30)
(932, 90) (932, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8206142  0.17938581]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 962 | Acuracia_2: 0.1429 | Contagem Geral: 125.0 
Ordem Natural: 194.0
Entrada: 4.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.2 | Acuracia_2: 0.1429 
Precisao modelo Geral: 59.8007
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
962 962 962
(933, 30) (933, 30) (933, 30)
(933, 90) (933, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.797049   0.20295106]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 963 | Acuracia_3: 0.0 | Contagem Geral: 125.0 
Ordem Natural: 195.0
Entrada: 13.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_3: 0.1667 
Precisao modelo Geral: 59.8673
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
963 963 963
(934, 30) (934, 30) (934, 30)
(934, 90) (934, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9386648  0.06133515]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 964 | Acuracia_4: 0.75 | Contagem Geral: 126.0 
Ordem Natural: 196.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_4: 0.75 
Precisao modelo Geral: 59.9338
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
964 964 964
(935, 30) (935, 30) (935, 30)
(935, 90) (935, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.86555344 0.1344466 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 965 | Acuracia_5: 0.3333 | Contagem Geral: 126.0 
Ordem Natural: 196.0
Entrada: 9.55
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_5: 0.3333 
Precisao modelo Geral: 59.8347
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
965 965 965
(936, 30) (936, 30) (936, 30)
(936, 90) (936, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9075618  0.09243824]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 966 | Acuracia_6: 1.0 | Contagem Geral: 126.0 
Ordem Natural: 197.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_6: 1.0 
Precisao modelo Geral: 59.901
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
966 966 966
(937, 30) (937, 30) (937, 30)
(937, 90) (937, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.9624417  0.03755829]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 967 | Acuracia_7: 0.3333 | Contagem Geral: 126.0 
Ordem Natural: 197.0
Entrada: 7.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_7: 0.3333 
Precisao modelo Geral: 59.8023
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
967 967 967
(938, 30) (938, 30) (938, 30)
(938, 90) (938, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.97282636 0.02717366]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 968 | Acuracia_8: 0.6667 | Contagem Geral: 126.0 
Ordem Natural: 198.0
Entrada: 3.82
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_8: 0.6667 
Precisao modelo Geral: 59.7039
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
968 968 968
(939, 30) (939, 30) (939, 30)
(939, 90) (939, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9201273  0.07987273]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 969 | Acuracia_9: 0.4 | Contagem Geral: 126.0 
Ordem Natural: 199.0
Entrada: 2.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_9: 0.4 
Precisao modelo Geral: 59.7701
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
969 969 969
(940, 30) (940, 30) (940, 30)
(940, 90) (940, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.82036036 0.17963962]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 970 | Acuracia_10: 0.5 | Contagem Geral: 126.0 
Ordem Natural: 199.0
Entrada: 5.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.746 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.6721
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
970 970 970
(941, 30) (941, 30) (941, 30)
(941, 90) (941, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.77166057 0.22833939]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 971 | Acuracia_11: 0.25 | Contagem Geral: 126.0 
Ordem Natural: 200.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_11: 0.2 
Precisao modelo Geral: 59.5745
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
971 971 971
(942, 30) (942, 30) (942, 30)
(942, 90) (942, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
[[0.85683435 0.1431656 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 972 | Acuracia_12: 0.0 | Contagem Geral: 127.0 
Ordem Natural: 200.0
Entrada: 3.56
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.4771
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
972 972 972
(943, 30) (943, 30) (943, 30)
(943, 90) (943, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.971913   0.02808704]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 973 | Acuracia_13: 0.6 | Contagem Geral: 127.0 
Ordem Natural: 201.0
Entrada: 3.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_13: 0.6 
Precisao modelo Geral: 59.3801
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
973 973 973
(944, 30) (944, 30) (944, 30)
(944, 90) (944, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.97256655 0.02743349]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 974 | Acuracia_14: 0.0 | Contagem Geral: 127.0 
Ordem Natural: 202.0
Entrada: 2.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_14: 0.0 
Precisao modelo Geral: 59.4463
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
974 974 974
(945, 30) (945, 30) (945, 30)
(945, 90) (945, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[[0.9571047  0.04289533]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 975 | Acuracia_15: 0.0 | Contagem Geral: 127.0 
Ordem Natural: 202.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_15: 0.0 
Precisao modelo Geral: 59.5122
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
975 975 975
(946, 30) (946, 30) (946, 30)
(946, 90) (946, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9491397  0.05086021]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 976 | Acuracia_16: 0.0 | Contagem Geral: 127.0 
Ordem Natural: 202.0
Entrada: 52.3
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.4156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
976 976 976
(947, 30) (947, 30) (947, 30)
(947, 90) (947, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9621244  0.03787562]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 977 | Acuracia_17: 0.3333 | Contagem Geral: 127.0 
Ordem Natural: 203.0
Entrada: 3.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_17: 0.3333 
Precisao modelo Geral: 59.3193
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
977 977 977
(948, 30) (948, 30) (948, 30)
(948, 90) (948, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8729966  0.12700333]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 978 | Acuracia_18: 0.1429 | Contagem Geral: 127.0 
Ordem Natural: 204.0
Entrada: 1.84
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_18: 0.1429 
Precisao modelo Geral: 59.3851
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
978 978 978
(949, 30) (949, 30) (949, 30)
(949, 90) (949, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8986342  0.10136579]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 979 | Acuracia_19: 0.1667 | Contagem Geral: 127.0 
Ordem Natural: 204.0
Entrada: 2.56
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_19: 0.1667 
Precisao modelo Geral: 59.4507
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
979 979 979
(950, 30) (950, 30) (950, 30)
(950, 90) (950, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 35ms/step
[[0.9448678  0.05513221]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 980 | Acuracia_20: 0.25 | Contagem Geral: 127.0 
Ordem Natural: 204.0
Entrada: 1.74
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4961 | Acuracia_20: 0.25 
Precisao modelo Geral: 59.5161
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
980 980 980
(951, 30) (951, 30) (951, 30)
(951, 90) (951, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 35ms/step
[[0.79363203 0.20636792]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 981 | Acuracia_21: 0.6 | Contagem Geral: 127.0 
Ordem Natural: 204.0
Entrada: 2.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_21: 0.5 
Precisao modelo Geral: 59.4203
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
981 981 981
(952, 30) (952, 30) (952, 30)
(952, 90) (952, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
[[0.93715346 0.06284647]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 982 | Acuracia_22: 0.25 | Contagem Geral: 128.0 
Ordem Natural: 204.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_22: 0.25 
Precisao modelo Geral: 59.4855
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
982 982 982
(953, 30) (953, 30) (953, 30)
(953, 90) (953, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
[[0.94454765 0.05545234]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 983 | Acuracia_23: 0.75 | Contagem Geral: 128.0 
Ordem Natural: 204.0
Entrada: 5.24
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_23: 0.75 
Precisao modelo Geral: 59.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
983 983 983
(954, 30) (954, 30) (954, 30)
(954, 90) (954, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 36ms/step
[[0.9428021  0.05719791]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 984 | Acuracia_24: 0.1667 | Contagem Geral: 128.0 
Ordem Natural: 205.0
Entrada: 1.42
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_24: 0.1667 
Precisao modelo Geral: 59.4551
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
984 984 984
(955, 30) (955, 30) (955, 30)
(955, 90) (955, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.96049017 0.03950978]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 985 | Acuracia_25: 0.0 | Contagem Geral: 128.0 
Ordem Natural: 205.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_25: 0.0 
Precisao modelo Geral: 59.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
985 985 985
(956, 30) (956, 30) (956, 30)
(956, 90) (956, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.7978407  0.20215933]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 986 | Acuracia_26: 0.6667 | Contagem Geral: 128.0 
Ordem Natural: 205.0
Entrada: 1.27
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0078 | Acuracia_26: 0.5 
Precisao modelo Geral: 59.4249
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
986 986 986
(957, 30) (957, 30) (957, 30)
(957, 90) (957, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.78548515 0.21451488]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 987 | Acuracia_27: 0.0 | Contagem Geral: 129.0 
Ordem Natural: 205.0
Entrada: 2.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_27: 0.0 
Precisao modelo Geral: 59.3301
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
987 987 987
(958, 30) (958, 30) (958, 30)
(958, 90) (958, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
[[0.96005046 0.03994953]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 988 | Acuracia_28: 0.0 | Contagem Geral: 130.0 
Ordem Natural: 205.0
Entrada: 1.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_28: 0.0 
Precisao modelo Geral: 59.3949
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
988 988 988
(959, 30) (959, 30) (959, 30)
(959, 90) (959, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9445848  0.05541523]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 989 | Acuracia_29: 0.0 | Contagem Geral: 130.0 
Ordem Natural: 205.0
Entrada: 1.57
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_29: 0.0 
Precisao modelo Geral: 59.4595
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
989 989 989
(960, 30) (960, 30) (960, 30)
(960, 90) (960, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8276266  0.17237335]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 990 | Acuracia_0: 0.5 | Contagem Geral: 130.0 
Ordem Natural: 205.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_30: 0.5 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
990 990 990
(961, 30) (961, 30) (961, 30)
(961, 90) (961, 30)
Matrix_30: [(961, 90), (961, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1898 - accuracy: 0.5456 - precision: 0.5456 - recall: 0.5456 - f1_score: 0.1867 - val_loss: 0.2274 - val_accuracy: 0.3481 - val_precision: 0.3481 - val_recall: 0.3481 - val_f1_score: 0.5165 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1930 - accuracy: 0.3073 - precision: 0.3073 - recall: 0.3073 - f1_score: 0.4609 - val_loss: 0.1777 - val_accuracy: 0.5185 - val_precision: 0.5185 - val_recall: 0.5185 - val_f1_score: 0.5638 - 86ms/epoch - 86ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.4953 - precision: 0.4953 - recall: 0.4953 - f1_score: 0.5117 - val_loss: 0.1485 - val_accuracy: 0.6963 - val_precision: 0.6963 - val_recall: 0.6963 - val_f1_score: 0.3051 - 81ms/epoch - 81ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.7449 - precision: 0.7449 - recall: 0.7449 - f1_score: 0.3507 - val_loss: 0.1411 - val_accuracy: 0.6815 - val_precision: 0.6815 - val_recall: 0.6815 - val_f1_score: 0.2182 - 83ms/epoch - 83ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.7356 - precision: 0.7356 - recall: 0.7356 - f1_score: 0.2447 - val_loss: 0.1383 - val_accuracy: 0.7704 - val_precision: 0.7704 - val_recall: 0.7704 - val_f1_score: 0.5753 - 83ms/epoch - 83ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1445 - accuracy: 0.8175 - precision: 0.8175 - recall: 0.8175 - f1_score: 0.6048 - val_loss: 0.1436 - val_accuracy: 0.8074 - val_precision: 0.8074 - val_recall: 0.8074 - val_f1_score: 0.7636 - 84ms/epoch - 84ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1365 - accuracy: 0.8287 - precision: 0.8287 - recall: 0.8287 - f1_score: 0.7592 - val_loss: 0.1497 - val_accuracy: 0.7037 - val_precision: 0.7037 - val_recall: 0.7037 - val_f1_score: 0.6923 - 80ms/epoch - 80ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1336 - accuracy: 0.7225 - precision: 0.7225 - recall: 0.7225 - f1_score: 0.6782 - val_loss: 0.1416 - val_accuracy: 0.7556 - val_precision: 0.7556 - val_recall: 0.7556 - val_f1_score: 0.7317 - 85ms/epoch - 85ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1260 - accuracy: 0.7709 - precision: 0.7709 - recall: 0.7709 - f1_score: 0.7198 - val_loss: 0.1225 - val_accuracy: 0.8444 - val_precision: 0.8444 - val_recall: 0.8444 - val_f1_score: 0.8037 - 82ms/epoch - 82ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1154 - accuracy: 0.8492 - precision: 0.8492 - recall: 0.8492 - f1_score: 0.7828 - val_loss: 0.1075 - val_accuracy: 0.8444 - val_precision: 0.8444 - val_recall: 0.8444 - val_f1_score: 0.7586 - 84ms/epoch - 84ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1103 - accuracy: 0.8696 - precision: 0.8696 - recall: 0.8696 - f1_score: 0.7771 - val_loss: 0.1004 - val_accuracy: 0.8370 - val_precision: 0.8370 - val_recall: 0.8370 - val_f1_score: 0.7442 - 85ms/epoch - 85ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1050 - accuracy: 0.8696 - precision: 0.8696 - recall: 0.8696 - f1_score: 0.7742 - val_loss: 0.0985 - val_accuracy: 0.8593 - val_precision: 0.8593 - val_recall: 0.8593 - val_f1_score: 0.8041 - 82ms/epoch - 82ms/step
Epoch 13/50
1/1 - 0s - loss: 0.0953 - accuracy: 0.8659 - precision: 0.8659 - recall: 0.8659 - f1_score: 0.7907 - val_loss: 0.1051 - val_accuracy: 0.8296 - val_precision: 0.8296 - val_recall: 0.8296 - val_f1_score: 0.7965 - 85ms/epoch - 85ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0916 - accuracy: 0.8492 - precision: 0.8492 - recall: 0.8492 - f1_score: 0.7907 - val_loss: 0.1015 - val_accuracy: 0.8296 - val_precision: 0.8296 - val_recall: 0.8296 - val_f1_score: 0.7965 - 86ms/epoch - 86ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0867 - accuracy: 0.8547 - precision: 0.8547 - recall: 0.8547 - f1_score: 0.7990 - val_loss: 0.0847 - val_accuracy: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_f1_score: 0.8200 - 81ms/epoch - 81ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0789 - accuracy: 0.8864 - precision: 0.8864 - recall: 0.8864 - f1_score: 0.8262 - val_loss: 0.0760 - val_accuracy: 0.8741 - val_precision: 0.8741 - val_recall: 0.8741 - val_f1_score: 0.8132 - 83ms/epoch - 83ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0777 - accuracy: 0.8883 - precision: 0.8883 - recall: 0.8883 - f1_score: 0.8125 - val_loss: 0.0736 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8387 - 80ms/epoch - 80ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0718 - accuracy: 0.8901 - precision: 0.8901 - recall: 0.8901 - f1_score: 0.8249 - val_loss: 0.0789 - val_accuracy: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_f1_score: 0.8302 - 94ms/epoch - 94ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0685 - accuracy: 0.8901 - precision: 0.8901 - recall: 0.8901 - f1_score: 0.8384 - val_loss: 0.0790 - val_accuracy: 0.8593 - val_precision: 0.8593 - val_recall: 0.8593 - val_f1_score: 0.8224 - 83ms/epoch - 83ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0667 - accuracy: 0.8827 - precision: 0.8827 - recall: 0.8827 - f1_score: 0.8293 - val_loss: 0.0672 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8485 - 85ms/epoch - 85ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0617 - accuracy: 0.8939 - precision: 0.8939 - recall: 0.8939 - f1_score: 0.8348 - val_loss: 0.0605 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8352 - 84ms/epoch - 84ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0610 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8537 - val_loss: 0.0588 - val_accuracy: 0.8963 - val_precision: 0.8963 - val_recall: 0.8963 - val_f1_score: 0.8511 - 84ms/epoch - 84ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0570 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - f1_score: 0.8563 - val_loss: 0.0620 - val_accuracy: 0.8963 - val_precision: 0.8963 - val_recall: 0.8963 - val_f1_score: 0.8627 - 90ms/epoch - 90ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0545 - accuracy: 0.9013 - precision: 0.9013 - recall: 0.9013 - f1_score: 0.8515 - val_loss: 0.0611 - val_accuracy: 0.9037 - val_precision: 0.9037 - val_recall: 0.9037 - val_f1_score: 0.8738 - 91ms/epoch - 91ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0528 - accuracy: 0.9032 - precision: 0.9032 - recall: 0.9032 - f1_score: 0.8556 - val_loss: 0.0529 - val_accuracy: 0.9111 - val_precision: 0.9111 - val_recall: 0.9111 - val_f1_score: 0.8723 - 80ms/epoch - 80ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0493 - accuracy: 0.9181 - precision: 0.9181 - recall: 0.9181 - f1_score: 0.8721 - val_loss: 0.0489 - val_accuracy: 0.9111 - val_precision: 0.9111 - val_recall: 0.9111 - val_f1_score: 0.8723 - 81ms/epoch - 81ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0484 - accuracy: 0.9255 - precision: 0.9255 - recall: 0.9255 - f1_score: 0.8773 - val_loss: 0.0479 - val_accuracy: 0.9111 - val_precision: 0.9111 - val_recall: 0.9111 - val_f1_score: 0.8723 - 84ms/epoch - 84ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0450 - accuracy: 0.9311 - precision: 0.9311 - recall: 0.9311 - f1_score: 0.8902 - val_loss: 0.0499 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9184 - 83ms/epoch - 83ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0434 - accuracy: 0.9274 - precision: 0.9274 - recall: 0.9274 - f1_score: 0.8883 - val_loss: 0.0471 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9184 - 84ms/epoch - 84ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0410 - accuracy: 0.9348 - precision: 0.9348 - recall: 0.9348 - f1_score: 0.8986 - val_loss: 0.0417 - val_accuracy: 0.9259 - val_precision: 0.9259 - val_recall: 0.9259 - val_f1_score: 0.8936 - 161ms/epoch - 161ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0387 - accuracy: 0.9479 - precision: 0.9479 - recall: 0.9479 - f1_score: 0.9152 - val_loss: 0.0395 - val_accuracy: 0.9407 - val_precision: 0.9407 - val_recall: 0.9407 - val_f1_score: 0.9130 - 103ms/epoch - 103ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0371 - accuracy: 0.9609 - precision: 0.9609 - recall: 0.9609 - f1_score: 0.9350 - val_loss: 0.0392 - val_accuracy: 0.9481 - val_precision: 0.9481 - val_recall: 0.9481 - val_f1_score: 0.9278 - 83ms/epoch - 83ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0345 - accuracy: 0.9572 - precision: 0.9572 - recall: 0.9572 - f1_score: 0.9313 - val_loss: 0.0396 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9091 - 92ms/epoch - 92ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0333 - accuracy: 0.9534 - precision: 0.9534 - recall: 0.9534 - f1_score: 0.9263 - val_loss: 0.0362 - val_accuracy: 0.9556 - val_precision: 0.9556 - val_recall: 0.9556 - val_f1_score: 0.9375 - 83ms/epoch - 83ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0309 - accuracy: 0.9683 - precision: 0.9683 - recall: 0.9683 - f1_score: 0.9486 - val_loss: 0.0336 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9565 - 84ms/epoch - 84ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0297 - accuracy: 0.9777 - precision: 0.9777 - recall: 0.9777 - f1_score: 0.9630 - val_loss: 0.0323 - val_accuracy: 0.9778 - val_precision: 0.9778 - val_recall: 0.9778 - val_f1_score: 0.9677 - 99ms/epoch - 99ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0279 - accuracy: 0.9814 - precision: 0.9814 - recall: 0.9814 - f1_score: 0.9691 - val_loss: 0.0322 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9574 - 105ms/epoch - 105ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0265 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - f1_score: 0.9662 - val_loss: 0.0312 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9574 - 83ms/epoch - 83ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0253 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - f1_score: 0.9725 - val_loss: 0.0290 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 80ms/epoch - 80ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0238 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - f1_score: 0.9721 - val_loss: 0.0280 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 81ms/epoch - 81ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0229 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9750 - val_loss: 0.0272 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 84ms/epoch - 84ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0215 - accuracy: 0.9888 - precision: 0.9888 - recall: 0.9888 - f1_score: 0.9815 - val_loss: 0.0270 - val_accuracy: 0.9778 - val_precision: 0.9778 - val_recall: 0.9778 - val_f1_score: 0.9684 - 85ms/epoch - 85ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0207 - accuracy: 0.9888 - precision: 0.9888 - recall: 0.9888 - f1_score: 0.9816 - val_loss: 0.0257 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9574 - 85ms/epoch - 85ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0195 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - f1_score: 0.9907 - val_loss: 0.0249 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 93ms/epoch - 93ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0187 - accuracy: 0.9907 - precision: 0.9907 - recall: 0.9907 - f1_score: 0.9844 - val_loss: 0.0243 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 81ms/epoch - 81ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0178 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - f1_score: 0.9876 - val_loss: 0.0238 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9574 - 85ms/epoch - 85ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0170 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - f1_score: 0.9877 - val_loss: 0.0233 - val_accuracy: 0.9704 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1_score: 0.9574 - 91ms/epoch - 91ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0162 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - f1_score: 0.9877 - val_loss: 0.0228 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 82ms/epoch - 82ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0154 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - f1_score: 0.9907 - val_loss: 0.0225 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 83ms/epoch - 83ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0148 - accuracy: 0.9963 - precision: 0.9963 - recall: 0.9963 - f1_score: 0.9938 - val_loss: 0.0219 - val_accuracy: 0.9630 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1_score: 0.9462 - 86ms/epoch - 86ms/step

🔍 Resultados no Teste:
Loss: 0.0474
Accuracy: 0.9204
Precision: 0.9204
Recall: 0.9204
F1 Score: 0.8796
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
990 990 990
(961, 30) (961, 30) (961, 30)
(961, 90) (961, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 86ms/step
[[0.79411954 0.20588042]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 991 | Acuracia_1: 0.5 | Contagem Geral: 130.0 
Ordem Natural: 205.0
Entrada: 2.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_1: 0.4286 
Precisao modelo Geral: 59.4295
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
991 991 991
(962, 30) (962, 30) (962, 30)
(962, 90) (962, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97760344 0.02239654]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 992 | Acuracia_2: 0.1429 | Contagem Geral: 131.0 
Ordem Natural: 205.0
Entrada: 3.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_2: 0.1429 
Precisao modelo Geral: 59.3354
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
992 992 992
(963, 30) (963, 30) (963, 30)
(963, 90) (963, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[[0.95323294 0.04676705]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 993 | Acuracia_3: 0.1667 | Contagem Geral: 131.0 
Ordem Natural: 206.0
Entrada: 6.68
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_3: 0.1667 
Precisao modelo Geral: 59.2417
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
993 993 993
(964, 30) (964, 30) (964, 30)
(964, 90) (964, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.91791934 0.08208062]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 994 | Acuracia_4: 0.75 | Contagem Geral: 131.0 
Ordem Natural: 207.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_4: 0.75 
Precisao modelo Geral: 59.306
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
994 994 994
(965, 30) (965, 30) (965, 30)
(965, 90) (965, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8619526  0.13804738]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 995 | Acuracia_5: 0.3333 | Contagem Geral: 131.0 
Ordem Natural: 207.0
Entrada: 3.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_5: 0.3333 
Precisao modelo Geral: 59.2126
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
995 995 995
(966, 30) (966, 30) (966, 30)
(966, 90) (966, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9592518  0.04074816]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 996 | Acuracia_6: 1.0 | Contagem Geral: 131.0 
Ordem Natural: 208.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_6: 1.0 
Precisao modelo Geral: 59.2767
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
996 996 996
(967, 30) (967, 30) (967, 30)
(967, 90) (967, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.969448   0.03055201]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 997 | Acuracia_7: 0.3333 | Contagem Geral: 131.0 
Ordem Natural: 208.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_7: 0.3333 
Precisao modelo Geral: 59.3407
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
997 997 997
(968, 30) (968, 30) (968, 30)
(968, 90) (968, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.91552025 0.08447978]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 998 | Acuracia_8: 0.6667 | Contagem Geral: 131.0 
Ordem Natural: 208.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_8: 0.6667 
Precisao modelo Geral: 59.2476
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
998 998 998
(969, 30) (969, 30) (969, 30)
(969, 90) (969, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.92549074 0.07450931]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 999 | Acuracia_9: 0.4 | Contagem Geral: 131.0 
Ordem Natural: 209.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_9: 0.4 
Precisao modelo Geral: 59.1549
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
999 999 999
(970, 30) (970, 30) (970, 30)
(970, 90) (970, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8651264  0.13487361]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1000 | Acuracia_10: 0.5 | Contagem Geral: 131.0 
Ordem Natural: 210.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.0625
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1000 1000 1000
(971, 30) (971, 30) (971, 30)
(971, 90) (971, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.82195276 0.17804724]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1001 | Acuracia_11: 0.2 | Contagem Geral: 131.0 
Ordem Natural: 211.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_11: 0.2 
Precisao modelo Geral: 59.1264
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1001 1001 1001
(972, 30) (972, 30) (972, 30)
(972, 90) (972, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9399231  0.06007693]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1002 | Acuracia_12: 0.0 | Contagem Geral: 131.0 
Ordem Natural: 211.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1002 1002 1002
(973, 30) (973, 30) (973, 30)
(973, 90) (973, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.95011103 0.04988896]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1003 | Acuracia_13: 0.6 | Contagem Geral: 131.0 
Ordem Natural: 211.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5344 | Acuracia_13: 0.6 
Precisao modelo Geral: 59.2535
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1003 1003 1003
(974, 30) (974, 30) (974, 30)
(974, 90) (974, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.7473582 0.2526418]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1004 | Acuracia_14: 0.0 | Contagem Geral: 131.0 
Ordem Natural: 211.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_14: 0.25 
Precisao modelo Geral: 59.3168
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1004 1004 1004
(975, 30) (975, 30) (975, 30)
(975, 90) (975, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8838971  0.11610293]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1005 | Acuracia_15: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 212.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_15: 0.0 
Precisao modelo Geral: 59.3798
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1005 1005 1005
(976, 30) (976, 30) (976, 30)
(976, 90) (976, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97507805 0.024922  ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1006 | Acuracia_16: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 212.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.4427
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1006 1006 1006
(977, 30) (977, 30) (977, 30)
(977, 90) (977, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9710297  0.02897028]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1007 | Acuracia_17: 0.3333 | Contagem Geral: 132.0 
Ordem Natural: 212.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_17: 0.3333 
Precisao modelo Geral: 59.3509
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1007 1007 1007
(978, 30) (978, 30) (978, 30)
(978, 90) (978, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9537454  0.04625452]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1008 | Acuracia_18: 0.1429 | Contagem Geral: 132.0 
Ordem Natural: 213.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_18: 0.1429 
Precisao modelo Geral: 59.2593
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1008 1008 1008
(979, 30) (979, 30) (979, 30)
(979, 90) (979, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87891555 0.1210845 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1009 | Acuracia_19: 0.1667 | Contagem Geral: 132.0 
Ordem Natural: 214.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_19: 0.1667 
Precisao modelo Geral: 59.322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1009 1009 1009
(980, 30) (980, 30) (980, 30)
(980, 90) (980, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.87459534 0.12540461]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1010 | Acuracia_20: 0.25 | Contagem Geral: 132.0 
Ordem Natural: 214.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_20: 0.25 
Precisao modelo Geral: 59.2308
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1010 1010 1010
(981, 30) (981, 30) (981, 30)
(981, 90) (981, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8906092  0.10939075]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1011 | Acuracia_21: 0.5 | Contagem Geral: 132.0 
Ordem Natural: 215.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_21: 0.5 
Precisao modelo Geral: 59.2934
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1011 1011 1011
(982, 30) (982, 30) (982, 30)
(982, 90) (982, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.982736   0.01726403]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1012 | Acuracia_22: 0.25 | Contagem Geral: 132.0 
Ordem Natural: 215.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_22: 0.25 
Precisao modelo Geral: 59.3558
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1012 1012 1012
(983, 30) (983, 30) (983, 30)
(983, 90) (983, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9873963  0.01260374]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1013 | Acuracia_23: 0.75 | Contagem Geral: 132.0 
Ordem Natural: 215.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_23: 0.75 
Precisao modelo Geral: 59.2649
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1013 1013 1013
(984, 30) (984, 30) (984, 30)
(984, 90) (984, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96060634 0.0393937 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1014 | Acuracia_24: 0.1667 | Contagem Geral: 132.0 
Ordem Natural: 216.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_24: 0.1667 
Precisao modelo Geral: 59.1743
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1014 1014 1014
(985, 30) (985, 30) (985, 30)
(985, 90) (985, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.93929785 0.06070211]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1015 | Acuracia_25: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 217.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_25: 0.0 
Precisao modelo Geral: 59.084
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1015 1015 1015
(986, 30) (986, 30) (986, 30)
(986, 90) (986, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.97542566 0.02457434]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1016 | Acuracia_26: 0.5 | Contagem Geral: 132.0 
Ordem Natural: 218.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_26: 0.5 
Precisao modelo Geral: 58.9939
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1016 1016 1016
(987, 30) (987, 30) (987, 30)
(987, 90) (987, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9828203  0.01717977]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1017 | Acuracia_27: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 219.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_27: 0.0 
Precisao modelo Geral: 59.0563
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1017 1017 1017
(988, 30) (988, 30) (988, 30)
(988, 90) (988, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9791789  0.02082106]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1018 | Acuracia_28: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 219.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_28: 0.0 
Precisao modelo Geral: 58.9666
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1018 1018 1018
(989, 30) (989, 30) (989, 30)
(989, 90) (989, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.9676536 0.0323465]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1019 | Acuracia_29: 0.0 | Contagem Geral: 132.0 
Ordem Natural: 220.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_29: 0.0 
Precisao modelo Geral: 59.0288
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1019 1019 1019
(990, 30) (990, 30) (990, 30)
(990, 90) (990, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8688743  0.13112561]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1020 | Acuracia_0: 0.5 | Contagem Geral: 132.0 
Ordem Natural: 220.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_30: 0.5 
Precisao modelo Geral: 59.0909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
1020 1020 1020
(991, 30) (991, 30) (991, 30)
(991, 90) (991, 30)
Matrix_30: [(991, 90), (991, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.3088 - accuracy: 0.3087 - precision: 0.3087 - recall: 0.3087 - f1_score: 0.4717 - val_loss: 0.2315 - val_accuracy: 0.6835 - val_precision: 0.6835 - val_recall: 0.6835 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.3139 - accuracy: 0.6913 - precision: 0.6913 - recall: 0.6913 - f1_score: 0.0000e+00 - val_loss: 0.1833 - val_accuracy: 0.6619 - val_precision: 0.6619 - val_recall: 0.6619 - val_f1_score: 0.0000e+00 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2236 - accuracy: 0.6787 - precision: 0.6787 - recall: 0.6787 - f1_score: 0.0532 - val_loss: 0.1852 - val_accuracy: 0.4245 - val_precision: 0.4245 - val_recall: 0.4245 - val_f1_score: 0.2727 - 76ms/epoch - 76ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1786 - accuracy: 0.4819 - precision: 0.4819 - recall: 0.4819 - f1_score: 0.3462 - val_loss: 0.2135 - val_accuracy: 0.3309 - val_precision: 0.3309 - val_recall: 0.3309 - val_f1_score: 0.4804 - 75ms/epoch - 75ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1810 - accuracy: 0.3285 - precision: 0.3285 - recall: 0.3285 - f1_score: 0.4701 - val_loss: 0.2183 - val_accuracy: 0.3237 - val_precision: 0.3237 - val_recall: 0.3237 - val_f1_score: 0.4835 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.3213 - precision: 0.3213 - recall: 0.3213 - f1_score: 0.4749 - val_loss: 0.2000 - val_accuracy: 0.3597 - val_precision: 0.3597 - val_recall: 0.3597 - val_f1_score: 0.4972 - 75ms/epoch - 75ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1734 - accuracy: 0.3466 - precision: 0.3466 - recall: 0.3466 - f1_score: 0.4784 - val_loss: 0.1747 - val_accuracy: 0.4964 - val_precision: 0.4964 - val_recall: 0.4964 - val_f1_score: 0.5000 - 75ms/epoch - 75ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.5144 - precision: 0.5144 - recall: 0.5144 - f1_score: 0.5239 - val_loss: 0.1558 - val_accuracy: 0.6835 - val_precision: 0.6835 - val_recall: 0.6835 - val_f1_score: 0.4359 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1619 - accuracy: 0.6859 - precision: 0.6859 - recall: 0.6859 - f1_score: 0.5323 - val_loss: 0.1477 - val_accuracy: 0.7194 - val_precision: 0.7194 - val_recall: 0.7194 - val_f1_score: 0.2642 - 75ms/epoch - 75ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.7274 - precision: 0.7274 - recall: 0.7274 - f1_score: 0.3837 - val_loss: 0.1450 - val_accuracy: 0.7194 - val_precision: 0.7194 - val_recall: 0.7194 - val_f1_score: 0.2642 - 72ms/epoch - 72ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.7292 - precision: 0.7292 - recall: 0.7292 - f1_score: 0.3243 - val_loss: 0.1440 - val_accuracy: 0.7266 - val_precision: 0.7266 - val_recall: 0.7266 - val_f1_score: 0.3448 - 75ms/epoch - 75ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1602 - accuracy: 0.7455 - precision: 0.7455 - recall: 0.7455 - f1_score: 0.4639 - val_loss: 0.1464 - val_accuracy: 0.7410 - val_precision: 0.7410 - val_recall: 0.7410 - val_f1_score: 0.5500 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.7437 - precision: 0.7437 - recall: 0.7437 - f1_score: 0.5989 - val_loss: 0.1536 - val_accuracy: 0.7122 - val_precision: 0.7122 - val_recall: 0.7122 - val_f1_score: 0.6000 - 76ms/epoch - 76ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1500 - accuracy: 0.6949 - precision: 0.6949 - recall: 0.6949 - f1_score: 0.6236 - val_loss: 0.1624 - val_accuracy: 0.6043 - val_precision: 0.6043 - val_recall: 0.6043 - val_f1_score: 0.5669 - 78ms/epoch - 78ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1499 - accuracy: 0.6065 - precision: 0.6065 - recall: 0.6065 - f1_score: 0.5918 - val_loss: 0.1673 - val_accuracy: 0.5540 - val_precision: 0.5540 - val_recall: 0.5540 - val_f1_score: 0.5571 - 77ms/epoch - 77ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1499 - accuracy: 0.5433 - precision: 0.5433 - recall: 0.5433 - f1_score: 0.5615 - val_loss: 0.1647 - val_accuracy: 0.5612 - val_precision: 0.5612 - val_recall: 0.5612 - val_f1_score: 0.5612 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1472 - accuracy: 0.5650 - precision: 0.5650 - recall: 0.5650 - f1_score: 0.5750 - val_loss: 0.1554 - val_accuracy: 0.6619 - val_precision: 0.6619 - val_recall: 0.6619 - val_f1_score: 0.6116 - 75ms/epoch - 75ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1420 - accuracy: 0.6480 - precision: 0.6480 - recall: 0.6480 - f1_score: 0.6243 - val_loss: 0.1433 - val_accuracy: 0.7338 - val_precision: 0.7338 - val_recall: 0.7338 - val_f1_score: 0.6337 - 76ms/epoch - 76ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1365 - accuracy: 0.7581 - precision: 0.7581 - recall: 0.7581 - f1_score: 0.6955 - val_loss: 0.1329 - val_accuracy: 0.7842 - val_precision: 0.7842 - val_recall: 0.7842 - val_f1_score: 0.6667 - 74ms/epoch - 74ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1329 - accuracy: 0.8159 - precision: 0.8159 - recall: 0.8159 - f1_score: 0.7330 - val_loss: 0.1260 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7160 - 78ms/epoch - 78ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1308 - accuracy: 0.8339 - precision: 0.8339 - recall: 0.8339 - f1_score: 0.7326 - val_loss: 0.1219 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7273 - 80ms/epoch - 80ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1277 - accuracy: 0.8412 - precision: 0.8412 - recall: 0.8412 - f1_score: 0.7381 - val_loss: 0.1196 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7250 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1226 - accuracy: 0.8448 - precision: 0.8448 - recall: 0.8448 - f1_score: 0.7571 - val_loss: 0.1197 - val_accuracy: 0.7986 - val_precision: 0.7986 - val_recall: 0.7986 - val_f1_score: 0.6889 - 74ms/epoch - 74ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1172 - accuracy: 0.8375 - precision: 0.8375 - recall: 0.8375 - f1_score: 0.7644 - val_loss: 0.1227 - val_accuracy: 0.7914 - val_precision: 0.7914 - val_recall: 0.7914 - val_f1_score: 0.7129 - 76ms/epoch - 76ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1138 - accuracy: 0.8213 - precision: 0.8213 - recall: 0.8213 - f1_score: 0.7579 - val_loss: 0.1244 - val_accuracy: 0.7842 - val_precision: 0.7842 - val_recall: 0.7842 - val_f1_score: 0.7115 - 76ms/epoch - 76ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1113 - accuracy: 0.8177 - precision: 0.8177 - recall: 0.8177 - f1_score: 0.7624 - val_loss: 0.1200 - val_accuracy: 0.7986 - val_precision: 0.7986 - val_recall: 0.7986 - val_f1_score: 0.7255 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1072 - accuracy: 0.8267 - precision: 0.8267 - recall: 0.8267 - f1_score: 0.7714 - val_loss: 0.1108 - val_accuracy: 0.8129 - val_precision: 0.8129 - val_recall: 0.8129 - val_f1_score: 0.7347 - 83ms/epoch - 83ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1019 - accuracy: 0.8412 - precision: 0.8412 - recall: 0.8412 - f1_score: 0.7789 - val_loss: 0.1022 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7586 - 77ms/epoch - 77ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0980 - accuracy: 0.8592 - precision: 0.8592 - recall: 0.8592 - f1_score: 0.7914 - val_loss: 0.0971 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7381 - 78ms/epoch - 78ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0956 - accuracy: 0.8755 - precision: 0.8755 - recall: 0.8755 - f1_score: 0.8078 - val_loss: 0.0943 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7529 - 72ms/epoch - 72ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0919 - accuracy: 0.8755 - precision: 0.8755 - recall: 0.8755 - f1_score: 0.8078 - val_loss: 0.0934 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7586 - 75ms/epoch - 75ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0874 - accuracy: 0.8646 - precision: 0.8646 - recall: 0.8646 - f1_score: 0.7978 - val_loss: 0.0946 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7742 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0846 - accuracy: 0.8700 - precision: 0.8700 - recall: 0.8700 - f1_score: 0.8154 - val_loss: 0.0942 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7742 - 81ms/epoch - 81ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0822 - accuracy: 0.8700 - precision: 0.8700 - recall: 0.8700 - f1_score: 0.8163 - val_loss: 0.0889 - val_accuracy: 0.8633 - val_precision: 0.8633 - val_recall: 0.8633 - val_f1_score: 0.7912 - 78ms/epoch - 78ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0785 - accuracy: 0.8736 - precision: 0.8736 - recall: 0.8736 - f1_score: 0.8196 - val_loss: 0.0827 - val_accuracy: 0.8705 - val_precision: 0.8705 - val_recall: 0.8705 - val_f1_score: 0.7955 - 76ms/epoch - 76ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0754 - accuracy: 0.8773 - precision: 0.8773 - recall: 0.8773 - f1_score: 0.8182 - val_loss: 0.0790 - val_accuracy: 0.8561 - val_precision: 0.8561 - val_recall: 0.8561 - val_f1_score: 0.7561 - 75ms/epoch - 75ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0735 - accuracy: 0.8935 - precision: 0.8935 - recall: 0.8935 - f1_score: 0.8338 - val_loss: 0.0772 - val_accuracy: 0.8633 - val_precision: 0.8633 - val_recall: 0.8633 - val_f1_score: 0.7711 - 73ms/epoch - 73ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0708 - accuracy: 0.8953 - precision: 0.8953 - recall: 0.8953 - f1_score: 0.8371 - val_loss: 0.0771 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8090 - 77ms/epoch - 77ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0679 - accuracy: 0.8953 - precision: 0.8953 - recall: 0.8953 - f1_score: 0.8441 - val_loss: 0.0781 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8132 - 73ms/epoch - 73ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0662 - accuracy: 0.8845 - precision: 0.8845 - recall: 0.8845 - f1_score: 0.8342 - val_loss: 0.0764 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8132 - 74ms/epoch - 74ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0641 - accuracy: 0.8863 - precision: 0.8863 - recall: 0.8863 - f1_score: 0.8364 - val_loss: 0.0721 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8090 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0614 - accuracy: 0.9007 - precision: 0.9007 - recall: 0.9007 - f1_score: 0.8518 - val_loss: 0.0692 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849 - val_f1_score: 0.8140 - 76ms/epoch - 76ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0598 - accuracy: 0.9061 - precision: 0.9061 - recall: 0.9061 - f1_score: 0.8547 - val_loss: 0.0676 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8000 - 79ms/epoch - 79ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0578 - accuracy: 0.9079 - precision: 0.9079 - recall: 0.9079 - f1_score: 0.8571 - val_loss: 0.0670 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8315 - 77ms/epoch - 77ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0555 - accuracy: 0.9152 - precision: 0.9152 - recall: 0.9152 - f1_score: 0.8712 - val_loss: 0.0669 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8352 - 80ms/epoch - 80ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0540 - accuracy: 0.9061 - precision: 0.9061 - recall: 0.9061 - f1_score: 0.8624 - val_loss: 0.0650 - val_accuracy: 0.8993 - val_precision: 0.8993 - val_recall: 0.8993 - val_f1_score: 0.8444 - 76ms/epoch - 76ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0520 - accuracy: 0.9134 - precision: 0.9134 - recall: 0.9134 - f1_score: 0.8710 - val_loss: 0.0621 - val_accuracy: 0.8993 - val_precision: 0.8993 - val_recall: 0.8993 - val_f1_score: 0.8409 - 77ms/epoch - 77ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0499 - accuracy: 0.9278 - precision: 0.9278 - recall: 0.9278 - f1_score: 0.8889 - val_loss: 0.0603 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849 - val_f1_score: 0.8140 - 75ms/epoch - 75ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0484 - accuracy: 0.9332 - precision: 0.9332 - recall: 0.9332 - f1_score: 0.8940 - val_loss: 0.0590 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849 - val_f1_score: 0.8140 - 81ms/epoch - 81ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0464 - accuracy: 0.9332 - precision: 0.9332 - recall: 0.9332 - f1_score: 0.8952 - val_loss: 0.0583 - val_accuracy: 0.9065 - val_precision: 0.9065 - val_recall: 0.9065 - val_f1_score: 0.8539 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0742
Accuracy: 0.8725
Precision: 0.8725
Recall: 0.8725
F1 Score: 0.8224
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
1020 1020 1020
(991, 30) (991, 30) (991, 30)
(991, 90) (991, 30)
Matrix_30: [(991, 90), (991, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.4164 - accuracy: 0.6913 - precision: 0.6913 - recall: 0.6913 - f1_score: 0.0000e+00 - val_loss: 0.1744 - val_accuracy: 0.5324 - val_precision: 0.5324 - val_recall: 0.5324 - val_f1_score: 0.5113 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.5505 - precision: 0.5505 - recall: 0.5505 - f1_score: 0.5311 - val_loss: 0.2655 - val_accuracy: 0.3165 - val_precision: 0.3165 - val_recall: 0.3165 - val_f1_score: 0.4809 - 77ms/epoch - 77ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2062 - accuracy: 0.3087 - precision: 0.3087 - recall: 0.3087 - f1_score: 0.4717 - val_loss: 0.2603 - val_accuracy: 0.3165 - val_precision: 0.3165 - val_recall: 0.3165 - val_f1_score: 0.4809 - 74ms/epoch - 74ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2048 - accuracy: 0.3087 - precision: 0.3087 - recall: 0.3087 - f1_score: 0.4717 - val_loss: 0.2207 - val_accuracy: 0.3165 - val_precision: 0.3165 - val_recall: 0.3165 - val_f1_score: 0.4809 - 76ms/epoch - 76ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1872 - accuracy: 0.3123 - precision: 0.3123 - recall: 0.3123 - f1_score: 0.4730 - val_loss: 0.1838 - val_accuracy: 0.3957 - val_precision: 0.3957 - val_recall: 0.3957 - val_f1_score: 0.4400 - 79ms/epoch - 79ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1761 - accuracy: 0.3899 - precision: 0.3899 - recall: 0.3899 - f1_score: 0.4422 - val_loss: 0.1641 - val_accuracy: 0.6619 - val_precision: 0.6619 - val_recall: 0.6619 - val_f1_score: 0.2769 - 79ms/epoch - 79ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1796 - accuracy: 0.6245 - precision: 0.6245 - recall: 0.6245 - f1_score: 0.2828 - val_loss: 0.1585 - val_accuracy: 0.6763 - val_precision: 0.6763 - val_recall: 0.6763 - val_f1_score: 0.0816 - 78ms/epoch - 78ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1837 - accuracy: 0.6751 - precision: 0.6751 - recall: 0.6751 - f1_score: 0.1346 - val_loss: 0.1558 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_f1_score: 0.1569 - 76ms/epoch - 76ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1778 - accuracy: 0.6841 - precision: 0.6841 - recall: 0.6841 - f1_score: 0.2081 - val_loss: 0.1556 - val_accuracy: 0.7338 - val_precision: 0.7338 - val_recall: 0.7338 - val_f1_score: 0.4478 - 74ms/epoch - 74ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6841 - precision: 0.6841 - recall: 0.6841 - f1_score: 0.4068 - val_loss: 0.1608 - val_accuracy: 0.6835 - val_precision: 0.6835 - val_recall: 0.6835 - val_f1_score: 0.5769 - 74ms/epoch - 74ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1622 - accuracy: 0.6534 - precision: 0.6534 - recall: 0.6534 - f1_score: 0.5556 - val_loss: 0.1669 - val_accuracy: 0.5899 - val_precision: 0.5899 - val_recall: 0.5899 - val_f1_score: 0.5899 - 77ms/epoch - 77ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.5722 - precision: 0.5722 - recall: 0.5722 - f1_score: 0.5683 - val_loss: 0.1685 - val_accuracy: 0.5396 - val_precision: 0.5396 - val_recall: 0.5396 - val_f1_score: 0.5676 - 76ms/epoch - 76ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1587 - accuracy: 0.5433 - precision: 0.5433 - recall: 0.5433 - f1_score: 0.5615 - val_loss: 0.1647 - val_accuracy: 0.6043 - val_precision: 0.6043 - val_recall: 0.6043 - val_f1_score: 0.5985 - 76ms/epoch - 76ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.5848 - precision: 0.5848 - recall: 0.5848 - f1_score: 0.5803 - val_loss: 0.1566 - val_accuracy: 0.6763 - val_precision: 0.6763 - val_recall: 0.6763 - val_f1_score: 0.6281 - 75ms/epoch - 75ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1516 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.6024 - val_loss: 0.1470 - val_accuracy: 0.7698 - val_precision: 0.7698 - val_recall: 0.7698 - val_f1_score: 0.6735 - 75ms/epoch - 75ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1482 - accuracy: 0.7617 - precision: 0.7617 - recall: 0.7617 - f1_score: 0.6580 - val_loss: 0.1393 - val_accuracy: 0.8058 - val_precision: 0.8058 - val_recall: 0.8058 - val_f1_score: 0.6582 - 75ms/epoch - 75ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1466 - accuracy: 0.7942 - precision: 0.7942 - recall: 0.7942 - f1_score: 0.6607 - val_loss: 0.1350 - val_accuracy: 0.7914 - val_precision: 0.7914 - val_recall: 0.7914 - val_f1_score: 0.6027 - 77ms/epoch - 77ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1453 - accuracy: 0.8051 - precision: 0.8051 - recall: 0.8051 - f1_score: 0.6582 - val_loss: 0.1332 - val_accuracy: 0.8129 - val_precision: 0.8129 - val_recall: 0.8129 - val_f1_score: 0.6579 - 72ms/epoch - 72ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1422 - accuracy: 0.8159 - precision: 0.8159 - recall: 0.8159 - f1_score: 0.6852 - val_loss: 0.1337 - val_accuracy: 0.8201 - val_precision: 0.8201 - val_recall: 0.8201 - val_f1_score: 0.7126 - 76ms/epoch - 76ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1385 - accuracy: 0.8069 - precision: 0.8069 - recall: 0.8069 - f1_score: 0.6934 - val_loss: 0.1358 - val_accuracy: 0.7842 - val_precision: 0.7842 - val_recall: 0.7842 - val_f1_score: 0.6875 - 80ms/epoch - 80ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1357 - accuracy: 0.8123 - precision: 0.8123 - recall: 0.8123 - f1_score: 0.7333 - val_loss: 0.1373 - val_accuracy: 0.7626 - val_precision: 0.7626 - val_recall: 0.7626 - val_f1_score: 0.6857 - 77ms/epoch - 77ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1335 - accuracy: 0.8051 - precision: 0.8051 - recall: 0.8051 - f1_score: 0.7366 - val_loss: 0.1360 - val_accuracy: 0.7698 - val_precision: 0.7698 - val_recall: 0.7698 - val_f1_score: 0.6981 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1310 - accuracy: 0.7996 - precision: 0.7996 - recall: 0.7996 - f1_score: 0.7325 - val_loss: 0.1315 - val_accuracy: 0.7842 - val_precision: 0.7842 - val_recall: 0.7842 - val_f1_score: 0.7059 - 74ms/epoch - 74ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1277 - accuracy: 0.8213 - precision: 0.8213 - recall: 0.8213 - f1_score: 0.7543 - val_loss: 0.1251 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7556 - 74ms/epoch - 74ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1244 - accuracy: 0.8448 - precision: 0.8448 - recall: 0.8448 - f1_score: 0.7725 - val_loss: 0.1195 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7294 - 76ms/epoch - 76ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1219 - accuracy: 0.8700 - precision: 0.8700 - recall: 0.8700 - f1_score: 0.7989 - val_loss: 0.1159 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7229 - 76ms/epoch - 76ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1197 - accuracy: 0.8664 - precision: 0.8664 - recall: 0.8664 - f1_score: 0.7886 - val_loss: 0.1140 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7381 - 78ms/epoch - 78ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1166 - accuracy: 0.8718 - precision: 0.8718 - recall: 0.8718 - f1_score: 0.8000 - val_loss: 0.1136 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7500 - 75ms/epoch - 75ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1130 - accuracy: 0.8592 - precision: 0.8592 - recall: 0.8592 - f1_score: 0.7903 - val_loss: 0.1144 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7527 - 76ms/epoch - 76ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1101 - accuracy: 0.8484 - precision: 0.8484 - recall: 0.8484 - f1_score: 0.7824 - val_loss: 0.1140 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7629 - 82ms/epoch - 82ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1074 - accuracy: 0.8466 - precision: 0.8466 - recall: 0.8466 - f1_score: 0.7859 - val_loss: 0.1106 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7660 - 76ms/epoch - 76ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1042 - accuracy: 0.8484 - precision: 0.8484 - recall: 0.8484 - f1_score: 0.7879 - val_loss: 0.1050 - val_accuracy: 0.8561 - val_precision: 0.8561 - val_recall: 0.8561 - val_f1_score: 0.7826 - 77ms/epoch - 77ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1007 - accuracy: 0.8628 - precision: 0.8628 - recall: 0.8628 - f1_score: 0.8000 - val_loss: 0.0998 - val_accuracy: 0.8417 - val_precision: 0.8417 - val_recall: 0.8417 - val_f1_score: 0.7500 - 78ms/epoch - 78ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0978 - accuracy: 0.8755 - precision: 0.8755 - recall: 0.8755 - f1_score: 0.8110 - val_loss: 0.0965 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7586 - 78ms/epoch - 78ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0951 - accuracy: 0.8791 - precision: 0.8791 - recall: 0.8791 - f1_score: 0.8144 - val_loss: 0.0950 - val_accuracy: 0.8489 - val_precision: 0.8489 - val_recall: 0.8489 - val_f1_score: 0.7640 - 77ms/epoch - 77ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0917 - accuracy: 0.8791 - precision: 0.8791 - recall: 0.8791 - f1_score: 0.8184 - val_loss: 0.0948 - val_accuracy: 0.8633 - val_precision: 0.8633 - val_recall: 0.8633 - val_f1_score: 0.7957 - 74ms/epoch - 74ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0885 - accuracy: 0.8791 - precision: 0.8791 - recall: 0.8791 - f1_score: 0.8241 - val_loss: 0.0938 - val_accuracy: 0.8561 - val_precision: 0.8561 - val_recall: 0.8561 - val_f1_score: 0.7872 - 75ms/epoch - 75ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0858 - accuracy: 0.8755 - precision: 0.8755 - recall: 0.8755 - f1_score: 0.8208 - val_loss: 0.0900 - val_accuracy: 0.8633 - val_precision: 0.8633 - val_recall: 0.8633 - val_f1_score: 0.7957 - 74ms/epoch - 74ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0826 - accuracy: 0.8809 - precision: 0.8809 - recall: 0.8809 - f1_score: 0.8272 - val_loss: 0.0848 - val_accuracy: 0.8705 - val_precision: 0.8705 - val_recall: 0.8705 - val_f1_score: 0.8043 - 76ms/epoch - 76ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0795 - accuracy: 0.8971 - precision: 0.8971 - recall: 0.8971 - f1_score: 0.8455 - val_loss: 0.0810 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849 - val_f1_score: 0.8182 - 78ms/epoch - 78ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0769 - accuracy: 0.9025 - precision: 0.9025 - recall: 0.9025 - f1_score: 0.8500 - val_loss: 0.0789 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8315 - 76ms/epoch - 76ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0740 - accuracy: 0.8989 - precision: 0.8989 - recall: 0.8989 - f1_score: 0.8462 - val_loss: 0.0781 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8132 - 85ms/epoch - 85ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0713 - accuracy: 0.8989 - precision: 0.8989 - recall: 0.8989 - f1_score: 0.8486 - val_loss: 0.0771 - val_accuracy: 0.8777 - val_precision: 0.8777 - val_recall: 0.8777 - val_f1_score: 0.8172 - 77ms/epoch - 77ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0690 - accuracy: 0.8953 - precision: 0.8953 - recall: 0.8953 - f1_score: 0.8449 - val_loss: 0.0740 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8352 - 78ms/epoch - 78ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0664 - accuracy: 0.9025 - precision: 0.9025 - recall: 0.9025 - f1_score: 0.8541 - val_loss: 0.0705 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8315 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0640 - accuracy: 0.9116 - precision: 0.9116 - recall: 0.9116 - f1_score: 0.8635 - val_loss: 0.0682 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849 - val_f1_score: 0.8140 - 78ms/epoch - 78ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0620 - accuracy: 0.9116 - precision: 0.9116 - recall: 0.9116 - f1_score: 0.8627 - val_loss: 0.0669 - val_accuracy: 0.9065 - val_precision: 0.9065 - val_recall: 0.9065 - val_f1_score: 0.8539 - 78ms/epoch - 78ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0596 - accuracy: 0.9170 - precision: 0.9170 - recall: 0.9170 - f1_score: 0.8729 - val_loss: 0.0662 - val_accuracy: 0.9065 - val_precision: 0.9065 - val_recall: 0.9065 - val_f1_score: 0.8539 - 77ms/epoch - 77ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0577 - accuracy: 0.9170 - precision: 0.9170 - recall: 0.9170 - f1_score: 0.8757 - val_loss: 0.0642 - val_accuracy: 0.9065 - val_precision: 0.9065 - val_recall: 0.9065 - val_f1_score: 0.8539 - 80ms/epoch - 80ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0556 - accuracy: 0.9242 - precision: 0.9242 - recall: 0.9242 - f1_score: 0.8846 - val_loss: 0.0616 - val_accuracy: 0.9065 - val_precision: 0.9065 - val_recall: 0.9065 - val_f1_score: 0.8471 - 94ms/epoch - 94ms/step

🔍 Resultados no Teste:
Loss: 0.0792
Accuracy: 0.8725
Precision: 0.8725
Recall: 0.8725
F1 Score: 0.8190
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
Carregando dados ...
1020 1020 1020
(991, 30) (991, 30) (991, 30)
(991, 90) (991, 30)
Matrix_30: [(991, 90), (991, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2173 - accuracy: 0.2978 - precision: 0.2978 - recall: 0.2978 - f1_score: 0.4403 - val_loss: 0.1636 - val_accuracy: 0.6835 - val_precision: 0.6835 - val_recall: 0.6835 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2221 - accuracy: 0.6877 - precision: 0.6877 - recall: 0.6877 - f1_score: 0.0114 - val_loss: 0.1525 - val_accuracy: 0.7050 - val_precision: 0.7050 - val_recall: 0.7050 - val_f1_score: 0.1277 - 74ms/epoch - 74ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1853 - accuracy: 0.6805 - precision: 0.6805 - recall: 0.6805 - f1_score: 0.0328 - val_loss: 0.1574 - val_accuracy: 0.7266 - val_precision: 0.7266 - val_recall: 0.7266 - val_f1_score: 0.5682 - 79ms/epoch - 79ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.6877 - precision: 0.6877 - recall: 0.6877 - f1_score: 0.5260 - val_loss: 0.1738 - val_accuracy: 0.4604 - val_precision: 0.4604 - val_recall: 0.4604 - val_f1_score: 0.5399 - 74ms/epoch - 74ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.4783 - precision: 0.4783 - recall: 0.4783 - f1_score: 0.5331 - val_loss: 0.1695 - val_accuracy: 0.4820 - val_precision: 0.4820 - val_recall: 0.4820 - val_f1_score: 0.5500 - 75ms/epoch - 75ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1518 - accuracy: 0.5217 - precision: 0.5217 - recall: 0.5217 - f1_score: 0.5591 - val_loss: 0.1483 - val_accuracy: 0.7554 - val_precision: 0.7554 - val_recall: 0.7554 - val_f1_score: 0.7018 - 76ms/epoch - 76ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1415 - accuracy: 0.7292 - precision: 0.7292 - recall: 0.7292 - f1_score: 0.6795 - val_loss: 0.1310 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8193 - 75ms/epoch - 75ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1358 - accuracy: 0.8718 - precision: 0.8718 - recall: 0.8718 - f1_score: 0.7855 - val_loss: 0.1233 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921 - val_f1_score: 0.8101 - 75ms/epoch - 75ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1297 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8123 - val_loss: 0.1229 - val_accuracy: 0.8633 - val_precision: 0.8633 - val_recall: 0.8633 - val_f1_score: 0.7912 - 76ms/epoch - 76ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1211 - accuracy: 0.8899 - precision: 0.8899 - recall: 0.8899 - f1_score: 0.8262 - val_loss: 0.1276 - val_accuracy: 0.8201 - val_precision: 0.8201 - val_recall: 0.8201 - val_f1_score: 0.7788 - 77ms/epoch - 77ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1156 - accuracy: 0.8357 - precision: 0.8357 - recall: 0.8357 - f1_score: 0.7818 - val_loss: 0.1215 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_f1_score: 0.7928 - 77ms/epoch - 77ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1088 - accuracy: 0.8484 - precision: 0.8484 - recall: 0.8484 - f1_score: 0.7961 - val_loss: 0.1045 - val_accuracy: 0.9281 - val_precision: 0.9281 - val_recall: 0.9281 - val_f1_score: 0.8837 - 78ms/epoch - 78ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1001 - accuracy: 0.9170 - precision: 0.9170 - recall: 0.9170 - f1_score: 0.8678 - val_loss: 0.0922 - val_accuracy: 0.9281 - val_precision: 0.9281 - val_recall: 0.9281 - val_f1_score: 0.8750 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.0944 - accuracy: 0.9332 - precision: 0.9332 - recall: 0.9332 - f1_score: 0.8869 - val_loss: 0.0865 - val_accuracy: 0.9281 - val_precision: 0.9281 - val_recall: 0.9281 - val_f1_score: 0.8750 - 74ms/epoch - 74ms/step
Epoch 15/50
1/1 - 0s - loss: 0.0867 - accuracy: 0.9440 - precision: 0.9440 - recall: 0.9440 - f1_score: 0.9063 - val_loss: 0.0867 - val_accuracy: 0.9353 - val_precision: 0.9353 - val_recall: 0.9353 - val_f1_score: 0.8989 - 76ms/epoch - 76ms/step
Epoch 16/50
1/1 - 0s - loss: 0.0793 - accuracy: 0.9278 - precision: 0.9278 - recall: 0.9278 - f1_score: 0.8870 - val_loss: 0.0852 - val_accuracy: 0.9424 - val_precision: 0.9424 - val_recall: 0.9424 - val_f1_score: 0.9130 - 78ms/epoch - 78ms/step
Epoch 17/50
1/1 - 0s - loss: 0.0739 - accuracy: 0.9170 - precision: 0.9170 - recall: 0.9170 - f1_score: 0.8750 - val_loss: 0.0730 - val_accuracy: 0.9496 - val_precision: 0.9496 - val_recall: 0.9496 - val_f1_score: 0.9195 - 76ms/epoch - 76ms/step
Epoch 18/50
1/1 - 0s - loss: 0.0666 - accuracy: 0.9477 - precision: 0.9477 - recall: 0.9477 - f1_score: 0.9155 - val_loss: 0.0634 - val_accuracy: 0.9353 - val_precision: 0.9353 - val_recall: 0.9353 - val_f1_score: 0.8889 - 77ms/epoch - 77ms/step
Epoch 19/50
1/1 - 0s - loss: 0.0620 - accuracy: 0.9513 - precision: 0.9513 - recall: 0.9513 - f1_score: 0.9184 - val_loss: 0.0598 - val_accuracy: 0.9568 - val_precision: 0.9568 - val_recall: 0.9568 - val_f1_score: 0.9302 - 73ms/epoch - 73ms/step
Epoch 20/50
1/1 - 0s - loss: 0.0562 - accuracy: 0.9549 - precision: 0.9549 - recall: 0.9549 - f1_score: 0.9254 - val_loss: 0.0608 - val_accuracy: 0.9568 - val_precision: 0.9568 - val_recall: 0.9568 - val_f1_score: 0.9333 - 76ms/epoch - 76ms/step
Epoch 21/50
1/1 - 0s - loss: 0.0518 - accuracy: 0.9585 - precision: 0.9585 - recall: 0.9585 - f1_score: 0.9341 - val_loss: 0.0574 - val_accuracy: 0.9568 - val_precision: 0.9568 - val_recall: 0.9568 - val_f1_score: 0.9333 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.0479 - accuracy: 0.9567 - precision: 0.9567 - recall: 0.9567 - f1_score: 0.9314 - val_loss: 0.0498 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 23/50
1/1 - 0s - loss: 0.0440 - accuracy: 0.9675 - precision: 0.9675 - recall: 0.9675 - f1_score: 0.9467 - val_loss: 0.0468 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1_score: 0.9425 - 77ms/epoch - 77ms/step
Epoch 24/50
1/1 - 0s - loss: 0.0412 - accuracy: 0.9711 - precision: 0.9711 - recall: 0.9711 - f1_score: 0.9524 - val_loss: 0.0473 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 79ms/epoch - 79ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0376 - accuracy: 0.9729 - precision: 0.9729 - recall: 0.9729 - f1_score: 0.9563 - val_loss: 0.0476 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1_score: 0.9438 - 71ms/epoch - 71ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0356 - accuracy: 0.9621 - precision: 0.9621 - recall: 0.9621 - f1_score: 0.9402 - val_loss: 0.0428 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 75ms/epoch - 75ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0326 - accuracy: 0.9783 - precision: 0.9783 - recall: 0.9783 - f1_score: 0.9647 - val_loss: 0.0406 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0309 - accuracy: 0.9801 - precision: 0.9801 - recall: 0.9801 - f1_score: 0.9674 - val_loss: 0.0403 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 78ms/epoch - 78ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0283 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9838 - f1_score: 0.9736 - val_loss: 0.0410 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1_score: 0.9438 - 81ms/epoch - 81ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0269 - accuracy: 0.9801 - precision: 0.9801 - recall: 0.9801 - f1_score: 0.9681 - val_loss: 0.0381 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 79ms/epoch - 79ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0247 - accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - f1_score: 0.9795 - val_loss: 0.0363 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0234 - accuracy: 0.9910 - precision: 0.9910 - recall: 0.9910 - f1_score: 0.9853 - val_loss: 0.0357 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 79ms/epoch - 79ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0216 - accuracy: 0.9910 - precision: 0.9910 - recall: 0.9910 - f1_score: 0.9853 - val_loss: 0.0361 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0205 - accuracy: 0.9892 - precision: 0.9892 - recall: 0.9892 - f1_score: 0.9824 - val_loss: 0.0344 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 78ms/epoch - 78ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0189 - accuracy: 0.9892 - precision: 0.9892 - recall: 0.9892 - f1_score: 0.9824 - val_loss: 0.0332 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 75ms/epoch - 75ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0179 - accuracy: 0.9928 - precision: 0.9928 - recall: 0.9928 - f1_score: 0.9882 - val_loss: 0.0325 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 85ms/epoch - 85ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0166 - accuracy: 0.9928 - precision: 0.9928 - recall: 0.9928 - f1_score: 0.9882 - val_loss: 0.0324 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 77ms/epoch - 77ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0157 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9912 - val_loss: 0.0314 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 78ms/epoch - 78ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0146 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9912 - val_loss: 0.0308 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 77ms/epoch - 77ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0138 - accuracy: 0.9946 - precision: 0.9946 - recall: 0.9946 - f1_score: 0.9912 - val_loss: 0.0303 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 87ms/epoch - 87ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0129 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - f1_score: 0.9941 - val_loss: 0.0298 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 80ms/epoch - 80ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0121 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - f1_score: 0.9941 - val_loss: 0.0293 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 79ms/epoch - 79ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0113 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0292 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 78ms/epoch - 78ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0107 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - f1_score: 0.9941 - val_loss: 0.0290 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0100 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0283 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0095 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0089 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0284 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1_score: 0.9425 - 75ms/epoch - 75ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0085 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0285 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1_score: 0.9425 - 77ms/epoch - 77ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0080 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0076 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1_score: 0.9971 - val_loss: 0.0276 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_f1_score: 0.9545 - 76ms/epoch - 76ms/step

🔍 Resultados no Teste:
Loss: 0.0366
Accuracy: 0.9430
Precision: 0.9430
Recall: 0.9430
F1 Score: 0.9194
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
1020 1020 1020
(991, 30) (991, 30) (991, 30)
(991, 90) (991, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 97ms/step
[[0.8744835  0.12551653]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1021 | Acuracia_1: 0.4286 | Contagem Geral: 132.0 
Ordem Natural: 220.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_1: 0.4286 
Precisao modelo Geral: 59.1528
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1021 1021 1021
(992, 30) (992, 30) (992, 30)
(992, 90) (992, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9849281  0.01507186]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1022 | Acuracia_2: 0.1429 | Contagem Geral: 132.0 
Ordem Natural: 220.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_2: 0.1429 
Precisao modelo Geral: 59.0634
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1022 1022 1022
(993, 30) (993, 30) (993, 30)
(993, 90) (993, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.99005336 0.00994664]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1023 | Acuracia_3: 0.1667 | Contagem Geral: 132.0 
Ordem Natural: 221.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_3: 0.1667 
Precisao modelo Geral: 59.1252
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1023 1023 1023
(994, 30) (994, 30) (994, 30)
(994, 90) (994, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9876073  0.01239267]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1024 | Acuracia_4: 0.75 | Contagem Geral: 132.0 
Ordem Natural: 221.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_4: 0.75 
Precisao modelo Geral: 59.1867
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1024 1024 1024
(995, 30) (995, 30) (995, 30)
(995, 90) (995, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9753294  0.02467059]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1025 | Acuracia_5: 0.3333 | Contagem Geral: 132.0 
Ordem Natural: 221.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0606 | Acuracia_5: 0.3333 
Precisao modelo Geral: 59.2481
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1025 1025 1025
(996, 30) (996, 30) (996, 30)
(996, 90) (996, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.74864435 0.25135565]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1026 | Acuracia_6: 1.0 | Contagem Geral: 132.0 
Ordem Natural: 221.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_6: 1.0 
Precisao modelo Geral: 59.3093
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1026 1026 1026
(997, 30) (997, 30) (997, 30)
(997, 90) (997, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.8224395 0.1775605]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1027 | Acuracia_7: 0.3333 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_7: 0.3333 
Precisao modelo Geral: 59.3703
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1027 1027 1027
(998, 30) (998, 30) (998, 30)
(998, 90) (998, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9677526  0.03224739]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1028 | Acuracia_8: 0.6667 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_8: 0.6667 
Precisao modelo Geral: 59.4311
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1028 1028 1028
(999, 30) (999, 30) (999, 30)
(999, 90) (999, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.95890224 0.04109778]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1029 | Acuracia_9: 0.4 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_9: 0.4 
Precisao modelo Geral: 59.4918
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1029 1029 1029
(1000, 30) (1000, 30) (1000, 30)
(1000, 90) (1000, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9897351  0.01026485]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1030 | Acuracia_10: 0.5 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_10: 0.5 
Precisao modelo Geral: 59.5522
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1030 1030 1030
(1001, 30) (1001, 30) (1001, 30)
(1001, 90) (1001, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9887285  0.01127152]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1031 | Acuracia_11: 0.2 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_11: 0.2 
Precisao modelo Geral: 59.6125
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1031 1031 1031
(1002, 30) (1002, 30) (1002, 30)
(1002, 90) (1002, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9074095 0.0925905]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1032 | Acuracia_12: 0.0 | Contagem Geral: 133.0 
Ordem Natural: 222.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_12: 0.0 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1032 1032 1032
(1003, 30) (1003, 30) (1003, 30)
(1003, 90) (1003, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.96921724 0.03078273]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1033 | Acuracia_13: 0.6 | Contagem Geral: 133.0 
Ordem Natural: 223.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_13: 0.6 
Precisao modelo Geral: 59.584
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1033 1033 1033
(1004, 30) (1004, 30) (1004, 30)
(1004, 90) (1004, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9882081  0.01179191]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1034 | Acuracia_14: 0.25 | Contagem Geral: 133.0 
Ordem Natural: 223.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_14: 0.25 
Precisao modelo Geral: 59.4955
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1034 1034 1034
(1005, 30) (1005, 30) (1005, 30)
(1005, 90) (1005, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.96736366 0.03263637]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1035 | Acuracia_15: 0.0 | Contagem Geral: 133.0 
Ordem Natural: 224.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_15: 0.0 
Precisao modelo Geral: 59.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1035 1035 1035
(1006, 30) (1006, 30) (1006, 30)
(1006, 90) (1006, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9544114 0.0455886]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1036 | Acuracia_16: 0.0 | Contagem Geral: 133.0 
Ordem Natural: 224.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_16: 0.0 
Precisao modelo Geral: 59.4675
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1036 1036 1036
(1007, 30) (1007, 30) (1007, 30)
(1007, 90) (1007, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.88536626 0.1146337 ]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1037 | Acuracia_17: 0.3333 | Contagem Geral: 133.0 
Ordem Natural: 225.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_17: 0.3333 
Precisao modelo Geral: 59.5273
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1037 1037 1037
(1008, 30) (1008, 30) (1008, 30)
(1008, 90) (1008, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.90872985 0.09127013]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1038 | Acuracia_18: 0.1429 | Contagem Geral: 133.0 
Ordem Natural: 225.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_18: 0.1429 
Precisao modelo Geral: 59.587
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1038 1038 1038
(1009, 30) (1009, 30) (1009, 30)
(1009, 90) (1009, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98028445 0.01971549]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1039 | Acuracia_19: 0.1667 | Contagem Geral: 133.0 
Ordem Natural: 225.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_19: 0.1667 
Precisao modelo Geral: 59.6465
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1039 1039 1039
(1010, 30) (1010, 30) (1010, 30)
(1010, 90) (1010, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.98224545 0.01775451]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1040 | Acuracia_20: 0.25 | Contagem Geral: 133.0 
Ordem Natural: 225.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.5789 | Acuracia_20: 0.25 
Precisao modelo Geral: 59.7059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1040 1040 1040
(1011, 30) (1011, 30) (1011, 30)
(1011, 90) (1011, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.797424   0.20257597]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1041 | Acuracia_21: 0.5 | Contagem Geral: 133.0 
Ordem Natural: 225.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.0896 | Acuracia_21: 0.5714 
Precisao modelo Geral: 59.7651
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1041 1041 1041
(1012, 30) (1012, 30) (1012, 30)
(1012, 90) (1012, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.6644364  0.33556363]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1042 | Acuracia_22: 0.25 | Contagem Geral: 134.0 
Ordem Natural: 226.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.5926 | Acuracia_22: 0.4 
Precisao modelo Geral: 59.824
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1042 1042 1042
(1013, 30) (1013, 30) (1013, 30)
(1013, 90) (1013, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.6865446 0.3134554]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1043 | Acuracia_23: 0.75 | Contagem Geral: 135.0 
Ordem Natural: 227.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_23: 0.8 
Precisao modelo Geral: 59.8829
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1043 1043 1043
(1014, 30) (1014, 30) (1014, 30)
(1014, 90) (1014, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.94814664 0.05185331]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1044 | Acuracia_24: 0.1667 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_24: 0.1667 
Precisao modelo Geral: 59.9415
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1044 1044 1044
(1015, 30) (1015, 30) (1015, 30)
(1015, 90) (1015, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.9752305  0.02476952]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1045 | Acuracia_25: 0.0 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_25: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1045 1045 1045
(1016, 30) (1016, 30) (1016, 30)
(1016, 90) (1016, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9622064 0.0377936]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1046 | Acuracia_26: 0.5 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_26: 0.5 
Precisao modelo Geral: 60.0583
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1046 1046 1046
(1017, 30) (1017, 30) (1017, 30)
(1017, 90) (1017, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9848038  0.01519615]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1047 | Acuracia_27: 0.0 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_27: 0.0 
Precisao modelo Geral: 60.1164
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1047 1047 1047
(1018, 30) (1018, 30) (1018, 30)
(1018, 90) (1018, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.96825635 0.03174364]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1048 | Acuracia_28: 0.0 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_28: 0.0 
Precisao modelo Geral: 60.1744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1048 1048 1048
(1019, 30) (1019, 30) (1019, 30)
(1019, 90) (1019, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[[0.88260025 0.11739976]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1049 | Acuracia_29: 0.0 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_29: 0.0 
Precisao modelo Geral: 60.2322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1049 1049 1049
(1020, 30) (1020, 30) (1020, 30)
(1020, 90) (1020, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8650958  0.13490422]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1050 | Acuracia_0: 0.5 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.0882 | Acuracia_30: 0.5 
Precisao modelo Geral: 60.2899
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
1050 1050 1050
(1021, 30) (1021, 30) (1021, 30)
(1021, 90) (1021, 30)
Matrix_30: [(1021, 90), (1021, 30)]
🚀 Criando novo modelo...
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1976 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.3750 - val_loss: 0.5866 - val_accuracy: 0.3077 - val_precision: 0.3077 - val_recall: 0.3077 - val_f1_score: 0.4706 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.4071 - accuracy: 0.3065 - precision: 0.3065 - recall: 0.3065 - f1_score: 0.4692 - val_loss: 0.1558 - val_accuracy: 0.6503 - val_precision: 0.6503 - val_recall: 0.6503 - val_f1_score: 0.5000 - 75ms/epoch - 75ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6813 - precision: 0.6813 - recall: 0.6813 - f1_score: 0.5539 - val_loss: 0.1888 - val_accuracy: 0.6993 - val_precision: 0.6993 - val_recall: 0.6993 - val_f1_score: 0.0444 - 78ms/epoch - 78ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2804 - accuracy: 0.6935 - precision: 0.6935 - recall: 0.6935 - f1_score: 0.0000e+00 - val_loss: 0.1656 - val_accuracy: 0.6993 - val_precision: 0.6993 - val_recall: 0.6993 - val_f1_score: 0.0444 - 81ms/epoch - 81ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2387 - accuracy: 0.6970 - precision: 0.6970 - recall: 0.6970 - f1_score: 0.0226 - val_loss: 0.1366 - val_accuracy: 0.7273 - val_precision: 0.7273 - val_recall: 0.7273 - val_f1_score: 0.2909 - 80ms/epoch - 80ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.7373 - precision: 0.7373 - recall: 0.7373 - f1_score: 0.3590 - val_loss: 0.1555 - val_accuracy: 0.6643 - val_precision: 0.6643 - val_recall: 0.6643 - val_f1_score: 0.5862 - 80ms/epoch - 80ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1439 - accuracy: 0.7005 - precision: 0.7005 - recall: 0.7005 - f1_score: 0.6354 - val_loss: 0.2018 - val_accuracy: 0.3916 - val_precision: 0.3916 - val_recall: 0.3916 - val_f1_score: 0.5029 - 79ms/epoch - 79ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.4326 - precision: 0.4326 - recall: 0.4326 - f1_score: 0.5179 - val_loss: 0.2303 - val_accuracy: 0.3566 - val_precision: 0.3566 - val_recall: 0.3566 - val_f1_score: 0.4889 - 78ms/epoch - 78ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1758 - accuracy: 0.3660 - precision: 0.3660 - recall: 0.3660 - f1_score: 0.4916 - val_loss: 0.2233 - val_accuracy: 0.3497 - val_precision: 0.3497 - val_recall: 0.3497 - val_f1_score: 0.4862 - 74ms/epoch - 74ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.3783 - precision: 0.3783 - recall: 0.3783 - f1_score: 0.4965 - val_loss: 0.1926 - val_accuracy: 0.4056 - val_precision: 0.4056 - val_recall: 0.4056 - val_f1_score: 0.5087 - 78ms/epoch - 78ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1540 - accuracy: 0.4396 - precision: 0.4396 - recall: 0.4396 - f1_score: 0.5210 - val_loss: 0.1593 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_f1_score: 0.6107 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1382 - accuracy: 0.6462 - precision: 0.6462 - recall: 0.6462 - f1_score: 0.6189 - val_loss: 0.1366 - val_accuracy: 0.7832 - val_precision: 0.7832 - val_recall: 0.7832 - val_f1_score: 0.6593 - 76ms/epoch - 76ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1323 - accuracy: 0.7898 - precision: 0.7898 - recall: 0.7898 - f1_score: 0.6970 - val_loss: 0.1264 - val_accuracy: 0.7902 - val_precision: 0.7902 - val_recall: 0.7902 - val_f1_score: 0.5946 - 78ms/epoch - 78ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1353 - accuracy: 0.8284 - precision: 0.8284 - recall: 0.8284 - f1_score: 0.6711 - val_loss: 0.1230 - val_accuracy: 0.7902 - val_precision: 0.7902 - val_recall: 0.7902 - val_f1_score: 0.5161 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1399 - accuracy: 0.8144 - precision: 0.8144 - recall: 0.8144 - f1_score: 0.5985 - val_loss: 0.1210 - val_accuracy: 0.7902 - val_precision: 0.7902 - val_recall: 0.7902 - val_f1_score: 0.5161 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1395 - accuracy: 0.8144 - precision: 0.8144 - recall: 0.8144 - f1_score: 0.5859 - val_loss: 0.1183 - val_accuracy: 0.8042 - val_precision: 0.8042 - val_recall: 0.8042 - val_f1_score: 0.5625 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1329 - accuracy: 0.8336 - precision: 0.8336 - recall: 0.8336 - f1_score: 0.6494 - val_loss: 0.1166 - val_accuracy: 0.8392 - val_precision: 0.8392 - val_recall: 0.8392 - val_f1_score: 0.6849 - 79ms/epoch - 79ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1232 - accuracy: 0.8634 - precision: 0.8634 - recall: 0.8634 - f1_score: 0.7451 - val_loss: 0.1185 - val_accuracy: 0.8252 - val_precision: 0.8252 - val_recall: 0.8252 - val_f1_score: 0.7126 - 79ms/epoch - 79ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1155 - accuracy: 0.8669 - precision: 0.8669 - recall: 0.8669 - f1_score: 0.7853 - val_loss: 0.1250 - val_accuracy: 0.8392 - val_precision: 0.8392 - val_recall: 0.8392 - val_f1_score: 0.7677 - 78ms/epoch - 78ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1122 - accuracy: 0.8319 - precision: 0.8319 - recall: 0.8319 - f1_score: 0.7714 - val_loss: 0.1332 - val_accuracy: 0.8042 - val_precision: 0.8042 - val_recall: 0.8042 - val_f1_score: 0.7407 - 78ms/epoch - 78ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1123 - accuracy: 0.7916 - precision: 0.7916 - recall: 0.7916 - f1_score: 0.7407 - val_loss: 0.1376 - val_accuracy: 0.7692 - val_precision: 0.7692 - val_recall: 0.7692 - val_f1_score: 0.7179 - 78ms/epoch - 78ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1124 - accuracy: 0.7566 - precision: 0.7566 - recall: 0.7566 - f1_score: 0.7110 - val_loss: 0.1341 - val_accuracy: 0.8042 - val_precision: 0.8042 - val_recall: 0.8042 - val_f1_score: 0.7500 - 78ms/epoch - 78ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1095 - accuracy: 0.7636 - precision: 0.7636 - recall: 0.7636 - f1_score: 0.7170 - val_loss: 0.1230 - val_accuracy: 0.8182 - val_precision: 0.8182 - val_recall: 0.8182 - val_f1_score: 0.7547 - 77ms/epoch - 77ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1037 - accuracy: 0.8039 - precision: 0.8039 - recall: 0.8039 - f1_score: 0.7500 - val_loss: 0.1103 - val_accuracy: 0.8462 - val_precision: 0.8462 - val_recall: 0.8462 - val_f1_score: 0.7708 - 78ms/epoch - 78ms/step
Epoch 25/50
1/1 - 0s - loss: 0.0982 - accuracy: 0.8669 - precision: 0.8669 - recall: 0.8669 - f1_score: 0.8090 - val_loss: 0.1008 - val_accuracy: 0.8392 - val_precision: 0.8392 - val_recall: 0.8392 - val_f1_score: 0.7160 - 74ms/epoch - 74ms/step
Epoch 26/50
1/1 - 0s - loss: 0.0962 - accuracy: 0.8949 - precision: 0.8949 - recall: 0.8949 - f1_score: 0.8305 - val_loss: 0.0965 - val_accuracy: 0.8601 - val_precision: 0.8601 - val_recall: 0.8601 - val_f1_score: 0.7368 - 80ms/epoch - 80ms/step
Epoch 27/50
1/1 - 0s - loss: 0.0946 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - f1_score: 0.8402 - val_loss: 0.0939 - val_accuracy: 0.8671 - val_precision: 0.8671 - val_recall: 0.8671 - val_f1_score: 0.7532 - 77ms/epoch - 77ms/step
Epoch 28/50
1/1 - 0s - loss: 0.0911 - accuracy: 0.9089 - precision: 0.9089 - recall: 0.9089 - f1_score: 0.8471 - val_loss: 0.0926 - val_accuracy: 0.8741 - val_precision: 0.8741 - val_recall: 0.8741 - val_f1_score: 0.7857 - 77ms/epoch - 77ms/step
Epoch 29/50
1/1 - 0s - loss: 0.0866 - accuracy: 0.9159 - precision: 0.9159 - recall: 0.9159 - f1_score: 0.8629 - val_loss: 0.0926 - val_accuracy: 0.8951 - val_precision: 0.8951 - val_recall: 0.8951 - val_f1_score: 0.8352 - 80ms/epoch - 80ms/step
Epoch 30/50
1/1 - 0s - loss: 0.0827 - accuracy: 0.9212 - precision: 0.9212 - recall: 0.9212 - f1_score: 0.8774 - val_loss: 0.0935 - val_accuracy: 0.8951 - val_precision: 0.8951 - val_recall: 0.8951 - val_f1_score: 0.8421 - 76ms/epoch - 76ms/step
Epoch 31/50
1/1 - 0s - loss: 0.0801 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - f1_score: 0.8675 - val_loss: 0.0931 - val_accuracy: 0.8881 - val_precision: 0.8881 - val_recall: 0.8881 - val_f1_score: 0.8333 - 76ms/epoch - 76ms/step
Epoch 32/50
1/1 - 0s - loss: 0.0780 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - f1_score: 0.8682 - val_loss: 0.0903 - val_accuracy: 0.8951 - val_precision: 0.8951 - val_recall: 0.8951 - val_f1_score: 0.8421 - 75ms/epoch - 75ms/step
Epoch 33/50
1/1 - 0s - loss: 0.0752 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - f1_score: 0.8675 - val_loss: 0.0856 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.8791 - 80ms/epoch - 80ms/step
Epoch 34/50
1/1 - 0s - loss: 0.0721 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9142 - f1_score: 0.8693 - val_loss: 0.0801 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8539 - 82ms/epoch - 82ms/step
Epoch 35/50
1/1 - 0s - loss: 0.0697 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - f1_score: 0.8864 - val_loss: 0.0758 - val_accuracy: 0.9091 - val_precision: 0.9091 - val_recall: 0.9091 - val_f1_score: 0.8506 - 78ms/epoch - 78ms/step
Epoch 36/50
1/1 - 0s - loss: 0.0682 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9034 - val_loss: 0.0733 - val_accuracy: 0.9161 - val_precision: 0.9161 - val_recall: 0.9161 - val_f1_score: 0.8605 - 79ms/epoch - 79ms/step
Epoch 37/50
1/1 - 0s - loss: 0.0663 - accuracy: 0.9387 - precision: 0.9387 - recall: 0.9387 - f1_score: 0.8997 - val_loss: 0.0722 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.8736 - 78ms/epoch - 78ms/step
Epoch 38/50
1/1 - 0s - loss: 0.0636 - accuracy: 0.9387 - precision: 0.9387 - recall: 0.9387 - f1_score: 0.9008 - val_loss: 0.0724 - val_accuracy: 0.9161 - val_precision: 0.9161 - val_recall: 0.9161 - val_f1_score: 0.8667 - 80ms/epoch - 80ms/step
Epoch 39/50
1/1 - 0s - loss: 0.0611 - accuracy: 0.9299 - precision: 0.9299 - recall: 0.9299 - f1_score: 0.8901 - val_loss: 0.0731 - val_accuracy: 0.9301 - val_precision: 0.9301 - val_recall: 0.9301 - val_f1_score: 0.8913 - 79ms/epoch - 79ms/step
Epoch 40/50
1/1 - 0s - loss: 0.0592 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - f1_score: 0.8889 - val_loss: 0.0726 - val_accuracy: 0.9301 - val_precision: 0.9301 - val_recall: 0.9301 - val_f1_score: 0.8913 - 81ms/epoch - 81ms/step
Epoch 41/50
1/1 - 0s - loss: 0.0576 - accuracy: 0.9264 - precision: 0.9264 - recall: 0.9264 - f1_score: 0.8871 - val_loss: 0.0699 - val_accuracy: 0.9371 - val_precision: 0.9371 - val_recall: 0.9371 - val_f1_score: 0.9011 - 79ms/epoch - 79ms/step
Epoch 42/50
1/1 - 0s - loss: 0.0554 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - f1_score: 0.8889 - val_loss: 0.0659 - val_accuracy: 0.9371 - val_precision: 0.9371 - val_recall: 0.9371 - val_f1_score: 0.8989 - 77ms/epoch - 77ms/step
Epoch 43/50
1/1 - 0s - loss: 0.0532 - accuracy: 0.9405 - precision: 0.9405 - recall: 0.9405 - f1_score: 0.9061 - val_loss: 0.0623 - val_accuracy: 0.9301 - val_precision: 0.9301 - val_recall: 0.9301 - val_f1_score: 0.8864 - 78ms/epoch - 78ms/step
Epoch 44/50
1/1 - 0s - loss: 0.0515 - accuracy: 0.9422 - precision: 0.9422 - recall: 0.9422 - f1_score: 0.9070 - val_loss: 0.0601 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.8736 - 79ms/epoch - 79ms/step
Epoch 45/50
1/1 - 0s - loss: 0.0499 - accuracy: 0.9475 - precision: 0.9475 - recall: 0.9475 - f1_score: 0.9148 - val_loss: 0.0590 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.8736 - 79ms/epoch - 79ms/step
Epoch 46/50
1/1 - 0s - loss: 0.0479 - accuracy: 0.9510 - precision: 0.9510 - recall: 0.9510 - f1_score: 0.9209 - val_loss: 0.0586 - val_accuracy: 0.9371 - val_precision: 0.9371 - val_recall: 0.9371 - val_f1_score: 0.8989 - 80ms/epoch - 80ms/step
Epoch 47/50
1/1 - 0s - loss: 0.0458 - accuracy: 0.9492 - precision: 0.9492 - recall: 0.9492 - f1_score: 0.9188 - val_loss: 0.0586 - val_accuracy: 0.9441 - val_precision: 0.9441 - val_recall: 0.9441 - val_f1_score: 0.9111 - 77ms/epoch - 77ms/step
Epoch 48/50
1/1 - 0s - loss: 0.0442 - accuracy: 0.9475 - precision: 0.9475 - recall: 0.9475 - f1_score: 0.9176 - val_loss: 0.0578 - val_accuracy: 0.9510 - val_precision: 0.9510 - val_recall: 0.9510 - val_f1_score: 0.9231 - 81ms/epoch - 81ms/step
Epoch 49/50
1/1 - 0s - loss: 0.0427 - accuracy: 0.9492 - precision: 0.9492 - recall: 0.9492 - f1_score: 0.9205 - val_loss: 0.0556 - val_accuracy: 0.9510 - val_precision: 0.9510 - val_recall: 0.9510 - val_f1_score: 0.9231 - 77ms/epoch - 77ms/step
Epoch 50/50
1/1 - 0s - loss: 0.0408 - accuracy: 0.9545 - precision: 0.9545 - recall: 0.9545 - f1_score: 0.9282 - val_loss: 0.0529 - val_accuracy: 0.9441 - val_precision: 0.9441 - val_recall: 0.9441 - val_f1_score: 0.9111 - 78ms/epoch - 78ms/step

🔍 Resultados no Teste:
Loss: 0.0610
Accuracy: 0.9023
Precision: 0.9023
Recall: 0.9023
F1 Score: 0.8598
📦 Modelo salvo em modelo_acumulado.keras
************************************************************
Continuar o treinamento? (s/n)
> ************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
1050 1050 1050
(1021, 30) (1021, 30) (1021, 30)
(1021, 90) (1021, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 89ms/step
[[0.7429593 0.2570407]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1051 | Acuracia_1: 0.4286 | Contagem Geral: 136.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.8467 | Acuracia_1: 0.375 
Precisao modelo Geral: 60.2026
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1051 1051 1051
(1022, 30) (1022, 30) (1022, 30)
(1022, 90) (1022, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8629582  0.13704184]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1052 | Acuracia_2: 0.1429 | Contagem Geral: 137.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.8467 | Acuracia_2: 0.1429 
Precisao modelo Geral: 60.2601
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1052 1052 1052
(1023, 30) (1023, 30) (1023, 30)
(1023, 90) (1023, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.8049215 0.1950785]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1053 | Acuracia_3: 0.1667 | Contagem Geral: 137.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.8467 | Acuracia_3: 0.1667 
Precisao modelo Geral: 60.3175
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1053 1053 1053
(1024, 30) (1024, 30) (1024, 30)
(1024, 90) (1024, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.78612757 0.21387242]]
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1054 | Acuracia_4: 0.75 | Contagem Geral: 137.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.6087 | Acuracia_4: 0.6 
Precisao modelo Geral: 60.2305
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1054 1054 1054
(1025, 30) (1025, 30) (1025, 30)
(1025, 90) (1025, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[[0.8694442  0.13055576]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1055 | Acuracia_5: 0.3333 | Contagem Geral: 138.0 
Ordem Natural: 228.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.6087 | Acuracia_5: 0.3333 
Precisao modelo Geral: 60.1439
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1055 1055 1055
(1026, 30) (1026, 30) (1026, 30)
(1026, 90) (1026, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.9265096  0.07349034]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1056 | Acuracia_6: 1.0 | Contagem Geral: 138.0 
Ordem Natural: 229.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.6087 | Acuracia_6: 1.0 
Precisao modelo Geral: 60.2011
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1056 1056 1056
(1027, 30) (1027, 30) (1027, 30)
(1027, 90) (1027, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.89136195 0.10863812]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1057 | Acuracia_7: 0.3333 | Contagem Geral: 138.0 
Ordem Natural: 229.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 32.6087 | Acuracia_7: 0.3333 
Precisao modelo Geral: 60.2582
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
1057 1057 1057
(1028, 30) (1028, 30) (1028, 30)
(1028, 90) (1028, 30)
(1, 87, 1, 1)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[[0.82017314 0.17982686]]
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 1058 | Acuracia_8: 0.6667 | Contagem Geral: 138.0 
Ordem Natural: 229.0
Entrada -> /home/darkcover/.pyenv/versions/3.10.17/lib/python3.10/tkinter/__init__.py:839: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from font(s) DejaVu Sans.
  func(*args)
📈 Histórico de desempenho salvo em 'historico_janelas.csv'
