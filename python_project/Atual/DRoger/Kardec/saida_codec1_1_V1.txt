/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
Insera a entrada até onde o modelo deve ser carregado --> ------------------------------------------------------------------------
Número da Entrada - 0 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 1 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 2 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 24.83
------------------------------------------------------------------------
Número da Entrada - 3 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.25
------------------------------------------------------------------------
Número da Entrada - 4 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.55
------------------------------------------------------------------------
Número da Entrada - 5 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 6 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.52
------------------------------------------------------------------------
Número da Entrada - 7 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 8 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.57
------------------------------------------------------------------------
Número da Entrada - 9 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 10 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 11 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.16
------------------------------------------------------------------------
Número da Entrada - 12 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 13 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 14 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 15 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 16 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.88
------------------------------------------------------------------------
Número da Entrada - 17 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 18 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 19 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 20 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.8
------------------------------------------------------------------------
Número da Entrada - 21 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.48
------------------------------------------------------------------------
Número da Entrada - 22 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 23 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 24 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 25 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 26 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.5
------------------------------------------------------------------------
Número da Entrada - 27 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.32
------------------------------------------------------------------------
Número da Entrada - 28 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 29 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.45
------------------------------------------------------------------------
Número da Entrada - 30 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.95
------------------------------------------------------------------------
Número da Entrada - 31 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.7
------------------------------------------------------------------------
Número da Entrada - 32 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.78
------------------------------------------------------------------------
Número da Entrada - 33 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 34 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.04
------------------------------------------------------------------------
Número da Entrada - 35 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 36 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 37 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 38 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 39 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 40 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.44
------------------------------------------------------------------------
Número da Entrada - 41 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 42 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 43 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 44 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 45 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 46 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 47 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.96
------------------------------------------------------------------------
Número da Entrada - 48 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.21
------------------------------------------------------------------------
Número da Entrada - 49 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.19
------------------------------------------------------------------------
Número da Entrada - 50 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.51
------------------------------------------------------------------------
Número da Entrada - 51 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 52 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 53 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 54 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 55 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 56 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 57 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 58 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 59 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.79
------------------------------------------------------------------------
Número da Entrada - 60 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.18
------------------------------------------------------------------------
Número da Entrada - 61 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.79
------------------------------------------------------------------------
Número da Entrada - 62 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 25.75
------------------------------------------------------------------------
Número da Entrada - 63 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.8
------------------------------------------------------------------------
Número da Entrada - 64 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 65 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 66 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.47
------------------------------------------------------------------------
Número da Entrada - 67 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 68 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.93
------------------------------------------------------------------------
Número da Entrada - 69 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.55
------------------------------------------------------------------------
Número da Entrada - 70 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 71 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.54
------------------------------------------------------------------------
Número da Entrada - 72 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.13
------------------------------------------------------------------------
Número da Entrada - 73 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.2
------------------------------------------------------------------------
Número da Entrada - 74 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 75 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.95
------------------------------------------------------------------------
Número da Entrada - 76 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 77 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.84
------------------------------------------------------------------------
Número da Entrada - 78 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.73
------------------------------------------------------------------------
Número da Entrada - 79 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.87
------------------------------------------------------------------------
Número da Entrada - 80 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 81 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.07
------------------------------------------------------------------------
Número da Entrada - 82 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 83 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 84 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.17
------------------------------------------------------------------------
Número da Entrada - 85 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 86 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 87 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.8
------------------------------------------------------------------------
Número da Entrada - 88 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 89 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 93.91
------------------------------------------------------------------------
Número da Entrada - 90 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.17
------------------------------------------------------------------------
Número da Entrada - 91 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 92 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 93 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.29
------------------------------------------------------------------------
Número da Entrada - 94 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.85
------------------------------------------------------------------------
Número da Entrada - 95 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 547.44
------------------------------------------------------------------------
Número da Entrada - 96 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.5
------------------------------------------------------------------------
Número da Entrada - 97 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 98 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 99 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.76
------------------------------------------------------------------------
Número da Entrada - 100 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.62
------------------------------------------------------------------------
Número da Entrada - 101 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.49
------------------------------------------------------------------------
Número da Entrada - 102 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 103 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.64
------------------------------------------------------------------------
Número da Entrada - 104 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.51
------------------------------------------------------------------------
Número da Entrada - 105 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 106 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.96
------------------------------------------------------------------------
Número da Entrada - 107 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 108 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 17.51
------------------------------------------------------------------------
Número da Entrada - 109 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 21.63
------------------------------------------------------------------------
Número da Entrada - 110 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 27.5
------------------------------------------------------------------------
Número da Entrada - 111 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.53
------------------------------------------------------------------------
Número da Entrada - 112 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 29.87
------------------------------------------------------------------------
Número da Entrada - 113 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.69
------------------------------------------------------------------------
Número da Entrada - 114 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.92
------------------------------------------------------------------------
Número da Entrada - 115 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
------------------------------------------------------------------------
Número da Entrada - 116 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.52
------------------------------------------------------------------------
Número da Entrada - 117 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.42
------------------------------------------------------------------------
Número da Entrada - 118 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.27
------------------------------------------------------------------------
Número da Entrada - 119 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.4
------------------------------------------------------------------------
Número da Entrada - 120 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.63
------------------------------------------------------------------------
Número da Entrada - 121 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.24
------------------------------------------------------------------------
Número da Entrada - 122 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 123 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 124 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.62
------------------------------------------------------------------------
Número da Entrada - 125 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.44
------------------------------------------------------------------------
Número da Entrada - 126 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.61
------------------------------------------------------------------------
Número da Entrada - 127 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 128 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 129 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 130 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.38
------------------------------------------------------------------------
Número da Entrada - 131 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.28
------------------------------------------------------------------------
Número da Entrada - 132 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 133 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.9
------------------------------------------------------------------------
Número da Entrada - 134 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.99
------------------------------------------------------------------------
Número da Entrada - 135 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 136 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.14
------------------------------------------------------------------------
Número da Entrada - 137 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 138 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.75
------------------------------------------------------------------------
Número da Entrada - 139 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.59
------------------------------------------------------------------------
Número da Entrada - 140 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.53
------------------------------------------------------------------------
Número da Entrada - 141 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 142 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 143 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.56
------------------------------------------------------------------------
Número da Entrada - 144 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 145 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 14.92
------------------------------------------------------------------------
Número da Entrada - 146 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 147 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 148 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.37
------------------------------------------------------------------------
Número da Entrada - 149 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.19
------------------------------------------------------------------------
Número da Entrada - 150 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.0
------------------------------------------------------------------------
Número da Entrada - 151 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.12
------------------------------------------------------------------------
Número da Entrada - 152 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.8
------------------------------------------------------------------------
Número da Entrada - 153 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.74
------------------------------------------------------------------------
Número da Entrada - 154 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 155 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 156 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 157 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 158 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 20.5
------------------------------------------------------------------------
Número da Entrada - 159 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 160 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 161 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.61
------------------------------------------------------------------------
Número da Entrada - 162 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 163 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 164 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.05
------------------------------------------------------------------------
Número da Entrada - 165 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 35.4
------------------------------------------------------------------------
Número da Entrada - 166 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.12
------------------------------------------------------------------------
Número da Entrada - 167 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 11.84
------------------------------------------------------------------------
Número da Entrada - 168 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 57.77
------------------------------------------------------------------------
Número da Entrada - 169 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 170 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.28
------------------------------------------------------------------------
Número da Entrada - 171 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 172 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 173 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.24
------------------------------------------------------------------------
Número da Entrada - 174 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.97
------------------------------------------------------------------------
Número da Entrada - 175 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.4
------------------------------------------------------------------------
Número da Entrada - 176 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 177 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.01
------------------------------------------------------------------------
Número da Entrada - 178 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 179 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.18
------------------------------------------------------------------------
Número da Entrada - 180 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.48
------------------------------------------------------------------------
Número da Entrada - 181 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.17
------------------------------------------------------------------------
Número da Entrada - 182 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 183 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 184 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 185 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.72
------------------------------------------------------------------------
Número da Entrada - 186 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.56
------------------------------------------------------------------------
Número da Entrada - 187 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.59
------------------------------------------------------------------------
Número da Entrada - 188 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.09
------------------------------------------------------------------------
Número da Entrada - 189 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 190 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 191 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.09
------------------------------------------------------------------------
Número da Entrada - 192 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.68
------------------------------------------------------------------------
Número da Entrada - 193 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 194 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 195 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.41
------------------------------------------------------------------------
Número da Entrada - 196 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 197 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 198 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 199 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 200 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 201 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.99
------------------------------------------------------------------------
Número da Entrada - 202 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.68
------------------------------------------------------------------------
Número da Entrada - 203 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.22
------------------------------------------------------------------------
Número da Entrada - 204 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 205 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.42
------------------------------------------------------------------------
Número da Entrada - 206 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 207 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.93
------------------------------------------------------------------------
Número da Entrada - 208 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 209 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 8.27
------------------------------------------------------------------------
Número da Entrada - 210 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.59
------------------------------------------------------------------------
Número da Entrada - 211 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.74
------------------------------------------------------------------------
Número da Entrada - 212 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.89
------------------------------------------------------------------------
Número da Entrada - 213 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 214 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.29
------------------------------------------------------------------------
Número da Entrada - 215 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.06
------------------------------------------------------------------------
Número da Entrada - 216 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.53
------------------------------------------------------------------------
Número da Entrada - 217 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 218 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 219 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 220 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.71
------------------------------------------------------------------------
Número da Entrada - 221 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 18.79
------------------------------------------------------------------------
Número da Entrada - 222 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.14
------------------------------------------------------------------------
Número da Entrada - 223 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 224 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.13
------------------------------------------------------------------------
Número da Entrada - 225 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.4
------------------------------------------------------------------------
Número da Entrada - 226 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.57
------------------------------------------------------------------------
Número da Entrada - 227 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.61
------------------------------------------------------------------------
Número da Entrada - 228 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 229 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 230 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.4
------------------------------------------------------------------------
Número da Entrada - 231 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.29
------------------------------------------------------------------------
Número da Entrada - 232 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.34
------------------------------------------------------------------------
Número da Entrada - 233 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 234 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.44
------------------------------------------------------------------------
Número da Entrada - 235 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.72
------------------------------------------------------------------------
Número da Entrada - 236 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 237 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.83
------------------------------------------------------------------------
Número da Entrada - 238 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.39
------------------------------------------------------------------------
Número da Entrada - 239 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.88
------------------------------------------------------------------------
Número da Entrada - 240 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 34.09
------------------------------------------------------------------------
Número da Entrada - 241 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.48
------------------------------------------------------------------------
Número da Entrada - 242 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.78
------------------------------------------------------------------------
Número da Entrada - 243 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 244 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.1
------------------------------------------------------------------------
Número da Entrada - 245 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 246 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.79
------------------------------------------------------------------------
Número da Entrada - 247 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.34
------------------------------------------------------------------------
Número da Entrada - 248 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 249 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.99
------------------------------------------------------------------------
Número da Entrada - 250 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.03
------------------------------------------------------------------------
Número da Entrada - 251 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.72
------------------------------------------------------------------------
Número da Entrada - 252 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 253 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.67
------------------------------------------------------------------------
Número da Entrada - 254 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.91
------------------------------------------------------------------------
Número da Entrada - 255 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 256 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.15
------------------------------------------------------------------------
Número da Entrada - 257 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.58
------------------------------------------------------------------------
Número da Entrada - 258 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.54
------------------------------------------------------------------------
Número da Entrada - 259 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.26
------------------------------------------------------------------------
Número da Entrada - 260 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.05
------------------------------------------------------------------------
Número da Entrada - 261 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.27
------------------------------------------------------------------------
Número da Entrada - 262 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.42
------------------------------------------------------------------------
Número da Entrada - 263 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.25
------------------------------------------------------------------------
Número da Entrada - 264 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.0
------------------------------------------------------------------------
Número da Entrada - 265 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.08
------------------------------------------------------------------------
Número da Entrada - 266 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.95
------------------------------------------------------------------------
Número da Entrada - 267 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.66
------------------------------------------------------------------------
Número da Entrada - 268 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 67.78
------------------------------------------------------------------------
Número da Entrada - 269 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.49
------------------------------------------------------------------------
Número da Entrada - 270 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 9.12
------------------------------------------------------------------------
Número da Entrada - 271 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.2
------------------------------------------------------------------------
Número da Entrada - 272 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 16.56
------------------------------------------------------------------------
Número da Entrada - 273 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 274 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 275 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 276 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.31
------------------------------------------------------------------------
Número da Entrada - 277 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.3
------------------------------------------------------------------------
Número da Entrada - 278 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.62
------------------------------------------------------------------------
Número da Entrada - 279 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.12
------------------------------------------------------------------------
Número da Entrada - 280 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.96
------------------------------------------------------------------------
Número da Entrada - 281 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.18
------------------------------------------------------------------------
Número da Entrada - 282 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 283 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.92
------------------------------------------------------------------------
Número da Entrada - 284 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.08
------------------------------------------------------------------------
Número da Entrada - 285 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.5
------------------------------------------------------------------------
Número da Entrada - 286 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.3
------------------------------------------------------------------------
Número da Entrada - 287 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.45
------------------------------------------------------------------------
Número da Entrada - 288 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.23
------------------------------------------------------------------------
Número da Entrada - 289 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 64.44
------------------------------------------------------------------------
Número da Entrada - 290 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 291 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 292 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 293 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.39
------------------------------------------------------------------------
Número da Entrada - 294 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.45
------------------------------------------------------------------------
Número da Entrada - 295 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.11
------------------------------------------------------------------------
Número da Entrada - 296 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.16
------------------------------------------------------------------------
Número da Entrada - 297 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.03
------------------------------------------------------------------------
Número da Entrada - 298 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 299 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 36.82
------------------------------------------------------------------------
Número da Entrada - 300 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.49
------------------------------------------------------------------------
Número da Entrada - 301 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.82
------------------------------------------------------------------------
Número da Entrada - 302 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.8
------------------------------------------------------------------------
Número da Entrada - 303 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.24
------------------------------------------------------------------------
Número da Entrada - 304 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.45
------------------------------------------------------------------------
Número da Entrada - 305 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.65
------------------------------------------------------------------------
Número da Entrada - 306 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 307 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.7
------------------------------------------------------------------------
Número da Entrada - 308 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.6
------------------------------------------------------------------------
Número da Entrada - 309 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 15.81
------------------------------------------------------------------------
Número da Entrada - 310 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 311 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 312 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.23
------------------------------------------------------------------------
Número da Entrada - 313 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.46
------------------------------------------------------------------------
Número da Entrada - 314 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 315 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.02
------------------------------------------------------------------------
Número da Entrada - 316 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.2
------------------------------------------------------------------------
Número da Entrada - 317 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.01
------------------------------------------------------------------------
Número da Entrada - 318 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.07
------------------------------------------------------------------------
Número da Entrada - 319 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.08
------------------------------------------------------------------------
Número da Entrada - 320 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.49
------------------------------------------------------------------------
Número da Entrada - 321 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 12.09
------------------------------------------------------------------------
Número da Entrada - 322 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 68.2
------------------------------------------------------------------------
Número da Entrada - 323 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.25
------------------------------------------------------------------------
Número da Entrada - 324 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.04
------------------------------------------------------------------------
Número da Entrada - 325 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.06
------------------------------------------------------------------------
Número da Entrada - 326 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 78.5
------------------------------------------------------------------------
Número da Entrada - 327 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 328 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.26
------------------------------------------------------------------------
Número da Entrada - 329 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
------------------------------------------------------------------------
Número da Entrada - 330 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.21
------------------------------------------------------------------------
Número da Entrada - 331 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.02
------------------------------------------------------------------------
Número da Entrada - 332 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.18
------------------------------------------------------------------------
Número da Entrada - 333 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 334 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.19
------------------------------------------------------------------------
Número da Entrada - 335 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.27
------------------------------------------------------------------------
Número da Entrada - 336 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.36
------------------------------------------------------------------------
Número da Entrada - 337 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.26
------------------------------------------------------------------------
Número da Entrada - 338 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.0
------------------------------------------------------------------------
Número da Entrada - 339 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 109.79
------------------------------------------------------------------------
Número da Entrada - 340 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.31
------------------------------------------------------------------------
Número da Entrada - 341 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 7.03
------------------------------------------------------------------------
Número da Entrada - 342 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.25
------------------------------------------------------------------------
Número da Entrada - 343 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 344 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.65
------------------------------------------------------------------------
Número da Entrada - 345 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 5.78
------------------------------------------------------------------------
Número da Entrada - 346 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 6.47
------------------------------------------------------------------------
Número da Entrada - 347 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.64
------------------------------------------------------------------------
Número da Entrada - 348 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 349 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 10.1
------------------------------------------------------------------------
Número da Entrada - 350 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.53
------------------------------------------------------------------------
Número da Entrada - 351 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.18
------------------------------------------------------------------------
Número da Entrada - 352 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.12
------------------------------------------------------------------------
Número da Entrada - 353 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 2.89
------------------------------------------------------------------------
Número da Entrada - 354 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.5
------------------------------------------------------------------------
Número da Entrada - 355 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.57
------------------------------------------------------------------------
Número da Entrada - 356 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.33
------------------------------------------------------------------------
Número da Entrada - 357 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.28
------------------------------------------------------------------------
Número da Entrada - 358 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 4.34
------------------------------------------------------------------------
Número da Entrada - 359 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 3.67
------------------------------------------------------------------------
Número da Entrada - 360 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.09
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
300
360 360
(241, 60) (241, 60) (241, 60) (241, 60)
(241, 60) (241, 60)
Matrix_60: [(241, 60), (241, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2287 - accuracy: 0.3657 - precision: 0.3657 - recall: 0.3657 - f1_score: 0.4586 - val_loss: 0.1860 - val_accuracy: 0.4412 - val_precision: 0.4412 - val_recall: 0.4412 - val_f1_score: 0.4571 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1842 - accuracy: 0.4478 - precision: 0.4478 - recall: 0.4478 - f1_score: 0.4219 - val_loss: 0.1576 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059 - val_f1_score: 0.1667 - 55ms/epoch - 55ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1980 - accuracy: 0.5299 - precision: 0.5299 - recall: 0.5299 - f1_score: 0.3368 - val_loss: 0.1489 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.0000e+00 - 67ms/epoch - 67ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1798 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.3902 - val_loss: 0.1457 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 74ms/epoch - 74ms/step
Epoch 5/50
1/1 - 0s - loss: 0.2103 - accuracy: 0.6045 - precision: 0.6045 - recall: 0.6045 - f1_score: 0.1846 - val_loss: 0.1467 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 62ms/epoch - 62ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1827 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.2059 - val_loss: 0.1498 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 67ms/epoch - 67ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1977 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.1471 - val_loss: 0.1550 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 62ms/epoch - 62ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1813 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.4043 - val_loss: 0.1609 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.1818 - 72ms/epoch - 72ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4792 - val_loss: 0.1668 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3333 - 66ms/epoch - 66ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1825 - accuracy: 0.5448 - precision: 0.5448 - recall: 0.5448 - f1_score: 0.4078 - val_loss: 0.1727 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3200 - 68ms/epoch - 68ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1744 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.4655 - val_loss: 0.1773 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.3750 - 86ms/epoch - 86ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1881 - accuracy: 0.3731 - precision: 0.3731 - recall: 0.3731 - f1_score: 0.3731 - val_loss: 0.1805 - val_accuracy: 0.3529 - val_precision: 0.3529 - val_recall: 0.3529 - val_f1_score: 0.3889 - 82ms/epoch - 82ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1774 - accuracy: 0.4328 - precision: 0.4328 - recall: 0.4328 - f1_score: 0.4493 - val_loss: 0.1817 - val_accuracy: 0.3529 - val_precision: 0.3529 - val_recall: 0.3529 - val_f1_score: 0.3889 - 94ms/epoch - 94ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.4104 - precision: 0.4104 - recall: 0.4104 - f1_score: 0.4626 - val_loss: 0.1807 - val_accuracy: 0.3235 - val_precision: 0.3235 - val_recall: 0.3235 - val_f1_score: 0.3429 - 102ms/epoch - 102ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.4776 - precision: 0.4776 - recall: 0.4776 - f1_score: 0.4776 - val_loss: 0.1785 - val_accuracy: 0.3824 - val_precision: 0.3824 - val_recall: 0.3824 - val_f1_score: 0.3636 - 84ms/epoch - 84ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.4627 - precision: 0.4627 - recall: 0.4627 - f1_score: 0.4706 - val_loss: 0.1755 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.3571 - 138ms/epoch - 138ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1703 - accuracy: 0.4478 - precision: 0.4478 - recall: 0.4478 - f1_score: 0.4394 - val_loss: 0.1720 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3200 - 97ms/epoch - 97ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4567 - val_loss: 0.1685 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2105 - 67ms/epoch - 67ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.6045 - precision: 0.6045 - recall: 0.6045 - f1_score: 0.5470 - val_loss: 0.1655 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765 - val_f1_score: 0.1538 - 69ms/epoch - 69ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6791 - precision: 0.6791 - recall: 0.6791 - f1_score: 0.5905 - val_loss: 0.1631 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.2000 - 81ms/epoch - 81ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1738 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.4200 - val_loss: 0.1614 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941 - val_f1_score: 0.2222 - 99ms/epoch - 99ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.5896 - precision: 0.5896 - recall: 0.5896 - f1_score: 0.3210 - val_loss: 0.1609 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941 - val_f1_score: 0.2222 - 83ms/epoch - 83ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4565 - val_loss: 0.1608 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941 - val_f1_score: 0.2222 - 89ms/epoch - 89ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4186 - val_loss: 0.1612 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941 - val_f1_score: 0.2222 - 62ms/epoch - 62ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.4471 - val_loss: 0.1622 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941 - val_f1_score: 0.2222 - 77ms/epoch - 77ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.4471 - val_loss: 0.1633 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.2000 - 61ms/epoch - 61ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1556 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5957 - val_loss: 0.1646 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.1818 - 56ms/epoch - 56ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1699 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.4259 - val_loss: 0.1657 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.1429 - 59ms/epoch - 59ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1643 - accuracy: 0.6194 - precision: 0.6194 - recall: 0.6194 - f1_score: 0.4950 - val_loss: 0.1670 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1250 - 144ms/epoch - 144ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.5746 - precision: 0.5746 - recall: 0.5746 - f1_score: 0.4771 - val_loss: 0.1680 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.1111 - 53ms/epoch - 53ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1623 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.5000 - val_loss: 0.1687 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1053 - 68ms/epoch - 68ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.5524 - val_loss: 0.1694 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.1000 - 53ms/epoch - 53ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.5179 - val_loss: 0.1696 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1905 - 53ms/epoch - 53ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.5688 - val_loss: 0.1695 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1905 - 54ms/epoch - 54ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.5172 - val_loss: 0.1691 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1905 - 47ms/epoch - 47ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1577 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.5500 - val_loss: 0.1686 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.1000 - 52ms/epoch - 52ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1547 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.5574 - val_loss: 0.1673 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.1176 - 48ms/epoch - 48ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1600 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.5172 - val_loss: 0.1658 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1250 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1494 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.6296 - val_loss: 0.1637 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059 - val_f1_score: 0.1667 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1528 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.6200 - val_loss: 0.1623 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.0000e+00 - 53ms/epoch - 53ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1518 - accuracy: 0.6791 - precision: 0.6791 - recall: 0.6791 - f1_score: 0.5275 - val_loss: 0.1610 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1493 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5319 - val_loss: 0.1598 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1544 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.5155 - val_loss: 0.1590 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 59ms/epoch - 59ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1523 - accuracy: 0.7090 - precision: 0.7090 - recall: 0.7090 - f1_score: 0.5412 - val_loss: 0.1592 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1401 - accuracy: 0.7388 - precision: 0.7388 - recall: 0.7388 - f1_score: 0.6316 - val_loss: 0.1594 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6940 - precision: 0.6940 - recall: 0.6940 - f1_score: 0.5591 - val_loss: 0.1609 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1442 - accuracy: 0.7388 - precision: 0.7388 - recall: 0.7388 - f1_score: 0.6067 - val_loss: 0.1630 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2222 - 48ms/epoch - 48ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1478 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.6000 - val_loss: 0.1640 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2105 - 48ms/epoch - 48ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1459 - accuracy: 0.6940 - precision: 0.6940 - recall: 0.6940 - f1_score: 0.5684 - val_loss: 0.1653 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2105 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.5192 - val_loss: 0.1665 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2105 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1625
Accuracy: 0.6301
Precision: 0.6301
Recall: 0.6301
F1 Score: 0.3415
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
300
360 360
(241, 60) (241, 60) (241, 60) (241, 60)
(241, 60) (241, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 112ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 361 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 0.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
301
361 361
(242, 60) (242, 60) (242, 60) (242, 60)
(242, 60) (242, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 362 | Acuracia_1: 0 | Contagem Geral: 0.0 
Ordem Natural: 0.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 50.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
302
362 362
(243, 60) (243, 60) (243, 60) (243, 60)
(243, 60) (243, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 363 | Acuracia_1: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 2.33
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
303
363 363
(244, 60) (244, 60) (244, 60) (244, 60)
(244, 60) (244, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 364 | Acuracia_1: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 2.66
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 0.0 | Acuracia_0: 0 
Precisao modelo Geral: 75.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
304
364 364
(245, 60) (245, 60) (245, 60) (245, 60)
(245, 60) (245, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 365 | Acuracia_1: 0 | Contagem Geral: 1.0 
Ordem Natural: 0.0
Entrada: 4.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 50.0 | Acuracia_0: 1.0 
Precisao modelo Geral: 80.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
305
365 365
(246, 60) (246, 60) (246, 60) (246, 60)
(246, 60) (246, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 366 | Acuracia_1: 0 | Contagem Geral: 2.0 
Ordem Natural: 1.0
Entrada: 1.15
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
306
366 366
(247, 60) (247, 60) (247, 60) (247, 60)
(247, 60) (247, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 367 | Acuracia_1: 0 | Contagem Geral: 3.0 
Ordem Natural: 1.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 71.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
307
367 367
(248, 60) (248, 60) (248, 60) (248, 60)
(248, 60) (248, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 368 | Acuracia_1: 0 | Contagem Geral: 3.0 
Ordem Natural: 1.0
Entrada: 1.47
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 75.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
308
368 368
(249, 60) (249, 60) (249, 60) (249, 60)
(249, 60) (249, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 369 | Acuracia_1: 0 | Contagem Geral: 3.0 
Ordem Natural: 1.0
Entrada: 2.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 77.7778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
309
369 369
(250, 60) (250, 60) (250, 60) (250, 60)
(250, 60) (250, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 370 | Acuracia_1: 0 | Contagem Geral: 3.0 
Ordem Natural: 1.0
Entrada: 1.38
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 70.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
310
370 370
(251, 60) (251, 60) (251, 60) (251, 60)
(251, 60) (251, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 371 | Acuracia_1: 0 | Contagem Geral: 4.0 
Ordem Natural: 1.0
Entrada: 2.79
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 72.7273
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
311
371 371
(252, 60) (252, 60) (252, 60) (252, 60)
(252, 60) (252, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 372 | Acuracia_1: 0 | Contagem Geral: 4.0 
Ordem Natural: 1.0
Entrada: 1.78
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 75.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
312
372 372
(253, 60) (253, 60) (253, 60) (253, 60)
(253, 60) (253, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 373 | Acuracia_1: 0 | Contagem Geral: 4.0 
Ordem Natural: 1.0
Entrada: 8.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 69.2308
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
313
373 373
(254, 60) (254, 60) (254, 60) (254, 60)
(254, 60) (254, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 374 | Acuracia_1: 0 | Contagem Geral: 4.0 
Ordem Natural: 2.0
Entrada: 1.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 71.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
314
374 374
(255, 60) (255, 60) (255, 60) (255, 60)
(255, 60) (255, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 375 | Acuracia_1: 0 | Contagem Geral: 4.0 
Ordem Natural: 2.0
Entrada: 5.21
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 40.0 | Acuracia_0: 1.0 
Precisao modelo Geral: 73.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
315
375 375
(256, 60) (256, 60) (256, 60) (256, 60)
(256, 60) (256, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 376 | Acuracia_1: 0 | Contagem Geral: 5.0 
Ordem Natural: 3.0
Entrada: 4.14
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 40.0 | Acuracia_0: 0 
Precisao modelo Geral: 68.75
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
316
376 376
(257, 60) (257, 60) (257, 60) (257, 60)
(257, 60) (257, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 377 | Acuracia_1: 0 | Contagem Geral: 5.0 
Ordem Natural: 4.0
Entrada: 1.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 64.7059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
317
377 377
(258, 60) (258, 60) (258, 60) (258, 60)
(258, 60) (258, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 378 | Acuracia_1: 0 | Contagem Geral: 6.0 
Ordem Natural: 4.0
Entrada: 1.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
318
378 378
(259, 60) (259, 60) (259, 60) (259, 60)
(259, 60) (259, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 379 | Acuracia_1: 0 | Contagem Geral: 6.0 
Ordem Natural: 4.0
Entrada: 2.39
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 68.4211
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
319
379 379
(260, 60) (260, 60) (260, 60) (260, 60)
(260, 60) (260, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 380 | Acuracia_1: 0 | Contagem Geral: 6.0 
Ordem Natural: 4.0
Entrada: 1.44
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 70.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
320
380 380
(261, 60) (261, 60) (261, 60) (261, 60)
(261, 60) (261, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 381 | Acuracia_1: 0 | Contagem Geral: 6.0 
Ordem Natural: 4.0
Entrada: 1.68
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 33.3333 | Acuracia_0: 0 
Precisao modelo Geral: 71.4286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
321
381 381
(262, 60) (262, 60) (262, 60) (262, 60)
(262, 60) (262, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 382 | Acuracia_1: 0 | Contagem Geral: 6.0 
Ordem Natural: 4.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.0 
Precisao modelo Geral: 68.1818
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
322
382 382
(263, 60) (263, 60) (263, 60) (263, 60)
(263, 60) (263, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 383 | Acuracia_1: 0 | Contagem Geral: 7.0 
Ordem Natural: 4.0
Entrada: 1.48
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 65.2174
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
323
383 383
(264, 60) (264, 60) (264, 60) (264, 60)
(264, 60) (264, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 384 | Acuracia_1: 0 | Contagem Geral: 8.0 
Ordem Natural: 4.0
Entrada: 2.23
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 66.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
324
384 384
(265, 60) (265, 60) (265, 60) (265, 60)
(265, 60) (265, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 385 | Acuracia_1: 0 | Contagem Geral: 8.0 
Ordem Natural: 4.0
Entrada: 6.89
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0 
Precisao modelo Geral: 64.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
325
385 385
(266, 60) (266, 60) (266, 60) (266, 60)
(266, 60) (266, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 386 | Acuracia_1: 0 | Contagem Geral: 8.0 
Ordem Natural: 5.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0.0 
Precisao modelo Geral: 61.5385
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
326
386 386
(267, 60) (267, 60) (267, 60) (267, 60)
(267, 60) (267, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 387 | Acuracia_1: 0 | Contagem Geral: 9.0 
Ordem Natural: 5.0
Entrada: 2.83
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0 
Precisao modelo Geral: 62.963
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
327
387 387
(268, 60) (268, 60) (268, 60) (268, 60)
(268, 60) (268, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 388 | Acuracia_1: 0 | Contagem Geral: 9.0 
Ordem Natural: 5.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.7143
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
328
388 388
(269, 60) (269, 60) (269, 60) (269, 60)
(269, 60) (269, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 389 | Acuracia_1: 0 | Contagem Geral: 10.0 
Ordem Natural: 5.0
Entrada: 53.26
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.0 | Acuracia_0: 0 
Precisao modelo Geral: 58.6207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
329
389 389
(270, 60) (270, 60) (270, 60) (270, 60)
(270, 60) (270, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 390 | Acuracia_1: 0 | Contagem Geral: 10.0 
Ordem Natural: 6.0
Entrada: 1.43
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.6667
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
330
390 390
(271, 60) (271, 60) (271, 60) (271, 60)
(271, 60) (271, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 391 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 58.0645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
331
391 391
(272, 60) (272, 60) (272, 60) (272, 60)
(272, 60) (272, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 392 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 59.375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
332
392 392
(273, 60) (273, 60) (273, 60) (273, 60)
(273, 60) (273, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 393 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
333
393 393
(274, 60) (274, 60) (274, 60) (274, 60)
(274, 60) (274, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 394 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.48
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 61.7647
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
334
394 394
(275, 60) (275, 60) (275, 60) (275, 60)
(275, 60) (275, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 395 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.93
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 62.8571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
335
395 395
(276, 60) (276, 60) (276, 60) (276, 60)
(276, 60) (276, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 396 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 63.8889
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
336
396 396
(277, 60) (277, 60) (277, 60) (277, 60)
(277, 60) (277, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 397 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 6.0
Entrada: 4.68
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 18.1818 | Acuracia_0: 0 
Precisao modelo Geral: 62.1622
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
337
397 397
(278, 60) (278, 60) (278, 60) (278, 60)
(278, 60) (278, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 398 | Acuracia_1: 0 | Contagem Geral: 11.0 
Ordem Natural: 7.0
Entrada: 1.41
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 16.6667 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.5263
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
338
398 398
(279, 60) (279, 60) (279, 60) (279, 60)
(279, 60) (279, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 399 | Acuracia_1: 0 | Contagem Geral: 12.0 
Ordem Natural: 7.0
Entrada: 2.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 15.3846 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.9744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
339
399 399
(280, 60) (280, 60) (280, 60) (280, 60)
(280, 60) (280, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 400 | Acuracia_1: 0 | Contagem Geral: 13.0 
Ordem Natural: 7.0
Entrada: 1.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 15.3846 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
340
400 400
(281, 60) (281, 60) (281, 60) (281, 60)
(281, 60) (281, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 401 | Acuracia_1: 0 | Contagem Geral: 13.0 
Ordem Natural: 7.0
Entrada: 1.04
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 15.3846 | Acuracia_0: 0 
Precisao modelo Geral: 60.9756
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
341
401 401
(282, 60) (282, 60) (282, 60) (282, 60)
(282, 60) (282, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 402 | Acuracia_1: 0 | Contagem Geral: 13.0 
Ordem Natural: 7.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 14.2857 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
342
402 402
(283, 60) (283, 60) (283, 60) (283, 60)
(283, 60) (283, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 403 | Acuracia_1: 0 | Contagem Geral: 14.0 
Ordem Natural: 7.0
Entrada: 2.72
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 13.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1395
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
343
403 403
(284, 60) (284, 60) (284, 60) (284, 60)
(284, 60) (284, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 404 | Acuracia_1: 0 | Contagem Geral: 15.0 
Ordem Natural: 7.0
Entrada: 1.97
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8182
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
344
404 404
(285, 60) (285, 60) (285, 60) (285, 60)
(285, 60) (285, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 405 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 7.0
Entrada: 7.09
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
345
405 405
(286, 60) (286, 60) (286, 60) (286, 60)
(286, 60) (286, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 406 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 8.0
Entrada: 3.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 54.3478
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
346
406 406
(287, 60) (287, 60) (287, 60) (287, 60)
(287, 60) (287, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 407 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 9.0
Entrada: 1.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 55.3191
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
347
407 407
(288, 60) (288, 60) (288, 60) (288, 60)
(288, 60) (288, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 408 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 9.0
Entrada: 1.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 56.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
348
408 408
(289, 60) (289, 60) (289, 60) (289, 60)
(289, 60) (289, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 409 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 9.0
Entrada: 3.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 55.102
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
349
409 409
(290, 60) (290, 60) (290, 60) (290, 60)
(290, 60) (290, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 410 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 10.0
Entrada: 2.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 56.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
350
410 410
(291, 60) (291, 60) (291, 60) (291, 60)
(291, 60) (291, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 411 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 10.0
Entrada: 2.01
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 56.8627
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
351
411 411
(292, 60) (292, 60) (292, 60) (292, 60)
(292, 60) (292, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 412 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 10.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 57.6923
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
352
412 412
(293, 60) (293, 60) (293, 60) (293, 60)
(293, 60) (293, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 413 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 10.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 12.5 | Acuracia_0: 0 
Precisao modelo Geral: 58.4906
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
353
413 413
(294, 60) (294, 60) (294, 60) (294, 60)
(294, 60) (294, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 414 | Acuracia_1: 0 | Contagem Geral: 16.0 
Ordem Natural: 10.0
Entrada: 4.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 17.6471 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.2593
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
354
414 414
(295, 60) (295, 60) (295, 60) (295, 60)
(295, 60) (295, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 415 | Acuracia_1: 0 | Contagem Geral: 17.0 
Ordem Natural: 11.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 17.6471 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
355
415 415
(296, 60) (296, 60) (296, 60) (296, 60)
(296, 60) (296, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 416 | Acuracia_1: 0 | Contagem Geral: 17.0 
Ordem Natural: 11.0
Entrada: 110.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 17.6471 | Acuracia_0: 0 
Precisao modelo Geral: 58.9286
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
356
416 416
(297, 60) (297, 60) (297, 60) (297, 60)
(297, 60) (297, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 417 | Acuracia_1: 0 | Contagem Geral: 17.0 
Ordem Natural: 12.0
Entrada: 3.02
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.6491
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
357
417 417
(298, 60) (298, 60) (298, 60) (298, 60)
(298, 60) (298, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 418 | Acuracia_1: 0 | Contagem Geral: 18.0 
Ordem Natural: 13.0
Entrada: 6.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.3158 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.3448
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
358
418 418
(299, 60) (299, 60) (299, 60) (299, 60)
(299, 60) (299, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 419 | Acuracia_1: 0 | Contagem Geral: 19.0 
Ordem Natural: 14.0
Entrada: 396.9
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.3158 | Acuracia_0: 0 
Precisao modelo Geral: 59.322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
359
419 419
(300, 60) (300, 60) (300, 60) (300, 60)
(300, 60) (300, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 420 | Acuracia_1: 0 | Contagem Geral: 19.0 
Ordem Natural: 15.0
Entrada: 2.35
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.3158 | Acuracia_60: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
360
420 420
(301, 60) (301, 60) (301, 60) (301, 60)
(301, 60) (301, 60)
Matrix_60: [(301, 60), (301, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1863 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.3459 - val_loss: 0.1718 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.1667 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1899 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.3939 - val_loss: 0.1740 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2308 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1795 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.4000 - val_loss: 0.1747 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2308 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1790 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.3676 - val_loss: 0.1764 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2000 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1766 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.4028 - val_loss: 0.1759 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.2581 - 48ms/epoch - 48ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.4627 - val_loss: 0.1747 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 49ms/epoch - 49ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1712 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.4262 - val_loss: 0.1747 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1717 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - f1_score: 0.4148 - val_loss: 0.1745 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1737 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.3810 - val_loss: 0.1745 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2424 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1710 - accuracy: 0.5417 - precision: 0.5417 - recall: 0.5417 - f1_score: 0.4380 - val_loss: 0.1743 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4444 - val_loss: 0.1733 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4553 - val_loss: 0.1726 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2000 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1774 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.4194 - val_loss: 0.1729 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.2581 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1753 - accuracy: 0.5774 - precision: 0.5774 - recall: 0.5774 - f1_score: 0.4034 - val_loss: 0.1745 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5238 - val_loss: 0.1771 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.3684 - 48ms/epoch - 48ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.5595 - precision: 0.5595 - recall: 0.5595 - f1_score: 0.4638 - val_loss: 0.1778 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.3684 - 48ms/epoch - 48ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5312 - val_loss: 0.1785 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.3684 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.5000 - val_loss: 0.1783 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3784 - 49ms/epoch - 49ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1592 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5672 - val_loss: 0.1774 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3529 - 48ms/epoch - 48ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.4889 - val_loss: 0.1763 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.4833 - val_loss: 0.1763 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5556 - val_loss: 0.1755 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5414 - val_loss: 0.1744 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 48ms/epoch - 48ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.4800 - val_loss: 0.1738 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4806 - val_loss: 0.1728 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.2963 - 49ms/epoch - 49ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6964 - precision: 0.6964 - recall: 0.6964 - f1_score: 0.5565 - val_loss: 0.1735 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5517 - val_loss: 0.1754 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1544 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5344 - val_loss: 0.1766 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5000 - val_loss: 0.1782 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 48ms/epoch - 48ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1513 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.6000 - val_loss: 0.1781 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5246 - val_loss: 0.1797 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3125 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1503 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5649 - val_loss: 0.1795 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3125 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1455 - accuracy: 0.6964 - precision: 0.6964 - recall: 0.6964 - f1_score: 0.5984 - val_loss: 0.1780 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.2581 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5147 - val_loss: 0.1760 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 51ms/epoch - 51ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1484 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5556 - val_loss: 0.1738 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1496 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5128 - val_loss: 0.1717 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 48ms/epoch - 48ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1509 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5043 - val_loss: 0.1714 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3200 - 50ms/epoch - 50ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1405 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - f1_score: 0.6140 - val_loss: 0.1717 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3200 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1444 - accuracy: 0.7560 - precision: 0.7560 - recall: 0.7560 - f1_score: 0.6555 - val_loss: 0.1725 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3200 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1400 - accuracy: 0.7440 - precision: 0.7440 - recall: 0.7440 - f1_score: 0.6387 - val_loss: 0.1723 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1394 - accuracy: 0.7440 - precision: 0.7440 - recall: 0.7440 - f1_score: 0.6195 - val_loss: 0.1724 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1276 - accuracy: 0.7619 - precision: 0.7619 - recall: 0.7619 - f1_score: 0.6610 - val_loss: 0.1698 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.2609 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1531 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - f1_score: 0.5299 - val_loss: 0.1691 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.1818 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1343 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.6034 - val_loss: 0.1687 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.1818 - 53ms/epoch - 53ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1493 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.5455 - val_loss: 0.1707 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.2609 - 48ms/epoch - 48ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1397 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - f1_score: 0.6452 - val_loss: 0.1726 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.2500 - 48ms/epoch - 48ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1435 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5391 - val_loss: 0.1762 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3704 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1349 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.6129 - val_loss: 0.1777 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3704 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1233 - accuracy: 0.7560 - precision: 0.7560 - recall: 0.7560 - f1_score: 0.6667 - val_loss: 0.1772 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 49ms/epoch - 49ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1297 - accuracy: 0.7798 - precision: 0.7798 - recall: 0.7798 - f1_score: 0.7040 - val_loss: 0.1750 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.1667 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1713
Accuracy: 0.5604
Precision: 0.5604
Recall: 0.5604
F1 Score: 0.3939
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
360
420 420
(301, 60) (301, 60) (301, 60) (301, 60)
(301, 60) (301, 60)
Matrix_60: [(301, 60), (301, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2208 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.0000e+00 - val_loss: 0.1557 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.1667 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1992 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.2222 - val_loss: 0.1795 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.3721 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1806 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - f1_score: 0.3540 - val_loss: 0.2042 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3922 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1861 - accuracy: 0.3929 - precision: 0.3929 - recall: 0.3929 - f1_score: 0.3704 - val_loss: 0.2227 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3922 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1787 - accuracy: 0.4226 - precision: 0.4226 - recall: 0.4226 - f1_score: 0.4699 - val_loss: 0.2326 - val_accuracy: 0.2381 - val_precision: 0.2381 - val_recall: 0.2381 - val_f1_score: 0.3846 - 52ms/epoch - 52ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1849 - accuracy: 0.3214 - precision: 0.3214 - recall: 0.3214 - f1_score: 0.4242 - val_loss: 0.2325 - val_accuracy: 0.2381 - val_precision: 0.2381 - val_recall: 0.2381 - val_f1_score: 0.3846 - 48ms/epoch - 48ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1902 - accuracy: 0.3095 - precision: 0.3095 - recall: 0.3095 - f1_score: 0.4423 - val_loss: 0.2250 - val_accuracy: 0.2381 - val_precision: 0.2381 - val_recall: 0.2381 - val_f1_score: 0.3846 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1846 - accuracy: 0.3095 - precision: 0.3095 - recall: 0.3095 - f1_score: 0.4200 - val_loss: 0.2149 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3922 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1752 - accuracy: 0.3750 - precision: 0.3750 - recall: 0.3750 - f1_score: 0.4444 - val_loss: 0.2043 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3922 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.3869 - precision: 0.3869 - recall: 0.3869 - f1_score: 0.4372 - val_loss: 0.1943 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3922 - 75ms/epoch - 75ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.4762 - precision: 0.4762 - recall: 0.4762 - f1_score: 0.4634 - val_loss: 0.1852 - val_accuracy: 0.2619 - val_precision: 0.2619 - val_recall: 0.2619 - val_f1_score: 0.3673 - 85ms/epoch - 85ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1814 - accuracy: 0.4345 - precision: 0.4345 - recall: 0.4345 - f1_score: 0.3709 - val_loss: 0.1774 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.3684 - 75ms/epoch - 75ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1759 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.4286 - val_loss: 0.1716 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3871 - 79ms/epoch - 79ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1672 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.4587 - val_loss: 0.1678 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.2609 - 60ms/epoch - 60ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.4000 - val_loss: 0.1654 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.2105 - 78ms/epoch - 78ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1760 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.3371 - val_loss: 0.1647 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.2222 - 57ms/epoch - 57ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.3721 - val_loss: 0.1652 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.2857 - 81ms/epoch - 81ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.4419 - val_loss: 0.1667 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.3333 - 72ms/epoch - 72ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.4200 - val_loss: 0.1690 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.4138 - 54ms/epoch - 54ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1703 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.3883 - val_loss: 0.1724 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.4000 - 63ms/epoch - 63ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.4727 - val_loss: 0.1766 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4444 - 56ms/epoch - 56ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.5203 - val_loss: 0.1810 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4211 - 56ms/epoch - 56ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5417 - val_loss: 0.1852 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.4000 - 57ms/epoch - 57ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4722 - val_loss: 0.1888 - val_accuracy: 0.3095 - val_precision: 0.3095 - val_recall: 0.3095 - val_f1_score: 0.4082 - 52ms/epoch - 52ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.5135 - val_loss: 0.1916 - val_accuracy: 0.3095 - val_precision: 0.3095 - val_recall: 0.3095 - val_f1_score: 0.4082 - 53ms/epoch - 53ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1694 - accuracy: 0.4940 - precision: 0.4940 - recall: 0.4940 - f1_score: 0.4785 - val_loss: 0.1931 - val_accuracy: 0.3095 - val_precision: 0.3095 - val_recall: 0.3095 - val_f1_score: 0.4082 - 70ms/epoch - 70ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.4545 - val_loss: 0.1936 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4167 - 83ms/epoch - 83ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5714 - val_loss: 0.1926 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4167 - 142ms/epoch - 142ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.5211 - val_loss: 0.1912 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.4255 - 141ms/epoch - 141ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - f1_score: 0.5101 - val_loss: 0.1887 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.4186 - 168ms/epoch - 168ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.5205 - val_loss: 0.1862 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.3415 - 73ms/epoch - 73ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.5152 - val_loss: 0.1840 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.3500 - 65ms/epoch - 65ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5547 - val_loss: 0.1823 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3889 - 67ms/epoch - 67ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5254 - val_loss: 0.1807 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 60ms/epoch - 60ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5691 - val_loss: 0.1798 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 74ms/epoch - 74ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.5789 - val_loss: 0.1794 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 63ms/epoch - 63ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1565 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5574 - val_loss: 0.1787 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 83ms/epoch - 83ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - f1_score: 0.6050 - val_loss: 0.1791 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 74ms/epoch - 74ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5517 - val_loss: 0.1798 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 58ms/epoch - 58ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5667 - val_loss: 0.1811 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 59ms/epoch - 59ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1544 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - f1_score: 0.5455 - val_loss: 0.1823 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 72ms/epoch - 72ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.4865 - val_loss: 0.1839 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 86ms/epoch - 86ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1492 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.6032 - val_loss: 0.1848 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 59ms/epoch - 59ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1545 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5289 - val_loss: 0.1859 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 72ms/epoch - 72ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1538 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5440 - val_loss: 0.1870 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 71ms/epoch - 71ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1508 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.5763 - val_loss: 0.1875 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 52ms/epoch - 52ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1452 - accuracy: 0.7321 - precision: 0.7321 - recall: 0.7321 - f1_score: 0.6154 - val_loss: 0.1869 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3636 - 76ms/epoch - 76ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1400 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - f1_score: 0.6116 - val_loss: 0.1849 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 57ms/epoch - 57ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1436 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.5932 - val_loss: 0.1832 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 53ms/epoch - 53ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1452 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.6034 - val_loss: 0.1820 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 52ms/epoch - 52ms/step

🔍 Resultados no Teste:
Loss: 0.1763
Accuracy: 0.4725
Precision: 0.4725
Recall: 0.4725
F1 Score: 0.3684
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
360
420 420
(301, 60) (301, 60) (301, 60) (301, 60)
(301, 60) (301, 60)
Matrix_60: [(301, 60), (301, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2021 - accuracy: 0.3631 - precision: 0.3631 - recall: 0.3631 - f1_score: 0.4216 - val_loss: 0.1611 - val_accuracy: 0.8095 - val_precision: 0.8095 - val_recall: 0.8095 - val_f1_score: 0.6667 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1853 - accuracy: 0.4940 - precision: 0.4940 - recall: 0.4940 - f1_score: 0.4295 - val_loss: 0.1467 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.1667 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1895 - accuracy: 0.5417 - precision: 0.5417 - recall: 0.5417 - f1_score: 0.2667 - val_loss: 0.1444 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.1818 - 48ms/epoch - 48ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1915 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.3030 - val_loss: 0.1476 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.1667 - 54ms/epoch - 54ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1789 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.2857 - val_loss: 0.1529 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.2667 - 48ms/epoch - 48ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1749 - accuracy: 0.5179 - precision: 0.5179 - recall: 0.5179 - f1_score: 0.3306 - val_loss: 0.1583 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.4706 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.4203 - val_loss: 0.1632 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.5926 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1738 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.4247 - val_loss: 0.1675 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.5333 - 49ms/epoch - 49ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1847 - accuracy: 0.4345 - precision: 0.4345 - recall: 0.4345 - f1_score: 0.3871 - val_loss: 0.1710 - val_accuracy: 0.6905 - val_precision: 0.6905 - val_recall: 0.6905 - val_f1_score: 0.5806 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1785 - accuracy: 0.4048 - precision: 0.4048 - recall: 0.4048 - f1_score: 0.3827 - val_loss: 0.1730 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.5294 - 51ms/epoch - 51ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1740 - accuracy: 0.4583 - precision: 0.4583 - recall: 0.4583 - f1_score: 0.4615 - val_loss: 0.1730 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.5143 - 48ms/epoch - 48ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1723 - accuracy: 0.4583 - precision: 0.4583 - recall: 0.4583 - f1_score: 0.4615 - val_loss: 0.1717 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.5455 - 57ms/epoch - 57ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1743 - accuracy: 0.4286 - precision: 0.4286 - recall: 0.4286 - f1_score: 0.4217 - val_loss: 0.1689 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.5333 - 48ms/epoch - 48ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4722 - val_loss: 0.1663 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.5000 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.4507 - val_loss: 0.1638 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143 - val_f1_score: 0.4545 - 53ms/epoch - 53ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.4390 - val_loss: 0.1621 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.4211 - 48ms/epoch - 48ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.5595 - precision: 0.5595 - recall: 0.5595 - f1_score: 0.4219 - val_loss: 0.1610 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.4706 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1661 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4407 - val_loss: 0.1607 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.4706 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4370 - val_loss: 0.1608 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 0.7857 - val_f1_score: 0.4706 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1702 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4000 - val_loss: 0.1618 - val_accuracy: 0.7619 - val_precision: 0.7619 - val_recall: 0.7619 - val_f1_score: 0.4444 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4706 - val_loss: 0.1634 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.4211 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4962 - val_loss: 0.1647 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.4000 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5197 - val_loss: 0.1660 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.3846 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.5152 - val_loss: 0.1675 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.4286 - 48ms/epoch - 48ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5652 - val_loss: 0.1686 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.4138 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.5417 - precision: 0.5417 - recall: 0.5417 - f1_score: 0.4762 - val_loss: 0.1683 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.4138 - 48ms/epoch - 48ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.5595 - precision: 0.5595 - recall: 0.5595 - f1_score: 0.4932 - val_loss: 0.1673 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.2963 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5286 - val_loss: 0.1661 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 51ms/epoch - 51ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4361 - val_loss: 0.1648 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.2500 - 48ms/epoch - 48ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1661 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5000 - val_loss: 0.1627 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3000 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1546 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.5833 - val_loss: 0.1614 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3000 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1512 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - f1_score: 0.6308 - val_loss: 0.1604 - val_accuracy: 0.7381 - val_precision: 0.7381 - val_recall: 0.7381 - val_f1_score: 0.3529 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1626 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.4821 - val_loss: 0.1610 - val_accuracy: 0.6905 - val_precision: 0.6905 - val_recall: 0.6905 - val_f1_score: 0.3158 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1595 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5225 - val_loss: 0.1623 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1545 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5439 - val_loss: 0.1644 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.2609 - 51ms/epoch - 51ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1580 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.5614 - val_loss: 0.1671 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 48ms/epoch - 48ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1556 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.5354 - val_loss: 0.1698 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.4138 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1595 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5271 - val_loss: 0.1728 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3871 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1617 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.5211 - val_loss: 0.1738 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.4375 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1468 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.6029 - val_loss: 0.1724 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.4138 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1519 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5811 - val_loss: 0.1680 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3200 - 51ms/epoch - 51ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.5109 - val_loss: 0.1634 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.2500 - 48ms/epoch - 48ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5344 - val_loss: 0.1592 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1509 - accuracy: 0.7024 - precision: 0.7024 - recall: 0.7024 - f1_score: 0.5370 - val_loss: 0.1574 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1525 - accuracy: 0.6964 - precision: 0.6964 - recall: 0.6964 - f1_score: 0.5234 - val_loss: 0.1576 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1416 - accuracy: 0.7440 - precision: 0.7440 - recall: 0.7440 - f1_score: 0.6126 - val_loss: 0.1595 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1505 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.5893 - val_loss: 0.1625 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1524 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5620 - val_loss: 0.1667 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.2963 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1385 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.6406 - val_loss: 0.1694 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1404 - accuracy: 0.7440 - precision: 0.7440 - recall: 0.7440 - f1_score: 0.6504 - val_loss: 0.1712 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3448 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1787
Accuracy: 0.5055
Precision: 0.5055
Recall: 0.5055
F1 Score: 0.3284
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
360
420 420
(301, 60) (301, 60) (301, 60) (301, 60)
(301, 60) (301, 60)
Matrix_60: [(301, 60), (301, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2304 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.0690 - val_loss: 0.1589 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.0000e+00 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1914 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - f1_score: 0.2617 - val_loss: 0.1786 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.2031 - accuracy: 0.4762 - precision: 0.4762 - recall: 0.4762 - f1_score: 0.3433 - val_loss: 0.1948 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.2857 - 48ms/epoch - 48ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1965 - accuracy: 0.3869 - precision: 0.3869 - recall: 0.3869 - f1_score: 0.3522 - val_loss: 0.2002 - val_accuracy: 0.2143 - val_precision: 0.2143 - val_recall: 0.2143 - val_f1_score: 0.2667 - 47ms/epoch - 47ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1908 - accuracy: 0.4464 - precision: 0.4464 - recall: 0.4464 - f1_score: 0.4497 - val_loss: 0.1964 - val_accuracy: 0.2143 - val_precision: 0.2143 - val_recall: 0.2143 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1845 - accuracy: 0.3988 - precision: 0.3988 - recall: 0.3988 - f1_score: 0.4024 - val_loss: 0.1890 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.3158 - 48ms/epoch - 48ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.4524 - precision: 0.4524 - recall: 0.4524 - f1_score: 0.4177 - val_loss: 0.1809 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2857 - 48ms/epoch - 48ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1783 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.3916 - val_loss: 0.1740 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1826 - accuracy: 0.5595 - precision: 0.5595 - recall: 0.5595 - f1_score: 0.3393 - val_loss: 0.1694 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.1000 - 48ms/epoch - 48ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1775 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.3929 - val_loss: 0.1665 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1828 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.3243 - val_loss: 0.1648 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.0000e+00 - 47ms/epoch - 47ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1823 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.3774 - val_loss: 0.1642 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1711 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.4314 - val_loss: 0.1644 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.7262 - precision: 0.7262 - recall: 0.7262 - f1_score: 0.5106 - val_loss: 0.1655 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1753 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.3689 - val_loss: 0.1672 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.3619 - val_loss: 0.1699 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4074 - val_loss: 0.1729 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.1538 - 48ms/epoch - 48ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1656 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4576 - val_loss: 0.1759 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 50ms/epoch - 50ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1732 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - f1_score: 0.3780 - val_loss: 0.1789 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 52ms/epoch - 52ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4898 - val_loss: 0.1814 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3429 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.4762 - precision: 0.4762 - recall: 0.4762 - f1_score: 0.4286 - val_loss: 0.1828 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.3243 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4755 - val_loss: 0.1832 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.3243 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1667 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.4459 - val_loss: 0.1828 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.3243 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.5352 - val_loss: 0.1817 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3429 - 48ms/epoch - 48ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4828 - val_loss: 0.1799 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2941 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.4706 - val_loss: 0.1779 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3125 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.5038 - val_loss: 0.1758 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2222 - 48ms/epoch - 48ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4878 - val_loss: 0.1743 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1600 - 48ms/epoch - 48ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1575 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5333 - val_loss: 0.1731 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.4697 - val_loss: 0.1721 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 51ms/epoch - 51ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1562 - accuracy: 0.7083 - precision: 0.7083 - recall: 0.7083 - f1_score: 0.5739 - val_loss: 0.1716 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1565 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.5124 - val_loss: 0.1713 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 51ms/epoch - 51ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5439 - val_loss: 0.1715 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5345 - val_loss: 0.1728 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 48ms/epoch - 48ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5345 - val_loss: 0.1751 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.1667 - 48ms/epoch - 48ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5312 - val_loss: 0.1768 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.2400 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5156 - val_loss: 0.1783 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1617 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.5224 - val_loss: 0.1804 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5821 - val_loss: 0.1815 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3226 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1565 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5373 - val_loss: 0.1816 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3125 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1594 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.4961 - val_loss: 0.1811 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1516 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5512 - val_loss: 0.1805 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.4531 - val_loss: 0.1799 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1507 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5161 - val_loss: 0.1794 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 47ms/epoch - 47ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1507 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5538 - val_loss: 0.1777 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3077 - 48ms/epoch - 48ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1583 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4960 - val_loss: 0.1758 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.2500 - 47ms/epoch - 47ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - f1_score: 0.5045 - val_loss: 0.1749 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1501 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5500 - val_loss: 0.1740 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 51ms/epoch - 51ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1547 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5000 - val_loss: 0.1744 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 49ms/epoch - 49ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1461 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5410 - val_loss: 0.1750 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1739 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1693
Accuracy: 0.5604
Precision: 0.5604
Recall: 0.5604
F1 Score: 0.3939
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
360
420 420
(301, 60) (301, 60) (301, 60) (301, 60)
(301, 60) (301, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 78ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 421 | Acuracia_1: 0 | Contagem Geral: 19.0 
Ordem Natural: 15.0
Entrada: 2.03
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.0164
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
361
421 421
(302, 60) (302, 60) (302, 60) (302, 60)
(302, 60) (302, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 422 | Acuracia_1: 0.0 | Contagem Geral: 20.0 
Ordem Natural: 15.0
Entrada: 6.36
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
362
422 422
(303, 60) (303, 60) (303, 60) (303, 60)
(303, 60) (303, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 423 | Acuracia_1: 0 | Contagem Geral: 20.0 
Ordem Natural: 16.0
Entrada: 1.32
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
363
423 423
(304, 60) (304, 60) (304, 60) (304, 60)
(304, 60) (304, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 424 | Acuracia_1: 0 | Contagem Geral: 21.0 
Ordem Natural: 16.0
Entrada: 36.54
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 0 
Precisao modelo Geral: 56.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
364
424 424
(305, 60) (305, 60) (305, 60) (305, 60)
(305, 60) (305, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 425 | Acuracia_1: 1.0 | Contagem Geral: 21.0 
Ordem Natural: 17.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.9231
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
365
425 425
(306, 60) (306, 60) (306, 60) (306, 60)
(306, 60) (306, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 426 | Acuracia_1: 0.0 | Contagem Geral: 21.0 
Ordem Natural: 17.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.5758
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
366
426 426
(307, 60) (307, 60) (307, 60) (307, 60)
(307, 60) (307, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 427 | Acuracia_1: 0 | Contagem Geral: 21.0 
Ordem Natural: 17.0
Entrada: 3.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 0 
Precisao modelo Geral: 56.7164
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
367
427 427
(308, 60) (308, 60) (308, 60) (308, 60)
(308, 60) (308, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 428 | Acuracia_1: 0 | Contagem Geral: 21.0 
Ordem Natural: 18.0
Entrada: 1.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.8095 | Acuracia_0: 0 
Precisao modelo Geral: 57.3529
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
368
428 428
(309, 60) (309, 60) (309, 60) (309, 60)
(309, 60) (309, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 429 | Acuracia_1: 0 | Contagem Geral: 21.0 
Ordem Natural: 18.0
Entrada: 1.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.5217
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
369
429 429
(310, 60) (310, 60) (310, 60) (310, 60)
(310, 60) (310, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 430 | Acuracia_1: 0.0 | Contagem Geral: 22.0 
Ordem Natural: 18.0
Entrada: 1.77
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
370
430 430
(311, 60) (311, 60) (311, 60) (311, 60)
(311, 60) (311, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 30ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 431 | Acuracia_1: 0 | Contagem Geral: 22.0 
Ordem Natural: 18.0
Entrada: 1.14
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_0: 0 
Precisao modelo Geral: 57.7465
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
371
431 431
(312, 60) (312, 60) (312, 60) (312, 60)
(312, 60) (312, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 432 | Acuracia_1: 0 | Contagem Geral: 22.0 
Ordem Natural: 18.0
Entrada: 2.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.7273 | Acuracia_0: 0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
372
432 432
(313, 60) (313, 60) (313, 60) (313, 60)
(313, 60) (313, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 433 | Acuracia_1: 0 | Contagem Geral: 22.0 
Ordem Natural: 18.0
Entrada: 5.76
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 26.087 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.9041
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
373
433 433
(314, 60) (314, 60) (314, 60) (314, 60)
(314, 60) (314, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 434 | Acuracia_1: 0 | Contagem Geral: 23.0 
Ordem Natural: 19.0
Entrada: 2.49
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
374
434 434
(315, 60) (315, 60) (315, 60) (315, 60)
(315, 60) (315, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 435 | Acuracia_1: 1.0 | Contagem Geral: 24.0 
Ordem Natural: 19.0
Entrada: 2.22
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_0: 0.5 
Precisao modelo Geral: 57.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
375
435 435
(316, 60) (316, 60) (316, 60) (316, 60)
(316, 60) (316, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 436 | Acuracia_1: 0 | Contagem Geral: 25.0 
Ordem Natural: 19.0
Entrada: 4.26
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 24.0 | Acuracia_0: 0 
Precisao modelo Geral: 56.5789
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
376
436 436
(317, 60) (317, 60) (317, 60) (317, 60)
(317, 60) (317, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 437 | Acuracia_1: 0.0 | Contagem Geral: 25.0 
Ordem Natural: 20.0
Entrada: 2.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.0769 | Acuracia_0: 0.0 
Precisao modelo Geral: 55.8442
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
377
437 437
(318, 60) (318, 60) (318, 60) (318, 60)
(318, 60) (318, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 438 | Acuracia_1: 0 | Contagem Geral: 26.0 
Ordem Natural: 20.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0.0 
Precisao modelo Geral: 55.1282
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
378
438 438
(319, 60) (319, 60) (319, 60) (319, 60)
(319, 60) (319, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 439 | Acuracia_1: 0 | Contagem Geral: 27.0 
Ordem Natural: 20.0
Entrada: 6.54
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0 
Precisao modelo Geral: 54.4304
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
379
439 439
(320, 60) (320, 60) (320, 60) (320, 60)
(320, 60) (320, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 440 | Acuracia_1: 0 | Contagem Geral: 27.0 
Ordem Natural: 21.0
Entrada: 1.31
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0 
Precisao modelo Geral: 55.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
380
440 440
(321, 60) (321, 60) (321, 60) (321, 60)
(321, 60) (321, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 41ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 441 | Acuracia_1: 0 | Contagem Geral: 27.0 
Ordem Natural: 21.0
Entrada: 3.65
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0 
Precisao modelo Geral: 54.321
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
381
441 441
(322, 60) (322, 60) (322, 60) (322, 60)
(322, 60) (322, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 37ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 442 | Acuracia_1: 0.0 | Contagem Geral: 27.0 
Ordem Natural: 22.0
Entrada: 7.93
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 22.2222 | Acuracia_0: 0.0 
Precisao modelo Geral: 53.6585
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
382
442 442
(323, 60) (323, 60) (323, 60) (323, 60)
(323, 60) (323, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 443 | Acuracia_1: 0.0 | Contagem Geral: 27.0 
Ordem Natural: 23.0
Entrada: 1.07
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_0: 0.0 
Precisao modelo Geral: 53.012
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
383
443 443
(324, 60) (324, 60) (324, 60) (324, 60)
(324, 60) (324, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 444 | Acuracia_1: 0 | Contagem Geral: 28.0 
Ordem Natural: 23.0
Entrada: 1.51
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_0: 0 
Precisao modelo Geral: 53.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
384
444 444
(325, 60) (325, 60) (325, 60) (325, 60)
(325, 60) (325, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 445 | Acuracia_1: 0 | Contagem Geral: 28.0 
Ordem Natural: 23.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 21.4286 | Acuracia_0: 0 
Precisao modelo Geral: 54.1176
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
385
445 445
(326, 60) (326, 60) (326, 60) (326, 60)
(326, 60) (326, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 39ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 446 | Acuracia_1: 0.0 | Contagem Geral: 28.0 
Ordem Natural: 23.0
Entrada: 1.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.6897 | Acuracia_0: 0.0 
Precisao modelo Geral: 53.4884
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
386
446 446
(327, 60) (327, 60) (327, 60) (327, 60)
(327, 60) (327, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 447 | Acuracia_1: 0 | Contagem Geral: 29.0 
Ordem Natural: 23.0
Entrada: 1.95
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 20.6897 | Acuracia_0: 0 
Precisao modelo Geral: 54.023
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
387
447 447
(328, 60) (328, 60) (328, 60) (328, 60)
(328, 60) (328, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 448 | Acuracia_1: 0.0 | Contagem Geral: 29.0 
Ordem Natural: 23.0
Entrada: 10.11
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 23.3333 | Acuracia_0: 0.5 
Precisao modelo Geral: 54.5455
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
388
448 448
(329, 60) (329, 60) (329, 60) (329, 60)
(329, 60) (329, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 31ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 449 | Acuracia_1: 0 | Contagem Geral: 30.0 
Ordem Natural: 24.0
Entrada: 3.88
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8065 | Acuracia_0: 1.0 
Precisao modelo Geral: 55.0562
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
389
449 449
(330, 60) (330, 60) (330, 60) (330, 60)
(330, 60) (330, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 450 | Acuracia_1: 0.0 | Contagem Geral: 31.0 
Ordem Natural: 25.0
Entrada: 1.62
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8065 | Acuracia_0: 0.0 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
390
450 450
(331, 60) (331, 60) (331, 60) (331, 60)
(331, 60) (331, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 451 | Acuracia_1: 0 | Contagem Geral: 31.0 
Ordem Natural: 25.0
Entrada: 1.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 25.8065 | Acuracia_0: 0 
Precisao modelo Geral: 56.044
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
391
451 451
(332, 60) (332, 60) (332, 60) (332, 60)
(332, 60) (332, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 452 | Acuracia_1: 0 | Contagem Geral: 31.0 
Ordem Natural: 25.0
Entrada: 5.29
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.5217
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
392
452 452
(333, 60) (333, 60) (333, 60) (333, 60)
(333, 60) (333, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 453 | Acuracia_1: 0 | Contagem Geral: 32.0 
Ordem Natural: 26.0
Entrada: 5.08
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.9892
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
393
453 453
(334, 60) (334, 60) (334, 60) (334, 60)
(334, 60) (334, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 454 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 27.0
Entrada: 1.34
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0 
Precisao modelo Geral: 57.4468
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
394
454 454
(335, 60) (335, 60) (335, 60) (335, 60)
(335, 60) (335, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 455 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 27.0
Entrada: 1.96
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0 
Precisao modelo Geral: 57.8947
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
395
455 455
(336, 60) (336, 60) (336, 60) (336, 60)
(336, 60) (336, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 456 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 27.0
Entrada: 9.45
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0 
Precisao modelo Geral: 57.2917
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
396
456 456
(337, 60) (337, 60) (337, 60) (337, 60)
(337, 60) (337, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 457 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 28.0
Entrada: 2.52
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0 
Precisao modelo Geral: 57.732
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
397
457 457
(338, 60) (338, 60) (338, 60) (338, 60)
(338, 60) (338, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 458 | Acuracia_1: 0.0 | Contagem Geral: 33.0 
Ordem Natural: 28.0
Entrada: 1.17
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1633
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
398
458 458
(339, 60) (339, 60) (339, 60) (339, 60)
(339, 60) (339, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 459 | Acuracia_1: 0.0 | Contagem Geral: 33.0 
Ordem Natural: 28.0
Entrada: 1.11
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.5859
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
399
459 459
(340, 60) (340, 60) (340, 60) (340, 60)
(340, 60) (340, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 460 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 28.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.303 | Acuracia_0: 0 
Precisao modelo Geral: 59.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
400
460 460
(341, 60) (341, 60) (341, 60) (341, 60)
(341, 60) (341, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 461 | Acuracia_1: 0 | Contagem Geral: 33.0 
Ordem Natural: 28.0
Entrada: 1.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.4158
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
401
461 461
(342, 60) (342, 60) (342, 60) (342, 60)
(342, 60) (342, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 462 | Acuracia_1: 0.0 | Contagem Geral: 34.0 
Ordem Natural: 28.0
Entrada: 17.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.4286 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
402
462 462
(343, 60) (343, 60) (343, 60) (343, 60)
(343, 60) (343, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 463 | Acuracia_1: 0.0 | Contagem Geral: 35.0 
Ordem Natural: 29.0
Entrada: 1.13
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5556 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.2524
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
403
463 463
(344, 60) (344, 60) (344, 60) (344, 60)
(344, 60) (344, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 464 | Acuracia_1: 0.0 | Contagem Geral: 36.0 
Ordem Natural: 29.0
Entrada: 4.4
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5556 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6923
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
404
464 464
(345, 60) (345, 60) (345, 60) (345, 60)
(345, 60) (345, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 465 | Acuracia_1: 0 | Contagem Geral: 36.0 
Ordem Natural: 30.0
Entrada: 1.61
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7297 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
405
465 465
(346, 60) (346, 60) (346, 60) (346, 60)
(346, 60) (346, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 466 | Acuracia_1: 0 | Contagem Geral: 37.0 
Ordem Natural: 30.0
Entrada: 1.14
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9474 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.6038
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
406
466 466
(347, 60) (347, 60) (347, 60) (347, 60)
(347, 60) (347, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 467 | Acuracia_1: 0 | Contagem Geral: 38.0 
Ordem Natural: 30.0
Entrada: 4.59
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.0093
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
407
467 467
(348, 60) (348, 60) (348, 60) (348, 60)
(348, 60) (348, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 468 | Acuracia_1: 0 | Contagem Geral: 39.0 
Ordem Natural: 31.0
Entrada: 1.1
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.7692 | Acuracia_0: 0 
Precisao modelo Geral: 57.4074
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
408
468 468
(349, 60) (349, 60) (349, 60) (349, 60)
(349, 60) (349, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 469 | Acuracia_1: 0 | Contagem Geral: 39.0 
Ordem Natural: 31.0
Entrada: 1.18
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8807
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
409
469 469
(350, 60) (350, 60) (350, 60) (350, 60)
(350, 60) (350, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 470 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 31.0
Entrada: 4.53
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 56.3636
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
410
470 470
(351, 60) (351, 60) (351, 60) (351, 60)
(351, 60) (351, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 471 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 32.0
Entrada: 112.64
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.8559
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
411
471 471
(352, 60) (352, 60) (352, 60) (352, 60)
(352, 60) (352, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 472 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 33.0
Entrada: 1.05
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 56.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
412
472 472
(353, 60) (353, 60) (353, 60) (353, 60)
(353, 60) (353, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 473 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 33.0
Entrada: 247.98
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.7522
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
413
473 473
(354, 60) (354, 60) (354, 60) (354, 60)
(354, 60) (354, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 474 | Acuracia_1: 1.0 | Contagem Geral: 40.0 
Ordem Natural: 34.0
Entrada: 3.65
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 1.0 
Precisao modelo Geral: 55.2632
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
414
474 474
(355, 60) (355, 60) (355, 60) (355, 60)
(355, 60) (355, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 475 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 35.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 55.6522
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
415
475 475
(356, 60) (356, 60) (356, 60) (356, 60)
(356, 60) (356, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 476 | Acuracia_1: 0 | Contagem Geral: 40.0 
Ordem Natural: 35.0
Entrada: 1.21
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 56.0345
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
416
476 476
(357, 60) (357, 60) (357, 60) (357, 60)
(357, 60) (357, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 477 | Acuracia_1: 1.0 | Contagem Geral: 40.0 
Ordem Natural: 35.0
Entrada: 1.46
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2683 | Acuracia_0: 0.5 
Precisao modelo Geral: 55.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
417
477 477
(358, 60) (358, 60) (358, 60) (358, 60)
(358, 60) (358, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 478 | Acuracia_1: 1.0 | Contagem Geral: 41.0 
Ordem Natural: 35.0
Entrada: 1.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2683 | Acuracia_0: 1.0 
Precisao modelo Geral: 55.9322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
418
478 478
(359, 60) (359, 60) (359, 60) (359, 60)
(359, 60) (359, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 479 | Acuracia_1: 0 | Contagem Geral: 41.0 
Ordem Natural: 35.0
Entrada: 1.16
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2683 | Acuracia_0: 0 
Precisao modelo Geral: 56.3025
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
419
479 479
(360, 60) (360, 60) (360, 60) (360, 60)
(360, 60) (360, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 480 | Acuracia_1: 0 | Contagem Geral: 41.0 
Ordem Natural: 35.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_60: 0.0 
Precisao modelo Geral: 55.8333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1972 - accuracy: 0.3184 - precision: 0.3184 - recall: 0.3184 - f1_score: 0.4017 - val_loss: 0.1731 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.5000 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1799 - accuracy: 0.4378 - precision: 0.4378 - recall: 0.4378 - f1_score: 0.3543 - val_loss: 0.1644 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.1667 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1754 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.3077 - val_loss: 0.1620 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1827 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.1905 - val_loss: 0.1618 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1776 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.2444 - val_loss: 0.1620 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.2118 - val_loss: 0.1625 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1780 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.2653 - val_loss: 0.1635 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1734 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.2832 - val_loss: 0.1648 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5572 - precision: 0.5572 - recall: 0.5572 - f1_score: 0.3407 - val_loss: 0.1662 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.0800 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - f1_score: 0.3311 - val_loss: 0.1673 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.2143 - 48ms/epoch - 48ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1732 - accuracy: 0.5124 - precision: 0.5124 - recall: 0.5124 - f1_score: 0.3875 - val_loss: 0.1680 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.2069 - 57ms/epoch - 57ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.4419 - val_loss: 0.1683 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.4353 - val_loss: 0.1683 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.2667 - 54ms/epoch - 54ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1688 - accuracy: 0.5274 - precision: 0.5274 - recall: 0.5274 - f1_score: 0.4633 - val_loss: 0.1680 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2759 - 48ms/epoch - 48ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.5323 - precision: 0.5323 - recall: 0.5323 - f1_score: 0.4471 - val_loss: 0.1674 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2759 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.5721 - precision: 0.5721 - recall: 0.5721 - f1_score: 0.4691 - val_loss: 0.1665 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.1538 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.5174 - precision: 0.5174 - recall: 0.5174 - f1_score: 0.3822 - val_loss: 0.1656 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6020 - precision: 0.6020 - recall: 0.6020 - f1_score: 0.4203 - val_loss: 0.1649 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.4394 - val_loss: 0.1642 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1654 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4390 - val_loss: 0.1637 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.3833 - val_loss: 0.1634 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1643 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.3860 - val_loss: 0.1632 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 53ms/epoch - 53ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1634 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.3684 - val_loss: 0.1631 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.3750 - val_loss: 0.1631 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.4821 - val_loss: 0.1631 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1632 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4000 - val_loss: 0.1633 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0952 - 51ms/epoch - 51ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.3937 - val_loss: 0.1636 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.0909 - 51ms/epoch - 51ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1626 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4706 - val_loss: 0.1640 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1600 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4348 - val_loss: 0.1646 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2222 - 49ms/epoch - 49ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.5072 - val_loss: 0.1650 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2759 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1609 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4228 - val_loss: 0.1653 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.6368 - precision: 0.6368 - recall: 0.6368 - f1_score: 0.4823 - val_loss: 0.1651 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.5634 - val_loss: 0.1643 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4531 - val_loss: 0.1636 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4923 - val_loss: 0.1627 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5289 - val_loss: 0.1619 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1537 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.4839 - val_loss: 0.1611 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3448 - 49ms/epoch - 49ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4844 - val_loss: 0.1608 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3448 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.3932 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5469 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1526 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5574 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6020 - precision: 0.6020 - recall: 0.6020 - f1_score: 0.3939 - val_loss: 0.1607 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 50ms/epoch - 50ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1536 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4878 - val_loss: 0.1608 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 53ms/epoch - 53ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1455 - accuracy: 0.7264 - precision: 0.7264 - recall: 0.7264 - f1_score: 0.5865 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 51ms/epoch - 51ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1494 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.5556 - val_loss: 0.1599 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4571 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1518 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.5152 - val_loss: 0.1592 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4706 - 49ms/epoch - 49ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1411 - accuracy: 0.7562 - precision: 0.7562 - recall: 0.7562 - f1_score: 0.6202 - val_loss: 0.1584 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1475 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5606 - val_loss: 0.1577 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1437 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5606 - val_loss: 0.1571 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1480 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.5203 - val_loss: 0.1569 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 48ms/epoch - 48ms/step

🔍 Resultados no Teste:
Loss: 0.1720
Accuracy: 0.5321
Precision: 0.5321
Recall: 0.5321
F1 Score: 0.2154
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1921 - accuracy: 0.4129 - precision: 0.4129 - recall: 0.4129 - f1_score: 0.3587 - val_loss: 0.1768 - val_accuracy: 0.4314 - val_precision: 0.4314 - val_recall: 0.4314 - val_f1_score: 0.2564 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1746 - accuracy: 0.5124 - precision: 0.5124 - recall: 0.5124 - f1_score: 0.3378 - val_loss: 0.1714 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1600 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.3802 - val_loss: 0.1693 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.1000 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1811 - accuracy: 0.6070 - precision: 0.6070 - recall: 0.6070 - f1_score: 0.2330 - val_loss: 0.1691 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0952 - 48ms/epoch - 48ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.2553 - val_loss: 0.1697 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0952 - 51ms/epoch - 51ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.3273 - val_loss: 0.1703 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1711 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.3387 - val_loss: 0.1708 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.6020 - precision: 0.6020 - recall: 0.6020 - f1_score: 0.3443 - val_loss: 0.1713 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.4412 - val_loss: 0.1715 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0741 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - f1_score: 0.3919 - val_loss: 0.1715 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0769 - 50ms/epoch - 50ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.3758 - val_loss: 0.1713 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0769 - 49ms/epoch - 49ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.5473 - precision: 0.5473 - recall: 0.5473 - f1_score: 0.4052 - val_loss: 0.1706 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1699 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.3830 - val_loss: 0.1698 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1653 - accuracy: 0.5871 - precision: 0.5871 - recall: 0.5871 - f1_score: 0.4029 - val_loss: 0.1692 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.3609 - val_loss: 0.1686 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1681 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.3968 - val_loss: 0.1681 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.3448 - val_loss: 0.1678 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.4032 - val_loss: 0.1676 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.3304 - val_loss: 0.1674 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1685 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4000 - val_loss: 0.1675 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.3333 - val_loss: 0.1679 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4237 - val_loss: 0.1683 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1722 - accuracy: 0.5473 - precision: 0.5473 - recall: 0.5473 - f1_score: 0.3053 - val_loss: 0.1689 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.3971 - val_loss: 0.1695 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.4138 - val_loss: 0.1700 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0769 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6368 - precision: 0.6368 - recall: 0.6368 - f1_score: 0.5166 - val_loss: 0.1703 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.1481 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6070 - precision: 0.6070 - recall: 0.6070 - f1_score: 0.4698 - val_loss: 0.1701 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.1481 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.5175 - val_loss: 0.1695 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.1481 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5191 - val_loss: 0.1687 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.0769 - 48ms/epoch - 48ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4531 - val_loss: 0.1678 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.5041 - val_loss: 0.1671 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1592 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4961 - val_loss: 0.1664 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.4696 - val_loss: 0.1660 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.0000e+00 - 48ms/epoch - 48ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.7214 - precision: 0.7214 - recall: 0.7214 - f1_score: 0.4615 - val_loss: 0.1660 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.3434 - val_loss: 0.1662 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1600 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1496 - accuracy: 0.7612 - precision: 0.7612 - recall: 0.7612 - f1_score: 0.5932 - val_loss: 0.1666 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.1538 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1561 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.4915 - val_loss: 0.1670 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.2143 - 48ms/epoch - 48ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4961 - val_loss: 0.1672 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.2667 - 51ms/epoch - 51ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1528 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5333 - val_loss: 0.1670 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4818 - val_loss: 0.1664 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 48ms/epoch - 48ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1594 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4697 - val_loss: 0.1661 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 48ms/epoch - 48ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4724 - val_loss: 0.1656 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6020 - precision: 0.6020 - recall: 0.6020 - f1_score: 0.4286 - val_loss: 0.1651 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.5082 - val_loss: 0.1649 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 49ms/epoch - 49ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1499 - accuracy: 0.7662 - precision: 0.7662 - recall: 0.7662 - f1_score: 0.5913 - val_loss: 0.1648 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 53ms/epoch - 53ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1520 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4640 - val_loss: 0.1650 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5246 - val_loss: 0.1649 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1417 - accuracy: 0.7861 - precision: 0.7861 - recall: 0.7861 - f1_score: 0.6560 - val_loss: 0.1649 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1470 - accuracy: 0.7264 - precision: 0.7264 - recall: 0.7264 - f1_score: 0.5600 - val_loss: 0.1648 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 48ms/epoch - 48ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1481 - accuracy: 0.7214 - precision: 0.7214 - recall: 0.7214 - f1_score: 0.5625 - val_loss: 0.1644 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 48ms/epoch - 48ms/step

🔍 Resultados no Teste:
Loss: 0.1771
Accuracy: 0.4954
Precision: 0.4954
Recall: 0.4954
F1 Score: 0.0984
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2160 - accuracy: 0.3035 - precision: 0.3035 - recall: 0.3035 - f1_score: 0.3694 - val_loss: 0.1767 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.2500 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1911 - accuracy: 0.4378 - precision: 0.4378 - recall: 0.4378 - f1_score: 0.2893 - val_loss: 0.1695 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.2400 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1897 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.2314 - val_loss: 0.1678 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1747 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.3818 - val_loss: 0.1670 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1805 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.2424 - val_loss: 0.1663 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1768 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.1915 - val_loss: 0.1662 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1759 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.2364 - val_loss: 0.1666 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.0909 - 50ms/epoch - 50ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4463 - val_loss: 0.1675 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3077 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.3968 - val_loss: 0.1689 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4865 - 52ms/epoch - 52ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.3600 - val_loss: 0.1700 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.5000 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - f1_score: 0.3952 - val_loss: 0.1702 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.5238 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.4776 - precision: 0.4776 - recall: 0.4776 - f1_score: 0.3713 - val_loss: 0.1697 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.5366 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1635 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.4790 - val_loss: 0.1687 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.5128 - 51ms/epoch - 51ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.5572 - precision: 0.5572 - recall: 0.5572 - f1_score: 0.4606 - val_loss: 0.1676 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4737 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.4138 - val_loss: 0.1663 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 49ms/epoch - 49ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.4085 - val_loss: 0.1651 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.3881 - val_loss: 0.1640 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4800 - val_loss: 0.1631 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.3846 - 48ms/epoch - 48ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4463 - val_loss: 0.1623 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.2609 - 49ms/epoch - 49ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.3966 - val_loss: 0.1619 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.4667 - val_loss: 0.1616 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4425 - val_loss: 0.1614 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.2609 - 48ms/epoch - 48ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1634 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4138 - val_loss: 0.1614 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1589 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.4505 - val_loss: 0.1616 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3704 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.3697 - val_loss: 0.1618 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4687 - val_loss: 0.1621 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4516 - 51ms/epoch - 51ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4407 - val_loss: 0.1627 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4516 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4741 - val_loss: 0.1630 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 51ms/epoch - 51ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5147 - val_loss: 0.1632 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5401 - val_loss: 0.1630 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4444 - 78ms/epoch - 78ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1566 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.5000 - val_loss: 0.1625 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4000 - 94ms/epoch - 94ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1543 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.5507 - val_loss: 0.1620 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 87ms/epoch - 87ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1566 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.5224 - val_loss: 0.1617 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 67ms/epoch - 67ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1528 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5390 - val_loss: 0.1612 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 61ms/epoch - 61ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4960 - val_loss: 0.1608 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 125ms/epoch - 125ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4531 - val_loss: 0.1606 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 161ms/epoch - 161ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.5000 - val_loss: 0.1605 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.2857 - 218ms/epoch - 218ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1536 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.4959 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 143ms/epoch - 143ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1549 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5039 - val_loss: 0.1608 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 131ms/epoch - 131ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.4865 - val_loss: 0.1611 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 154ms/epoch - 154ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1538 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4444 - val_loss: 0.1615 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 151ms/epoch - 151ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1492 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5035 - val_loss: 0.1620 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3889 - 109ms/epoch - 109ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4776 - val_loss: 0.1621 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3889 - 101ms/epoch - 101ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1433 - accuracy: 0.7413 - precision: 0.7413 - recall: 0.7413 - f1_score: 0.6000 - val_loss: 0.1619 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3889 - 116ms/epoch - 116ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1468 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.5507 - val_loss: 0.1614 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4000 - 87ms/epoch - 87ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1494 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5401 - val_loss: 0.1607 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 53ms/epoch - 53ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1442 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5440 - val_loss: 0.1600 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 66ms/epoch - 66ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1523 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5043 - val_loss: 0.1597 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 66ms/epoch - 66ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1448 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5714 - val_loss: 0.1596 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 70ms/epoch - 70ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1416 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5512 - val_loss: 0.1595 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 52ms/epoch - 52ms/step

🔍 Resultados no Teste:
Loss: 0.1766
Accuracy: 0.5413
Precision: 0.5413
Recall: 0.5413
F1 Score: 0.2187
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2647 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.1143 - val_loss: 0.1522 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.2609 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2115 - accuracy: 0.5771 - precision: 0.5771 - recall: 0.5771 - f1_score: 0.1748 - val_loss: 0.1692 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.5455 - 53ms/epoch - 53ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1949 - accuracy: 0.4776 - precision: 0.4776 - recall: 0.4776 - f1_score: 0.3713 - val_loss: 0.1859 - val_accuracy: 0.4510 - val_precision: 0.4510 - val_recall: 0.4510 - val_f1_score: 0.5484 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2085 - accuracy: 0.3632 - precision: 0.3632 - recall: 0.3632 - f1_score: 0.3191 - val_loss: 0.1929 - val_accuracy: 0.3725 - val_precision: 0.3725 - val_recall: 0.3725 - val_f1_score: 0.5294 - 61ms/epoch - 61ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1968 - accuracy: 0.4080 - precision: 0.4080 - recall: 0.4080 - f1_score: 0.3834 - val_loss: 0.1914 - val_accuracy: 0.3725 - val_precision: 0.3725 - val_recall: 0.3725 - val_f1_score: 0.5294 - 53ms/epoch - 53ms/step
Epoch 6/50
1/1 - 0s - loss: 0.2019 - accuracy: 0.3881 - precision: 0.3881 - recall: 0.3881 - f1_score: 0.3756 - val_loss: 0.1853 - val_accuracy: 0.4314 - val_precision: 0.4314 - val_recall: 0.4314 - val_f1_score: 0.5397 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1944 - accuracy: 0.3881 - precision: 0.3881 - recall: 0.3881 - f1_score: 0.3881 - val_loss: 0.1784 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.5574 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1876 - accuracy: 0.4378 - precision: 0.4378 - recall: 0.4378 - f1_score: 0.3825 - val_loss: 0.1720 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.5714 - 53ms/epoch - 53ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1747 - accuracy: 0.4876 - precision: 0.4876 - recall: 0.4876 - f1_score: 0.4246 - val_loss: 0.1667 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.5417 - 51ms/epoch - 51ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.5721 - precision: 0.5721 - recall: 0.5721 - f1_score: 0.3582 - val_loss: 0.1632 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4865 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - f1_score: 0.3750 - val_loss: 0.1610 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.4667 - 52ms/epoch - 52ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.3077 - val_loss: 0.1598 - val_accuracy: 0.6863 - val_precision: 0.6863 - val_recall: 0.6863 - val_f1_score: 0.3846 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1727 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.2376 - val_loss: 0.1594 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.4348 - 51ms/epoch - 51ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1729 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.2947 - val_loss: 0.1596 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.4348 - 71ms/epoch - 71ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.2667 - val_loss: 0.1600 - val_accuracy: 0.7451 - val_precision: 0.7451 - val_recall: 0.7451 - val_f1_score: 0.4348 - 52ms/epoch - 52ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.2340 - val_loss: 0.1608 - val_accuracy: 0.7255 - val_precision: 0.7255 - val_recall: 0.7255 - val_f1_score: 0.4167 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.2766 - val_loss: 0.1620 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059 - val_f1_score: 0.4444 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1672 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.3654 - val_loss: 0.1635 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.3619 - val_loss: 0.1653 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.3429 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.6020 - precision: 0.6020 - recall: 0.6020 - f1_score: 0.3651 - val_loss: 0.1674 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 53ms/epoch - 53ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4186 - val_loss: 0.1695 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4783 - 52ms/epoch - 52ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.4265 - val_loss: 0.1714 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5306 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.4474 - val_loss: 0.1729 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 51ms/epoch - 51ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.4677 - precision: 0.4677 - recall: 0.4677 - f1_score: 0.3185 - val_loss: 0.1739 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5423 - precision: 0.5423 - recall: 0.5423 - f1_score: 0.4026 - val_loss: 0.1746 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 52ms/epoch - 52ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5423 - precision: 0.5423 - recall: 0.5423 - f1_score: 0.3947 - val_loss: 0.1748 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5323 - precision: 0.5323 - recall: 0.5323 - f1_score: 0.4268 - val_loss: 0.1744 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1710 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.4000 - val_loss: 0.1739 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.5490 - 52ms/epoch - 52ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.4225 - val_loss: 0.1730 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.4898 - 51ms/epoch - 51ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1665 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.4247 - val_loss: 0.1721 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.4898 - 52ms/epoch - 52ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.4167 - val_loss: 0.1712 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.4681 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1638 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4186 - val_loss: 0.1702 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4783 - 51ms/epoch - 51ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4628 - val_loss: 0.1694 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4538 - val_loss: 0.1686 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.5000 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.4878 - val_loss: 0.1681 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.4211 - 53ms/epoch - 53ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.3604 - val_loss: 0.1679 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.3784 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.3826 - val_loss: 0.1678 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4324 - 50ms/epoch - 50ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.4587 - val_loss: 0.1680 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4324 - 51ms/epoch - 51ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4715 - val_loss: 0.1683 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4737 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1614 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4480 - val_loss: 0.1686 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4878 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.4786 - val_loss: 0.1689 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4878 - 51ms/epoch - 51ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1614 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4274 - val_loss: 0.1692 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.5116 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1549 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.4715 - val_loss: 0.1695 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.5116 - 50ms/epoch - 50ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5401 - val_loss: 0.1695 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 53ms/epoch - 53ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.5630 - val_loss: 0.1693 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1587 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.4737 - val_loss: 0.1695 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4724 - val_loss: 0.1696 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1500 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5846 - val_loss: 0.1694 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1583 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5255 - val_loss: 0.1692 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4545 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1571 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4545 - val_loss: 0.1690 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4545 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1780
Accuracy: 0.4771
Precision: 0.4771
Recall: 0.4771
F1 Score: 0.3448
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2052 - accuracy: 0.3234 - precision: 0.3234 - recall: 0.3234 - f1_score: 0.4237 - val_loss: 0.1990 - val_accuracy: 0.3725 - val_precision: 0.3725 - val_recall: 0.3725 - val_f1_score: 0.5000 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1791 - accuracy: 0.4776 - precision: 0.4776 - recall: 0.4776 - f1_score: 0.4000 - val_loss: 0.1795 - val_accuracy: 0.4902 - val_precision: 0.4902 - val_recall: 0.4902 - val_f1_score: 0.2778 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1832 - accuracy: 0.5871 - precision: 0.5871 - recall: 0.5871 - f1_score: 0.3465 - val_loss: 0.1737 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1600 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1758 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.3400 - val_loss: 0.1722 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.0909 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1854 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.2553 - val_loss: 0.1727 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.1538 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1773 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.2970 - val_loss: 0.1746 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.2581 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1661 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.3929 - val_loss: 0.1771 - val_accuracy: 0.4510 - val_precision: 0.4510 - val_recall: 0.4510 - val_f1_score: 0.3000 - 54ms/epoch - 54ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.3871 - val_loss: 0.1801 - val_accuracy: 0.4314 - val_precision: 0.4314 - val_recall: 0.4314 - val_f1_score: 0.3830 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.4225 - val_loss: 0.1829 - val_accuracy: 0.3725 - val_precision: 0.3725 - val_recall: 0.3725 - val_f1_score: 0.4074 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1638 - accuracy: 0.5622 - precision: 0.5622 - recall: 0.5622 - f1_score: 0.4211 - val_loss: 0.1846 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4138 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5323 - precision: 0.5323 - recall: 0.5323 - f1_score: 0.4337 - val_loss: 0.1848 - val_accuracy: 0.3529 - val_precision: 0.3529 - val_recall: 0.3529 - val_f1_score: 0.4211 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.5423 - precision: 0.5423 - recall: 0.5423 - f1_score: 0.4588 - val_loss: 0.1836 - val_accuracy: 0.3725 - val_precision: 0.3725 - val_recall: 0.3725 - val_f1_score: 0.4286 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5672 - precision: 0.5672 - recall: 0.5672 - f1_score: 0.4790 - val_loss: 0.1815 - val_accuracy: 0.3922 - val_precision: 0.3922 - val_recall: 0.3922 - val_f1_score: 0.4151 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - f1_score: 0.4118 - val_loss: 0.1789 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4231 - 50ms/epoch - 50ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1699 - accuracy: 0.5174 - precision: 0.5174 - recall: 0.5174 - f1_score: 0.3742 - val_loss: 0.1764 - val_accuracy: 0.4510 - val_precision: 0.4510 - val_recall: 0.4510 - val_f1_score: 0.4167 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1651 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.4507 - val_loss: 0.1743 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.4762 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.4031 - val_loss: 0.1728 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.4500 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1702 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.3710 - val_loss: 0.1717 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3684 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1653 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.3784 - val_loss: 0.1712 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1661 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.4259 - val_loss: 0.1711 - val_accuracy: 0.4902 - val_precision: 0.4902 - val_recall: 0.4902 - val_f1_score: 0.2353 - 48ms/epoch - 48ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.4032 - val_loss: 0.1710 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1602 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4426 - val_loss: 0.1712 - val_accuracy: 0.4902 - val_precision: 0.4902 - val_recall: 0.4902 - val_f1_score: 0.3158 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4000 - val_loss: 0.1716 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.3590 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4068 - val_loss: 0.1725 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4286 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5217 - val_loss: 0.1730 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 49ms/epoch - 49ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4930 - val_loss: 0.1733 - val_accuracy: 0.5490 - val_precision: 0.5490 - val_recall: 0.5490 - val_f1_score: 0.4651 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1535 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5248 - val_loss: 0.1738 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4545 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.5278 - val_loss: 0.1738 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4545 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4783 - val_loss: 0.1732 - val_accuracy: 0.5098 - val_precision: 0.5098 - val_recall: 0.5098 - val_f1_score: 0.4186 - 51ms/epoch - 51ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5248 - val_loss: 0.1726 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4286 - 52ms/epoch - 52ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1563 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.4615 - val_loss: 0.1716 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.4885 - val_loss: 0.1709 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4390 - val_loss: 0.1705 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1561 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4706 - val_loss: 0.1700 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1531 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5440 - val_loss: 0.1694 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1504 - accuracy: 0.7214 - precision: 0.7214 - recall: 0.7214 - f1_score: 0.5000 - val_loss: 0.1691 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1438 - accuracy: 0.7612 - precision: 0.7612 - recall: 0.7612 - f1_score: 0.5862 - val_loss: 0.1690 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1476 - accuracy: 0.7562 - precision: 0.7562 - recall: 0.7562 - f1_score: 0.6202 - val_loss: 0.1689 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1453 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5424 - val_loss: 0.1689 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1466 - accuracy: 0.7264 - precision: 0.7264 - recall: 0.7264 - f1_score: 0.5669 - val_loss: 0.1692 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1472 - accuracy: 0.7363 - precision: 0.7363 - recall: 0.7363 - f1_score: 0.5225 - val_loss: 0.1698 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1496 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5512 - val_loss: 0.1706 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1429 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5672 - val_loss: 0.1711 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.4118 - 48ms/epoch - 48ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1398 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5846 - val_loss: 0.1715 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1430 - accuracy: 0.7363 - precision: 0.7363 - recall: 0.7363 - f1_score: 0.5691 - val_loss: 0.1721 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4706 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1459 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.5373 - val_loss: 0.1728 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.5143 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1413 - accuracy: 0.7761 - precision: 0.7761 - recall: 0.7761 - f1_score: 0.6341 - val_loss: 0.1733 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4706 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1411 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.5714 - val_loss: 0.1735 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4375 - 52ms/epoch - 52ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1448 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5645 - val_loss: 0.1736 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1435 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5289 - val_loss: 0.1744 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4848 - 48ms/epoch - 48ms/step

🔍 Resultados no Teste:
Loss: 0.1798
Accuracy: 0.5229
Precision: 0.5229
Recall: 0.5229
F1 Score: 0.2353
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
Matrix_60: [(361, 60), (361, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2102 - accuracy: 0.4478 - precision: 0.4478 - recall: 0.4478 - f1_score: 0.3273 - val_loss: 0.1744 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3200 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.2167 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.2615 - val_loss: 0.1768 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.4242 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1933 - accuracy: 0.4826 - precision: 0.4826 - recall: 0.4826 - f1_score: 0.2676 - val_loss: 0.1788 - val_accuracy: 0.4902 - val_precision: 0.4902 - val_recall: 0.4902 - val_f1_score: 0.3500 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1739 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.4224 - val_loss: 0.1770 - val_accuracy: 0.4902 - val_precision: 0.4902 - val_recall: 0.4902 - val_f1_score: 0.3500 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1918 - accuracy: 0.4279 - precision: 0.4279 - recall: 0.4279 - f1_score: 0.3114 - val_loss: 0.1736 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.6219 - precision: 0.6219 - recall: 0.6219 - f1_score: 0.4571 - val_loss: 0.1709 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3077 - 48ms/epoch - 48ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1732 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.4000 - val_loss: 0.1697 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3200 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1791 - accuracy: 0.5423 - precision: 0.5423 - recall: 0.5423 - f1_score: 0.2333 - val_loss: 0.1690 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.3200 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.3276 - val_loss: 0.1690 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3077 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.3590 - val_loss: 0.1696 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.2857 - 53ms/epoch - 53ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4286 - val_loss: 0.1709 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3226 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1716 - accuracy: 0.5821 - precision: 0.5821 - recall: 0.5821 - f1_score: 0.3913 - val_loss: 0.1723 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4000 - 53ms/epoch - 53ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1628 - accuracy: 0.5721 - precision: 0.5721 - recall: 0.5721 - f1_score: 0.4416 - val_loss: 0.1731 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.4324 - 52ms/epoch - 52ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.4224 - val_loss: 0.1733 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.4211 - 50ms/epoch - 50ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.5473 - precision: 0.5473 - recall: 0.5473 - f1_score: 0.3974 - val_loss: 0.1731 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3889 - 58ms/epoch - 58ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - f1_score: 0.4533 - val_loss: 0.1722 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 52ms/epoch - 52ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1754 - accuracy: 0.5373 - precision: 0.5373 - recall: 0.5373 - f1_score: 0.3309 - val_loss: 0.1714 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.4296 - val_loss: 0.1705 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3226 - 49ms/epoch - 49ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1703 - accuracy: 0.5423 - precision: 0.5423 - recall: 0.5423 - f1_score: 0.3611 - val_loss: 0.1698 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4687 - val_loss: 0.1695 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 62ms/epoch - 62ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1699 - accuracy: 0.6169 - precision: 0.6169 - recall: 0.6169 - f1_score: 0.3636 - val_loss: 0.1697 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.5871 - precision: 0.5871 - recall: 0.5871 - f1_score: 0.3852 - val_loss: 0.1700 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.4755 - val_loss: 0.1700 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3226 - 51ms/epoch - 51ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.4754 - val_loss: 0.1702 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3125 - 52ms/epoch - 52ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4923 - val_loss: 0.1705 - val_accuracy: 0.5686 - val_precision: 0.5686 - val_recall: 0.5686 - val_f1_score: 0.3125 - 68ms/epoch - 68ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1587 - accuracy: 0.6816 - precision: 0.6816 - recall: 0.6816 - f1_score: 0.4754 - val_loss: 0.1707 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 54ms/epoch - 54ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1571 - accuracy: 0.6318 - precision: 0.6318 - recall: 0.6318 - f1_score: 0.4932 - val_loss: 0.1708 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6617 - precision: 0.6617 - recall: 0.6617 - f1_score: 0.4603 - val_loss: 0.1709 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1538 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5180 - val_loss: 0.1708 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 51ms/epoch - 51ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5109 - val_loss: 0.1704 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1577 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.4355 - val_loss: 0.1699 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 48ms/epoch - 48ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.6517 - precision: 0.6517 - recall: 0.6517 - f1_score: 0.5139 - val_loss: 0.1693 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 51ms/epoch - 51ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1520 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5401 - val_loss: 0.1687 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1497 - accuracy: 0.7065 - precision: 0.7065 - recall: 0.7065 - f1_score: 0.5426 - val_loss: 0.1681 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1442 - accuracy: 0.7363 - precision: 0.7363 - recall: 0.7363 - f1_score: 0.6015 - val_loss: 0.1673 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1467 - accuracy: 0.7264 - precision: 0.7264 - recall: 0.7264 - f1_score: 0.5600 - val_loss: 0.1667 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1535 - accuracy: 0.6915 - precision: 0.6915 - recall: 0.6915 - f1_score: 0.5231 - val_loss: 0.1663 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 48ms/epoch - 48ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1520 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.5263 - val_loss: 0.1660 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 51ms/epoch - 51ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1523 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.4423 - val_loss: 0.1662 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1509 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4844 - val_loss: 0.1667 - val_accuracy: 0.6275 - val_precision: 0.6275 - val_recall: 0.6275 - val_f1_score: 0.3871 - 48ms/epoch - 48ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1577 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.4407 - val_loss: 0.1677 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1473 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - f1_score: 0.5606 - val_loss: 0.1686 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1504 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5442 - val_loss: 0.1685 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1495 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5581 - val_loss: 0.1684 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1398 - accuracy: 0.7313 - precision: 0.7313 - recall: 0.7313 - f1_score: 0.6029 - val_loss: 0.1680 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3636 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1462 - accuracy: 0.6965 - precision: 0.6965 - recall: 0.6965 - f1_score: 0.5734 - val_loss: 0.1672 - val_accuracy: 0.6078 - val_precision: 0.6078 - val_recall: 0.6078 - val_f1_score: 0.3750 - 49ms/epoch - 49ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1447 - accuracy: 0.7463 - precision: 0.7463 - recall: 0.7463 - f1_score: 0.6277 - val_loss: 0.1665 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.4000 - 52ms/epoch - 52ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1390 - accuracy: 0.7562 - precision: 0.7562 - recall: 0.7562 - f1_score: 0.6080 - val_loss: 0.1659 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1392 - accuracy: 0.7264 - precision: 0.7264 - recall: 0.7264 - f1_score: 0.5802 - val_loss: 0.1656 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_f1_score: 0.4138 - 49ms/epoch - 49ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1405 - accuracy: 0.7363 - precision: 0.7363 - recall: 0.7363 - f1_score: 0.5470 - val_loss: 0.1657 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3571 - 52ms/epoch - 52ms/step

🔍 Resultados no Teste:
Loss: 0.1708
Accuracy: 0.6147
Precision: 0.6147
Recall: 0.6147
F1 Score: 0.2222
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
420
480 480
(361, 60) (361, 60) (361, 60) (361, 60)
(361, 60) (361, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 75ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 481 | Acuracia_1: 0.0 | Contagem Geral: 42.0 
Ordem Natural: 35.0
Entrada: 12.69
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.0 
Precisao modelo Geral: 55.3719
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
421
481 481
(362, 60) (362, 60) (362, 60) (362, 60)
(362, 60) (362, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 482 | Acuracia_1: 0.0 | Contagem Geral: 42.0 
Ordem Natural: 36.0
Entrada: 7.6
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.0 
Precisao modelo Geral: 54.918
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
422
482 482
(363, 60) (363, 60) (363, 60) (363, 60)
(363, 60) (363, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 483 | Acuracia_1: 0.0 | Contagem Geral: 42.0 
Ordem Natural: 37.0
Entrada: 1.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.0 
Precisao modelo Geral: 55.2846
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
423
483 483
(364, 60) (364, 60) (364, 60) (364, 60)
(364, 60) (364, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 484 | Acuracia_1: 0 | Contagem Geral: 42.0 
Ordem Natural: 37.0
Entrada: 1.63
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0 
Precisao modelo Geral: 55.6452
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
424
484 484
(365, 60) (365, 60) (365, 60) (365, 60)
(365, 60) (365, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 485 | Acuracia_1: 1.0 | Contagem Geral: 42.0 
Ordem Natural: 37.0
Entrada: 1.2
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
425
485 485
(366, 60) (366, 60) (366, 60) (366, 60)
(366, 60) (366, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 486 | Acuracia_1: 0.0 | Contagem Geral: 42.0 
Ordem Natural: 37.0
Entrada: 14.67
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.2326 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.3492
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
426
486 486
(367, 60) (367, 60) (367, 60) (367, 60)
(367, 60) (367, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 487 | Acuracia_1: 0 | Contagem Geral: 43.0 
Ordem Natural: 38.0
Entrada: 2.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.2326 | Acuracia_0: 0 
Precisao modelo Geral: 56.6929
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
427
487 487
(368, 60) (368, 60) (368, 60) (368, 60)
(368, 60) (368, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 488 | Acuracia_1: 0 | Contagem Geral: 43.0 
Ordem Natural: 38.0
Entrada: 1.19
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.25
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
428
488 488
(369, 60) (369, 60) (369, 60) (369, 60)
(369, 60) (369, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 489 | Acuracia_1: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 38.0
Entrada: 1.06
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.5891
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
429
489 489
(370, 60) (370, 60) (370, 60) (370, 60)
(370, 60) (370, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 490 | Acuracia_1: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 38.0
Entrada: 1.37
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.9231
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
430
490 490
(371, 60) (371, 60) (371, 60) (371, 60)
(371, 60) (371, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 491 | Acuracia_1: 0 | Contagem Geral: 44.0 
Ordem Natural: 38.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0 
Precisao modelo Geral: 57.2519
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
431
491 491
(372, 60) (372, 60) (372, 60) (372, 60)
(372, 60) (372, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 492 | Acuracia_1: 0 | Contagem Geral: 44.0 
Ordem Natural: 38.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0 
Precisao modelo Geral: 57.5758
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
432
492 492
(373, 60) (373, 60) (373, 60) (373, 60)
(373, 60) (373, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 493 | Acuracia_1: 1.0 | Contagem Geral: 44.0 
Ordem Natural: 38.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
433
493 493
(374, 60) (374, 60) (374, 60) (374, 60)
(374, 60) (374, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 494 | Acuracia_1: 0.0 | Contagem Geral: 44.0 
Ordem Natural: 39.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.4627
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
434
494 494
(375, 60) (375, 60) (375, 60) (375, 60)
(375, 60) (375, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 495 | Acuracia_1: 0.5 | Contagem Geral: 44.0 
Ordem Natural: 39.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.6667 
Precisao modelo Geral: 57.7778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
435
495 495
(376, 60) (376, 60) (376, 60) (376, 60)
(376, 60) (376, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 496 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 40.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 57.3529
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
436
496 496
(377, 60) (377, 60) (377, 60) (377, 60)
(377, 60) (377, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 497 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 41.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6642
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
437
497 497
(378, 60) (378, 60) (378, 60) (378, 60)
(378, 60) (378, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 498 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 41.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.971
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
438
498 498
(379, 60) (379, 60) (379, 60) (379, 60)
(379, 60) (379, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 499 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 41.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 58.2734
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
439
499 499
(380, 60) (380, 60) (380, 60) (380, 60)
(380, 60) (380, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 500 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 41.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 57.8571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
440
500 500
(381, 60) (381, 60) (381, 60) (381, 60)
(381, 60) (381, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 501 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 42.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 58.156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
441
501 501
(382, 60) (382, 60) (382, 60) (382, 60)
(382, 60) (382, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 502 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 42.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.7465
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
442
502 502
(383, 60) (383, 60) (383, 60) (383, 60)
(383, 60) (383, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 503 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 43.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.042
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
443
503 503
(384, 60) (384, 60) (384, 60) (384, 60)
(384, 60) (384, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 504 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 43.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
444
504 504
(385, 60) (385, 60) (385, 60) (385, 60)
(385, 60) (385, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 505 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 43.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 57.931
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
445
505 505
(386, 60) (386, 60) (386, 60) (386, 60)
(386, 60) (386, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 506 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 44.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.2192
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
446
506 506
(387, 60) (387, 60) (387, 60) (387, 60)
(387, 60) (387, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 507 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 44.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0 
Precisao modelo Geral: 57.8231
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
447
507 507
(388, 60) (388, 60) (388, 60) (388, 60)
(388, 60) (388, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 508 | Acuracia_1: 0.5 | Contagem Geral: 45.0 
Ordem Natural: 45.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.1081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
448
508 508
(389, 60) (389, 60) (389, 60) (389, 60)
(389, 60) (389, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 509 | Acuracia_1: 1.0 | Contagem Geral: 45.0 
Ordem Natural: 45.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.3893
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
449
509 509
(390, 60) (390, 60) (390, 60) (390, 60)
(390, 60) (390, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 510 | Acuracia_1: 0.0 | Contagem Geral: 45.0 
Ordem Natural: 45.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.1111 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
450
510 510
(391, 60) (391, 60) (391, 60) (391, 60)
(391, 60) (391, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 511 | Acuracia_1: 0 | Contagem Geral: 45.0 
Ordem Natural: 46.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.4348 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6159
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
451
511 511
(392, 60) (392, 60) (392, 60) (392, 60)
(392, 60) (392, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 512 | Acuracia_1: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 46.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.4348 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.2368
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
452
512 512
(393, 60) (393, 60) (393, 60) (393, 60)
(393, 60) (393, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 513 | Acuracia_1: 1.0 | Contagem Geral: 46.0 
Ordem Natural: 47.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7872 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.8627
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
453
513 513
(394, 60) (394, 60) (394, 60) (394, 60)
(394, 60) (394, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 514 | Acuracia_1: 0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7872 | Acuracia_0: 0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
454
514 514
(395, 60) (395, 60) (395, 60) (395, 60)
(395, 60) (395, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 515 | Acuracia_1: 0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7872 | Acuracia_0: 0 
Precisao modelo Geral: 57.4194
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
455
515 515
(396, 60) (396, 60) (396, 60) (396, 60)
(396, 60) (396, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 516 | Acuracia_1: 0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7872 | Acuracia_0: 0 
Precisao modelo Geral: 57.6923
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
456
516 516
(397, 60) (397, 60) (397, 60) (397, 60)
(397, 60) (397, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 517 | Acuracia_1: 0 | Contagem Geral: 47.0 
Ordem Natural: 47.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.9618
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
457
517 517
(398, 60) (398, 60) (398, 60) (398, 60)
(398, 60) (398, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 518 | Acuracia_1: 0.0 | Contagem Geral: 48.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.2278
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
458
518 518
(399, 60) (399, 60) (399, 60) (399, 60)
(399, 60) (399, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 519 | Acuracia_1: 0.0 | Contagem Geral: 48.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.4906
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
459
519 519
(400, 60) (400, 60) (400, 60) (400, 60)
(400, 60) (400, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 520 | Acuracia_1: 0 | Contagem Geral: 48.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_0: 0 
Precisao modelo Geral: 58.75
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
460
520 520
(401, 60) (401, 60) (401, 60) (401, 60)
(401, 60) (401, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 521 | Acuracia_1: 0.0 | Contagem Geral: 48.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.25 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.0062
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
461
521 521
(402, 60) (402, 60) (402, 60) (402, 60)
(402, 60) (402, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 522 | Acuracia_1: 0.5 | Contagem Geral: 48.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.6122 | Acuracia_0: 0.3333 
Precisao modelo Geral: 58.642
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
462
522 522
(403, 60) (403, 60) (403, 60) (403, 60)
(403, 60) (403, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 523 | Acuracia_1: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.6122 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.8957
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
463
523 523
(404, 60) (404, 60) (404, 60) (404, 60)
(404, 60) (404, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 524 | Acuracia_1: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.6122 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.1463
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
464
524 524
(405, 60) (405, 60) (405, 60) (405, 60)
(405, 60) (405, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 525 | Acuracia_1: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.6122 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.3939
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
465
525 525
(406, 60) (406, 60) (406, 60) (406, 60)
(406, 60) (406, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 526 | Acuracia_1: 0.0 | Contagem Geral: 49.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.0361
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
466
526 526
(407, 60) (407, 60) (407, 60) (407, 60)
(407, 60) (407, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 527 | Acuracia_1: 1.0 | Contagem Geral: 50.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.2814
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
467
527 527
(408, 60) (408, 60) (408, 60) (408, 60)
(408, 60) (408, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 528 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
468
528 528
(409, 60) (409, 60) (409, 60) (409, 60)
(409, 60) (409, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 529 | Acuracia_1: 0.0 | Contagem Geral: 50.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.7633
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
469
529 529
(410, 60) (410, 60) (410, 60) (410, 60)
(410, 60) (410, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 530 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 48.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.4118
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
470
530 530
(411, 60) (411, 60) (411, 60) (411, 60)
(411, 60) (411, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 531 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.6491
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
471
531 531
(412, 60) (412, 60) (412, 60) (412, 60)
(412, 60) (412, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 532 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.8837
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
472
532 532
(413, 60) (413, 60) (413, 60) (413, 60)
(413, 60) (413, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 533 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.1156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
473
533 533
(414, 60) (414, 60) (414, 60) (414, 60)
(414, 60) (414, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 534 | Acuracia_1: 1.0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.3448
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
474
534 534
(415, 60) (415, 60) (415, 60) (415, 60)
(415, 60) (415, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 535 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
475
535 535
(416, 60) (416, 60) (416, 60) (416, 60)
(416, 60) (416, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 536 | Acuracia_1: 0 | Contagem Geral: 50.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.2273
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
476
536 536
(417, 60) (417, 60) (417, 60) (417, 60)
(417, 60) (417, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 537 | Acuracia_1: 0.5 | Contagem Geral: 51.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.5 
Precisao modelo Geral: 60.452
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
477
537 537
(418, 60) (418, 60) (418, 60) (418, 60)
(418, 60) (418, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 538 | Acuracia_1: 1.0 | Contagem Geral: 51.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.6742
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
478
538 538
(419, 60) (419, 60) (419, 60) (419, 60)
(419, 60) (419, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 539 | Acuracia_1: 0 | Contagem Geral: 51.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.8462 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.3352
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
479
539 539
(420, 60) (420, 60) (420, 60) (420, 60)
(420, 60) (420, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 540 | Acuracia_1: 0.0 | Contagem Geral: 52.0 
Ordem Natural: 49.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.8462 | Acuracia_60: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1945 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.1982 - val_loss: 0.1711 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.4000 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1823 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4000 - val_loss: 0.1936 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3492 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1857 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.4397 - val_loss: 0.2073 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1844 - accuracy: 0.3745 - precision: 0.3745 - recall: 0.3745 - f1_score: 0.4453 - val_loss: 0.2108 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1832 - accuracy: 0.3745 - precision: 0.3745 - recall: 0.3745 - f1_score: 0.4368 - val_loss: 0.2057 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1805 - accuracy: 0.4128 - precision: 0.4128 - recall: 0.4128 - f1_score: 0.4651 - val_loss: 0.1980 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3636 - 48ms/epoch - 48ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1775 - accuracy: 0.4170 - precision: 0.4170 - recall: 0.4170 - f1_score: 0.4585 - val_loss: 0.1896 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.3548 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1766 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - f1_score: 0.4825 - val_loss: 0.1817 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1781 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.4444 - val_loss: 0.1757 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1744 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4372 - val_loss: 0.1715 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3077 - 50ms/epoch - 50ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1761 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4094 - val_loss: 0.1688 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.2941 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.4878 - val_loss: 0.1678 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.3226 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1727 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.3824 - val_loss: 0.1691 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.3125 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.4306 - val_loss: 0.1716 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 51ms/epoch - 51ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1706 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.4459 - val_loss: 0.1752 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.5404 - precision: 0.5404 - recall: 0.5404 - f1_score: 0.4255 - val_loss: 0.1787 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1725 - accuracy: 0.5404 - precision: 0.5404 - recall: 0.5404 - f1_score: 0.4375 - val_loss: 0.1821 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5078 - val_loss: 0.1853 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2857 - 52ms/epoch - 52ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1694 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4631 - val_loss: 0.1878 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 49ms/epoch - 49ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.5114 - val_loss: 0.1888 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.4936 - precision: 0.4936 - recall: 0.4936 - f1_score: 0.4360 - val_loss: 0.1892 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5507 - val_loss: 0.1879 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4904 - val_loss: 0.1859 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.5200 - val_loss: 0.1828 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2400 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5426 - val_loss: 0.1794 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 48ms/epoch - 48ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5464 - val_loss: 0.1768 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 52ms/epoch - 52ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5665 - val_loss: 0.1749 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2353 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5000 - val_loss: 0.1756 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1614 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5549 - val_loss: 0.1773 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2703 - 49ms/epoch - 49ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5207 - val_loss: 0.1813 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5161 - val_loss: 0.1849 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5574 - val_loss: 0.1880 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1526 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5373 - val_loss: 0.1896 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5368 - val_loss: 0.1910 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5528 - val_loss: 0.1915 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5567 - val_loss: 0.1910 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1556 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5670 - val_loss: 0.1890 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4767 - val_loss: 0.1870 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1529 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5532 - val_loss: 0.1845 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5506 - val_loss: 0.1827 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2105 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5311 - val_loss: 0.1819 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2105 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5714 - val_loss: 0.1822 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2051 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1491 - accuracy: 0.7362 - precision: 0.7362 - recall: 0.7362 - f1_score: 0.6265 - val_loss: 0.1822 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2051 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1491 - accuracy: 0.6894 - precision: 0.6894 - recall: 0.6894 - f1_score: 0.5829 - val_loss: 0.1808 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.1579 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1484 - accuracy: 0.7191 - precision: 0.7191 - recall: 0.7191 - f1_score: 0.6250 - val_loss: 0.1802 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.1622 - 48ms/epoch - 48ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1535 - accuracy: 0.6894 - precision: 0.6894 - recall: 0.6894 - f1_score: 0.5576 - val_loss: 0.1805 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.1622 - 48ms/epoch - 48ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5587 - val_loss: 0.1818 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.1622 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1500 - accuracy: 0.7319 - precision: 0.7319 - recall: 0.7319 - f1_score: 0.6272 - val_loss: 0.1839 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.1579 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1396 - accuracy: 0.7191 - precision: 0.7191 - recall: 0.7191 - f1_score: 0.6374 - val_loss: 0.1854 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.1579 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1539 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5579 - val_loss: 0.1866 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.1579 - 52ms/epoch - 52ms/step

🔍 Resultados no Teste:
Loss: 0.1891
Accuracy: 0.4646
Precision: 0.4646
Recall: 0.4646
F1 Score: 0.3585
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2082 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.1348 - val_loss: 0.1685 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.1429 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1902 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.3145 - val_loss: 0.1927 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3051 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1805 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4155 - val_loss: 0.2106 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 51ms/epoch - 51ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1747 - accuracy: 0.4128 - precision: 0.4128 - recall: 0.4128 - f1_score: 0.4524 - val_loss: 0.2149 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1924 - accuracy: 0.3404 - precision: 0.3404 - recall: 0.3404 - f1_score: 0.4061 - val_loss: 0.2094 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1895 - accuracy: 0.3872 - precision: 0.3872 - recall: 0.3872 - f1_score: 0.4419 - val_loss: 0.2008 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3478 - 51ms/epoch - 51ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1780 - accuracy: 0.4340 - precision: 0.4340 - recall: 0.4340 - f1_score: 0.4527 - val_loss: 0.1914 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3125 - 53ms/epoch - 53ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1802 - accuracy: 0.4511 - precision: 0.4511 - recall: 0.4511 - f1_score: 0.4557 - val_loss: 0.1822 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2963 - 49ms/epoch - 49ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1744 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4577 - val_loss: 0.1753 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 52ms/epoch - 52ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1754 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4286 - val_loss: 0.1705 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.2581 - 48ms/epoch - 48ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1745 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4048 - val_loss: 0.1675 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1756 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.3784 - val_loss: 0.1664 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.2759 - 50ms/epoch - 50ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.3922 - val_loss: 0.1672 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.2581 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1749 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.4314 - val_loss: 0.1694 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3243 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4497 - val_loss: 0.1725 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3077 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4318 - val_loss: 0.1761 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2979 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.4457 - val_loss: 0.1800 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2800 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4837 - val_loss: 0.1832 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2963 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1729 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4312 - val_loss: 0.1853 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2857 - 51ms/epoch - 51ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1724 - accuracy: 0.4936 - precision: 0.4936 - recall: 0.4936 - f1_score: 0.4803 - val_loss: 0.1864 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4701 - val_loss: 0.1866 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.4681 - precision: 0.4681 - recall: 0.4681 - f1_score: 0.4856 - val_loss: 0.1853 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.4894 - precision: 0.4894 - recall: 0.4894 - f1_score: 0.4872 - val_loss: 0.1833 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2963 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.4681 - precision: 0.4681 - recall: 0.4681 - f1_score: 0.4344 - val_loss: 0.1808 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3077 - 51ms/epoch - 51ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1703 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4592 - val_loss: 0.1788 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2800 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1737 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4249 - val_loss: 0.1772 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 52ms/epoch - 52ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4718 - val_loss: 0.1756 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5155 - val_loss: 0.1742 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5083 - val_loss: 0.1733 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 53ms/epoch - 53ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4565 - val_loss: 0.1730 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1638 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5486 - val_loss: 0.1740 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.4509 - val_loss: 0.1756 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4699 - val_loss: 0.1770 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 50ms/epoch - 50ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.5152 - val_loss: 0.1781 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5231 - val_loss: 0.1789 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1668 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4821 - val_loss: 0.1794 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.5126 - val_loss: 0.1790 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1635 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4873 - val_loss: 0.1779 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5104 - val_loss: 0.1767 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4896 - val_loss: 0.1751 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 55ms/epoch - 55ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1628 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5464 - val_loss: 0.1741 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5140 - val_loss: 0.1736 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 50ms/epoch - 50ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1578 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5525 - val_loss: 0.1733 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 50ms/epoch - 50ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.5862 - val_loss: 0.1729 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6894 - precision: 0.6894 - recall: 0.6894 - f1_score: 0.5829 - val_loss: 0.1732 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5810 - val_loss: 0.1737 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1605 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5000 - val_loss: 0.1758 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5763 - val_loss: 0.1791 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5907 - val_loss: 0.1811 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1552 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5371 - val_loss: 0.1834 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1857
Accuracy: 0.4803
Precision: 0.4803
Recall: 0.4803
F1 Score: 0.4211
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2257 - accuracy: 0.2979 - precision: 0.2979 - recall: 0.2979 - f1_score: 0.4482 - val_loss: 0.2359 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2046 - accuracy: 0.3447 - precision: 0.3447 - recall: 0.3447 - f1_score: 0.4338 - val_loss: 0.1963 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1890 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.3981 - val_loss: 0.1738 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3673 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1880 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.3394 - val_loss: 0.1631 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.3448 - 49ms/epoch - 49ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1925 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.2639 - val_loss: 0.1591 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.3000 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1930 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.1296 - val_loss: 0.1594 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1852 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.2540 - val_loss: 0.1614 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.3636 - 48ms/epoch - 48ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1797 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.3134 - val_loss: 0.1640 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1856 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.3194 - val_loss: 0.1677 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3429 - 51ms/epoch - 51ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.3709 - val_loss: 0.1716 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3810 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1811 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4044 - val_loss: 0.1752 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.4608 - val_loss: 0.1782 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3571 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1775 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.4667 - val_loss: 0.1810 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3390 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1782 - accuracy: 0.4043 - precision: 0.4043 - recall: 0.4043 - f1_score: 0.4068 - val_loss: 0.1830 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3125 - 54ms/epoch - 54ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1752 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4553 - val_loss: 0.1842 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3385 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4597 - val_loss: 0.1843 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3385 - 52ms/epoch - 52ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1800 - accuracy: 0.3872 - precision: 0.3872 - recall: 0.3872 - f1_score: 0.4146 - val_loss: 0.1837 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3175 - 51ms/epoch - 51ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1766 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4508 - val_loss: 0.1830 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3226 - 50ms/epoch - 50ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.4681 - precision: 0.4681 - recall: 0.4681 - f1_score: 0.4939 - val_loss: 0.1817 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3390 - 52ms/epoch - 52ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1739 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4851 - val_loss: 0.1803 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3571 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1702 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.4831 - val_loss: 0.1785 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.3273 - 54ms/epoch - 54ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1712 - accuracy: 0.4894 - precision: 0.4894 - recall: 0.4894 - f1_score: 0.4915 - val_loss: 0.1766 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.3200 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1736 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - f1_score: 0.4685 - val_loss: 0.1746 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3556 - 52ms/epoch - 52ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.5089 - val_loss: 0.1726 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3810 - 58ms/epoch - 58ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.4455 - val_loss: 0.1709 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.4000 - 52ms/epoch - 52ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4674 - val_loss: 0.1695 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.4103 - 51ms/epoch - 51ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.5000 - val_loss: 0.1682 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.4211 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.4859 - val_loss: 0.1675 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3784 - 51ms/epoch - 51ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5291 - val_loss: 0.1672 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3784 - 53ms/epoch - 53ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1719 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4497 - val_loss: 0.1674 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3784 - 48ms/epoch - 48ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.3905 - val_loss: 0.1682 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3784 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1725 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4253 - val_loss: 0.1697 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.3684 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.5123 - val_loss: 0.1710 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3590 - 48ms/epoch - 48ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1730 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.4278 - val_loss: 0.1724 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3500 - 52ms/epoch - 52ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.4339 - val_loss: 0.1735 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3415 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4752 - val_loss: 0.1742 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3415 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4536 - val_loss: 0.1748 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5333 - val_loss: 0.1753 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3256 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4948 - val_loss: 0.1756 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.5429 - val_loss: 0.1754 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.5404 - precision: 0.5404 - recall: 0.5404 - f1_score: 0.4953 - val_loss: 0.1747 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3256 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5263 - val_loss: 0.1738 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1665 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4536 - val_loss: 0.1728 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3415 - 48ms/epoch - 48ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5178 - val_loss: 0.1719 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4541 - val_loss: 0.1707 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4725 - val_loss: 0.1702 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4641 - val_loss: 0.1708 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5503 - val_loss: 0.1712 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5275 - val_loss: 0.1712 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 49ms/epoch - 49ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1596 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5326 - val_loss: 0.1706 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2353 - 53ms/epoch - 53ms/step

🔍 Resultados no Teste:
Loss: 0.1764
Accuracy: 0.4173
Precision: 0.4173
Recall: 0.4173
F1 Score: 0.2885
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2105 - accuracy: 0.4638 - precision: 0.4638 - recall: 0.4638 - f1_score: 0.3368 - val_loss: 0.2034 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.2023 - accuracy: 0.3957 - precision: 0.3957 - recall: 0.3957 - f1_score: 0.3717 - val_loss: 0.2100 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3077 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1957 - accuracy: 0.3489 - precision: 0.3489 - recall: 0.3489 - f1_score: 0.3704 - val_loss: 0.2025 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3226 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1828 - accuracy: 0.4638 - precision: 0.4638 - recall: 0.4638 - f1_score: 0.4375 - val_loss: 0.1919 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2857 - 53ms/epoch - 53ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1828 - accuracy: 0.4596 - precision: 0.4596 - recall: 0.4596 - f1_score: 0.4405 - val_loss: 0.1823 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3404 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1798 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.4330 - val_loss: 0.1752 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 48ms/epoch - 48ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1808 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.3860 - val_loss: 0.1728 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 50ms/epoch - 50ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1812 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.3503 - val_loss: 0.1730 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2353 - 51ms/epoch - 51ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1793 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.3908 - val_loss: 0.1745 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1762 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.3690 - val_loss: 0.1769 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1741 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4541 - val_loss: 0.1801 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1773 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5021 - f1_score: 0.4061 - val_loss: 0.1830 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2400 - 53ms/epoch - 53ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1769 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4579 - val_loss: 0.1853 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2692 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1762 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.4299 - val_loss: 0.1865 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2642 - 52ms/epoch - 52ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1725 - accuracy: 0.4766 - precision: 0.4766 - recall: 0.4766 - f1_score: 0.4533 - val_loss: 0.1862 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2642 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.5108 - val_loss: 0.1844 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.2745 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1694 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.5047 - val_loss: 0.1822 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 51ms/epoch - 51ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.4400 - val_loss: 0.1802 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 50ms/epoch - 50ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4639 - val_loss: 0.1782 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1656 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.5208 - val_loss: 0.1774 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4731 - val_loss: 0.1768 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4757 - val_loss: 0.1768 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2703 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5193 - val_loss: 0.1779 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3077 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5213 - val_loss: 0.1793 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 48ms/epoch - 48ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4835 - val_loss: 0.1812 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 53ms/epoch - 53ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4918 - val_loss: 0.1838 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5300 - val_loss: 0.1857 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4747 - val_loss: 0.1869 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5231 - val_loss: 0.1874 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4842 - val_loss: 0.1875 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4918 - val_loss: 0.1880 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1594 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5528 - val_loss: 0.1881 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 51ms/epoch - 51ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1596 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5510 - val_loss: 0.1872 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5699 - val_loss: 0.1856 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5222 - val_loss: 0.1855 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5281 - val_loss: 0.1857 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1560 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5622 - val_loss: 0.1855 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2326 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.4606 - val_loss: 0.1871 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5632 - val_loss: 0.1889 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.4785 - val_loss: 0.1918 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5464 - val_loss: 0.1944 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 48ms/epoch - 48ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1628 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5304 - val_loss: 0.1966 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5532 - val_loss: 0.1981 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.2449 - 51ms/epoch - 51ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1453 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.6114 - val_loss: 0.1980 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.2449 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5746 - val_loss: 0.1974 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1539 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5746 - val_loss: 0.1970 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1508 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.5934 - val_loss: 0.1958 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.2128 - 53ms/epoch - 53ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1485 - accuracy: 0.6979 - precision: 0.6979 - recall: 0.6979 - f1_score: 0.5848 - val_loss: 0.1927 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2174 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.7149 - precision: 0.7149 - recall: 0.7149 - f1_score: 0.5839 - val_loss: 0.1904 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1444 - accuracy: 0.7319 - precision: 0.7319 - recall: 0.7319 - f1_score: 0.6228 - val_loss: 0.1884 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.1429 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1957
Accuracy: 0.4646
Precision: 0.4646
Recall: 0.4646
F1 Score: 0.3333
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2138 - accuracy: 0.3660 - precision: 0.3660 - recall: 0.3660 - f1_score: 0.4542 - val_loss: 0.1913 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3492 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1927 - accuracy: 0.4340 - precision: 0.4340 - recall: 0.4340 - f1_score: 0.3814 - val_loss: 0.1622 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.2759 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1960 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.3727 - val_loss: 0.1543 - val_accuracy: 0.7797 - val_precision: 0.7797 - val_recall: 0.7797 - val_f1_score: 0.3810 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1982 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.2687 - val_loss: 0.1575 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.3200 - 51ms/epoch - 51ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1862 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.3758 - val_loss: 0.1646 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1884 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.3875 - val_loss: 0.1745 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1910 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5021 - f1_score: 0.3464 - val_loss: 0.1854 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2692 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1849 - accuracy: 0.4766 - precision: 0.4766 - recall: 0.4766 - f1_score: 0.4115 - val_loss: 0.1939 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1872 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4018 - val_loss: 0.1986 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3188 - 53ms/epoch - 53ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1790 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4609 - val_loss: 0.1998 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 51ms/epoch - 51ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1814 - accuracy: 0.4085 - precision: 0.4085 - recall: 0.4085 - f1_score: 0.4506 - val_loss: 0.1976 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 53ms/epoch - 53ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1795 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4417 - val_loss: 0.1928 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3226 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1795 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4274 - val_loss: 0.1871 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3214 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1835 - accuracy: 0.4000 - precision: 0.4000 - recall: 0.4000 - f1_score: 0.4149 - val_loss: 0.1810 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 52ms/epoch - 52ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1783 - accuracy: 0.4553 - precision: 0.4553 - recall: 0.4553 - f1_score: 0.4182 - val_loss: 0.1758 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1746 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.4762 - val_loss: 0.1719 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1791 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5021 - f1_score: 0.3390 - val_loss: 0.1691 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.2143 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.4852 - val_loss: 0.1678 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.2143 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1740 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4294 - val_loss: 0.1680 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.2143 - 51ms/epoch - 51ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.4000 - val_loss: 0.1690 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.2069 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.4099 - val_loss: 0.1705 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 51ms/epoch - 51ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1727 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.4800 - val_loss: 0.1724 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1681 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4835 - val_loss: 0.1742 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1672 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4845 - val_loss: 0.1759 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1706 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4747 - val_loss: 0.1772 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2979 - 49ms/epoch - 49ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4694 - val_loss: 0.1784 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4821 - val_loss: 0.1795 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 52ms/epoch - 52ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1651 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.5297 - val_loss: 0.1798 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 52ms/epoch - 52ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.4677 - val_loss: 0.1803 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1665 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.4878 - val_loss: 0.1802 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.4608 - val_loss: 0.1797 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1623 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5556 - val_loss: 0.1786 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 53ms/epoch - 53ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5366 - val_loss: 0.1776 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1675 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.4976 - val_loss: 0.1761 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 52ms/epoch - 52ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5300 - val_loss: 0.1745 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4862 - val_loss: 0.1734 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5085 - val_loss: 0.1731 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5081 - val_loss: 0.1730 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1638 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5087 - val_loss: 0.1735 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5514 - val_loss: 0.1745 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4894 - val_loss: 0.1755 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5222 - val_loss: 0.1772 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2326 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1596 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5591 - val_loss: 0.1785 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 54ms/epoch - 54ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5700 - val_loss: 0.1784 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 52ms/epoch - 52ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5181 - val_loss: 0.1778 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.5149 - val_loss: 0.1760 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5217 - val_loss: 0.1747 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2439 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1523 - accuracy: 0.6894 - precision: 0.6894 - recall: 0.6894 - f1_score: 0.6096 - val_loss: 0.1729 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5244 - val_loss: 0.1731 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1536 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.5714 - val_loss: 0.1742 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2500 - 51ms/epoch - 51ms/step

🔍 Resultados no Teste:
Loss: 0.1754
Accuracy: 0.5276
Precision: 0.5276
Recall: 0.5276
F1 Score: 0.3617
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2026 - accuracy: 0.3489 - precision: 0.3489 - recall: 0.3489 - f1_score: 0.3904 - val_loss: 0.1918 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3448 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1855 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.4084 - val_loss: 0.1753 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.3810 - val_loss: 0.1694 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 52ms/epoch - 52ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1900 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.3333 - val_loss: 0.1713 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 49ms/epoch - 49ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1862 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.2893 - val_loss: 0.1757 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1801 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.3929 - val_loss: 0.1820 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1785 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.3795 - val_loss: 0.1865 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3226 - 53ms/epoch - 53ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1766 - accuracy: 0.4638 - precision: 0.4638 - recall: 0.4638 - f1_score: 0.4273 - val_loss: 0.1882 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3437 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1754 - accuracy: 0.4638 - precision: 0.4638 - recall: 0.4638 - f1_score: 0.4522 - val_loss: 0.1873 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3125 - 51ms/epoch - 51ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1793 - accuracy: 0.4383 - precision: 0.4383 - recall: 0.4383 - f1_score: 0.4359 - val_loss: 0.1857 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.3226 - 50ms/epoch - 50ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.4298 - precision: 0.4298 - recall: 0.4298 - f1_score: 0.4123 - val_loss: 0.1825 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1756 - accuracy: 0.4511 - precision: 0.4511 - recall: 0.4511 - f1_score: 0.4416 - val_loss: 0.1791 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3571 - 50ms/epoch - 50ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.4936 - precision: 0.4936 - recall: 0.4936 - f1_score: 0.4566 - val_loss: 0.1754 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1751 - accuracy: 0.4681 - precision: 0.4681 - recall: 0.4681 - f1_score: 0.4131 - val_loss: 0.1725 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3500 - 50ms/epoch - 50ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1750 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.4279 - val_loss: 0.1700 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.3784 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1784 - accuracy: 0.4894 - precision: 0.4894 - recall: 0.4894 - f1_score: 0.3750 - val_loss: 0.1685 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.3636 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4731 - val_loss: 0.1674 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.3125 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.5054 - val_loss: 0.1668 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.3125 - 52ms/epoch - 52ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4598 - val_loss: 0.1667 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.3125 - 52ms/epoch - 52ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5291 - val_loss: 0.1665 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.2500 - 51ms/epoch - 51ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4918 - val_loss: 0.1671 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.2500 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5027 - val_loss: 0.1673 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.2500 - 52ms/epoch - 52ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5000 - val_loss: 0.1676 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1727 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.4488 - val_loss: 0.1682 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 51ms/epoch - 51ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.4695 - val_loss: 0.1682 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.5123 - val_loss: 0.1681 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 51ms/epoch - 51ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1665 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4873 - val_loss: 0.1681 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 51ms/epoch - 51ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4898 - val_loss: 0.1687 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2286 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1688 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.4762 - val_loss: 0.1694 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5561 - val_loss: 0.1691 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2857 - 51ms/epoch - 51ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4947 - val_loss: 0.1690 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.5327 - val_loss: 0.1680 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5204 - val_loss: 0.1672 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2353 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.4687 - val_loss: 0.1662 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.1935 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5185 - val_loss: 0.1650 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1333 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1667 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5081 - val_loss: 0.1653 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.1935 - 49ms/epoch - 49ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4835 - val_loss: 0.1657 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.1935 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5618 - val_loss: 0.1667 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5109 - val_loss: 0.1676 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5584 - val_loss: 0.1675 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5556 - val_loss: 0.1678 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5775 - val_loss: 0.1679 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5532 - val_loss: 0.1677 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2424 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5556 - val_loss: 0.1673 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 49ms/epoch - 49ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1563 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5304 - val_loss: 0.1679 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5550 - val_loss: 0.1682 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1516 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5730 - val_loss: 0.1681 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5870 - val_loss: 0.1674 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 51ms/epoch - 51ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1499 - accuracy: 0.7064 - precision: 0.7064 - recall: 0.7064 - f1_score: 0.6012 - val_loss: 0.1674 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 49ms/epoch - 49ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1457 - accuracy: 0.7277 - precision: 0.7277 - recall: 0.7277 - f1_score: 0.6444 - val_loss: 0.1662 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1875 - 54ms/epoch - 54ms/step

🔍 Resultados no Teste:
Loss: 0.1861
Accuracy: 0.4724
Precision: 0.4724
Recall: 0.4724
F1 Score: 0.2796
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1937 - accuracy: 0.4213 - precision: 0.4213 - recall: 0.4213 - f1_score: 0.4729 - val_loss: 0.1761 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1863 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.3892 - val_loss: 0.1570 - val_accuracy: 0.6949 - val_precision: 0.6949 - val_recall: 0.6949 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1922 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.3566 - val_loss: 0.1555 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1819 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.2975 - val_loss: 0.1599 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1884 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.2595 - val_loss: 0.1673 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.1481 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1822 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.3226 - val_loss: 0.1759 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 51ms/epoch - 51ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1843 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.3626 - val_loss: 0.1850 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3390 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4579 - val_loss: 0.1919 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1722 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4653 - val_loss: 0.1950 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1747 - accuracy: 0.4596 - precision: 0.4596 - recall: 0.4596 - f1_score: 0.4816 - val_loss: 0.1946 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 52ms/epoch - 52ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1807 - accuracy: 0.4085 - precision: 0.4085 - recall: 0.4085 - f1_score: 0.4418 - val_loss: 0.1911 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1788 - accuracy: 0.3915 - precision: 0.3915 - recall: 0.3915 - f1_score: 0.4211 - val_loss: 0.1864 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3692 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1802 - accuracy: 0.4255 - precision: 0.4255 - recall: 0.4255 - f1_score: 0.4304 - val_loss: 0.1819 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3448 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1792 - accuracy: 0.4511 - precision: 0.4511 - recall: 0.4511 - f1_score: 0.3944 - val_loss: 0.1775 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2353 - 50ms/epoch - 50ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.4670 - val_loss: 0.1739 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.4809 - val_loss: 0.1712 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3243 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1724 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.4342 - val_loss: 0.1702 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1732 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4503 - val_loss: 0.1705 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3243 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.4941 - val_loss: 0.1716 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1706 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5057 - val_loss: 0.1731 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1744 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4746 - val_loss: 0.1754 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 51ms/epoch - 51ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.4889 - val_loss: 0.1775 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2593 - 51ms/epoch - 51ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4783 - val_loss: 0.1798 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 51ms/epoch - 51ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4949 - val_loss: 0.1819 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.2759 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.5093 - val_loss: 0.1833 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2712 - 48ms/epoch - 48ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.5333 - val_loss: 0.1840 - val_accuracy: 0.2881 - val_precision: 0.2881 - val_recall: 0.2881 - val_f1_score: 0.2759 - 51ms/epoch - 51ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.5000 - val_loss: 0.1833 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 51ms/epoch - 51ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4630 - val_loss: 0.1818 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.5072 - val_loss: 0.1799 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2909 - 51ms/epoch - 51ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1688 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4585 - val_loss: 0.1776 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.2963 - 51ms/epoch - 51ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.5102 - val_loss: 0.1751 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4492 - val_loss: 0.1726 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4918 - val_loss: 0.1711 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 50ms/epoch - 50ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5251 - val_loss: 0.1700 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5029 - val_loss: 0.1702 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 51ms/epoch - 51ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.7021 - precision: 0.7021 - recall: 0.7021 - f1_score: 0.5625 - val_loss: 0.1712 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 51ms/epoch - 51ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5667 - val_loss: 0.1721 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1550 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5263 - val_loss: 0.1732 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1577 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5514 - val_loss: 0.1745 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1591 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5161 - val_loss: 0.1751 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 51ms/epoch - 51ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1545 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5368 - val_loss: 0.1746 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 53ms/epoch - 53ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5408 - val_loss: 0.1722 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.4889 - val_loss: 0.1707 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 51ms/epoch - 51ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.4944 - val_loss: 0.1709 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 49ms/epoch - 49ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1525 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5838 - val_loss: 0.1707 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 49ms/epoch - 49ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1547 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5714 - val_loss: 0.1708 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5444 - val_loss: 0.1718 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1464 - accuracy: 0.7064 - precision: 0.7064 - recall: 0.7064 - f1_score: 0.6057 - val_loss: 0.1727 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1516 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5587 - val_loss: 0.1741 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1493 - accuracy: 0.6766 - precision: 0.6766 - recall: 0.6766 - f1_score: 0.5730 - val_loss: 0.1736 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 70ms/epoch - 70ms/step

🔍 Resultados no Teste:
Loss: 0.1842
Accuracy: 0.4882
Precision: 0.4882
Recall: 0.4882
F1 Score: 0.3810
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2174 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.2222 - val_loss: 0.1744 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2703 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1820 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.3913 - val_loss: 0.2000 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.3548 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1961 - accuracy: 0.4043 - precision: 0.4043 - recall: 0.4043 - f1_score: 0.3860 - val_loss: 0.2142 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1834 - accuracy: 0.4511 - precision: 0.4511 - recall: 0.4511 - f1_score: 0.4557 - val_loss: 0.2156 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 48ms/epoch - 48ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1832 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4653 - val_loss: 0.2099 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3429 - 51ms/epoch - 51ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1800 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.4672 - val_loss: 0.2012 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3284 - 49ms/epoch - 49ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1781 - accuracy: 0.4894 - precision: 0.4894 - recall: 0.4894 - f1_score: 0.4545 - val_loss: 0.1927 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3492 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1776 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - f1_score: 0.4587 - val_loss: 0.1853 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.3636 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.4356 - val_loss: 0.1794 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3404 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1743 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.4530 - val_loss: 0.1750 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3256 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4382 - val_loss: 0.1729 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3415 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1804 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.3600 - val_loss: 0.1731 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1730 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4268 - val_loss: 0.1740 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 48ms/epoch - 48ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1770 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4276 - val_loss: 0.1766 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 51ms/epoch - 51ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.4713 - val_loss: 0.1800 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4667 - val_loss: 0.1834 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.3265 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1719 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4108 - val_loss: 0.1871 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3214 - 51ms/epoch - 51ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.5404 - precision: 0.5404 - recall: 0.5404 - f1_score: 0.4194 - val_loss: 0.1902 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.3103 - 54ms/epoch - 54ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1719 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4876 - val_loss: 0.1924 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 51ms/epoch - 51ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1746 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4785 - val_loss: 0.1941 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4476 - val_loss: 0.1951 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1668 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.4977 - val_loss: 0.1946 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 51ms/epoch - 51ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.4519 - val_loss: 0.1931 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2903 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.5023 - val_loss: 0.1908 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.3103 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.5196 - val_loss: 0.1879 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3077 - 51ms/epoch - 51ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4646 - val_loss: 0.1852 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1643 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5026 - val_loss: 0.1828 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.4678 - val_loss: 0.1813 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 57ms/epoch - 57ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1619 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.4941 - val_loss: 0.1809 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 52ms/epoch - 52ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4327 - val_loss: 0.1815 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1634 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4804 - val_loss: 0.1830 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 48ms/epoch - 48ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.4693 - val_loss: 0.1855 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 48ms/epoch - 48ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5397 - val_loss: 0.1881 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 52ms/epoch - 52ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4821 - val_loss: 0.1908 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1510 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5946 - val_loss: 0.1922 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5588 - val_loss: 0.1927 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1643 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.4687 - val_loss: 0.1928 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1554 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5588 - val_loss: 0.1912 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 48ms/epoch - 48ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5699 - val_loss: 0.1881 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4746 - val_loss: 0.1855 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1532 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5600 - val_loss: 0.1836 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1520 - accuracy: 0.6851 - precision: 0.6851 - recall: 0.6851 - f1_score: 0.5889 - val_loss: 0.1816 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.5556 - val_loss: 0.1816 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.5665 - val_loss: 0.1836 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1511 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5568 - val_loss: 0.1854 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5143 - val_loss: 0.1877 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1496 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5838 - val_loss: 0.1899 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1504 - accuracy: 0.6979 - precision: 0.6979 - recall: 0.6979 - f1_score: 0.5848 - val_loss: 0.1926 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1483 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5820 - val_loss: 0.1927 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1506 - accuracy: 0.6894 - precision: 0.6894 - recall: 0.6894 - f1_score: 0.5967 - val_loss: 0.1922 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1921
Accuracy: 0.4803
Precision: 0.4803
Recall: 0.4803
F1 Score: 0.4000
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2126 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.2759 - val_loss: 0.2051 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3810 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1926 - accuracy: 0.4383 - precision: 0.4383 - recall: 0.4383 - f1_score: 0.4310 - val_loss: 0.2177 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3529 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1981 - accuracy: 0.3957 - precision: 0.3957 - recall: 0.3957 - f1_score: 0.4228 - val_loss: 0.2073 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1850 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4609 - val_loss: 0.1911 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3810 - 50ms/epoch - 50ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1771 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4821 - val_loss: 0.1769 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.4231 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1815 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.3708 - val_loss: 0.1689 - val_accuracy: 0.6102 - val_precision: 0.6102 - val_recall: 0.6102 - val_f1_score: 0.4103 - 49ms/epoch - 49ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1839 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.3234 - val_loss: 0.1663 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.4000 - 51ms/epoch - 51ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1801 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.3975 - val_loss: 0.1676 - val_accuracy: 0.6271 - val_precision: 0.6271 - val_recall: 0.6271 - val_f1_score: 0.4211 - 53ms/epoch - 53ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.4678 - val_loss: 0.1700 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3902 - 51ms/epoch - 51ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.4258 - val_loss: 0.1740 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3830 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4556 - val_loss: 0.1783 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.4231 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4787 - val_loss: 0.1829 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.3860 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.5574 - precision: 0.5574 - recall: 0.5574 - f1_score: 0.4747 - val_loss: 0.1859 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.3729 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5226 - val_loss: 0.1881 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3607 - 48ms/epoch - 48ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1734 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.4601 - val_loss: 0.1896 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3607 - 50ms/epoch - 50ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1783 - accuracy: 0.4553 - precision: 0.4553 - recall: 0.4553 - f1_score: 0.4234 - val_loss: 0.1901 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.3607 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1776 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4525 - val_loss: 0.1893 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3667 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5021 - f1_score: 0.4658 - val_loss: 0.1875 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.3860 - 50ms/epoch - 50ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.4815 - val_loss: 0.1847 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.4151 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.4541 - val_loss: 0.1816 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 51ms/epoch - 51ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1714 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4577 - val_loss: 0.1786 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 49ms/epoch - 49ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4556 - val_loss: 0.1772 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 48ms/epoch - 48ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1679 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4520 - val_loss: 0.1772 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 52ms/epoch - 52ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1667 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4422 - val_loss: 0.1772 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1668 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4712 - val_loss: 0.1774 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 51ms/epoch - 51ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4757 - val_loss: 0.1778 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5275 - val_loss: 0.1784 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2609 - 51ms/epoch - 51ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5207 - val_loss: 0.1795 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2979 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4839 - val_loss: 0.1805 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5319 - val_loss: 0.1815 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5079 - val_loss: 0.1824 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1623 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5213 - val_loss: 0.1838 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1652 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4845 - val_loss: 0.1845 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 54ms/epoch - 54ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.5222 - val_loss: 0.1838 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5181 - val_loss: 0.1820 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 51ms/epoch - 51ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.4889 - val_loss: 0.1812 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 48ms/epoch - 48ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5217 - val_loss: 0.1805 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2667 - 49ms/epoch - 49ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5444 - val_loss: 0.1798 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5304 - val_loss: 0.1799 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5312 - val_loss: 0.1798 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1634 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5111 - val_loss: 0.1797 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1525 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5714 - val_loss: 0.1795 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.4941 - val_loss: 0.1811 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2727 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4891 - val_loss: 0.1827 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5608 - val_loss: 0.1842 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 49ms/epoch - 49ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6809 - precision: 0.6809 - recall: 0.6809 - f1_score: 0.6032 - val_loss: 0.1831 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 48ms/epoch - 48ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1503 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5926 - val_loss: 0.1810 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5587 - val_loss: 0.1804 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1474 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.6044 - val_loss: 0.1798 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1474 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.6000 - val_loss: 0.1795 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 51ms/epoch - 51ms/step

🔍 Resultados no Teste:
Loss: 0.1901
Accuracy: 0.4646
Precision: 0.4646
Recall: 0.4646
F1 Score: 0.4035
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2186 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.2857 - val_loss: 0.2130 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.2581 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.2022 - accuracy: 0.4255 - precision: 0.4255 - recall: 0.4255 - f1_score: 0.3216 - val_loss: 0.2457 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 49ms/epoch - 49ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1884 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.4882 - val_loss: 0.2485 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 52ms/epoch - 52ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1943 - accuracy: 0.3660 - precision: 0.3660 - recall: 0.3660 - f1_score: 0.4377 - val_loss: 0.2361 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 51ms/epoch - 51ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1920 - accuracy: 0.3489 - precision: 0.3489 - recall: 0.3489 - f1_score: 0.4183 - val_loss: 0.2188 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.2985 - 49ms/epoch - 49ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1887 - accuracy: 0.3957 - precision: 0.3957 - recall: 0.3957 - f1_score: 0.3932 - val_loss: 0.2025 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1859 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.4299 - val_loss: 0.1891 - val_accuracy: 0.3390 - val_precision: 0.3390 - val_recall: 0.3390 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1814 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.3696 - val_loss: 0.1805 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.1818 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1865 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.3478 - val_loss: 0.1770 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.1429 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1802 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.3908 - val_loss: 0.1763 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1538 - 51ms/epoch - 51ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1860 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.2945 - val_loss: 0.1784 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2273 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1782 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.3537 - val_loss: 0.1824 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.2449 - 52ms/epoch - 52ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1714 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4253 - val_loss: 0.1865 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2264 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1780 - accuracy: 0.5362 - precision: 0.5362 - recall: 0.5362 - f1_score: 0.4233 - val_loss: 0.1904 - val_accuracy: 0.3220 - val_precision: 0.3220 - val_recall: 0.3220 - val_f1_score: 0.2857 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1735 - accuracy: 0.4936 - precision: 0.4936 - recall: 0.4936 - f1_score: 0.4664 - val_loss: 0.1937 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.2807 - 49ms/epoch - 49ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1746 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.4673 - val_loss: 0.1964 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2712 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5234 - precision: 0.5234 - recall: 0.5234 - f1_score: 0.4862 - val_loss: 0.1980 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.2667 - 51ms/epoch - 51ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1717 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.4840 - val_loss: 0.1984 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2951 - 52ms/epoch - 52ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.4874 - val_loss: 0.1974 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2712 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4807 - val_loss: 0.1953 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2712 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.4649 - val_loss: 0.1927 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.2182 - 51ms/epoch - 51ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.4843 - val_loss: 0.1902 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.1852 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1743 - accuracy: 0.5064 - precision: 0.5064 - recall: 0.5064 - f1_score: 0.4679 - val_loss: 0.1877 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.1852 - 48ms/epoch - 48ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4804 - val_loss: 0.1850 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.1961 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5447 - precision: 0.5447 - recall: 0.5447 - f1_score: 0.4569 - val_loss: 0.1828 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2174 - 50ms/epoch - 50ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.5226 - val_loss: 0.1808 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2326 - 48ms/epoch - 48ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4481 - val_loss: 0.1794 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1653 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5193 - val_loss: 0.1786 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2105 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1644 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.4918 - val_loss: 0.1783 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2105 - 52ms/epoch - 52ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.4343 - val_loss: 0.1787 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.2381 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5568 - val_loss: 0.1795 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2326 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1608 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5543 - val_loss: 0.1807 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2326 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.6213 - precision: 0.6213 - recall: 0.6213 - f1_score: 0.5291 - val_loss: 0.1823 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2174 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.5155 - val_loss: 0.1835 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2174 - 50ms/epoch - 50ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.5075 - val_loss: 0.1843 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5231 - val_loss: 0.1845 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2553 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1576 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5455 - val_loss: 0.1845 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.2174 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5699 - val_loss: 0.1838 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2222 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1574 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5635 - val_loss: 0.1829 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.1860 - 48ms/epoch - 48ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.5702 - precision: 0.5702 - recall: 0.5702 - f1_score: 0.4767 - val_loss: 0.1819 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 53ms/epoch - 53ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1635 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.4535 - val_loss: 0.1828 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.1905 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1592 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.5193 - val_loss: 0.1834 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1546 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5652 - val_loss: 0.1842 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 54ms/epoch - 54ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5622 - val_loss: 0.1842 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5236 - val_loss: 0.1841 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 49ms/epoch - 49ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5484 - val_loss: 0.1839 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.1951 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1503 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5761 - val_loss: 0.1837 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2105 - 48ms/epoch - 48ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1484 - accuracy: 0.6638 - precision: 0.6638 - recall: 0.6638 - f1_score: 0.5730 - val_loss: 0.1824 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1470 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.6000 - val_loss: 0.1807 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1479 - accuracy: 0.6936 - precision: 0.6936 - recall: 0.6936 - f1_score: 0.5955 - val_loss: 0.1805 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1740
Accuracy: 0.5354
Precision: 0.5354
Recall: 0.5354
F1 Score: 0.4040
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2145 - accuracy: 0.3362 - precision: 0.3362 - recall: 0.3362 - f1_score: 0.4583 - val_loss: 0.2101 - val_accuracy: 0.3051 - val_precision: 0.3051 - val_recall: 0.3051 - val_f1_score: 0.3692 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1928 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.4348 - val_loss: 0.1646 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3243 - 50ms/epoch - 50ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1944 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.3108 - val_loss: 0.1542 - val_accuracy: 0.7119 - val_precision: 0.7119 - val_recall: 0.7119 - val_f1_score: 0.4138 - 51ms/epoch - 51ms/step
Epoch 4/50
1/1 - 0s - loss: 0.2002 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.3066 - val_loss: 0.1573 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.3871 - 49ms/epoch - 49ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1914 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.3053 - val_loss: 0.1663 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3500 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1886 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.3758 - val_loss: 0.1775 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3043 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1916 - accuracy: 0.4681 - precision: 0.4681 - recall: 0.4681 - f1_score: 0.3169 - val_loss: 0.1894 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3214 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1839 - accuracy: 0.4809 - precision: 0.4809 - recall: 0.4809 - f1_score: 0.3960 - val_loss: 0.1999 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3175 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1790 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4561 - val_loss: 0.2068 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1805 - accuracy: 0.3915 - precision: 0.3915 - recall: 0.3915 - f1_score: 0.4479 - val_loss: 0.2088 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3478 - 47ms/epoch - 47ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1753 - accuracy: 0.4468 - precision: 0.4468 - recall: 0.4468 - f1_score: 0.4922 - val_loss: 0.2068 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3188 - 49ms/epoch - 49ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1775 - accuracy: 0.4340 - precision: 0.4340 - recall: 0.4340 - f1_score: 0.4784 - val_loss: 0.2016 - val_accuracy: 0.2203 - val_precision: 0.2203 - val_recall: 0.2203 - val_f1_score: 0.3235 - 50ms/epoch - 50ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1750 - accuracy: 0.4383 - precision: 0.4383 - recall: 0.4383 - f1_score: 0.4844 - val_loss: 0.1947 - val_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2542 - val_f1_score: 0.3125 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1817 - accuracy: 0.4255 - precision: 0.4255 - recall: 0.4255 - f1_score: 0.4304 - val_loss: 0.1874 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.3509 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1755 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4701 - val_loss: 0.1803 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.3462 - 49ms/epoch - 49ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1725 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4478 - val_loss: 0.1747 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3750 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.4945 - val_loss: 0.1705 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3415 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1741 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4457 - val_loss: 0.1679 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 66ms/epoch - 66ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1780 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.4277 - val_loss: 0.1673 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.2857 - 77ms/epoch - 77ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.4375 - val_loss: 0.1683 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 56ms/epoch - 56ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4353 - val_loss: 0.1698 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 68ms/epoch - 68ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1743 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4114 - val_loss: 0.1717 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2791 - 55ms/epoch - 55ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5872 - precision: 0.5872 - recall: 0.5872 - f1_score: 0.4393 - val_loss: 0.1742 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3673 - 53ms/epoch - 53ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1762 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4111 - val_loss: 0.1774 - val_accuracy: 0.4576 - val_precision: 0.4576 - val_recall: 0.4576 - val_f1_score: 0.3600 - 54ms/epoch - 54ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1706 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.4876 - val_loss: 0.1805 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.3462 - 57ms/epoch - 57ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1685 - accuracy: 0.5532 - precision: 0.5532 - recall: 0.5532 - f1_score: 0.4928 - val_loss: 0.1829 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3333 - 60ms/epoch - 60ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - f1_score: 0.4537 - val_loss: 0.1846 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3571 - 53ms/epoch - 53ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1724 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - f1_score: 0.4585 - val_loss: 0.1861 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.3509 - 59ms/epoch - 59ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.4911 - val_loss: 0.1865 - val_accuracy: 0.3729 - val_precision: 0.3729 - val_recall: 0.3729 - val_f1_score: 0.3509 - 67ms/epoch - 67ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.4936 - precision: 0.4936 - recall: 0.4936 - f1_score: 0.4936 - val_loss: 0.1852 - val_accuracy: 0.3898 - val_precision: 0.3898 - val_recall: 0.3898 - val_f1_score: 0.3571 - 85ms/epoch - 85ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5319 - precision: 0.5319 - recall: 0.5319 - f1_score: 0.4907 - val_loss: 0.1834 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.3704 - 62ms/epoch - 62ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5404 - precision: 0.5404 - recall: 0.5404 - f1_score: 0.5135 - val_loss: 0.1813 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.3396 - 141ms/epoch - 141ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1679 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.5238 - val_loss: 0.1793 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.2857 - 138ms/epoch - 138ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5604 - val_loss: 0.1770 - val_accuracy: 0.4237 - val_precision: 0.4237 - val_recall: 0.4237 - val_f1_score: 0.2917 - 100ms/epoch - 100ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5475 - val_loss: 0.1747 - val_accuracy: 0.4407 - val_precision: 0.4407 - val_recall: 0.4407 - val_f1_score: 0.2979 - 116ms/epoch - 116ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.5915 - precision: 0.5915 - recall: 0.5915 - f1_score: 0.4839 - val_loss: 0.1728 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 81ms/epoch - 81ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5119 - val_loss: 0.1714 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 61ms/epoch - 61ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.4756 - val_loss: 0.1706 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.2703 - 57ms/epoch - 57ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.6723 - precision: 0.6723 - recall: 0.6723 - f1_score: 0.5444 - val_loss: 0.1707 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3077 - 81ms/epoch - 81ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5402 - val_loss: 0.1714 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3000 - 79ms/epoch - 79ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5412 - val_loss: 0.1727 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2927 - 68ms/epoch - 68ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1602 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5385 - val_loss: 0.1736 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 85ms/epoch - 85ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5304 - val_loss: 0.1750 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.2857 - 60ms/epoch - 60ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5506 - val_loss: 0.1764 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 89ms/epoch - 89ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1579 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5745 - val_loss: 0.1772 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 97ms/epoch - 97ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1656 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.5208 - val_loss: 0.1780 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3556 - 85ms/epoch - 85ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1541 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5729 - val_loss: 0.1775 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 82ms/epoch - 82ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1559 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.5699 - val_loss: 0.1760 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3256 - 67ms/epoch - 67ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5622 - val_loss: 0.1741 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.3256 - 67ms/epoch - 67ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5806 - val_loss: 0.1718 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.3077 - 61ms/epoch - 61ms/step

🔍 Resultados no Teste:
Loss: 0.1786
Accuracy: 0.4724
Precision: 0.4724
Recall: 0.4724
F1 Score: 0.3093
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
Matrix_60: [(421, 60), (421, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2248 - accuracy: 0.6468 - precision: 0.6468 - recall: 0.6468 - f1_score: 0.0879 - val_loss: 0.1547 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.1176 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1985 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.2958 - val_loss: 0.1866 - val_accuracy: 0.3559 - val_precision: 0.3559 - val_recall: 0.3559 - val_f1_score: 0.3667 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1862 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4312 - val_loss: 0.2108 - val_accuracy: 0.2373 - val_precision: 0.2373 - val_recall: 0.2373 - val_f1_score: 0.3478 - 48ms/epoch - 48ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1949 - accuracy: 0.3702 - precision: 0.3702 - recall: 0.3702 - f1_score: 0.4394 - val_loss: 0.2161 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 49ms/epoch - 49ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1993 - accuracy: 0.3362 - precision: 0.3362 - recall: 0.3362 - f1_score: 0.4348 - val_loss: 0.2079 - val_accuracy: 0.2034 - val_precision: 0.2034 - val_recall: 0.2034 - val_f1_score: 0.3380 - 55ms/epoch - 55ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1990 - accuracy: 0.3106 - precision: 0.3106 - recall: 0.3106 - f1_score: 0.3864 - val_loss: 0.1953 - val_accuracy: 0.2712 - val_precision: 0.2712 - val_recall: 0.2712 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1870 - accuracy: 0.4043 - precision: 0.4043 - recall: 0.4043 - f1_score: 0.4262 - val_loss: 0.1825 - val_accuracy: 0.4068 - val_precision: 0.4068 - val_recall: 0.4068 - val_f1_score: 0.3860 - 58ms/epoch - 58ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1839 - accuracy: 0.4085 - precision: 0.4085 - recall: 0.4085 - f1_score: 0.3767 - val_loss: 0.1724 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1810 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - f1_score: 0.4162 - val_loss: 0.1646 - val_accuracy: 0.6610 - val_precision: 0.6610 - val_recall: 0.6610 - val_f1_score: 0.1667 - 50ms/epoch - 50ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1798 - accuracy: 0.5191 - precision: 0.5191 - recall: 0.5191 - f1_score: 0.3757 - val_loss: 0.1595 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1863 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.2400 - val_loss: 0.1570 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1830 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - f1_score: 0.3088 - val_loss: 0.1560 - val_accuracy: 0.7627 - val_precision: 0.7627 - val_recall: 0.7627 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1822 - accuracy: 0.5787 - precision: 0.5787 - recall: 0.5787 - f1_score: 0.2326 - val_loss: 0.1564 - val_accuracy: 0.7458 - val_precision: 0.7458 - val_recall: 0.7458 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1804 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.3182 - val_loss: 0.1577 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1745 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.3704 - val_loss: 0.1597 - val_accuracy: 0.7288 - val_precision: 0.7288 - val_recall: 0.7288 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1777 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.3448 - val_loss: 0.1622 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1753 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.3919 - val_loss: 0.1651 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1761 - accuracy: 0.5617 - precision: 0.5617 - recall: 0.5617 - f1_score: 0.3832 - val_loss: 0.1683 - val_accuracy: 0.5932 - val_precision: 0.5932 - val_recall: 0.5932 - val_f1_score: 0.1429 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1710 - accuracy: 0.5830 - precision: 0.5830 - recall: 0.5830 - f1_score: 0.4674 - val_loss: 0.1715 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 49ms/epoch - 49ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.4894 - precision: 0.4894 - recall: 0.4894 - f1_score: 0.4286 - val_loss: 0.1745 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3182 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1752 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4312 - val_loss: 0.1771 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.4167 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.4766 - precision: 0.4766 - recall: 0.4766 - f1_score: 0.4581 - val_loss: 0.1790 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.4400 - 51ms/epoch - 51ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1745 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4426 - val_loss: 0.1801 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.4314 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1748 - accuracy: 0.4511 - precision: 0.4511 - recall: 0.4511 - f1_score: 0.4464 - val_loss: 0.1805 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.4314 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1720 - accuracy: 0.4170 - precision: 0.4170 - recall: 0.4170 - f1_score: 0.4315 - val_loss: 0.1801 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.4400 - 48ms/epoch - 48ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1748 - accuracy: 0.4426 - precision: 0.4426 - recall: 0.4426 - f1_score: 0.4329 - val_loss: 0.1792 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.4082 - 50ms/epoch - 50ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1735 - accuracy: 0.4553 - precision: 0.4553 - recall: 0.4553 - f1_score: 0.4286 - val_loss: 0.1780 - val_accuracy: 0.4915 - val_precision: 0.4915 - val_recall: 0.4915 - val_f1_score: 0.3750 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1763 - accuracy: 0.4723 - precision: 0.4723 - recall: 0.4723 - f1_score: 0.4655 - val_loss: 0.1761 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.3111 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.4979 - precision: 0.4979 - recall: 0.4979 - f1_score: 0.4685 - val_loss: 0.1742 - val_accuracy: 0.4746 - val_precision: 0.4746 - val_recall: 0.4746 - val_f1_score: 0.2051 - 51ms/epoch - 51ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1669 - accuracy: 0.5660 - precision: 0.5660 - recall: 0.5660 - f1_score: 0.5234 - val_loss: 0.1721 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.1212 - 51ms/epoch - 51ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5489 - precision: 0.5489 - recall: 0.5489 - f1_score: 0.4804 - val_loss: 0.1706 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1250 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1712 - accuracy: 0.6170 - precision: 0.6170 - recall: 0.6170 - f1_score: 0.5361 - val_loss: 0.1693 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.1290 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1667 - accuracy: 0.6553 - precision: 0.6553 - recall: 0.6553 - f1_score: 0.5424 - val_loss: 0.1685 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1333 - 50ms/epoch - 50ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1691 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5029 - val_loss: 0.1680 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.1379 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1675 - accuracy: 0.6298 - precision: 0.6298 - recall: 0.6298 - f1_score: 0.4528 - val_loss: 0.1682 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.1379 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1712 - accuracy: 0.5957 - precision: 0.5957 - recall: 0.5957 - f1_score: 0.4751 - val_loss: 0.1685 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.1333 - 51ms/epoch - 51ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5745 - precision: 0.5745 - recall: 0.5745 - f1_score: 0.4505 - val_loss: 0.1690 - val_accuracy: 0.5424 - val_precision: 0.5424 - val_recall: 0.5424 - val_f1_score: 0.1290 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1668 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5027 - val_loss: 0.1696 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1250 - 52ms/epoch - 52ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1656 - accuracy: 0.6681 - precision: 0.6681 - recall: 0.6681 - f1_score: 0.5465 - val_loss: 0.1703 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1250 - 54ms/epoch - 54ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - f1_score: 0.5435 - val_loss: 0.1708 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.6383 - precision: 0.6383 - recall: 0.6383 - f1_score: 0.5251 - val_loss: 0.1715 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.2778 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6596 - precision: 0.6596 - recall: 0.6596 - f1_score: 0.5652 - val_loss: 0.1725 - val_accuracy: 0.5763 - val_precision: 0.5763 - val_recall: 0.5763 - val_f1_score: 0.3243 - 50ms/epoch - 50ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1620 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5326 - val_loss: 0.1731 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 51ms/epoch - 51ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5686 - val_loss: 0.1738 - val_accuracy: 0.5593 - val_precision: 0.5593 - val_recall: 0.5593 - val_f1_score: 0.3158 - 48ms/epoch - 48ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.6043 - precision: 0.6043 - recall: 0.6043 - f1_score: 0.5131 - val_loss: 0.1739 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2632 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1606 - accuracy: 0.6511 - precision: 0.6511 - recall: 0.6511 - f1_score: 0.5543 - val_loss: 0.1741 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2632 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1653 - accuracy: 0.6128 - precision: 0.6128 - recall: 0.6128 - f1_score: 0.5027 - val_loss: 0.1739 - val_accuracy: 0.5085 - val_precision: 0.5085 - val_recall: 0.5085 - val_f1_score: 0.2564 - 48ms/epoch - 48ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1573 - accuracy: 0.6255 - precision: 0.6255 - recall: 0.6255 - f1_score: 0.5417 - val_loss: 0.1729 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 49ms/epoch - 49ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1634 - accuracy: 0.6085 - precision: 0.6085 - recall: 0.6085 - f1_score: 0.5158 - val_loss: 0.1723 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.1765 - 52ms/epoch - 52ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.6340 - precision: 0.6340 - recall: 0.6340 - f1_score: 0.5222 - val_loss: 0.1722 - val_accuracy: 0.5254 - val_precision: 0.5254 - val_recall: 0.5254 - val_f1_score: 0.2222 - 51ms/epoch - 51ms/step

🔍 Resultados no Teste:
Loss: 0.1750
Accuracy: 0.5591
Precision: 0.5591
Recall: 0.5591
F1 Score: 0.3913
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
480
540 540
(421, 60) (421, 60) (421, 60) (421, 60)
(421, 60) (421, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 76ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 541 | Acuracia_1: 0.0 | Contagem Geral: 52.0 
Ordem Natural: 50.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.8462 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.221
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
481
541 541
(422, 60) (422, 60) (422, 60) (422, 60)
(422, 60) (422, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 542 | Acuracia_1: 0.0 | Contagem Geral: 52.0 
Ordem Natural: 50.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1887 | Acuracia_0: 0.5 
Precisao modelo Geral: 60.4396
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
482
542 542
(423, 60) (423, 60) (423, 60) (423, 60)
(423, 60) (423, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 543 | Acuracia_1: 0.0 | Contagem Geral: 53.0 
Ordem Natural: 51.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1887 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.1093
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
483
543 543
(424, 60) (424, 60) (424, 60) (424, 60)
(424, 60) (424, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 544 | Acuracia_1: 0 | Contagem Geral: 53.0 
Ordem Natural: 52.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1887 | Acuracia_0: 0 
Precisao modelo Geral: 59.7826
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
484
544 544
(425, 60) (425, 60) (425, 60) (425, 60)
(425, 60) (425, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 545 | Acuracia_1: 1.0 | Contagem Geral: 53.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1887 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
485
545 545
(426, 60) (426, 60) (426, 60) (426, 60)
(426, 60) (426, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 546 | Acuracia_1: 0.5 | Contagem Geral: 53.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.6296 | Acuracia_0: 0.3333 
Precisao modelo Geral: 59.6774
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
486
546 546
(427, 60) (427, 60) (427, 60) (427, 60)
(427, 60) (427, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 547 | Acuracia_1: 0 | Contagem Geral: 54.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.6296 | Acuracia_0: 0 
Precisao modelo Geral: 59.893
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
487
547 547
(428, 60) (428, 60) (428, 60) (428, 60)
(428, 60) (428, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 548 | Acuracia_1: 0.0 | Contagem Geral: 54.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.6296 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.1064
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
488
548 548
(429, 60) (429, 60) (429, 60) (429, 60)
(429, 60) (429, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 549 | Acuracia_1: 0.0 | Contagem Geral: 54.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0909 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.7884
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
489
549 549
(430, 60) (430, 60) (430, 60) (430, 60)
(430, 60) (430, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 550 | Acuracia_1: 0.0 | Contagem Geral: 55.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0909 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
490
550 550
(431, 60) (431, 60) (431, 60) (431, 60)
(431, 60) (431, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 551 | Acuracia_1: 0 | Contagem Geral: 55.0 
Ordem Natural: 53.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3571 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.2094
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
491
551 551
(432, 60) (432, 60) (432, 60) (432, 60)
(432, 60) (432, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 552 | Acuracia_1: 0 | Contagem Geral: 56.0 
Ordem Natural: 54.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3571 | Acuracia_0: 0 
Precisao modelo Geral: 60.4167
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
492
552 552
(433, 60) (433, 60) (433, 60) (433, 60)
(433, 60) (433, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 553 | Acuracia_1: 1.0 | Contagem Geral: 56.0 
Ordem Natural: 54.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3571 | Acuracia_0: 1.0 
Precisao modelo Geral: 60.6218
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
493
553 553
(434, 60) (434, 60) (434, 60) (434, 60)
(434, 60) (434, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 554 | Acuracia_1: 0.0 | Contagem Geral: 56.0 
Ordem Natural: 54.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3571 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.8247
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
494
554 554
(435, 60) (435, 60) (435, 60) (435, 60)
(435, 60) (435, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 555 | Acuracia_1: 0.6667 | Contagem Geral: 56.0 
Ordem Natural: 54.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3571 | Acuracia_0: 0.6667 
Precisao modelo Geral: 60.5128
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
495
555 555
(436, 60) (436, 60) (436, 60) (436, 60)
(436, 60) (436, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 556 | Acuracia_1: 0 | Contagem Geral: 56.0 
Ordem Natural: 55.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8246 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.2041
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
496
556 556
(437, 60) (437, 60) (437, 60) (437, 60)
(437, 60) (437, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 557 | Acuracia_1: 0.0 | Contagem Geral: 57.0 
Ordem Natural: 55.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8246 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.4061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
497
557 557
(438, 60) (438, 60) (438, 60) (438, 60)
(438, 60) (438, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 558 | Acuracia_1: 0.0 | Contagem Geral: 57.0 
Ordem Natural: 55.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 31.0345 | Acuracia_0: 0.5 
Precisao modelo Geral: 60.6061
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
498
558 558
(439, 60) (439, 60) (439, 60) (439, 60)
(439, 60) (439, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 559 | Acuracia_1: 0 | Contagem Geral: 58.0 
Ordem Natural: 56.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5085 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.3015
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
499
559 559
(440, 60) (440, 60) (440, 60) (440, 60)
(440, 60) (440, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 560 | Acuracia_1: 0 | Contagem Geral: 59.0 
Ordem Natural: 56.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.5085 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
500
560 560
(441, 60) (441, 60) (441, 60) (441, 60)
(441, 60) (441, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 561 | Acuracia_1: 0 | Contagem Geral: 59.0 
Ordem Natural: 57.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.7015
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
501
561 561
(442, 60) (442, 60) (442, 60) (442, 60)
(442, 60) (442, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 562 | Acuracia_1: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 57.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.4059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
502
562 562
(443, 60) (443, 60) (443, 60) (443, 60)
(443, 60) (443, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 563 | Acuracia_1: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.6059
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
503
563 563
(444, 60) (444, 60) (444, 60) (444, 60)
(444, 60) (444, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 564 | Acuracia_1: 0 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.8039
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
504
564 564
(445, 60) (445, 60) (445, 60) (445, 60)
(445, 60) (445, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 565 | Acuracia_1: 0 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
505
565 565
(446, 60) (446, 60) (446, 60) (446, 60)
(446, 60) (446, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 566 | Acuracia_1: 0.0 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 60.1942
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
506
566 566
(447, 60) (447, 60) (447, 60) (447, 60)
(447, 60) (447, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 567 | Acuracia_1: 0 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 60.3865
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
507
567 567
(448, 60) (448, 60) (448, 60) (448, 60)
(448, 60) (448, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 568 | Acuracia_1: 0.5 | Contagem Geral: 60.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5082 | Acuracia_0: 0.3333 
Precisao modelo Geral: 60.0962
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
508
568 568
(449, 60) (449, 60) (449, 60) (449, 60)
(449, 60) (449, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 569 | Acuracia_1: 1.0 | Contagem Geral: 61.0 
Ordem Natural: 58.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5082 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.8086
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
509
569 569
(450, 60) (450, 60) (450, 60) (450, 60)
(450, 60) (450, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 570 | Acuracia_1: 0.0 | Contagem Geral: 61.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.5238
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
510
570 570
(451, 60) (451, 60) (451, 60) (451, 60)
(451, 60) (451, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 571 | Acuracia_1: 0.0 | Contagem Geral: 62.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.7156
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
511
571 571
(452, 60) (452, 60) (452, 60) (452, 60)
(452, 60) (452, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 572 | Acuracia_1: 1.0 | Contagem Geral: 62.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0323 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.9057
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
512
572 572
(453, 60) (453, 60) (453, 60) (453, 60)
(453, 60) (453, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 573 | Acuracia_1: 0.5 | Contagem Geral: 62.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.3333 
Precisao modelo Geral: 59.6244
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
513
573 573
(454, 60) (454, 60) (454, 60) (454, 60)
(454, 60) (454, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 574 | Acuracia_1: 0 | Contagem Geral: 63.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.3458
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
514
574 574
(455, 60) (455, 60) (455, 60) (455, 60)
(455, 60) (455, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 575 | Acuracia_1: 0 | Contagem Geral: 64.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 0 
Precisao modelo Geral: 59.5349
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
515
575 575
(456, 60) (456, 60) (456, 60) (456, 60)
(456, 60) (456, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 576 | Acuracia_1: 0 | Contagem Geral: 64.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 0 
Precisao modelo Geral: 59.7222
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
516
576 576
(457, 60) (457, 60) (457, 60) (457, 60)
(457, 60) (457, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 577 | Acuracia_1: 1.0 | Contagem Geral: 64.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.9078
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
517
577 577
(458, 60) (458, 60) (458, 60) (458, 60)
(458, 60) (458, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 578 | Acuracia_1: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 59.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.125 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.633
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
518
578 578
(459, 60) (459, 60) (459, 60) (459, 60)
(459, 60) (459, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 579 | Acuracia_1: 0.0 | Contagem Geral: 64.0 
Ordem Natural: 60.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.3607
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
519
579 579
(460, 60) (460, 60) (460, 60) (460, 60)
(460, 60) (460, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 580 | Acuracia_1: 0 | Contagem Geral: 65.0 
Ordem Natural: 60.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0 
Precisao modelo Geral: 59.0909
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
520
580 580
(461, 60) (461, 60) (461, 60) (461, 60)
(461, 60) (461, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 581 | Acuracia_1: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 61.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
521
581 581
(462, 60) (462, 60) (462, 60) (462, 60)
(462, 60) (462, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 582 | Acuracia_1: 0.3333 | Contagem Geral: 65.0 
Ordem Natural: 62.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0.3333 
Precisao modelo Geral: 59.009
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
522
582 582
(463, 60) (463, 60) (463, 60) (463, 60)
(463, 60) (463, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 583 | Acuracia_1: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 62.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.1928
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
523
583 583
(464, 60) (464, 60) (464, 60) (464, 60)
(464, 60) (464, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 584 | Acuracia_1: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 62.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6923 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.375
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
524
584 584
(465, 60) (465, 60) (465, 60) (465, 60)
(465, 60) (465, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 35ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 585 | Acuracia_1: 0.0 | Contagem Geral: 65.0 
Ordem Natural: 62.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.7879 | Acuracia_0: 0.5 
Precisao modelo Geral: 59.5556
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
525
585 585
(466, 60) (466, 60) (466, 60) (466, 60)
(466, 60) (466, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 586 | Acuracia_1: 0.0 | Contagem Geral: 66.0 
Ordem Natural: 63.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.292
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
526
586 586
(467, 60) (467, 60) (467, 60) (467, 60)
(467, 60) (467, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 587 | Acuracia_1: 1.0 | Contagem Geral: 67.0 
Ordem Natural: 63.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.4714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
527
587 587
(468, 60) (468, 60) (468, 60) (468, 60)
(468, 60) (468, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 588 | Acuracia_1: 0 | Contagem Geral: 67.0 
Ordem Natural: 63.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0 
Precisao modelo Geral: 59.6491
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
528
588 588
(469, 60) (469, 60) (469, 60) (469, 60)
(469, 60) (469, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 589 | Acuracia_1: 0.0 | Contagem Geral: 67.0 
Ordem Natural: 63.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.3886
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
529
589 589
(470, 60) (470, 60) (470, 60) (470, 60)
(470, 60) (470, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 590 | Acuracia_1: 0 | Contagem Geral: 67.0 
Ordem Natural: 64.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0 
Precisao modelo Geral: 59.5652
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
530
590 590
(471, 60) (471, 60) (471, 60) (471, 60)
(471, 60) (471, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 591 | Acuracia_1: 0 | Contagem Geral: 67.0 
Ordem Natural: 64.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0 
Precisao modelo Geral: 59.7403
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
531
591 591
(472, 60) (472, 60) (472, 60) (472, 60)
(472, 60) (472, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 592 | Acuracia_1: 0 | Contagem Geral: 67.0 
Ordem Natural: 64.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3582 | Acuracia_0: 0 
Precisao modelo Geral: 59.4828
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
532
592 592
(473, 60) (473, 60) (473, 60) (473, 60)
(473, 60) (473, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 593 | Acuracia_1: 0 | Contagem Geral: 67.0 
Ordem Natural: 65.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.2275
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
533
593 593
(474, 60) (474, 60) (474, 60) (474, 60)
(474, 60) (474, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 594 | Acuracia_1: 1.0 | Contagem Geral: 68.0 
Ordem Natural: 65.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.9744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
534
594 594
(475, 60) (475, 60) (475, 60) (475, 60)
(475, 60) (475, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 595 | Acuracia_1: 0 | Contagem Geral: 68.0 
Ordem Natural: 66.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_0: 0 
Precisao modelo Geral: 59.1489
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
535
595 595
(476, 60) (476, 60) (476, 60) (476, 60)
(476, 60) (476, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 596 | Acuracia_1: 0.0 | Contagem Geral: 68.0 
Ordem Natural: 66.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
536
596 596
(477, 60) (477, 60) (477, 60) (477, 60)
(477, 60) (477, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 597 | Acuracia_1: 0.5 | Contagem Geral: 68.0 
Ordem Natural: 66.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.9412 | Acuracia_0: 0.5 
Precisao modelo Geral: 59.0717
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
537
597 597
(478, 60) (478, 60) (478, 60) (478, 60)
(478, 60) (478, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 598 | Acuracia_1: 1.0 | Contagem Geral: 68.0 
Ordem Natural: 67.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.5362 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
538
598 598
(479, 60) (479, 60) (479, 60) (479, 60)
(479, 60) (479, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 599 | Acuracia_1: 0.0 | Contagem Geral: 69.0 
Ordem Natural: 67.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.5774
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
539
599 599
(480, 60) (480, 60) (480, 60) (480, 60)
(480, 60) (480, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 600 | Acuracia_1: 0.0 | Contagem Geral: 70.0 
Ordem Natural: 67.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_60: 0.0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
540
600 600
(481, 60) (481, 60) (481, 60) (481, 60)
(481, 60) (481, 60)
Matrix_60: [(481, 60), (481, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2054 - accuracy: 0.6530 - precision: 0.6530 - recall: 0.6530 - f1_score: 0.3008 - val_loss: 0.1709 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4667 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1986 - accuracy: 0.5261 - precision: 0.5261 - recall: 0.5261 - f1_score: 0.3553 - val_loss: 0.1874 - val_accuracy: 0.3971 - val_precision: 0.3971 - val_recall: 0.3971 - val_f1_score: 0.4675 - 58ms/epoch - 58ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1939 - accuracy: 0.4067 - precision: 0.4067 - recall: 0.4067 - f1_score: 0.3563 - val_loss: 0.1922 - val_accuracy: 0.3971 - val_precision: 0.3971 - val_recall: 0.3971 - val_f1_score: 0.4938 - 54ms/epoch - 54ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1870 - accuracy: 0.4067 - precision: 0.4067 - recall: 0.4067 - f1_score: 0.4000 - val_loss: 0.1881 - val_accuracy: 0.4265 - val_precision: 0.4265 - val_recall: 0.4265 - val_f1_score: 0.5063 - 99ms/epoch - 99ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1818 - accuracy: 0.4030 - precision: 0.4030 - recall: 0.4030 - f1_score: 0.4161 - val_loss: 0.1807 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4737 - 91ms/epoch - 91ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1760 - accuracy: 0.4963 - precision: 0.4963 - recall: 0.4963 - f1_score: 0.4255 - val_loss: 0.1742 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.4545 - 151ms/epoch - 151ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1778 - accuracy: 0.5261 - precision: 0.5261 - recall: 0.5261 - f1_score: 0.3744 - val_loss: 0.1691 - val_accuracy: 0.6176 - val_precision: 0.6176 - val_recall: 0.6176 - val_f1_score: 0.4800 - 129ms/epoch - 129ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.6007 - precision: 0.6007 - recall: 0.6007 - f1_score: 0.4456 - val_loss: 0.1657 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3684 - 114ms/epoch - 114ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1695 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.3521 - val_loss: 0.1641 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765 - val_f1_score: 0.3529 - 88ms/epoch - 88ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1748 - accuracy: 0.6679 - precision: 0.6679 - recall: 0.6679 - f1_score: 0.3597 - val_loss: 0.1637 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765 - val_f1_score: 0.3125 - 97ms/epoch - 97ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1717 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - f1_score: 0.2362 - val_loss: 0.1644 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.3333 - 70ms/epoch - 70ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.6604 - precision: 0.6604 - recall: 0.6604 - f1_score: 0.3724 - val_loss: 0.1660 - val_accuracy: 0.6176 - val_precision: 0.6176 - val_recall: 0.6176 - val_f1_score: 0.3158 - 51ms/epoch - 51ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.6343 - precision: 0.6343 - recall: 0.6343 - f1_score: 0.3553 - val_loss: 0.1684 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 51ms/epoch - 51ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.6343 - precision: 0.6343 - recall: 0.6343 - f1_score: 0.4024 - val_loss: 0.1712 - val_accuracy: 0.6029 - val_precision: 0.6029 - val_recall: 0.6029 - val_f1_score: 0.4490 - 52ms/epoch - 52ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.5634 - precision: 0.5634 - recall: 0.5634 - f1_score: 0.3536 - val_loss: 0.1739 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.4561 - 53ms/epoch - 53ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.5597 - precision: 0.5597 - recall: 0.5597 - f1_score: 0.4327 - val_loss: 0.1761 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.4590 - 51ms/epoch - 51ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.5410 - precision: 0.5410 - recall: 0.5410 - f1_score: 0.4629 - val_loss: 0.1775 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.4923 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5299 - precision: 0.5299 - recall: 0.5299 - f1_score: 0.4569 - val_loss: 0.1776 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4516 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1640 - accuracy: 0.5485 - precision: 0.5485 - recall: 0.5485 - f1_score: 0.4807 - val_loss: 0.1768 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.4667 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1685 - accuracy: 0.5187 - precision: 0.5187 - recall: 0.5187 - f1_score: 0.4317 - val_loss: 0.1755 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.4561 - 52ms/epoch - 52ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.5933 - precision: 0.5933 - recall: 0.5933 - f1_score: 0.4734 - val_loss: 0.1740 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.4444 - 52ms/epoch - 52ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1639 - accuracy: 0.5634 - precision: 0.5634 - recall: 0.5634 - f1_score: 0.4236 - val_loss: 0.1726 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3846 - 52ms/epoch - 52ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6754 - precision: 0.6754 - recall: 0.6754 - f1_score: 0.5538 - val_loss: 0.1712 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.4082 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.4946 - val_loss: 0.1702 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.3111 - 50ms/epoch - 50ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1594 - accuracy: 0.6604 - precision: 0.6604 - recall: 0.6604 - f1_score: 0.5236 - val_loss: 0.1692 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.3111 - 51ms/epoch - 51ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1577 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5000 - val_loss: 0.1686 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 52ms/epoch - 52ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.7201 - precision: 0.7201 - recall: 0.7201 - f1_score: 0.5455 - val_loss: 0.1685 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 54ms/epoch - 54ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.6791 - precision: 0.6791 - recall: 0.6791 - f1_score: 0.5057 - val_loss: 0.1688 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2857 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.6343 - precision: 0.6343 - recall: 0.6343 - f1_score: 0.3553 - val_loss: 0.1694 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1622 - accuracy: 0.6679 - precision: 0.6679 - recall: 0.6679 - f1_score: 0.4403 - val_loss: 0.1703 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1530 - accuracy: 0.7276 - precision: 0.7276 - recall: 0.7276 - f1_score: 0.5876 - val_loss: 0.1712 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.3478 - 50ms/epoch - 50ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6642 - precision: 0.6642 - recall: 0.6642 - f1_score: 0.5055 - val_loss: 0.1722 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6082 - precision: 0.6082 - recall: 0.6082 - f1_score: 0.4615 - val_loss: 0.1731 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.3673 - 53ms/epoch - 53ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6642 - precision: 0.6642 - recall: 0.6642 - f1_score: 0.5361 - val_loss: 0.1742 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.3529 - 52ms/epoch - 52ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1600 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.5053 - val_loss: 0.1747 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.3529 - 50ms/epoch - 50ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1518 - accuracy: 0.6157 - precision: 0.6157 - recall: 0.6157 - f1_score: 0.4824 - val_loss: 0.1743 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3200 - 51ms/epoch - 51ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1568 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.5306 - val_loss: 0.1734 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.2979 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6343 - precision: 0.6343 - recall: 0.6343 - f1_score: 0.4731 - val_loss: 0.1727 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.3182 - 53ms/epoch - 53ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1546 - accuracy: 0.7015 - precision: 0.7015 - recall: 0.7015 - f1_score: 0.5181 - val_loss: 0.1727 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.3182 - 50ms/epoch - 50ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1481 - accuracy: 0.7127 - precision: 0.7127 - recall: 0.7127 - f1_score: 0.5650 - val_loss: 0.1731 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1507 - accuracy: 0.7201 - precision: 0.7201 - recall: 0.7201 - f1_score: 0.5665 - val_loss: 0.1734 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 50ms/epoch - 50ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1516 - accuracy: 0.6754 - precision: 0.6754 - recall: 0.6754 - f1_score: 0.5348 - val_loss: 0.1738 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 54ms/epoch - 54ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1437 - accuracy: 0.7463 - precision: 0.7463 - recall: 0.7463 - f1_score: 0.6180 - val_loss: 0.1741 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 54ms/epoch - 54ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1502 - accuracy: 0.7090 - precision: 0.7090 - recall: 0.7090 - f1_score: 0.5667 - val_loss: 0.1740 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 50ms/epoch - 50ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1484 - accuracy: 0.7388 - precision: 0.7388 - recall: 0.7388 - f1_score: 0.6067 - val_loss: 0.1743 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3043 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1471 - accuracy: 0.7612 - precision: 0.7612 - recall: 0.7612 - f1_score: 0.6279 - val_loss: 0.1751 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3333 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1466 - accuracy: 0.7164 - precision: 0.7164 - recall: 0.7164 - f1_score: 0.5824 - val_loss: 0.1757 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6754 - precision: 0.6754 - recall: 0.6754 - f1_score: 0.5297 - val_loss: 0.1764 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3600 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1447 - accuracy: 0.7201 - precision: 0.7201 - recall: 0.7201 - f1_score: 0.6032 - val_loss: 0.1766 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3600 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1400 - accuracy: 0.7351 - precision: 0.7351 - recall: 0.7351 - f1_score: 0.6203 - val_loss: 0.1766 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.3600 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1835
Accuracy: 0.4966
Precision: 0.4966
Recall: 0.4966
F1 Score: 0.2626
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
540
600 600
(481, 60) (481, 60) (481, 60) (481, 60)
(481, 60) (481, 60)
Matrix_60: [(481, 60), (481, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.2179 - accuracy: 0.6978 - precision: 0.6978 - recall: 0.6978 - f1_score: 0.0690 - val_loss: 0.1720 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.0625 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1937 - accuracy: 0.5896 - precision: 0.5896 - recall: 0.5896 - f1_score: 0.2667 - val_loss: 0.1902 - val_accuracy: 0.3529 - val_precision: 0.3529 - val_recall: 0.3529 - val_f1_score: 0.4211 - 52ms/epoch - 52ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1896 - accuracy: 0.4366 - precision: 0.4366 - recall: 0.4366 - f1_score: 0.3629 - val_loss: 0.2055 - val_accuracy: 0.3088 - val_precision: 0.3088 - val_recall: 0.3088 - val_f1_score: 0.4598 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1900 - accuracy: 0.2948 - precision: 0.2948 - recall: 0.2948 - f1_score: 0.3636 - val_loss: 0.2087 - val_accuracy: 0.3382 - val_precision: 0.3382 - val_recall: 0.3382 - val_f1_score: 0.4944 - 51ms/epoch - 51ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1967 - accuracy: 0.3321 - precision: 0.3321 - recall: 0.3321 - f1_score: 0.3973 - val_loss: 0.2038 - val_accuracy: 0.3382 - val_precision: 0.3382 - val_recall: 0.3382 - val_f1_score: 0.4944 - 50ms/epoch - 50ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1802 - accuracy: 0.3993 - precision: 0.3993 - recall: 0.3993 - f1_score: 0.4505 - val_loss: 0.1957 - val_accuracy: 0.2941 - val_precision: 0.2941 - val_recall: 0.2941 - val_f1_score: 0.4419 - 50ms/epoch - 50ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1835 - accuracy: 0.3619 - precision: 0.3619 - recall: 0.3619 - f1_score: 0.3958 - val_loss: 0.1875 - val_accuracy: 0.2941 - val_precision: 0.2941 - val_recall: 0.2941 - val_f1_score: 0.4146 - 53ms/epoch - 53ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.4291 - precision: 0.4291 - recall: 0.4291 - f1_score: 0.3953 - val_loss: 0.1806 - val_accuracy: 0.4265 - val_precision: 0.4265 - val_recall: 0.4265 - val_f1_score: 0.4179 - 50ms/epoch - 50ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1778 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - f1_score: 0.3645 - val_loss: 0.1757 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.3774 - 52ms/epoch - 52ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1725 - accuracy: 0.5746 - precision: 0.5746 - recall: 0.5746 - f1_score: 0.3871 - val_loss: 0.1723 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.0606 - 49ms/epoch - 49ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.5970 - precision: 0.5970 - recall: 0.5970 - f1_score: 0.3165 - val_loss: 0.1701 - val_accuracy: 0.6029 - val_precision: 0.6029 - val_recall: 0.6029 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1768 - accuracy: 0.6194 - precision: 0.6194 - recall: 0.6194 - f1_score: 0.3108 - val_loss: 0.1689 - val_accuracy: 0.6324 - val_precision: 0.6324 - val_recall: 0.6324 - val_f1_score: 0.0000e+00 - 50ms/epoch - 50ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1762 - accuracy: 0.6269 - precision: 0.6269 - recall: 0.6269 - f1_score: 0.2958 - val_loss: 0.1684 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.6940 - precision: 0.6940 - recall: 0.6940 - f1_score: 0.3492 - val_loss: 0.1685 - val_accuracy: 0.6471 - val_precision: 0.6471 - val_recall: 0.6471 - val_f1_score: 0.0000e+00 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1813 - accuracy: 0.6231 - precision: 0.6231 - recall: 0.6231 - f1_score: 0.2406 - val_loss: 0.1693 - val_accuracy: 0.6176 - val_precision: 0.6176 - val_recall: 0.6176 - val_f1_score: 0.0000e+00 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1771 - accuracy: 0.6194 - precision: 0.6194 - recall: 0.6194 - f1_score: 0.2500 - val_loss: 0.1707 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.0667 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - f1_score: 0.3660 - val_loss: 0.1723 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.1143 - 49ms/epoch - 49ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1681 - accuracy: 0.6194 - precision: 0.6194 - recall: 0.6194 - f1_score: 0.3780 - val_loss: 0.1740 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.2667 - 52ms/epoch - 52ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1685 - accuracy: 0.6082 - precision: 0.6082 - recall: 0.6082 - f1_score: 0.4262 - val_loss: 0.1757 - val_accuracy: 0.5441 - val_precision: 0.5441 - val_recall: 0.5441 - val_f1_score: 0.4151 - 49ms/epoch - 49ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1733 - accuracy: 0.5485 - precision: 0.5485 - recall: 0.5485 - f1_score: 0.3858 - val_loss: 0.1772 - val_accuracy: 0.4706 - val_precision: 0.4706 - val_recall: 0.4706 - val_f1_score: 0.4194 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1730 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - f1_score: 0.3832 - val_loss: 0.1784 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.3939 - 50ms/epoch - 50ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.4530 - val_loss: 0.1791 - val_accuracy: 0.3824 - val_precision: 0.3824 - val_recall: 0.3824 - val_f1_score: 0.4000 - 48ms/epoch - 48ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.4888 - precision: 0.4888 - recall: 0.4888 - f1_score: 0.4498 - val_loss: 0.1792 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4286 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.4370 - val_loss: 0.1789 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4286 - 51ms/epoch - 51ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - f1_score: 0.4336 - val_loss: 0.1783 - val_accuracy: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4118 - 51ms/epoch - 51ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1713 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.3964 - val_loss: 0.1774 - val_accuracy: 0.4412 - val_precision: 0.4412 - val_recall: 0.4412 - val_f1_score: 0.4242 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1651 - accuracy: 0.5560 - precision: 0.5560 - recall: 0.5560 - f1_score: 0.4465 - val_loss: 0.1762 - val_accuracy: 0.4853 - val_precision: 0.4853 - val_recall: 0.4853 - val_f1_score: 0.4262 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.5597 - precision: 0.5597 - recall: 0.5597 - f1_score: 0.4327 - val_loss: 0.1749 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_f1_score: 0.4000 - 48ms/epoch - 48ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.5896 - precision: 0.5896 - recall: 0.5896 - f1_score: 0.4608 - val_loss: 0.1737 - val_accuracy: 0.4412 - val_precision: 0.4412 - val_recall: 0.4412 - val_f1_score: 0.2400 - 52ms/epoch - 52ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6343 - precision: 0.6343 - recall: 0.6343 - f1_score: 0.4842 - val_loss: 0.1724 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_f1_score: 0.2727 - 50ms/epoch - 50ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6194 - precision: 0.6194 - recall: 0.6194 - f1_score: 0.5000 - val_loss: 0.1714 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2632 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5896 - precision: 0.5896 - recall: 0.5896 - f1_score: 0.3820 - val_loss: 0.1706 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.1714 - 50ms/epoch - 50ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4458 - val_loss: 0.1701 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.1714 - 50ms/epoch - 50ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1636 - accuracy: 0.6455 - precision: 0.6455 - recall: 0.6455 - f1_score: 0.4633 - val_loss: 0.1696 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1765 - 49ms/epoch - 49ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.6530 - precision: 0.6530 - recall: 0.6530 - f1_score: 0.4624 - val_loss: 0.1694 - val_accuracy: 0.6029 - val_precision: 0.6029 - val_recall: 0.6029 - val_f1_score: 0.1290 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1622 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - f1_score: 0.4535 - val_loss: 0.1693 - val_accuracy: 0.6029 - val_precision: 0.6029 - val_recall: 0.6029 - val_f1_score: 0.1290 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.4419 - val_loss: 0.1694 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1250 - 50ms/epoch - 50ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6604 - precision: 0.6604 - recall: 0.6604 - f1_score: 0.4916 - val_loss: 0.1695 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.1765 - 50ms/epoch - 50ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1618 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4250 - val_loss: 0.1698 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.2632 - 51ms/epoch - 51ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1638 - accuracy: 0.6119 - precision: 0.6119 - recall: 0.6119 - f1_score: 0.4526 - val_loss: 0.1699 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3000 - 49ms/epoch - 49ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.7052 - precision: 0.7052 - recall: 0.7052 - f1_score: 0.5269 - val_loss: 0.1701 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 51ms/epoch - 51ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6567 - precision: 0.6567 - recall: 0.6567 - f1_score: 0.4773 - val_loss: 0.1703 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1565 - accuracy: 0.6754 - precision: 0.6754 - recall: 0.6754 - f1_score: 0.5246 - val_loss: 0.1703 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 49ms/epoch - 49ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5111 - val_loss: 0.1704 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.3256 - 49ms/epoch - 49ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1563 - accuracy: 0.6418 - precision: 0.6418 - recall: 0.6418 - f1_score: 0.5000 - val_loss: 0.1705 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.3182 - 51ms/epoch - 51ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - f1_score: 0.4689 - val_loss: 0.1704 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6978 - precision: 0.6978 - recall: 0.6978 - f1_score: 0.5622 - val_loss: 0.1701 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6716 - precision: 0.6716 - recall: 0.6716 - f1_score: 0.5217 - val_loss: 0.1698 - val_accuracy: 0.5882 - val_precision: 0.5882 - val_recall: 0.5882 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1549 - accuracy: 0.6866 - precision: 0.6866 - recall: 0.6866 - f1_score: 0.5625 - val_loss: 0.1695 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_f1_score: 0.2500 - 51ms/epoch - 51ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1511 - accuracy: 0.6642 - precision: 0.6642 - recall: 0.6642 - f1_score: 0.5312 - val_loss: 0.1689 - val_accuracy: 0.5735 - val_precision: 0.5735 - val_recall: 0.5735 - val_f1_score: 0.2564 - 51ms/epoch - 51ms/step

🔍 Resultados no Teste:
Loss: 0.1691
Accuracy: 0.5655
Precision: 0.5655
Recall: 0.5655
F1 Score: 0.2410
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
540
600 600
(481, 60) (481, 60) (481, 60) (481, 60)
(481, 60) (481, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 77ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 601 | Acuracia_1: 0.0 | Contagem Geral: 70.0 
Ordem Natural: 68.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.1429 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0913
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
541
601 601
(482, 60) (482, 60) (482, 60) (482, 60)
(482, 60) (482, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 602 | Acuracia_1: 0.5 | Contagem Geral: 70.0 
Ordem Natural: 69.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_0: 0.6667 
Precisao modelo Geral: 58.2645
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
542
602 602
(483, 60) (483, 60) (483, 60) (483, 60)
(483, 60) (483, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 603 | Acuracia_1: 0.0 | Contagem Geral: 71.0 
Ordem Natural: 70.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.169 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0247
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
543
603 603
(484, 60) (484, 60) (484, 60) (484, 60)
(484, 60) (484, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 604 | Acuracia_1: 0 | Contagem Geral: 71.0 
Ordem Natural: 71.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.7869
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
544
604 604
(485, 60) (485, 60) (485, 60) (485, 60)
(485, 60) (485, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 605 | Acuracia_1: 1.0 | Contagem Geral: 72.0 
Ordem Natural: 71.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.9592
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
545
605 605
(486, 60) (486, 60) (486, 60) (486, 60)
(486, 60) (486, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 606 | Acuracia_1: 0.3333 | Contagem Geral: 72.0 
Ordem Natural: 71.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.7778 | Acuracia_0: 0.3333 
Precisao modelo Geral: 57.7236
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
546
606 606
(487, 60) (487, 60) (487, 60) (487, 60)
(487, 60) (487, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 607 | Acuracia_1: 0 | Contagem Geral: 72.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.4899
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
547
607 607
(488, 60) (488, 60) (488, 60) (488, 60)
(488, 60) (488, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 608 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6613
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
548
608 608
(489, 60) (489, 60) (489, 60) (489, 60)
(489, 60) (489, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 609 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.8313
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
549
609 609
(490, 60) (490, 60) (490, 60) (490, 60)
(490, 60) (490, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 610 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
550
610 610
(491, 60) (491, 60) (491, 60) (491, 60)
(491, 60) (491, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 611 | Acuracia_1: 1.0 | Contagem Geral: 73.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.1673
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
551
611 611
(492, 60) (492, 60) (492, 60) (492, 60)
(492, 60) (492, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 612 | Acuracia_1: 0 | Contagem Geral: 73.0 
Ordem Natural: 72.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0 
Precisao modelo Geral: 57.9365
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
552
612 612
(493, 60) (493, 60) (493, 60) (493, 60)
(493, 60) (493, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 613 | Acuracia_1: 1.0 | Contagem Geral: 73.0 
Ordem Natural: 73.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.7075
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
553
613 613
(494, 60) (494, 60) (494, 60) (494, 60)
(494, 60) (494, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 614 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 74.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.4803
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
554
614 614
(495, 60) (495, 60) (495, 60) (495, 60)
(495, 60) (495, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 615 | Acuracia_1: 0.6667 | Contagem Geral: 73.0 
Ordem Natural: 75.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.6667 
Precisao modelo Geral: 57.6471
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
555
615 615
(496, 60) (496, 60) (496, 60) (496, 60)
(496, 60) (496, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 616 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 75.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.8125
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
556
616 616
(497, 60) (497, 60) (497, 60) (497, 60)
(497, 60) (497, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 617 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 75.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.9767
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
557
617 617
(498, 60) (498, 60) (498, 60) (498, 60)
(498, 60) (498, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 618 | Acuracia_1: 0.5 | Contagem Geral: 73.0 
Ordem Natural: 75.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3973 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.1395
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
558
618 618
(499, 60) (499, 60) (499, 60) (499, 60)
(499, 60) (499, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 619 | Acuracia_1: 0.0 | Contagem Geral: 73.0 
Ordem Natural: 75.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.3784 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.3012
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
559
619 619
(500, 60) (500, 60) (500, 60) (500, 60)
(500, 60) (500, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 620 | Acuracia_1: 0 | Contagem Geral: 74.0 
Ordem Natural: 76.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.3333 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.4615
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
560
620 620
(501, 60) (501, 60) (501, 60) (501, 60)
(501, 60) (501, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 621 | Acuracia_1: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 77.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.6207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
561
621 621
(502, 60) (502, 60) (502, 60) (502, 60)
(502, 60) (502, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 622 | Acuracia_1: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 77.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.3969
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
562
622 622
(503, 60) (503, 60) (503, 60) (503, 60)
(503, 60) (503, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 623 | Acuracia_1: 0.0 | Contagem Geral: 75.0 
Ordem Natural: 78.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.3333 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1749
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
563
623 623
(504, 60) (504, 60) (504, 60) (504, 60)
(504, 60) (504, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 624 | Acuracia_1: 0 | Contagem Geral: 75.0 
Ordem Natural: 79.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9474 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.9545
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
564
624 624
(505, 60) (505, 60) (505, 60) (505, 60)
(505, 60) (505, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 625 | Acuracia_1: 0 | Contagem Geral: 76.0 
Ordem Natural: 79.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9474 | Acuracia_0: 0 
Precisao modelo Geral: 58.1132
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
565
625 625
(506, 60) (506, 60) (506, 60) (506, 60)
(506, 60) (506, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 626 | Acuracia_1: 0.0 | Contagem Geral: 76.0 
Ordem Natural: 79.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.9474 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.2707
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
566
626 626
(507, 60) (507, 60) (507, 60) (507, 60)
(507, 60) (507, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 627 | Acuracia_1: 0 | Contagem Geral: 76.0 
Ordem Natural: 79.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.427
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
567
627 627
(508, 60) (508, 60) (508, 60) (508, 60)
(508, 60) (508, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 628 | Acuracia_1: 0.3333 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0.3333 
Precisao modelo Geral: 58.5821
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
568
628 628
(509, 60) (509, 60) (509, 60) (509, 60)
(509, 60) (509, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 629 | Acuracia_1: 1.0 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.7361
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
569
629 629
(510, 60) (510, 60) (510, 60) (510, 60)
(510, 60) (510, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 630 | Acuracia_1: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.8889
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
570
630 630
(511, 60) (511, 60) (511, 60) (511, 60)
(511, 60) (511, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 631 | Acuracia_1: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.0406
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
571
631 631
(512, 60) (512, 60) (512, 60) (512, 60)
(512, 60) (512, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 632 | Acuracia_1: 1.0 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.1912
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
572
632 632
(513, 60) (513, 60) (513, 60) (513, 60)
(513, 60) (513, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 633 | Acuracia_1: 0.3333 | Contagem Geral: 77.0 
Ordem Natural: 80.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0.3333 
Precisao modelo Geral: 58.9744
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
573
633 633
(514, 60) (514, 60) (514, 60) (514, 60)
(514, 60) (514, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 634 | Acuracia_1: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.1241
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
574
634 634
(515, 60) (515, 60) (515, 60) (515, 60)
(515, 60) (515, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 635 | Acuracia_1: 0 | Contagem Geral: 77.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0 
Precisao modelo Geral: 59.2727
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
575
635 635
(516, 60) (516, 60) (516, 60) (516, 60)
(516, 60) (516, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 636 | Acuracia_1: 0 | Contagem Geral: 77.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 0 
Precisao modelo Geral: 59.4203
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
576
636 636
(517, 60) (517, 60) (517, 60) (517, 60)
(517, 60) (517, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 637 | Acuracia_1: 1.0 | Contagem Geral: 77.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.8701 | Acuracia_0: 1.0 
Precisao modelo Geral: 59.5668
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
577
637 637
(518, 60) (518, 60) (518, 60) (518, 60)
(518, 60) (518, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 638 | Acuracia_1: 0.0 | Contagem Geral: 77.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.3525
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
578
638 638
(519, 60) (519, 60) (519, 60) (519, 60)
(519, 60) (519, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 639 | Acuracia_1: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.4982
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
579
639 639
(520, 60) (520, 60) (520, 60) (520, 60)
(520, 60) (520, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 640 | Acuracia_1: 0 | Contagem Geral: 78.0 
Ordem Natural: 81.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0 
Precisao modelo Geral: 59.2857
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
580
640 640
(521, 60) (521, 60) (521, 60) (521, 60)
(521, 60) (521, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 641 | Acuracia_1: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 82.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.4306
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
581
641 641
(522, 60) (522, 60) (522, 60) (522, 60)
(522, 60) (522, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 642 | Acuracia_1: 0.3333 | Contagem Geral: 78.0 
Ordem Natural: 82.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.3333 
Precisao modelo Geral: 59.2199
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
582
642 642
(523, 60) (523, 60) (523, 60) (523, 60)
(523, 60) (523, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 643 | Acuracia_1: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 83.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.364
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
583
643 643
(524, 60) (524, 60) (524, 60) (524, 60)
(524, 60) (524, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 644 | Acuracia_1: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 83.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.0 
Precisao modelo Geral: 59.1549
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
584
644 644
(525, 60) (525, 60) (525, 60) (525, 60)
(525, 60) (525, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 645 | Acuracia_1: 0.5 | Contagem Geral: 78.0 
Ordem Natural: 84.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4872 | Acuracia_0: 0.5 
Precisao modelo Geral: 59.2982
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
585
645 645
(526, 60) (526, 60) (526, 60) (526, 60)
(526, 60) (526, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 646 | Acuracia_1: 0.0 | Contagem Geral: 78.0 
Ordem Natural: 84.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.3797 | Acuracia_0: 0.25 
Precisao modelo Geral: 59.4406
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
586
646 646
(527, 60) (527, 60) (527, 60) (527, 60)
(527, 60) (527, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 647 | Acuracia_1: 1.0 | Contagem Geral: 79.0 
Ordem Natural: 85.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.5 
Precisao modelo Geral: 59.2334
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
587
647 647
(528, 60) (528, 60) (528, 60) (528, 60)
(528, 60) (528, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 648 | Acuracia_1: 0 | Contagem Geral: 80.0 
Ordem Natural: 85.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 59.0278
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
588
648 648
(529, 60) (529, 60) (529, 60) (529, 60)
(529, 60) (529, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 649 | Acuracia_1: 0.0 | Contagem Geral: 80.0 
Ordem Natural: 86.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.8235
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
589
649 649
(530, 60) (530, 60) (530, 60) (530, 60)
(530, 60) (530, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 650 | Acuracia_1: 0 | Contagem Geral: 80.0 
Ordem Natural: 87.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 58.6207
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
590
650 650
(531, 60) (531, 60) (531, 60) (531, 60)
(531, 60) (531, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 651 | Acuracia_1: 0 | Contagem Geral: 80.0 
Ordem Natural: 88.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.0 | Acuracia_0: 0 
Precisao modelo Geral: 58.7629
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
591
651 651
(532, 60) (532, 60) (532, 60) (532, 60)
(532, 60) (532, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 652 | Acuracia_1: 0 | Contagem Geral: 80.0 
Ordem Natural: 88.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.6296 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.5616
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
592
652 652
(533, 60) (533, 60) (533, 60) (533, 60)
(533, 60) (533, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 653 | Acuracia_1: 0.0 | Contagem Geral: 81.0 
Ordem Natural: 88.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.4878 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.7031
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
593
653 653
(534, 60) (534, 60) (534, 60) (534, 60)
(534, 60) (534, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 654 | Acuracia_1: 1.0 | Contagem Geral: 82.0 
Ordem Natural: 89.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.4878 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.5034
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
594
654 654
(535, 60) (535, 60) (535, 60) (535, 60)
(535, 60) (535, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 655 | Acuracia_1: 0 | Contagem Geral: 82.0 
Ordem Natural: 90.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1205 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.3051
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
595
655 655
(536, 60) (536, 60) (536, 60) (536, 60)
(536, 60) (536, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 656 | Acuracia_1: 0.0 | Contagem Geral: 83.0 
Ordem Natural: 90.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 30.1205 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1081
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
596
656 656
(537, 60) (537, 60) (537, 60) (537, 60)
(537, 60) (537, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 657 | Acuracia_1: 0.5 | Contagem Geral: 83.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7619 | Acuracia_0: 0.3333 
Precisao modelo Geral: 57.9125
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
597
657 657
(538, 60) (538, 60) (538, 60) (538, 60)
(538, 60) (538, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 658 | Acuracia_1: 0.5 | Contagem Geral: 84.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7619 | Acuracia_0: 0.5 
Precisao modelo Geral: 58.0537
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
598
658 658
(539, 60) (539, 60) (539, 60) (539, 60)
(539, 60) (539, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 659 | Acuracia_1: 0.0 | Contagem Geral: 84.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7619 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.194
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
599
659 659
(540, 60) (540, 60) (540, 60) (540, 60)
(540, 60) (540, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 660 | Acuracia_1: 0.0 | Contagem Geral: 84.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.7619 | Acuracia_60: 0.0 
Precisao modelo Geral: 58.3333
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
600
660 660
(541, 60) (541, 60) (541, 60) (541, 60)
(541, 60) (541, 60)
Matrix_60: [(541, 60), (541, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.2080 - accuracy: 0.6192 - precision: 0.6192 - recall: 0.6192 - f1_score: 0.2384 - val_loss: 0.1960 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.5051 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1900 - accuracy: 0.4536 - precision: 0.4536 - recall: 0.4536 - f1_score: 0.3529 - val_loss: 0.2078 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.5149 - 51ms/epoch - 51ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1851 - accuracy: 0.4238 - precision: 0.4238 - recall: 0.4238 - f1_score: 0.3916 - val_loss: 0.2076 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.5149 - 49ms/epoch - 49ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1804 - accuracy: 0.4735 - precision: 0.4735 - recall: 0.4735 - f1_score: 0.4260 - val_loss: 0.2016 - val_accuracy: 0.3421 - val_precision: 0.3421 - val_recall: 0.3421 - val_f1_score: 0.5000 - 51ms/epoch - 51ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1826 - accuracy: 0.4172 - precision: 0.4172 - recall: 0.4172 - f1_score: 0.3577 - val_loss: 0.1949 - val_accuracy: 0.3421 - val_precision: 0.3421 - val_recall: 0.3421 - val_f1_score: 0.5000 - 51ms/epoch - 51ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1784 - accuracy: 0.4536 - precision: 0.4536 - recall: 0.4536 - f1_score: 0.3678 - val_loss: 0.1885 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.4731 - 51ms/epoch - 51ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1745 - accuracy: 0.5132 - precision: 0.5132 - recall: 0.5132 - f1_score: 0.3226 - val_loss: 0.1840 - val_accuracy: 0.3289 - val_precision: 0.3289 - val_recall: 0.3289 - val_f1_score: 0.4000 - 49ms/epoch - 49ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1732 - accuracy: 0.5960 - precision: 0.5960 - recall: 0.5960 - f1_score: 0.3838 - val_loss: 0.1809 - val_accuracy: 0.3289 - val_precision: 0.3289 - val_recall: 0.3289 - val_f1_score: 0.3014 - 51ms/epoch - 51ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1741 - accuracy: 0.5927 - precision: 0.5927 - recall: 0.5927 - f1_score: 0.3422 - val_loss: 0.1793 - val_accuracy: 0.3421 - val_precision: 0.3421 - val_recall: 0.3421 - val_f1_score: 0.2857 - 51ms/epoch - 51ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.6490 - precision: 0.6490 - recall: 0.6490 - f1_score: 0.3375 - val_loss: 0.1790 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_f1_score: 0.2941 - 54ms/epoch - 54ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1755 - accuracy: 0.6358 - precision: 0.6358 - recall: 0.6358 - f1_score: 0.3210 - val_loss: 0.1794 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.3099 - 51ms/epoch - 51ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.3860 - val_loss: 0.1804 - val_accuracy: 0.3947 - val_precision: 0.3947 - val_recall: 0.3947 - val_f1_score: 0.3784 - 52ms/epoch - 52ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1742 - accuracy: 0.5960 - precision: 0.5960 - recall: 0.5960 - f1_score: 0.3222 - val_loss: 0.1821 - val_accuracy: 0.3816 - val_precision: 0.3816 - val_recall: 0.3816 - val_f1_score: 0.4051 - 50ms/epoch - 50ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1695 - accuracy: 0.6490 - precision: 0.6490 - recall: 0.6490 - f1_score: 0.3765 - val_loss: 0.1840 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_f1_score: 0.4419 - 49ms/epoch - 49ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1673 - accuracy: 0.5762 - precision: 0.5762 - recall: 0.5762 - f1_score: 0.3846 - val_loss: 0.1856 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.4494 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1659 - accuracy: 0.6358 - precision: 0.6358 - recall: 0.6358 - f1_score: 0.5133 - val_loss: 0.1866 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_f1_score: 0.4667 - 50ms/epoch - 50ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.5795 - precision: 0.5795 - recall: 0.5795 - f1_score: 0.4730 - val_loss: 0.1868 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_f1_score: 0.4667 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1661 - accuracy: 0.5563 - precision: 0.5563 - recall: 0.5563 - f1_score: 0.4553 - val_loss: 0.1860 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.4494 - 51ms/epoch - 51ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - f1_score: 0.4414 - val_loss: 0.1849 - val_accuracy: 0.3553 - val_precision: 0.3553 - val_recall: 0.3553 - val_f1_score: 0.4368 - 51ms/epoch - 51ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5695 - precision: 0.5695 - recall: 0.5695 - f1_score: 0.4248 - val_loss: 0.1838 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.4578 - 49ms/epoch - 49ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - f1_score: 0.4775 - val_loss: 0.1824 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.4304 - 51ms/epoch - 51ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.6325 - precision: 0.6325 - recall: 0.6325 - f1_score: 0.4739 - val_loss: 0.1817 - val_accuracy: 0.3947 - val_precision: 0.3947 - val_recall: 0.3947 - val_f1_score: 0.3947 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1646 - accuracy: 0.6722 - precision: 0.6722 - recall: 0.6722 - f1_score: 0.4817 - val_loss: 0.1809 - val_accuracy: 0.3947 - val_precision: 0.3947 - val_recall: 0.3947 - val_f1_score: 0.3784 - 49ms/epoch - 49ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.5960 - precision: 0.5960 - recall: 0.5960 - f1_score: 0.4078 - val_loss: 0.1803 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3662 - 51ms/epoch - 51ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.6093 - precision: 0.6093 - recall: 0.6093 - f1_score: 0.3789 - val_loss: 0.1800 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_f1_score: 0.3529 - 51ms/epoch - 51ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - f1_score: 0.4375 - val_loss: 0.1800 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1649 - accuracy: 0.6126 - precision: 0.6126 - recall: 0.6126 - f1_score: 0.4061 - val_loss: 0.1799 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 50ms/epoch - 50ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1602 - accuracy: 0.7119 - precision: 0.7119 - recall: 0.7119 - f1_score: 0.5246 - val_loss: 0.1801 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_f1_score: 0.3529 - 49ms/epoch - 49ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1604 - accuracy: 0.6556 - precision: 0.6556 - recall: 0.6556 - f1_score: 0.4951 - val_loss: 0.1802 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 48ms/epoch - 48ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1643 - accuracy: 0.6126 - precision: 0.6126 - recall: 0.6126 - f1_score: 0.4121 - val_loss: 0.1805 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 51ms/epoch - 51ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.6556 - precision: 0.6556 - recall: 0.6556 - f1_score: 0.4902 - val_loss: 0.1810 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6258 - precision: 0.6258 - recall: 0.6258 - f1_score: 0.4840 - val_loss: 0.1815 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.6457 - precision: 0.6457 - recall: 0.6457 - f1_score: 0.4977 - val_loss: 0.1817 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1620 - accuracy: 0.6192 - precision: 0.6192 - recall: 0.6192 - f1_score: 0.4444 - val_loss: 0.1816 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 51ms/epoch - 51ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1653 - accuracy: 0.6192 - precision: 0.6192 - recall: 0.6192 - f1_score: 0.3979 - val_loss: 0.1819 - val_accuracy: 0.4079 - val_precision: 0.4079 - val_recall: 0.4079 - val_f1_score: 0.3478 - 49ms/epoch - 49ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6556 - precision: 0.6556 - recall: 0.6556 - f1_score: 0.5229 - val_loss: 0.1819 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_f1_score: 0.3529 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1590 - accuracy: 0.6689 - precision: 0.6689 - recall: 0.6689 - f1_score: 0.5327 - val_loss: 0.1821 - val_accuracy: 0.4342 - val_precision: 0.4342 - val_recall: 0.4342 - val_f1_score: 0.3582 - 51ms/epoch - 51ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1595 - accuracy: 0.6788 - precision: 0.6788 - recall: 0.6788 - f1_score: 0.5174 - val_loss: 0.1826 - val_accuracy: 0.4342 - val_precision: 0.4342 - val_recall: 0.4342 - val_f1_score: 0.3582 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6589 - precision: 0.6589 - recall: 0.6589 - f1_score: 0.5253 - val_loss: 0.1828 - val_accuracy: 0.4474 - val_precision: 0.4474 - val_recall: 0.4474 - val_f1_score: 0.3636 - 49ms/epoch - 49ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.4776 - val_loss: 0.1834 - val_accuracy: 0.4342 - val_precision: 0.4342 - val_recall: 0.4342 - val_f1_score: 0.3582 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1531 - accuracy: 0.7086 - precision: 0.7086 - recall: 0.7086 - f1_score: 0.5926 - val_loss: 0.1838 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_f1_score: 0.3333 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6656 - precision: 0.6656 - recall: 0.6656 - f1_score: 0.5471 - val_loss: 0.1837 - val_accuracy: 0.4342 - val_precision: 0.4342 - val_recall: 0.4342 - val_f1_score: 0.3385 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - f1_score: 0.4953 - val_loss: 0.1839 - val_accuracy: 0.4342 - val_precision: 0.4342 - val_recall: 0.4342 - val_f1_score: 0.3385 - 52ms/epoch - 52ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1578 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.4976 - val_loss: 0.1840 - val_accuracy: 0.4474 - val_precision: 0.4474 - val_recall: 0.4474 - val_f1_score: 0.3437 - 51ms/epoch - 51ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.6921 - precision: 0.6921 - recall: 0.6921 - f1_score: 0.5634 - val_loss: 0.1845 - val_accuracy: 0.4605 - val_precision: 0.4605 - val_recall: 0.4605 - val_f1_score: 0.3492 - 50ms/epoch - 50ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1547 - accuracy: 0.6821 - precision: 0.6821 - recall: 0.6821 - f1_score: 0.5152 - val_loss: 0.1849 - val_accuracy: 0.4605 - val_precision: 0.4605 - val_recall: 0.4605 - val_f1_score: 0.3492 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1483 - accuracy: 0.6954 - precision: 0.6954 - recall: 0.6954 - f1_score: 0.5619 - val_loss: 0.1852 - val_accuracy: 0.4605 - val_precision: 0.4605 - val_recall: 0.4605 - val_f1_score: 0.3492 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1543 - accuracy: 0.6821 - precision: 0.6821 - recall: 0.6821 - f1_score: 0.5294 - val_loss: 0.1858 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.3333 - 48ms/epoch - 48ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1551 - accuracy: 0.6623 - precision: 0.6623 - recall: 0.6623 - f1_score: 0.5143 - val_loss: 0.1861 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.3333 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1467 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - f1_score: 0.6075 - val_loss: 0.1859 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 50ms/epoch - 50ms/step

🔍 Resultados no Teste:
Loss: 0.1829
Accuracy: 0.4785
Precision: 0.4785
Recall: 0.4785
F1 Score: 0.3200
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
600
660 660
(541, 60) (541, 60) (541, 60) (541, 60)
(541, 60) (541, 60)
Matrix_60: [(541, 60), (541, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1966 - accuracy: 0.3940 - precision: 0.3940 - recall: 0.3940 - f1_score: 0.4369 - val_loss: 0.1734 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.2449 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1904 - accuracy: 0.4768 - precision: 0.4768 - recall: 0.4768 - f1_score: 0.3130 - val_loss: 0.1667 - val_accuracy: 0.6184 - val_precision: 0.6184 - val_recall: 0.6184 - val_f1_score: 0.0645 - 75ms/epoch - 75ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1876 - accuracy: 0.5762 - precision: 0.5762 - recall: 0.5762 - f1_score: 0.3191 - val_loss: 0.1659 - val_accuracy: 0.6711 - val_precision: 0.6711 - val_recall: 0.6711 - val_f1_score: 0.0741 - 96ms/epoch - 96ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1848 - accuracy: 0.6258 - precision: 0.6258 - recall: 0.6258 - f1_score: 0.2981 - val_loss: 0.1660 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_f1_score: 0.0690 - 86ms/epoch - 86ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1815 - accuracy: 0.6060 - precision: 0.6060 - recall: 0.6060 - f1_score: 0.2516 - val_loss: 0.1674 - val_accuracy: 0.6316 - val_precision: 0.6316 - val_recall: 0.6316 - val_f1_score: 0.1250 - 89ms/epoch - 89ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1784 - accuracy: 0.5695 - precision: 0.5695 - recall: 0.5695 - f1_score: 0.3011 - val_loss: 0.1704 - val_accuracy: 0.5658 - val_precision: 0.5658 - val_recall: 0.5658 - val_f1_score: 0.2326 - 63ms/epoch - 63ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1756 - accuracy: 0.5762 - precision: 0.5762 - recall: 0.5762 - f1_score: 0.4074 - val_loss: 0.1745 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 64ms/epoch - 64ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1704 - accuracy: 0.5530 - precision: 0.5530 - recall: 0.5530 - f1_score: 0.3891 - val_loss: 0.1777 - val_accuracy: 0.4605 - val_precision: 0.4605 - val_recall: 0.4605 - val_f1_score: 0.3692 - 73ms/epoch - 73ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.5132 - precision: 0.5132 - recall: 0.5132 - f1_score: 0.4453 - val_loss: 0.1788 - val_accuracy: 0.4474 - val_precision: 0.4474 - val_recall: 0.4474 - val_f1_score: 0.3636 - 52ms/epoch - 52ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1738 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.4302 - val_loss: 0.1784 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.3750 - 58ms/epoch - 58ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1789 - accuracy: 0.4868 - precision: 0.4868 - recall: 0.4868 - f1_score: 0.3969 - val_loss: 0.1769 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3810 - 75ms/epoch - 75ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1719 - accuracy: 0.4801 - precision: 0.4801 - recall: 0.4801 - f1_score: 0.3938 - val_loss: 0.1749 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 55ms/epoch - 55ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1686 - accuracy: 0.5530 - precision: 0.5530 - recall: 0.5530 - f1_score: 0.4255 - val_loss: 0.1728 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2353 - 79ms/epoch - 79ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1736 - accuracy: 0.6026 - precision: 0.6026 - recall: 0.6026 - f1_score: 0.4393 - val_loss: 0.1714 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_f1_score: 0.2500 - 67ms/epoch - 67ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.5960 - precision: 0.5960 - recall: 0.5960 - f1_score: 0.3838 - val_loss: 0.1703 - val_accuracy: 0.6053 - val_precision: 0.6053 - val_recall: 0.6053 - val_f1_score: 0.2500 - 84ms/epoch - 84ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - f1_score: 0.4255 - val_loss: 0.1698 - val_accuracy: 0.5921 - val_precision: 0.5921 - val_recall: 0.5921 - val_f1_score: 0.1622 - 89ms/epoch - 89ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.3931 - val_loss: 0.1696 - val_accuracy: 0.6053 - val_precision: 0.6053 - val_recall: 0.6053 - val_f1_score: 0.1667 - 60ms/epoch - 60ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1602 - accuracy: 0.7152 - precision: 0.7152 - recall: 0.7152 - f1_score: 0.5057 - val_loss: 0.1696 - val_accuracy: 0.6053 - val_precision: 0.6053 - val_recall: 0.6053 - val_f1_score: 0.1667 - 62ms/epoch - 62ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.3787 - val_loss: 0.1699 - val_accuracy: 0.6053 - val_precision: 0.6053 - val_recall: 0.6053 - val_f1_score: 0.1667 - 56ms/epoch - 56ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1632 - accuracy: 0.6788 - precision: 0.6788 - recall: 0.6788 - f1_score: 0.4641 - val_loss: 0.1705 - val_accuracy: 0.5921 - val_precision: 0.5921 - val_recall: 0.5921 - val_f1_score: 0.1622 - 51ms/epoch - 51ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1637 - accuracy: 0.6656 - precision: 0.6656 - recall: 0.6656 - f1_score: 0.4294 - val_loss: 0.1713 - val_accuracy: 0.5658 - val_precision: 0.5658 - val_recall: 0.5658 - val_f1_score: 0.2667 - 55ms/epoch - 55ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1600 - accuracy: 0.6523 - precision: 0.6523 - recall: 0.6523 - f1_score: 0.4324 - val_loss: 0.1725 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_f1_score: 0.2500 - 49ms/epoch - 49ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - f1_score: 0.4066 - val_loss: 0.1738 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2400 - 52ms/epoch - 52ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.6225 - precision: 0.6225 - recall: 0.6225 - f1_score: 0.4184 - val_loss: 0.1751 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2642 - 49ms/epoch - 49ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - f1_score: 0.4369 - val_loss: 0.1765 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.3509 - 49ms/epoch - 49ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1620 - accuracy: 0.6689 - precision: 0.6689 - recall: 0.6689 - f1_score: 0.5098 - val_loss: 0.1778 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.3333 - 53ms/epoch - 53ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6391 - precision: 0.6391 - recall: 0.6391 - f1_score: 0.5156 - val_loss: 0.1788 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1609 - accuracy: 0.6126 - precision: 0.6126 - recall: 0.6126 - f1_score: 0.5021 - val_loss: 0.1792 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 50ms/epoch - 50ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.5728 - precision: 0.5728 - recall: 0.5728 - f1_score: 0.4511 - val_loss: 0.1791 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 50ms/epoch - 50ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1637 - accuracy: 0.6225 - precision: 0.6225 - recall: 0.6225 - f1_score: 0.5000 - val_loss: 0.1783 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.3509 - 49ms/epoch - 49ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1642 - accuracy: 0.6093 - precision: 0.6093 - recall: 0.6093 - f1_score: 0.4486 - val_loss: 0.1772 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.3509 - 49ms/epoch - 49ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6457 - precision: 0.6457 - recall: 0.6457 - f1_score: 0.5069 - val_loss: 0.1763 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.2593 - 53ms/epoch - 53ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6391 - precision: 0.6391 - recall: 0.6391 - f1_score: 0.4683 - val_loss: 0.1759 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2642 - 51ms/epoch - 51ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1615 - accuracy: 0.6854 - precision: 0.6854 - recall: 0.6854 - f1_score: 0.4865 - val_loss: 0.1758 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2642 - 52ms/epoch - 52ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.6358 - precision: 0.6358 - recall: 0.6358 - f1_score: 0.4388 - val_loss: 0.1760 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2642 - 51ms/epoch - 51ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1593 - accuracy: 0.6623 - precision: 0.6623 - recall: 0.6623 - f1_score: 0.4516 - val_loss: 0.1765 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.2308 - 51ms/epoch - 51ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1554 - accuracy: 0.6755 - precision: 0.6755 - recall: 0.6755 - f1_score: 0.4896 - val_loss: 0.1773 - val_accuracy: 0.4737 - val_precision: 0.4737 - val_recall: 0.4737 - val_f1_score: 0.2308 - 48ms/epoch - 48ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6821 - precision: 0.6821 - recall: 0.6821 - f1_score: 0.5052 - val_loss: 0.1784 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.3273 - 49ms/epoch - 49ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1619 - accuracy: 0.6556 - precision: 0.6556 - recall: 0.6556 - f1_score: 0.4694 - val_loss: 0.1798 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_f1_score: 0.3571 - 52ms/epoch - 52ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6689 - precision: 0.6689 - recall: 0.6689 - f1_score: 0.4845 - val_loss: 0.1811 - val_accuracy: 0.5132 - val_precision: 0.5132 - val_recall: 0.5132 - val_f1_score: 0.3509 - 50ms/epoch - 50ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1540 - accuracy: 0.6589 - precision: 0.6589 - recall: 0.6589 - f1_score: 0.5422 - val_loss: 0.1823 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 49ms/epoch - 49ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6722 - precision: 0.6722 - recall: 0.6722 - f1_score: 0.5217 - val_loss: 0.1832 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 51ms/epoch - 51ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1527 - accuracy: 0.6854 - precision: 0.6854 - recall: 0.6854 - f1_score: 0.5455 - val_loss: 0.1836 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 50ms/epoch - 50ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.6887 - precision: 0.6887 - recall: 0.6887 - f1_score: 0.5566 - val_loss: 0.1838 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.3390 - 49ms/epoch - 49ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1527 - accuracy: 0.6457 - precision: 0.6457 - recall: 0.6457 - f1_score: 0.5069 - val_loss: 0.1837 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 53ms/epoch - 53ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1529 - accuracy: 0.6722 - precision: 0.6722 - recall: 0.6722 - f1_score: 0.4975 - val_loss: 0.1838 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1481 - accuracy: 0.7185 - precision: 0.7185 - recall: 0.7185 - f1_score: 0.5641 - val_loss: 0.1841 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1537 - accuracy: 0.7152 - precision: 0.7152 - recall: 0.7152 - f1_score: 0.5326 - val_loss: 0.1848 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1512 - accuracy: 0.6987 - precision: 0.6987 - recall: 0.6987 - f1_score: 0.5285 - val_loss: 0.1857 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 50ms/epoch - 50ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1453 - accuracy: 0.7020 - precision: 0.7020 - recall: 0.7020 - f1_score: 0.5588 - val_loss: 0.1868 - val_accuracy: 0.4868 - val_precision: 0.4868 - val_recall: 0.4868 - val_f1_score: 0.2909 - 49ms/epoch - 49ms/step

🔍 Resultados no Teste:
Loss: 0.1681
Accuracy: 0.6442
Precision: 0.6442
Recall: 0.6442
F1 Score: 0.3095
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
600
660 660
(541, 60) (541, 60) (541, 60) (541, 60)
(541, 60) (541, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 76ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 661 | Acuracia_1: 0.0 | Contagem Geral: 84.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.1395
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
601
661 661
(542, 60) (542, 60) (542, 60) (542, 60)
(542, 60) (542, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 662 | Acuracia_1: 0.6667 | Contagem Geral: 85.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.6667 
Precisao modelo Geral: 58.2781
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
602
662 662
(543, 60) (543, 60) (543, 60) (543, 60)
(543, 60) (543, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 663 | Acuracia_1: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 91.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.4118 | Acuracia_0: 0.0 
Precisao modelo Geral: 58.0858
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
603
663 663
(544, 60) (544, 60) (544, 60) (544, 60)
(544, 60) (544, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 664 | Acuracia_1: 0.0 | Contagem Geral: 85.0 
Ordem Natural: 92.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0698 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.8947
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
604
664 664
(545, 60) (545, 60) (545, 60) (545, 60)
(545, 60) (545, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 665 | Acuracia_1: 1.0 | Contagem Geral: 86.0 
Ordem Natural: 92.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0698 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.7049
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
605
665 665
(546, 60) (546, 60) (546, 60) (546, 60)
(546, 60) (546, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 666 | Acuracia_1: 0.3333 | Contagem Geral: 86.0 
Ordem Natural: 93.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0698 | Acuracia_0: 0.3333 
Precisao modelo Geral: 57.5163
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
606
666 666
(547, 60) (547, 60) (547, 60) (547, 60)
(547, 60) (547, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 667 | Acuracia_1: 0.0 | Contagem Geral: 86.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0698 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6547
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
607
667 667
(548, 60) (548, 60) (548, 60) (548, 60)
(548, 60) (548, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 668 | Acuracia_1: 0.0 | Contagem Geral: 86.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.0698 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.7922
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
608
668 668
(549, 60) (549, 60) (549, 60) (549, 60)
(549, 60) (549, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 669 | Acuracia_1: 0.0 | Contagem Geral: 86.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.7356 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.6052
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
609
669 669
(550, 60) (550, 60) (550, 60) (550, 60)
(550, 60) (550, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 670 | Acuracia_1: 0.0 | Contagem Geral: 87.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.7356 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.7419
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
610
670 670
(551, 60) (551, 60) (551, 60) (551, 60)
(551, 60) (551, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 671 | Acuracia_1: 1.0 | Contagem Geral: 87.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.7356 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.8778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
611
671 671
(552, 60) (552, 60) (552, 60) (552, 60)
(552, 60) (552, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 672 | Acuracia_1: 0 | Contagem Geral: 87.0 
Ordem Natural: 94.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.5455 | Acuracia_0: 1.0 
Precisao modelo Geral: 58.0128
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
612
672 672
(553, 60) (553, 60) (553, 60) (553, 60)
(553, 60) (553, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 673 | Acuracia_1: 1.0 | Contagem Geral: 88.0 
Ordem Natural: 95.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2135 | Acuracia_0: 0.5 
Precisao modelo Geral: 57.8275
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
613
673 673
(554, 60) (554, 60) (554, 60) (554, 60)
(554, 60) (554, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 674 | Acuracia_1: 0.0 | Contagem Geral: 89.0 
Ordem Natural: 95.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2135 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.9618
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
614
674 674
(555, 60) (555, 60) (555, 60) (555, 60)
(555, 60) (555, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 675 | Acuracia_1: 0.6667 | Contagem Geral: 89.0 
Ordem Natural: 95.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2135 | Acuracia_0: 0.6667 
Precisao modelo Geral: 57.7778
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
615
675 675
(556, 60) (556, 60) (556, 60) (556, 60)
(556, 60) (556, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 676 | Acuracia_1: 0.0 | Contagem Geral: 89.0 
Ordem Natural: 96.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 29.2135 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.5949
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
616
676 676
(557, 60) (557, 60) (557, 60) (557, 60)
(557, 60) (557, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 677 | Acuracia_1: 0.0 | Contagem Geral: 89.0 
Ordem Natural: 97.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.8889 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.4132
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
617
677 677
(558, 60) (558, 60) (558, 60) (558, 60)
(558, 60) (558, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 678 | Acuracia_1: 0.5 | Contagem Geral: 90.0 
Ordem Natural: 97.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.3333 
Precisao modelo Geral: 57.2327
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
618
678 678
(559, 60) (559, 60) (559, 60) (559, 60)
(559, 60) (559, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 679 | Acuracia_1: 0.5 | Contagem Geral: 91.0 
Ordem Natural: 97.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.5 
Precisao modelo Geral: 57.3668
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
619
679 679
(560, 60) (560, 60) (560, 60) (560, 60)
(560, 60) (560, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 680 | Acuracia_1: 1.0 | Contagem Geral: 91.0 
Ordem Natural: 97.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.5
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
620
680 680
(561, 60) (561, 60) (561, 60) (561, 60)
(561, 60) (561, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 681 | Acuracia_1: 0.0 | Contagem Geral: 91.0 
Ordem Natural: 97.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.5714 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.3209
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
621
681 681
(562, 60) (562, 60) (562, 60) (562, 60)
(562, 60) (562, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 682 | Acuracia_1: 0.0 | Contagem Geral: 91.0 
Ordem Natural: 98.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
622
682 682
(563, 60) (563, 60) (563, 60) (563, 60)
(563, 60) (563, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 683 | Acuracia_1: 0.0 | Contagem Geral: 92.0 
Ordem Natural: 98.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.2755
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
623
683 683
(564, 60) (564, 60) (564, 60) (564, 60)
(564, 60) (564, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 684 | Acuracia_1: 0.0 | Contagem Geral: 92.0 
Ordem Natural: 98.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.0988
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
624
684 684
(565, 60) (565, 60) (565, 60) (565, 60)
(565, 60) (565, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 685 | Acuracia_1: 0 | Contagem Geral: 92.0 
Ordem Natural: 99.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0 
Precisao modelo Geral: 57.2308
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
625
685 685
(566, 60) (566, 60) (566, 60) (566, 60)
(566, 60) (566, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 686 | Acuracia_1: 0.0 | Contagem Geral: 92.0 
Ordem Natural: 99.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.0552
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
626
686 686
(567, 60) (567, 60) (567, 60) (567, 60)
(567, 60) (567, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 687 | Acuracia_1: 1.0 | Contagem Geral: 92.0 
Ordem Natural: 100.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.1865
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
627
687 687
(568, 60) (568, 60) (568, 60) (568, 60)
(568, 60) (568, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 688 | Acuracia_1: 0.3333 | Contagem Geral: 92.0 
Ordem Natural: 100.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 0.3333 
Precisao modelo Geral: 57.3171
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
628
688 688
(569, 60) (569, 60) (569, 60) (569, 60)
(569, 60) (569, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 689 | Acuracia_1: 1.0 | Contagem Geral: 92.0 
Ordem Natural: 100.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2609 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.1429
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
629
689 689
(570, 60) (570, 60) (570, 60) (570, 60)
(570, 60) (570, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 690 | Acuracia_1: 0.0 | Contagem Geral: 92.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.957 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.9697
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
630
690 690
(571, 60) (571, 60) (571, 60) (571, 60)
(571, 60) (571, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 691 | Acuracia_1: 0.0 | Contagem Geral: 93.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.957 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.0997
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
631
691 691
(572, 60) (572, 60) (572, 60) (572, 60)
(572, 60) (572, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 692 | Acuracia_1: 1.0 | Contagem Geral: 93.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.957 | Acuracia_0: 1.0 
Precisao modelo Geral: 57.2289
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
632
692 692
(573, 60) (573, 60) (573, 60) (573, 60)
(573, 60) (573, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 693 | Acuracia_1: 0.3333 | Contagem Geral: 93.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6596 | Acuracia_0: 0.25 
Precisao modelo Geral: 57.0571
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
633
693 693
(574, 60) (574, 60) (574, 60) (574, 60)
(574, 60) (574, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 694 | Acuracia_1: 0.0 | Contagem Geral: 94.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6596 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1856
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
634
694 694
(575, 60) (575, 60) (575, 60) (575, 60)
(575, 60) (575, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 695 | Acuracia_1: 0 | Contagem Geral: 94.0 
Ordem Natural: 101.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.6596 | Acuracia_0: 0 
Precisao modelo Geral: 57.0149
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
635
695 695
(576, 60) (576, 60) (576, 60) (576, 60)
(576, 60) (576, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 696 | Acuracia_1: 0 | Contagem Geral: 94.0 
Ordem Natural: 102.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8452
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
636
696 696
(577, 60) (577, 60) (577, 60) (577, 60)
(577, 60) (577, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 697 | Acuracia_1: 1.0 | Contagem Geral: 95.0 
Ordem Natural: 102.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.6766
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
637
697 697
(578, 60) (578, 60) (578, 60) (578, 60)
(578, 60) (578, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 698 | Acuracia_1: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 103.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8047
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
638
698 698
(579, 60) (579, 60) (579, 60) (579, 60)
(579, 60) (579, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 699 | Acuracia_1: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 103.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.9322
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
639
699 699
(580, 60) (580, 60) (580, 60) (580, 60)
(580, 60) (580, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 700 | Acuracia_1: 0 | Contagem Geral: 95.0 
Ordem Natural: 103.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0 
Precisao modelo Geral: 56.7647
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
640
700 700
(581, 60) (581, 60) (581, 60) (581, 60)
(581, 60) (581, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 701 | Acuracia_1: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 104.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8915
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
641
701 701
(582, 60) (582, 60) (582, 60) (582, 60)
(582, 60) (582, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 702 | Acuracia_1: 0.3333 | Contagem Geral: 95.0 
Ordem Natural: 104.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.3684 | Acuracia_0: 0.3333 
Precisao modelo Geral: 56.7251
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
642
702 702
(583, 60) (583, 60) (583, 60) (583, 60)
(583, 60) (583, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 703 | Acuracia_1: 0.0 | Contagem Geral: 95.0 
Ordem Natural: 105.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.0833 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.5598
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
643
703 703
(584, 60) (584, 60) (584, 60) (584, 60)
(584, 60) (584, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 704 | Acuracia_1: 0.0 | Contagem Geral: 96.0 
Ordem Natural: 105.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.8351 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.686
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
644
704 704
(585, 60) (585, 60) (585, 60) (585, 60)
(585, 60) (585, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 705 | Acuracia_1: 0.5 | Contagem Geral: 97.0 
Ordem Natural: 106.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.8351 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.8116
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
645
705 705
(586, 60) (586, 60) (586, 60) (586, 60)
(586, 60) (586, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 706 | Acuracia_1: 0.25 | Contagem Geral: 97.0 
Ordem Natural: 106.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.8351 | Acuracia_0: 0.25 
Precisao modelo Geral: 56.6474
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
646
706 706
(587, 60) (587, 60) (587, 60) (587, 60)
(587, 60) (587, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 34ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 707 | Acuracia_1: 0.5 | Contagem Geral: 97.0 
Ordem Natural: 107.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.8351 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.4841
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
647
707 707
(588, 60) (588, 60) (588, 60) (588, 60)
(588, 60) (588, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 708 | Acuracia_1: 0 | Contagem Geral: 97.0 
Ordem Natural: 108.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.8351 | Acuracia_0: 0 
Precisao modelo Geral: 56.6092
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
648
708 708
(589, 60) (589, 60) (589, 60) (589, 60)
(589, 60) (589, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 709 | Acuracia_1: 0.0 | Contagem Geral: 97.0 
Ordem Natural: 108.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 27.551 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.447
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
649
709 709
(590, 60) (590, 60) (590, 60) (590, 60)
(590, 60) (590, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 710 | Acuracia_1: 0 | Contagem Geral: 98.0 
Ordem Natural: 108.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.5714
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
650
710 710
(591, 60) (591, 60) (591, 60) (591, 60)
(591, 60) (591, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 711 | Acuracia_1: 0 | Contagem Geral: 99.0 
Ordem Natural: 109.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 0 
Precisao modelo Geral: 56.6952
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
651
711 711
(592, 60) (592, 60) (592, 60) (592, 60)
(592, 60) (592, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 712 | Acuracia_1: 0.0 | Contagem Geral: 99.0 
Ordem Natural: 109.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.8182
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
652
712 712
(593, 60) (593, 60) (593, 60) (593, 60)
(593, 60) (593, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 713 | Acuracia_1: 0.5 | Contagem Geral: 99.0 
Ordem Natural: 109.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.6572
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
653
713 713
(594, 60) (594, 60) (594, 60) (594, 60)
(594, 60) (594, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 714 | Acuracia_1: 1.0 | Contagem Geral: 99.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 1.0 
Precisao modelo Geral: 56.7797
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
654
714 714
(595, 60) (595, 60) (595, 60) (595, 60)
(595, 60) (595, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 715 | Acuracia_1: 0.0 | Contagem Geral: 99.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.2828 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.9014
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
655
715 715
(596, 60) (596, 60) (596, 60) (596, 60)
(596, 60) (596, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[1]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 1
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 716 | Acuracia_1: 0.0 | Contagem Geral: 99.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 56.7416
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
656
716 716
(597, 60) (597, 60) (597, 60) (597, 60)
(597, 60) (597, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 717 | Acuracia_1: 0.3333 | Contagem Geral: 100.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_0: 0.3333 
Precisao modelo Geral: 56.8627
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
657
717 717
(598, 60) (598, 60) (598, 60) (598, 60)
(598, 60) (598, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 718 | Acuracia_1: 0.5 | Contagem Geral: 100.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_0: 0.5 
Precisao modelo Geral: 56.9832
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
658
718 718
(599, 60) (599, 60) (599, 60) (599, 60)
(599, 60) (599, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 719 | Acuracia_1: 0.0 | Contagem Geral: 100.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_0: 0.0 
Precisao modelo Geral: 57.1031
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
0 60
659
719 719
(600, 60) (600, 60) (600, 60) (600, 60)
(600, 60) (600, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 720 | Acuracia_1: 0.0 | Contagem Geral: 100.0 
Ordem Natural: 110.0
Entrada -> -'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
Acuracia modelo Geral: 28.0 | Acuracia_60: 0.0 
Precisao modelo Geral: 56.9444
-'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'--'-
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
660
720 720
(601, 60) (601, 60) (601, 60) (601, 60)
(601, 60) (601, 60)
Matrix_60: [(601, 60), (601, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1910 - accuracy: 0.5446 - precision: 0.5446 - recall: 0.5446 - f1_score: 0.3377 - val_loss: 0.1967 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.3415 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1846 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.4238 - val_loss: 0.1908 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.3590 - 102ms/epoch - 102ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1889 - accuracy: 0.4256 - precision: 0.4256 - recall: 0.4256 - f1_score: 0.3545 - val_loss: 0.1833 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.3099 - 91ms/epoch - 91ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1827 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.3958 - val_loss: 0.1756 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 82ms/epoch - 82ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - f1_score: 0.4382 - val_loss: 0.1721 - val_accuracy: 0.5833 - val_precision: 0.5833 - val_recall: 0.5833 - val_f1_score: 0.3137 - 65ms/epoch - 65ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1728 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - f1_score: 0.4156 - val_loss: 0.1722 - val_accuracy: 0.5952 - val_precision: 0.5952 - val_recall: 0.5952 - val_f1_score: 0.3200 - 55ms/epoch - 55ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - f1_score: 0.4000 - val_loss: 0.1746 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.2807 - 58ms/epoch - 58ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1719 - accuracy: 0.5774 - precision: 0.5774 - recall: 0.5774 - f1_score: 0.4580 - val_loss: 0.1774 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3000 - 52ms/epoch - 52ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1758 - accuracy: 0.5030 - precision: 0.5030 - recall: 0.5030 - f1_score: 0.3838 - val_loss: 0.1795 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.2857 - 54ms/epoch - 54ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1724 - accuracy: 0.5030 - precision: 0.5030 - recall: 0.5030 - f1_score: 0.4181 - val_loss: 0.1803 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.3077 - 60ms/epoch - 60ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1756 - accuracy: 0.4970 - precision: 0.4970 - recall: 0.4970 - f1_score: 0.4385 - val_loss: 0.1800 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.3125 - 76ms/epoch - 76ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4933 - val_loss: 0.1791 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.3077 - 69ms/epoch - 69ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1692 - accuracy: 0.5387 - precision: 0.5387 - recall: 0.5387 - f1_score: 0.4484 - val_loss: 0.1776 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2903 - 83ms/epoch - 83ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.4773 - val_loss: 0.1762 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3103 - 74ms/epoch - 74ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1696 - accuracy: 0.5625 - precision: 0.5625 - recall: 0.5625 - f1_score: 0.4411 - val_loss: 0.1747 - val_accuracy: 0.5595 - val_precision: 0.5595 - val_recall: 0.5595 - val_f1_score: 0.3273 - 67ms/epoch - 67ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1708 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4553 - val_loss: 0.1740 - val_accuracy: 0.5833 - val_precision: 0.5833 - val_recall: 0.5833 - val_f1_score: 0.3137 - 61ms/epoch - 61ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.6161 - precision: 0.6161 - recall: 0.6161 - f1_score: 0.4735 - val_loss: 0.1739 - val_accuracy: 0.5833 - val_precision: 0.5833 - val_recall: 0.5833 - val_f1_score: 0.3137 - 56ms/epoch - 56ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.3898 - val_loss: 0.1746 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - f1_score: 0.4427 - val_loss: 0.1760 - val_accuracy: 0.5595 - val_precision: 0.5595 - val_recall: 0.5595 - val_f1_score: 0.3509 - 55ms/epoch - 55ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5565 - precision: 0.5565 - recall: 0.5565 - f1_score: 0.4335 - val_loss: 0.1772 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3448 - 52ms/epoch - 52ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1675 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.4925 - val_loss: 0.1785 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3492 - 52ms/epoch - 52ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1671 - accuracy: 0.5625 - precision: 0.5625 - recall: 0.5625 - f1_score: 0.4655 - val_loss: 0.1789 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3437 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1631 - accuracy: 0.6042 - precision: 0.6042 - recall: 0.6042 - f1_score: 0.5092 - val_loss: 0.1789 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3279 - 52ms/epoch - 52ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1637 - accuracy: 0.5863 - precision: 0.5863 - recall: 0.5863 - f1_score: 0.4794 - val_loss: 0.1784 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5581 - val_loss: 0.1779 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3103 - 52ms/epoch - 52ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4634 - val_loss: 0.1774 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3103 - 49ms/epoch - 49ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4923 - val_loss: 0.1772 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3051 - 51ms/epoch - 51ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6488 - precision: 0.6488 - recall: 0.6488 - f1_score: 0.5391 - val_loss: 0.1773 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3051 - 57ms/epoch - 57ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.6339 - precision: 0.6339 - recall: 0.6339 - f1_score: 0.5138 - val_loss: 0.1780 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 55ms/epoch - 55ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1617 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5197 - val_loss: 0.1789 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 55ms/epoch - 55ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1611 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5210 - val_loss: 0.1802 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 54ms/epoch - 54ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1622 - accuracy: 0.6101 - precision: 0.6101 - recall: 0.6101 - f1_score: 0.5236 - val_loss: 0.1804 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 53ms/epoch - 53ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5620 - val_loss: 0.1811 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3692 - 56ms/epoch - 56ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1633 - accuracy: 0.6101 - precision: 0.6101 - recall: 0.6101 - f1_score: 0.4942 - val_loss: 0.1813 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 57ms/epoch - 57ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6577 - precision: 0.6577 - recall: 0.6577 - f1_score: 0.5306 - val_loss: 0.1820 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3810 - 72ms/epoch - 72ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1553 - accuracy: 0.6637 - precision: 0.6637 - recall: 0.6637 - f1_score: 0.5425 - val_loss: 0.1823 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 58ms/epoch - 58ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1535 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5760 - val_loss: 0.1815 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3750 - 54ms/epoch - 54ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5424 - val_loss: 0.1817 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 55ms/epoch - 55ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5263 - val_loss: 0.1820 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 54ms/epoch - 54ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1569 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5169 - val_loss: 0.1827 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 56ms/epoch - 56ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5512 - val_loss: 0.1835 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.3333 - 52ms/epoch - 52ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1549 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.5263 - val_loss: 0.1842 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3667 - 49ms/epoch - 49ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1557 - accuracy: 0.6577 - precision: 0.6577 - recall: 0.6577 - f1_score: 0.5148 - val_loss: 0.1856 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.3667 - 54ms/epoch - 54ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.6935 - precision: 0.6935 - recall: 0.6935 - f1_score: 0.5726 - val_loss: 0.1881 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3492 - 51ms/epoch - 51ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1476 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5969 - val_loss: 0.1902 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3437 - 55ms/epoch - 55ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1542 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5120 - val_loss: 0.1914 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3437 - 51ms/epoch - 51ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5781 - val_loss: 0.1917 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3437 - 49ms/epoch - 49ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6696 - precision: 0.6696 - recall: 0.6696 - f1_score: 0.5714 - val_loss: 0.1903 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.3492 - 51ms/epoch - 51ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1470 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5794 - val_loss: 0.1883 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3607 - 57ms/epoch - 57ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.6786 - precision: 0.6786 - recall: 0.6786 - f1_score: 0.5645 - val_loss: 0.1864 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3158 - 59ms/epoch - 59ms/step

🔍 Resultados no Teste:
Loss: 0.1804
Accuracy: 0.5028
Precision: 0.5028
Recall: 0.5028
F1 Score: 0.3382
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
660
720 720
(601, 60) (601, 60) (601, 60) (601, 60)
(601, 60) (601, 60)
Matrix_60: [(601, 60), (601, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1907 - accuracy: 0.4554 - precision: 0.4554 - recall: 0.4554 - f1_score: 0.4039 - val_loss: 0.1820 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3947 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1890 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.3043 - val_loss: 0.1768 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.3824 - 74ms/epoch - 74ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1884 - accuracy: 0.6042 - precision: 0.6042 - recall: 0.6042 - f1_score: 0.3448 - val_loss: 0.1817 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.3733 - 71ms/epoch - 71ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1851 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.3394 - val_loss: 0.1902 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.4176 - 68ms/epoch - 68ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1844 - accuracy: 0.5060 - precision: 0.5060 - recall: 0.5060 - f1_score: 0.3759 - val_loss: 0.1953 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.3878 - 77ms/epoch - 77ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1828 - accuracy: 0.4851 - precision: 0.4851 - recall: 0.4851 - f1_score: 0.4136 - val_loss: 0.1953 - val_accuracy: 0.2857 - val_precision: 0.2857 - val_recall: 0.2857 - val_f1_score: 0.3878 - 98ms/epoch - 98ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1767 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - f1_score: 0.4116 - val_loss: 0.1941 - val_accuracy: 0.3095 - val_precision: 0.3095 - val_recall: 0.3095 - val_f1_score: 0.3958 - 89ms/epoch - 89ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1780 - accuracy: 0.4821 - precision: 0.4821 - recall: 0.4821 - f1_score: 0.3696 - val_loss: 0.1916 - val_accuracy: 0.3214 - val_precision: 0.3214 - val_recall: 0.3214 - val_f1_score: 0.4000 - 61ms/epoch - 61ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1781 - accuracy: 0.5060 - precision: 0.5060 - recall: 0.5060 - f1_score: 0.4071 - val_loss: 0.1894 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.4043 - 64ms/epoch - 64ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1745 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - f1_score: 0.3957 - val_loss: 0.1868 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.4270 - 51ms/epoch - 51ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1754 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.4161 - val_loss: 0.1844 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.4368 - 50ms/epoch - 50ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1695 - accuracy: 0.5923 - precision: 0.5923 - recall: 0.5923 - f1_score: 0.4669 - val_loss: 0.1825 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.4096 - 52ms/epoch - 52ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1731 - accuracy: 0.5595 - precision: 0.5595 - recall: 0.5595 - f1_score: 0.3984 - val_loss: 0.1805 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.4103 - 51ms/epoch - 51ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1751 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.3217 - val_loss: 0.1796 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3947 - 54ms/epoch - 54ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1715 - accuracy: 0.5744 - precision: 0.5744 - recall: 0.5744 - f1_score: 0.3915 - val_loss: 0.1795 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.4000 - 51ms/epoch - 51ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4425 - val_loss: 0.1806 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.4000 - 53ms/epoch - 53ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1709 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.4480 - val_loss: 0.1815 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.4000 - 50ms/epoch - 50ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.5952 - precision: 0.5952 - recall: 0.5952 - f1_score: 0.4516 - val_loss: 0.1823 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4359 - 53ms/epoch - 53ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4094 - val_loss: 0.1835 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4359 - 50ms/epoch - 50ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1680 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.4815 - val_loss: 0.1838 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.4250 - 50ms/epoch - 50ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.6101 - precision: 0.6101 - recall: 0.6101 - f1_score: 0.4942 - val_loss: 0.1832 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.4103 - 52ms/epoch - 52ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - f1_score: 0.4639 - val_loss: 0.1823 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.3947 - 50ms/epoch - 50ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.6220 - precision: 0.6220 - recall: 0.6220 - f1_score: 0.5020 - val_loss: 0.1813 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4054 - 50ms/epoch - 50ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.5714 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.4586 - val_loss: 0.1806 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4110 - 52ms/epoch - 52ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1621 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5079 - val_loss: 0.1799 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.4225 - 65ms/epoch - 65ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1650 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4839 - val_loss: 0.1796 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4444 - 97ms/epoch - 97ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4961 - val_loss: 0.1788 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4444 - 70ms/epoch - 70ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1687 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4640 - val_loss: 0.1788 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.4384 - 75ms/epoch - 75ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1660 - accuracy: 0.6042 - precision: 0.6042 - recall: 0.6042 - f1_score: 0.4865 - val_loss: 0.1799 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4267 - 66ms/epoch - 66ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6161 - precision: 0.6161 - recall: 0.6161 - f1_score: 0.4901 - val_loss: 0.1805 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4267 - 54ms/epoch - 54ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1693 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4361 - val_loss: 0.1813 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4267 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1626 - accuracy: 0.6280 - precision: 0.6280 - recall: 0.6280 - f1_score: 0.5318 - val_loss: 0.1810 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4324 - 57ms/epoch - 57ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1616 - accuracy: 0.5923 - precision: 0.5923 - recall: 0.5923 - f1_score: 0.4945 - val_loss: 0.1800 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4324 - 71ms/epoch - 71ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1658 - accuracy: 0.5863 - precision: 0.5863 - recall: 0.5863 - f1_score: 0.4794 - val_loss: 0.1785 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4110 - 56ms/epoch - 56ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5360 - val_loss: 0.1767 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4286 - 73ms/epoch - 73ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1597 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.5145 - val_loss: 0.1764 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4286 - 50ms/epoch - 50ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1570 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5207 - val_loss: 0.1763 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.4286 - 55ms/epoch - 55ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1610 - accuracy: 0.6131 - precision: 0.6131 - recall: 0.6131 - f1_score: 0.5000 - val_loss: 0.1776 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.4225 - 55ms/epoch - 55ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1607 - accuracy: 0.6042 - precision: 0.6042 - recall: 0.6042 - f1_score: 0.4571 - val_loss: 0.1794 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4167 - 52ms/epoch - 52ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1599 - accuracy: 0.6339 - precision: 0.6339 - recall: 0.6339 - f1_score: 0.5176 - val_loss: 0.1819 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4167 - 60ms/epoch - 60ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1612 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.5227 - val_loss: 0.1847 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4167 - 53ms/epoch - 53ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1586 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.5299 - val_loss: 0.1865 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4054 - 50ms/epoch - 50ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1566 - accuracy: 0.6280 - precision: 0.6280 - recall: 0.6280 - f1_score: 0.5487 - val_loss: 0.1869 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.4110 - 55ms/epoch - 55ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1533 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5373 - val_loss: 0.1847 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.4167 - 53ms/epoch - 53ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1594 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.5115 - val_loss: 0.1817 - val_accuracy: 0.5119 - val_precision: 0.5119 - val_recall: 0.5119 - val_f1_score: 0.4225 - 54ms/epoch - 54ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1585 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4961 - val_loss: 0.1787 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.4179 - 53ms/epoch - 53ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1531 - accuracy: 0.6905 - precision: 0.6905 - recall: 0.6905 - f1_score: 0.5593 - val_loss: 0.1772 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.4242 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1546 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5431 - val_loss: 0.1787 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.4179 - 56ms/epoch - 56ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1514 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5508 - val_loss: 0.1801 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.4412 - 55ms/epoch - 55ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1517 - accuracy: 0.6696 - precision: 0.6696 - recall: 0.6696 - f1_score: 0.5356 - val_loss: 0.1823 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.4348 - 50ms/epoch - 50ms/step

🔍 Resultados no Teste:
Loss: 0.1830
Accuracy: 0.4807
Precision: 0.4807
Recall: 0.4807
F1 Score: 0.3816
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
660
720 720
(601, 60) (601, 60) (601, 60) (601, 60)
(601, 60) (601, 60)
Matrix_60: [(601, 60), (601, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 3s - loss: 0.1870 - accuracy: 0.4881 - precision: 0.4881 - recall: 0.4881 - f1_score: 0.3175 - val_loss: 0.1825 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.3291 - 3s/epoch - 3s/step
Epoch 2/50
1/1 - 0s - loss: 0.1885 - accuracy: 0.4286 - precision: 0.4286 - recall: 0.4286 - f1_score: 0.3379 - val_loss: 0.1851 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.4000 - 78ms/epoch - 78ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1764 - accuracy: 0.4970 - precision: 0.4970 - recall: 0.4970 - f1_score: 0.4348 - val_loss: 0.1798 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.2933 - 66ms/epoch - 66ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1789 - accuracy: 0.4911 - precision: 0.4911 - recall: 0.4911 - f1_score: 0.3690 - val_loss: 0.1753 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.2581 - 66ms/epoch - 66ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1746 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - f1_score: 0.4471 - val_loss: 0.1738 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.2456 - 69ms/epoch - 69ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1793 - accuracy: 0.5327 - precision: 0.5327 - recall: 0.5327 - f1_score: 0.3485 - val_loss: 0.1742 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2414 - 66ms/epoch - 66ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1796 - accuracy: 0.5060 - precision: 0.5060 - recall: 0.5060 - f1_score: 0.3615 - val_loss: 0.1764 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286 - val_f1_score: 0.2500 - 69ms/epoch - 69ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - f1_score: 0.4030 - val_loss: 0.1789 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.2535 - 95ms/epoch - 95ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.5536 - precision: 0.5536 - recall: 0.5536 - f1_score: 0.4565 - val_loss: 0.1807 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.2703 - 135ms/epoch - 135ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1697 - accuracy: 0.5387 - precision: 0.5387 - recall: 0.5387 - f1_score: 0.4599 - val_loss: 0.1813 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.3158 - 97ms/epoch - 97ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1677 - accuracy: 0.5744 - precision: 0.5744 - recall: 0.5744 - f1_score: 0.5052 - val_loss: 0.1815 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.3117 - 100ms/epoch - 100ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.5863 - precision: 0.5863 - recall: 0.5863 - f1_score: 0.5088 - val_loss: 0.1811 - val_accuracy: 0.3452 - val_precision: 0.3452 - val_recall: 0.3452 - val_f1_score: 0.2857 - 69ms/epoch - 69ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1716 - accuracy: 0.5119 - precision: 0.5119 - recall: 0.5119 - f1_score: 0.4306 - val_loss: 0.1803 - val_accuracy: 0.3690 - val_precision: 0.3690 - val_recall: 0.3690 - val_f1_score: 0.2535 - 67ms/epoch - 67ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1726 - accuracy: 0.5268 - precision: 0.5268 - recall: 0.5268 - f1_score: 0.4382 - val_loss: 0.1793 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.2388 - 65ms/epoch - 65ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1729 - accuracy: 0.5030 - precision: 0.5030 - recall: 0.5030 - f1_score: 0.4014 - val_loss: 0.1780 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2424 - 67ms/epoch - 67ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5446 - precision: 0.5446 - recall: 0.5446 - f1_score: 0.4706 - val_loss: 0.1763 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.2373 - 72ms/epoch - 72ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1700 - accuracy: 0.5565 - precision: 0.5565 - recall: 0.5565 - f1_score: 0.4461 - val_loss: 0.1750 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1923 - 88ms/epoch - 88ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1730 - accuracy: 0.5387 - precision: 0.5387 - recall: 0.5387 - f1_score: 0.3825 - val_loss: 0.1747 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1923 - 88ms/epoch - 88ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1707 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - f1_score: 0.4351 - val_loss: 0.1755 - val_accuracy: 0.4524 - val_precision: 0.4524 - val_recall: 0.4524 - val_f1_score: 0.1786 - 71ms/epoch - 71ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1690 - accuracy: 0.6280 - precision: 0.6280 - recall: 0.6280 - f1_score: 0.4770 - val_loss: 0.1770 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.2034 - 67ms/epoch - 67ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1689 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4766 - val_loss: 0.1788 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.2222 - 95ms/epoch - 95ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1674 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4571 - val_loss: 0.1803 - val_accuracy: 0.3571 - val_precision: 0.3571 - val_recall: 0.3571 - val_f1_score: 0.2059 - 176ms/epoch - 176ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1684 - accuracy: 0.5506 - precision: 0.5506 - recall: 0.5506 - f1_score: 0.4549 - val_loss: 0.1808 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.2571 - 87ms/epoch - 87ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1701 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.4531 - val_loss: 0.1809 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.2571 - 75ms/epoch - 75ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1678 - accuracy: 0.5565 - precision: 0.5565 - recall: 0.5565 - f1_score: 0.4659 - val_loss: 0.1803 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.2388 - 65ms/epoch - 65ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1656 - accuracy: 0.5774 - precision: 0.5774 - recall: 0.5774 - f1_score: 0.4855 - val_loss: 0.1796 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.1875 - 57ms/epoch - 57ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1664 - accuracy: 0.5863 - precision: 0.5863 - recall: 0.5863 - f1_score: 0.4591 - val_loss: 0.1792 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.1875 - 67ms/epoch - 67ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1662 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4962 - val_loss: 0.1789 - val_accuracy: 0.3810 - val_precision: 0.3810 - val_recall: 0.3810 - val_f1_score: 0.1875 - 57ms/epoch - 57ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1592 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5758 - val_loss: 0.1784 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.1356 - 52ms/epoch - 52ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1648 - accuracy: 0.6220 - precision: 0.6220 - recall: 0.6220 - f1_score: 0.4900 - val_loss: 0.1780 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.1356 - 56ms/epoch - 56ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1645 - accuracy: 0.6220 - precision: 0.6220 - recall: 0.6220 - f1_score: 0.4816 - val_loss: 0.1786 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.1356 - 51ms/epoch - 51ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1641 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.4979 - val_loss: 0.1795 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.1667 - 57ms/epoch - 57ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5200 - val_loss: 0.1804 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.1695 - 57ms/epoch - 57ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1601 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5447 - val_loss: 0.1818 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.1935 - 55ms/epoch - 55ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1625 - accuracy: 0.6280 - precision: 0.6280 - recall: 0.6280 - f1_score: 0.5020 - val_loss: 0.1838 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2187 - 65ms/epoch - 65ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1588 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.5447 - val_loss: 0.1855 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.2154 - 63ms/epoch - 63ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1581 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5294 - val_loss: 0.1864 - val_accuracy: 0.3929 - val_precision: 0.3929 - val_recall: 0.3929 - val_f1_score: 0.2154 - 58ms/epoch - 58ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1584 - accuracy: 0.6696 - precision: 0.6696 - recall: 0.6696 - f1_score: 0.5394 - val_loss: 0.1869 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.2462 - 80ms/epoch - 80ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1647 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.5078 - val_loss: 0.1863 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.2540 - 74ms/epoch - 74ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1556 - accuracy: 0.6845 - precision: 0.6845 - recall: 0.6845 - f1_score: 0.5620 - val_loss: 0.1853 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.2456 - 70ms/epoch - 70ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1598 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5234 - val_loss: 0.1836 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2143 - 65ms/epoch - 65ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.6994 - precision: 0.6994 - recall: 0.6994 - f1_score: 0.5628 - val_loss: 0.1826 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2143 - 65ms/epoch - 65ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1555 - accuracy: 0.6696 - precision: 0.6696 - recall: 0.6696 - f1_score: 0.5236 - val_loss: 0.1828 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2143 - 60ms/epoch - 60ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1580 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - f1_score: 0.5210 - val_loss: 0.1841 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.2143 - 55ms/epoch - 55ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1544 - accuracy: 0.6637 - precision: 0.6637 - recall: 0.6637 - f1_score: 0.5272 - val_loss: 0.1860 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2759 - 52ms/epoch - 52ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1627 - accuracy: 0.6042 - precision: 0.6042 - recall: 0.6042 - f1_score: 0.4527 - val_loss: 0.1881 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.2623 - 52ms/epoch - 52ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1614 - accuracy: 0.6696 - precision: 0.6696 - recall: 0.6696 - f1_score: 0.5394 - val_loss: 0.1916 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.2687 - 51ms/epoch - 51ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1511 - accuracy: 0.6577 - precision: 0.6577 - recall: 0.6577 - f1_score: 0.5693 - val_loss: 0.1918 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2647 - 50ms/epoch - 50ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1548 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5455 - val_loss: 0.1896 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.2424 - 53ms/epoch - 53ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1521 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - f1_score: 0.5484 - val_loss: 0.1859 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.2034 - 52ms/epoch - 52ms/step

🔍 Resultados no Teste:
Loss: 0.1813
Accuracy: 0.5249
Precision: 0.5249
Recall: 0.5249
F1 Score: 0.3857
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
************************************************************
Carregando dados ...
*-*-*-*-*-*-*-*-*-*-*-*- 
Posições que devem ser carregadas: [60] 
*-*-*-*-*-*-*-*-*-*-*-*-
Treinamento para 60
660
720 720
(601, 60) (601, 60) (601, 60) (601, 60)
(601, 60) (601, 60)
Matrix_60: [(601, 60), (601, 60)] | Posicao: 0
Epoch 1/50
/home/darkcover/.cache/pypoetry/virtualenvs/out-idYdofvy-py3.10/lib/python3.10/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
1/1 - 2s - loss: 0.1892 - accuracy: 0.5893 - precision: 0.5893 - recall: 0.5893 - f1_score: 0.3100 - val_loss: 0.1808 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.3896 - 2s/epoch - 2s/step
Epoch 2/50
1/1 - 0s - loss: 0.1955 - accuracy: 0.4643 - precision: 0.4643 - recall: 0.4643 - f1_score: 0.3878 - val_loss: 0.1840 - val_accuracy: 0.4048 - val_precision: 0.4048 - val_recall: 0.4048 - val_f1_score: 0.4186 - 52ms/epoch - 52ms/step
Epoch 3/50
1/1 - 0s - loss: 0.1790 - accuracy: 0.4583 - precision: 0.4583 - recall: 0.4583 - f1_score: 0.4312 - val_loss: 0.1765 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.3380 - 50ms/epoch - 50ms/step
Epoch 4/50
1/1 - 0s - loss: 0.1820 - accuracy: 0.4911 - precision: 0.4911 - recall: 0.4911 - f1_score: 0.4319 - val_loss: 0.1684 - val_accuracy: 0.6071 - val_precision: 0.6071 - val_recall: 0.6071 - val_f1_score: 0.2667 - 56ms/epoch - 56ms/step
Epoch 5/50
1/1 - 0s - loss: 0.1771 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4370 - val_loss: 0.1628 - val_accuracy: 0.6548 - val_precision: 0.6548 - val_recall: 0.6548 - val_f1_score: 0.0000e+00 - 52ms/epoch - 52ms/step
Epoch 6/50
1/1 - 0s - loss: 0.1782 - accuracy: 0.5446 - precision: 0.5446 - recall: 0.5446 - f1_score: 0.3953 - val_loss: 0.1598 - val_accuracy: 0.6905 - val_precision: 0.6905 - val_recall: 0.6905 - val_f1_score: 0.0000e+00 - 66ms/epoch - 66ms/step
Epoch 7/50
1/1 - 0s - loss: 0.1735 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4182 - val_loss: 0.1588 - val_accuracy: 0.7024 - val_precision: 0.7024 - val_recall: 0.7024 - val_f1_score: 0.0000e+00 - 69ms/epoch - 69ms/step
Epoch 8/50
1/1 - 0s - loss: 0.1851 - accuracy: 0.5833 - precision: 0.5833 - recall: 0.5833 - f1_score: 0.2857 - val_loss: 0.1598 - val_accuracy: 0.7024 - val_precision: 0.7024 - val_recall: 0.7024 - val_f1_score: 0.0741 - 71ms/epoch - 71ms/step
Epoch 9/50
1/1 - 0s - loss: 0.1759 - accuracy: 0.5685 - precision: 0.5685 - recall: 0.5685 - f1_score: 0.3830 - val_loss: 0.1621 - val_accuracy: 0.6548 - val_precision: 0.6548 - val_recall: 0.6548 - val_f1_score: 0.0645 - 96ms/epoch - 96ms/step
Epoch 10/50
1/1 - 0s - loss: 0.1758 - accuracy: 0.5417 - precision: 0.5417 - recall: 0.5417 - f1_score: 0.4122 - val_loss: 0.1648 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.1176 - 96ms/epoch - 96ms/step
Epoch 11/50
1/1 - 0s - loss: 0.1757 - accuracy: 0.5327 - precision: 0.5327 - recall: 0.5327 - f1_score: 0.3843 - val_loss: 0.1679 - val_accuracy: 0.5595 - val_precision: 0.5595 - val_recall: 0.5595 - val_f1_score: 0.1778 - 86ms/epoch - 86ms/step
Epoch 12/50
1/1 - 0s - loss: 0.1779 - accuracy: 0.4792 - precision: 0.4792 - recall: 0.4792 - f1_score: 0.3945 - val_loss: 0.1702 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.2692 - 84ms/epoch - 84ms/step
Epoch 13/50
1/1 - 0s - loss: 0.1741 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - f1_score: 0.4429 - val_loss: 0.1720 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2857 - 77ms/epoch - 77ms/step
Epoch 14/50
1/1 - 0s - loss: 0.1769 - accuracy: 0.4643 - precision: 0.4643 - recall: 0.4643 - f1_score: 0.4375 - val_loss: 0.1721 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.3158 - 76ms/epoch - 76ms/step
Epoch 15/50
1/1 - 0s - loss: 0.1718 - accuracy: 0.4702 - precision: 0.4702 - recall: 0.4702 - f1_score: 0.4472 - val_loss: 0.1706 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.2353 - 79ms/epoch - 79ms/step
Epoch 16/50
1/1 - 0s - loss: 0.1684 - accuracy: 0.5119 - precision: 0.5119 - recall: 0.5119 - f1_score: 0.4675 - val_loss: 0.1684 - val_accuracy: 0.5595 - val_precision: 0.5595 - val_recall: 0.5595 - val_f1_score: 0.1778 - 77ms/epoch - 77ms/step
Epoch 17/50
1/1 - 0s - loss: 0.1702 - accuracy: 0.5179 - precision: 0.5179 - recall: 0.5179 - f1_score: 0.4296 - val_loss: 0.1663 - val_accuracy: 0.5833 - val_precision: 0.5833 - val_recall: 0.5833 - val_f1_score: 0.1026 - 68ms/epoch - 68ms/step
Epoch 18/50
1/1 - 0s - loss: 0.1683 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4962 - val_loss: 0.1647 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.1176 - 71ms/epoch - 71ms/step
Epoch 19/50
1/1 - 0s - loss: 0.1670 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4793 - val_loss: 0.1639 - val_accuracy: 0.6429 - val_precision: 0.6429 - val_recall: 0.6429 - val_f1_score: 0.1176 - 72ms/epoch - 72ms/step
Epoch 20/50
1/1 - 0s - loss: 0.1676 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - f1_score: 0.4105 - val_loss: 0.1635 - val_accuracy: 0.6310 - val_precision: 0.6310 - val_recall: 0.6310 - val_f1_score: 0.0606 - 75ms/epoch - 75ms/step
Epoch 21/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.4299 - val_loss: 0.1642 - val_accuracy: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.0588 - 64ms/epoch - 64ms/step
Epoch 22/50
1/1 - 0s - loss: 0.1682 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - f1_score: 0.4574 - val_loss: 0.1656 - val_accuracy: 0.6071 - val_precision: 0.6071 - val_recall: 0.6071 - val_f1_score: 0.0571 - 86ms/epoch - 86ms/step
Epoch 23/50
1/1 - 0s - loss: 0.1712 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.4474 - val_loss: 0.1676 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.1000 - 95ms/epoch - 95ms/step
Epoch 24/50
1/1 - 0s - loss: 0.1721 - accuracy: 0.6012 - precision: 0.6012 - recall: 0.6012 - f1_score: 0.4553 - val_loss: 0.1701 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.1304 - 104ms/epoch - 104ms/step
Epoch 25/50
1/1 - 0s - loss: 0.1666 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - f1_score: 0.4677 - val_loss: 0.1722 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1600 - 92ms/epoch - 92ms/step
Epoch 26/50
1/1 - 0s - loss: 0.1698 - accuracy: 0.5476 - precision: 0.5476 - recall: 0.5476 - f1_score: 0.4242 - val_loss: 0.1742 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.1538 - 78ms/epoch - 78ms/step
Epoch 27/50
1/1 - 0s - loss: 0.1629 - accuracy: 0.5446 - precision: 0.5446 - recall: 0.5446 - f1_score: 0.4814 - val_loss: 0.1749 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.1509 - 63ms/epoch - 63ms/step
Epoch 28/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.5744 - precision: 0.5744 - recall: 0.5744 - f1_score: 0.4723 - val_loss: 0.1752 - val_accuracy: 0.4405 - val_precision: 0.4405 - val_recall: 0.4405 - val_f1_score: 0.1455 - 54ms/epoch - 54ms/step
Epoch 29/50
1/1 - 0s - loss: 0.1663 - accuracy: 0.5744 - precision: 0.5744 - recall: 0.5744 - f1_score: 0.5052 - val_loss: 0.1745 - val_accuracy: 0.4643 - val_precision: 0.4643 - val_recall: 0.4643 - val_f1_score: 0.1509 - 53ms/epoch - 53ms/step
Epoch 30/50
1/1 - 0s - loss: 0.1623 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - f1_score: 0.5407 - val_loss: 0.1731 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.1667 - 70ms/epoch - 70ms/step
Epoch 31/50
1/1 - 0s - loss: 0.1655 - accuracy: 0.5744 - precision: 0.5744 - recall: 0.5744 - f1_score: 0.4604 - val_loss: 0.1716 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.1702 - 66ms/epoch - 66ms/step
Epoch 32/50
1/1 - 0s - loss: 0.1628 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.5039 - val_loss: 0.1701 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1364 - 74ms/epoch - 74ms/step
Epoch 33/50
1/1 - 0s - loss: 0.1657 - accuracy: 0.6190 - precision: 0.6190 - recall: 0.6190 - f1_score: 0.4797 - val_loss: 0.1698 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.0952 - 70ms/epoch - 70ms/step
Epoch 34/50
1/1 - 0s - loss: 0.1633 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - f1_score: 0.4762 - val_loss: 0.1701 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.0952 - 74ms/epoch - 74ms/step
Epoch 35/50
1/1 - 0s - loss: 0.1630 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.5063 - val_loss: 0.1708 - val_accuracy: 0.5476 - val_precision: 0.5476 - val_recall: 0.5476 - val_f1_score: 0.1364 - 122ms/epoch - 122ms/step
Epoch 36/50
1/1 - 0s - loss: 0.1651 - accuracy: 0.6280 - precision: 0.6280 - recall: 0.6280 - f1_score: 0.4813 - val_loss: 0.1719 - val_accuracy: 0.5357 - val_precision: 0.5357 - val_recall: 0.5357 - val_f1_score: 0.1333 - 94ms/epoch - 94ms/step
Epoch 37/50
1/1 - 0s - loss: 0.1609 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5246 - val_loss: 0.1735 - val_accuracy: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.2000 - 85ms/epoch - 85ms/step
Epoch 38/50
1/1 - 0s - loss: 0.1609 - accuracy: 0.6369 - precision: 0.6369 - recall: 0.6369 - f1_score: 0.5000 - val_loss: 0.1750 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.1887 - 80ms/epoch - 80ms/step
Epoch 39/50
1/1 - 0s - loss: 0.1613 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - f1_score: 0.5276 - val_loss: 0.1759 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.2222 - 66ms/epoch - 66ms/step
Epoch 40/50
1/1 - 0s - loss: 0.1603 - accuracy: 0.6220 - precision: 0.6220 - recall: 0.6220 - f1_score: 0.5020 - val_loss: 0.1767 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.2182 - 131ms/epoch - 131ms/step
Epoch 41/50
1/1 - 0s - loss: 0.1624 - accuracy: 0.6220 - precision: 0.6220 - recall: 0.6220 - f1_score: 0.5058 - val_loss: 0.1767 - val_accuracy: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.1852 - 113ms/epoch - 113ms/step
Epoch 42/50
1/1 - 0s - loss: 0.1628 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - f1_score: 0.5263 - val_loss: 0.1762 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.1887 - 135ms/epoch - 135ms/step
Epoch 43/50
1/1 - 0s - loss: 0.1582 - accuracy: 0.6548 - precision: 0.6548 - recall: 0.6548 - f1_score: 0.5433 - val_loss: 0.1759 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.1887 - 115ms/epoch - 115ms/step
Epoch 44/50
1/1 - 0s - loss: 0.1587 - accuracy: 0.6518 - precision: 0.6518 - recall: 0.6518 - f1_score: 0.5224 - val_loss: 0.1756 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1923 - 101ms/epoch - 101ms/step
Epoch 45/50
1/1 - 0s - loss: 0.1571 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - f1_score: 0.5328 - val_loss: 0.1750 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1923 - 76ms/epoch - 76ms/step
Epoch 46/50
1/1 - 0s - loss: 0.1567 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - f1_score: 0.5378 - val_loss: 0.1748 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.1569 - 65ms/epoch - 65ms/step
Epoch 47/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6935 - precision: 0.6935 - recall: 0.6935 - f1_score: 0.5579 - val_loss: 0.1749 - val_accuracy: 0.4881 - val_precision: 0.4881 - val_recall: 0.4881 - val_f1_score: 0.1569 - 140ms/epoch - 140ms/step
Epoch 48/50
1/1 - 0s - loss: 0.1572 - accuracy: 0.6756 - precision: 0.6756 - recall: 0.6756 - f1_score: 0.5477 - val_loss: 0.1753 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1600 - 100ms/epoch - 100ms/step
Epoch 49/50
1/1 - 0s - loss: 0.1547 - accuracy: 0.6577 - precision: 0.6577 - recall: 0.6577 - f1_score: 0.5344 - val_loss: 0.1751 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1600 - 75ms/epoch - 75ms/step
Epoch 50/50
1/1 - 0s - loss: 0.1534 - accuracy: 0.6815 - precision: 0.6815 - recall: 0.6815 - f1_score: 0.5447 - val_loss: 0.1755 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_f1_score: 0.1600 - 138ms/epoch - 138ms/step

🔍 Resultados no Teste:
Loss: 0.1732
Accuracy: 0.5304
Precision: 0.5304
Recall: 0.5304
F1 Score: 0.2609
Treinamento 60 realizado com sucesso ...  

************************************************************
Continuar o treinamento? (s/n)
------------------------------------------------------------------------
************************************************************
*** Treinamento concluído com sucesso! ***
************************************************************
0 60
660
720 720
(601, 60) (601, 60) (601, 60) (601, 60)
(601, 60) (601, 60)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 77ms/step
[0]
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
Proxima Entrada: 0
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
------------------------------------------------------------------------
Número da Entrada - 721 | Acuracia_1: 0.0 | Contagem Geral: 100.0 
Ordem Natural: 111.0
Entrada -> Ordenandos os dados ...
