{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkcover/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/25 - Precisão: 1.9994, Acurácia Direcional: 3.9621, Acurácia Direcional Ponderada: 5.9615\n",
      "Época 2/25 - Precisão: 2.0150, Acurácia Direcional: 3.9609, Acurácia Direcional Ponderada: 5.9759\n",
      "Época 3/25 - Precisão: 2.0233, Acurácia Direcional: 3.9611, Acurácia Direcional Ponderada: 5.9844\n",
      "Época 4/25 - Precisão: 2.0295, Acurácia Direcional: 3.9611, Acurácia Direcional Ponderada: 5.9905\n",
      "Época 5/25 - Precisão: 1.9912, Acurácia Direcional: 3.9622, Acurácia Direcional Ponderada: 5.9534\n",
      "Época 6/25 - Precisão: 1.9535, Acurácia Direcional: 3.9625, Acurácia Direcional Ponderada: 5.9160\n",
      "Época 7/25 - Precisão: 2.0324, Acurácia Direcional: 3.9607, Acurácia Direcional Ponderada: 5.9931\n",
      "Época 8/25 - Precisão: 2.0586, Acurácia Direcional: 3.9618, Acurácia Direcional Ponderada: 6.0203\n",
      "Época 9/25 - Precisão: 2.0343, Acurácia Direcional: 3.9627, Acurácia Direcional Ponderada: 5.9970\n",
      "Época 10/25 - Precisão: 2.0187, Acurácia Direcional: 3.9617, Acurácia Direcional Ponderada: 5.9803\n",
      "Época 11/25 - Precisão: 1.9804, Acurácia Direcional: 3.9625, Acurácia Direcional Ponderada: 5.9429\n",
      "Época 12/25 - Precisão: 2.0890, Acurácia Direcional: 3.9607, Acurácia Direcional Ponderada: 6.0498\n",
      "Época 13/25 - Precisão: 2.0783, Acurácia Direcional: 3.9601, Acurácia Direcional Ponderada: 6.0385\n",
      "Época 14/25 - Precisão: 1.9994, Acurácia Direcional: 3.9602, Acurácia Direcional Ponderada: 5.9596\n",
      "Época 15/25 - Precisão: 2.0696, Acurácia Direcional: 3.9592, Acurácia Direcional Ponderada: 6.0287\n",
      "Época 16/25 - Precisão: 1.9789, Acurácia Direcional: 3.9607, Acurácia Direcional Ponderada: 5.9396\n",
      "Época 17/25 - Precisão: 2.0292, Acurácia Direcional: 3.9593, Acurácia Direcional Ponderada: 5.9884\n",
      "Época 18/25 - Precisão: 1.9969, Acurácia Direcional: 3.9596, Acurácia Direcional Ponderada: 5.9565\n",
      "Época 19/25 - Precisão: 2.1518, Acurácia Direcional: 3.9578, Acurácia Direcional Ponderada: 6.1096\n",
      "Época 20/25 - Precisão: 2.0976, Acurácia Direcional: 3.9576, Acurácia Direcional Ponderada: 6.0552\n",
      "Época 21/25 - Precisão: 2.0118, Acurácia Direcional: 3.9606, Acurácia Direcional Ponderada: 5.9724\n",
      "Época 22/25 - Precisão: 1.9897, Acurácia Direcional: 3.9601, Acurácia Direcional Ponderada: 5.9497\n",
      "Época 23/25 - Precisão: 1.8337, Acurácia Direcional: 3.9606, Acurácia Direcional Ponderada: 5.7942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 14:12:03.515454: W tensorflow/core/data/root_dataset.cc:350] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 24/25 - Precisão: 1.9445, Acurácia Direcional: 3.9613, Acurácia Direcional Ponderada: 5.9058\n",
      "Época 25/25 - Precisão: 2.1103, Acurácia Direcional: 3.9573, Acurácia Direcional Ponderada: 6.0676\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, n_states, n_actions, learning_rate=0.001, gamma=0.99, epsilon=1.0, buffer_size=10000):\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, input_dim=self.n_states, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(self.n_actions, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        q_values = self.model.predict(state.reshape(1, -1), batch_size=1, verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state.reshape(1, -1), batch_size=1, verbose=0)[0]))\n",
    "            target_f = self.model.predict(state.reshape(1, -1), batch_size=1, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state.reshape(1, -1), target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "def calculate_reward(action, acerto):\n",
    "    if action == 1:\n",
    "        if acerto == 1:\n",
    "            return 10\n",
    "        elif acerto == 2:\n",
    "            return -5\n",
    "    return 0\n",
    "\n",
    "def normalize_data(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "def main():\n",
    "    data = pd.read_csv('/home/darkcover/Documentos/Out/dados/data_final.csv')\n",
    "    features = data[['odd_entrada', 'media5', 'media10', 'media20', 'media40', 'media80', 'media160', 'media320', 'media640', 'level', 'contagem']].values\n",
    "    rewards = data['apostar'].values\n",
    "    features = normalize_data(features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, rewards, test_size=0.2, random_state=42)\n",
    "\n",
    "    n_epochs = 25\n",
    "    batch_size = 128\n",
    "\n",
    "    n_states = X_train.shape[1]\n",
    "    n_actions = 2\n",
    "    dqn_agent = DQNAgent(n_states, n_actions)\n",
    "\n",
    "    epoch_accuracies = []\n",
    "    epoch_directional_accuracies = []\n",
    "    epoch_weighted_directional_accuracies = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        correct_predictions = 0\n",
    "        overestimations = 0\n",
    "        weighted_correct_predictions = 0\n",
    "        weighted_overestimations = 0\n",
    "\n",
    "        for i in range(len(X_train) - 1):\n",
    "            state = X_train[i]\n",
    "            action = dqn_agent.get_action(state)\n",
    "            true_action = y_train[i]\n",
    "            acerto = state[-3]\n",
    "            reward = calculate_reward(action, acerto)\n",
    "            next_state = X_train[i + 1]\n",
    "            done = (i == len(X_train) - 2)\n",
    "\n",
    "            dqn_agent.remember(state, action, reward, next_state, done)\n",
    "            if done:\n",
    "                dqn_agent.replay(batch_size)\n",
    "\n",
    "            if action == true_action:\n",
    "                correct_predictions += 1\n",
    "                weighted_correct_predictions += 2\n",
    "            elif action > true_action:\n",
    "                overestimations += 1\n",
    "                weighted_overestimations += 1\n",
    "\n",
    "        epoch_accuracy = correct_predictions / len(X_test)\n",
    "        epoch_directional_accuracy = (correct_predictions + overestimations) / len(X_test)\n",
    "        epoch_weighted_directional_accuracy = (weighted_correct_predictions + weighted_overestimations) / len(X_test)\n",
    "\n",
    "        epoch_accuracies.append(epoch_accuracy)\n",
    "        epoch_directional_accuracies.append(epoch_directional_accuracy)\n",
    "        epoch_weighted_directional_accuracies.append(epoch_weighted_directional_accuracy)\n",
    "\n",
    "        print(f'Época {epoch + 1}/{n_epochs} - Precisão: {epoch_accuracy:.4f}, Acurácia Direcional: {epoch_directional_accuracy:.4f}, Acurácia Direcional Ponderada: {epoch_weighted_directional_accuracy:.4f}')\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epoch_accuracies, label='Precisão')\n",
    "    plt.plot(epoch_directional_accuracies, label='Acurácia Direcional')\n",
    "    plt.plot(epoch_weighted_directional_accuracies, label='Acurácia Direcional Ponderada')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.legend()\n",
    "    plt.title('Desempenho do Modelo ao Longo das Épocas')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:14:21.980749: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 13:14:22.081447: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 13:14:22.572251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 13:14:26.253084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m\n\u001b[1;32m    199\u001b[0m     data_save\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/darkcover/Documentos/Out/dados/metricas_aposta.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    113\u001b[0m     state \u001b[38;5;241m=\u001b[39m X_train[i, :]\n\u001b[0;32m--> 114\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mdqn_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     true_action \u001b[38;5;241m=\u001b[39m y_train[i]\n\u001b[1;32m    116\u001b[0m     acerto \u001b[38;5;241m=\u001b[39m acerto_train[i][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m, in \u001b[0;36mDQNAgent.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_actions)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(q_values)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:503\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    502\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m--> 503\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(data)\n\u001b[1;32m    505\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:483\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict.<locals>.get_data\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         single_step_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mStopIteration\u001b[39;00m, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOutOfRangeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;66;03m# Suppress the error when still have remaining data.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3081\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3080\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, n_states, n_actions, learning_rate, gamma, epsilon, epsilon_decay, epsilon_min, buffer_size=10000):\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.model = self.build_model()\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=tf.keras.losses.Huber())\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(self.n_states,)),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(self.n_actions, activation='linear')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            q_values = self.model.predict(state.reshape(1, -1), batch_size=1, verbose=0)\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state.reshape(1, -1), batch_size=1, verbose=0))\n",
    "            target_f = self.model.predict(state.reshape(1, -1), batch_size=1, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state.reshape(1, -1), target_f, epochs=1, verbose=0)\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "def calculate_reward(action, acerto):\n",
    "    reward = 0\n",
    "    if action == 1:  # Apostou\n",
    "        if acerto == 1:\n",
    "            reward = 1  # Recompensa por apostar corretamente\n",
    "        elif acerto == 2:\n",
    "            reward = -1  # Penalidade por apostar incorretamente\n",
    "    return reward\n",
    "\n",
    "def normalize_data(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "def main():\n",
    "    # Carregar os dados\n",
    "    data = pd.read_csv('/home/darkcover/Documentos/Out/dados/data_final.csv')\n",
    "\n",
    "    # Selecionar as features e a variável de saída\n",
    "    features = data[['odd_entrada', 'media5', 'media10', 'media20', 'media40', 'media80', 'media160', 'media320', 'media640']].values\n",
    "    actions = data['apostar'].values  # Variável de saída: se deve apostar ou não\n",
    "    acertos = data[['acerto', 'level', 'contagem']].values  # Variável de saída para calcular a recompensa\n",
    "\n",
    "    features = normalize_data(features)\n",
    "\n",
    "    # Adicionar level e contagem às features\n",
    "    features = np.hstack((features, acertos[:, 1:]))\n",
    "\n",
    "    # Dividir os dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test, acerto_train, acerto_test = train_test_split(features, actions, acertos, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Parâmetros de treinamento\n",
    "    n_epochs = 5\n",
    "    batch_size = 264\n",
    "\n",
    "    # Crie o agente DQN\n",
    "    n_states = X_train.shape[1]\n",
    "    n_actions = 2  # Ações possíveis: apostar ou não apostar\n",
    "    dqn_agent = DQNAgent(n_states, n_actions, learning_rate=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.99, epsilon_min=0.01, buffer_size=10000)\n",
    "\n",
    "    epoch_accuracies = []\n",
    "    epoch_directional_accuracies = []\n",
    "    epoch_weighted_directional_accuracies = []\n",
    "\n",
    "    # Treinamento do agente\n",
    "    for epoch in range(n_epochs):\n",
    "        correct_predictions = 0\n",
    "        overestimations = 0\n",
    "        weighted_correct_predictions = 0\n",
    "        weighted_overestimations = 0\n",
    "\n",
    "        for i in range(len(X_train) - 1):\n",
    "            state = X_train[i, :]\n",
    "            action = dqn_agent.get_action(state)\n",
    "            true_action = y_train[i]\n",
    "            acerto = acerto_train[i][0]\n",
    "            reward = calculate_reward(action, acerto)\n",
    "            next_state = X_train[i + 1, :]\n",
    "            done = (i == len(X_train) - 2)\n",
    "\n",
    "            dqn_agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "            if done:\n",
    "                dqn_agent.replay(batch_size)\n",
    "                dqn_agent.update_epsilon()\n",
    "\n",
    "            if action == true_action:\n",
    "                correct_predictions += 1\n",
    "                weighted_correct_predictions += 2  # Peso maior para acertos exatos\n",
    "            elif action > true_action:\n",
    "                overestimations += 1\n",
    "                weighted_overestimations += 1  # Peso menor para erros\n",
    "\n",
    "        epoch_accuracy = correct_predictions / len(X_test)\n",
    "        epoch_directional_accuracy = (correct_predictions + overestimations) / len(X_test)\n",
    "        epoch_weighted_directional_accuracy = (weighted_correct_predictions + weighted_overestimations) / len(X_test)\n",
    "\n",
    "        epoch_accuracies.append(epoch_accuracy)\n",
    "        epoch_directional_accuracies.append(epoch_directional_accuracy)\n",
    "        epoch_weighted_directional_accuracies.append(epoch_weighted_directional_accuracy)\n",
    "\n",
    "        print(f'Época {epoch + 1}/{n_epochs} - Precisão: {epoch_accuracy:.4f}, Acurácia Direcional: {epoch_directional_accuracy:.4f}, Acurácia Direcional Ponderada: {epoch_weighted_directional_accuracy:.4f}')\n",
    "\n",
    "    # Teste o agente\n",
    "    correct_predictions = 0\n",
    "    overestimations = 0\n",
    "    weighted_correct_predictions = 0\n",
    "    weighted_overestimations = 0\n",
    "\n",
    "    predicted_actions = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        state = X_test[i, :]\n",
    "        action = dqn_agent.get_action(state)\n",
    "        true_action = y_test[i]\n",
    "\n",
    "        predicted_actions.append(action)\n",
    "\n",
    "        if action == true_action:\n",
    "            correct_predictions += 1\n",
    "            weighted_correct_predictions += 2\n",
    "        elif action > true_action:\n",
    "            overestimations += 1\n",
    "            weighted_overestimations += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(X_test)\n",
    "    directional_accuracy = (correct_predictions + overestimations) / len(X_test)\n",
    "    weighted_directional_accuracy = (weighted_correct_predictions + weighted_overestimations) / len(X_test)\n",
    "\n",
    "    print(\"Precisão:\", accuracy)\n",
    "    print(\"Acurácia Direcional:\", directional_accuracy)\n",
    "    print(\"Acurácia Direcional Ponderada:\", weighted_directional_accuracy)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epoch_accuracies, label='Precisão')\n",
    "    plt.plot(epoch_directional_accuracies, label='Acurácia Direcional')\n",
    "    plt.plot(epoch_weighted_directional_accuracies, label='Acurácia Direcional Ponderada')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.title('Desempenho do Modelo ao Longo das Épocas')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    metrics = [accuracy, directional_accuracy, weighted_directional_accuracy]\n",
    "    metric_labels = ['Precisão', 'Acurácia Direcional', 'Acurácia Direcional Ponderada']\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    plt.bar(metric_labels, metrics, color=colors)\n",
    "    plt.xlabel('Métricas')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.title('Métricas de Desempenho no Conjunto de Teste')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "    dqn_agent.model.save('AgenteAposta.h5')\n",
    "    data_save = pd.DataFrame({'epoch_accuracies': epoch_accuracies,\n",
    "                              'epoch_directional_accuracies': epoch_directional_accuracies,\n",
    "                              'epoch_weighted_directional_accuracies': epoch_weighted_directional_accuracies})\n",
    "    data_save.to_csv('/home/darkcover/Documentos/Out/dados/metricas_aposta.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 12:25:59.631988: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 12:25:59.737802: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 12:26:00.305591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 12:26:04.285181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from datetime import timedelta, datetime, time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from scipy.stats import entropy\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv('/home/darkcover/Documentos/Out/dados/data_final.csv')\n",
    "\n",
    "    # Selecionar as features e a variável de saída\n",
    "features = data[['odd_entrada', 'media5', 'media10', 'media20', 'media40', 'media80', 'media160', 'media320', 'media640']].values\n",
    "actions = data['apostar'].values  # Variável de saída: se deve apostar ou não\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 1.0\n",
      "F1-Score do modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Separar recursos (X) e rótulos (y)\n",
    "X1 = features\n",
    "y1 = actions\n",
    "\n",
    "# Normalizar os recursos (importante para redes neurais)\n",
    "scaler1 = StandardScaler()\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "\n",
    "# Divida seus dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crie uma instância do GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Execute a pesquisa de grade no conjunto de treinamento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo: {accuracy}')\n",
    "\n",
    "# Calcular o F1-Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1-Score do modelo: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1858 - val_accuracy: 0.9911 - val_loss: 0.0270\n",
      "Epoch 2/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0323 - val_accuracy: 0.9912 - val_loss: 0.0228\n",
      "Epoch 3/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0227 - val_accuracy: 0.9899 - val_loss: 0.0260\n",
      "Epoch 4/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0221 - val_accuracy: 0.9927 - val_loss: 0.0220\n",
      "Epoch 5/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0195 - val_accuracy: 0.9946 - val_loss: 0.0171\n",
      "Epoch 6/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0164 - val_accuracy: 0.9934 - val_loss: 0.0227\n",
      "Epoch 7/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0166 - val_accuracy: 0.9957 - val_loss: 0.0198\n",
      "Epoch 8/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0165 - val_accuracy: 0.9952 - val_loss: 0.0268\n",
      "Epoch 9/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0158 - val_accuracy: 0.9962 - val_loss: 0.0208\n",
      "Epoch 10/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.9951 - val_loss: 0.0261\n",
      "Epoch 11/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0139 - val_accuracy: 0.9959 - val_loss: 0.0190\n",
      "Epoch 12/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0141 - val_accuracy: 0.9958 - val_loss: 0.0267\n",
      "Epoch 13/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0122 - val_accuracy: 0.9971 - val_loss: 0.0313\n",
      "Epoch 14/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0120 - val_accuracy: 0.9951 - val_loss: 0.0289\n",
      "Epoch 15/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0122 - val_accuracy: 0.9959 - val_loss: 0.0326\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0145\n",
      "Acurácia nos dados de teste: 0.9949749708175659\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "F1-Score do modelo: 0.9950266525968962\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separar recursos (X) e rótulos (y)\n",
    "X1 = features\n",
    "y1 = actions\n",
    "\n",
    "# Normalizar os recursos (importante para redes neurais)\n",
    "scaler1 = StandardScaler()\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "\n",
    "\n",
    "# Divida seus dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=64, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Acurácia nos dados de teste: {test_accuracy}')\n",
    "\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Arredondar as previsões para obter rótulos de classe\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calcular o F1-Score\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'F1-Score do modelo: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.1501 - val_accuracy: 0.9918 - val_loss: 0.0220\n",
      "Epoch 2/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0261 - val_accuracy: 0.9917 - val_loss: 0.0221\n",
      "Epoch 3/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0212 - val_accuracy: 0.9929 - val_loss: 0.0209\n",
      "Epoch 4/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0188 - val_accuracy: 0.9945 - val_loss: 0.0194\n",
      "Epoch 5/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0158 - val_accuracy: 0.9944 - val_loss: 0.0215\n",
      "Epoch 6/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0162 - val_accuracy: 0.9921 - val_loss: 0.0345\n",
      "Epoch 7/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0150 - val_accuracy: 0.9949 - val_loss: 0.0276\n",
      "Epoch 8/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0140 - val_accuracy: 0.9927 - val_loss: 0.0295\n",
      "Epoch 9/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0131 - val_accuracy: 0.9964 - val_loss: 0.0202\n",
      "Epoch 10/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0140 - val_accuracy: 0.9931 - val_loss: 0.0498\n",
      "Epoch 11/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0128 - val_accuracy: 0.9959 - val_loss: 0.0428\n",
      "Epoch 12/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0125 - val_accuracy: 0.9958 - val_loss: 0.0346\n",
      "Epoch 13/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0122 - val_accuracy: 0.9956 - val_loss: 0.0528\n",
      "Epoch 14/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0127 - val_accuracy: 0.9969 - val_loss: 0.0294\n",
      "Epoch 15/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0121 - val_accuracy: 0.9964 - val_loss: 0.0485\n",
      "Epoch 16/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0109 - val_accuracy: 0.9961 - val_loss: 0.0385\n",
      "Epoch 17/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0110 - val_accuracy: 0.9958 - val_loss: 0.0556\n",
      "Epoch 18/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0105 - val_accuracy: 0.9966 - val_loss: 0.0466\n",
      "Epoch 19/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0117 - val_accuracy: 0.9966 - val_loss: 0.0707\n",
      "Epoch 20/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0107 - val_accuracy: 0.9988 - val_loss: 0.0606\n",
      "Epoch 21/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0098 - val_accuracy: 0.9939 - val_loss: 0.0858\n",
      "Epoch 22/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0107 - val_accuracy: 0.9967 - val_loss: 0.0650\n",
      "Epoch 23/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0095 - val_accuracy: 0.9981 - val_loss: 0.1141\n",
      "Epoch 24/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0096 - val_accuracy: 0.9974 - val_loss: 0.1035\n",
      "Epoch 25/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.9977 - val_loss: 0.0981\n",
      "Epoch 26/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0086 - val_accuracy: 0.9958 - val_loss: 0.0820\n",
      "Epoch 27/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0101 - val_accuracy: 0.9967 - val_loss: 0.1197\n",
      "Epoch 28/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0094 - val_accuracy: 0.9974 - val_loss: 0.0911\n",
      "Epoch 29/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0089 - val_accuracy: 0.9968 - val_loss: 0.0925\n",
      "Epoch 30/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0085 - val_accuracy: 0.9979 - val_loss: 0.0650\n",
      "Epoch 31/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0093 - val_accuracy: 0.9959 - val_loss: 0.1131\n",
      "Epoch 32/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.9977 - val_loss: 0.0901\n",
      "Epoch 33/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0088 - val_accuracy: 0.9974 - val_loss: 0.0876\n",
      "Epoch 34/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0082 - val_accuracy: 0.9973 - val_loss: 0.1014\n",
      "Epoch 35/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 0.9981 - val_loss: 0.0544\n",
      "Epoch 36/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0148 - val_accuracy: 0.9980 - val_loss: 0.1015\n",
      "Epoch 37/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0077 - val_accuracy: 0.9978 - val_loss: 0.0757\n",
      "Epoch 38/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9964 - val_loss: 0.1287\n",
      "Epoch 39/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.9970 - val_loss: 0.1045\n",
      "Epoch 40/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.9974 - val_loss: 0.0997\n",
      "Epoch 41/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 0.9980 - val_loss: 0.0770\n",
      "Epoch 42/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0078 - val_accuracy: 0.9982 - val_loss: 0.0764\n",
      "Epoch 43/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0081 - val_accuracy: 0.9982 - val_loss: 0.0693\n",
      "Epoch 44/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0084 - val_accuracy: 0.9977 - val_loss: 0.0911\n",
      "Epoch 45/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0073 - val_accuracy: 0.9972 - val_loss: 0.0841\n",
      "Epoch 46/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0072 - val_accuracy: 0.9981 - val_loss: 0.0835\n",
      "Epoch 47/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0076 - val_accuracy: 0.9977 - val_loss: 0.0778\n",
      "Epoch 48/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.9978 - val_loss: 0.0995\n",
      "Epoch 49/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0073 - val_accuracy: 0.9982 - val_loss: 0.1032\n",
      "Epoch 50/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0078 - val_accuracy: 0.9977 - val_loss: 0.0721\n",
      "Epoch 51/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9974 - val_loss: 0.1429\n",
      "Epoch 52/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0065 - val_accuracy: 0.9975 - val_loss: 0.1196\n",
      "Epoch 53/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.9973 - val_loss: 0.1264\n",
      "Epoch 54/250\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 0.9983 - val_loss: 0.0956\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0138\n",
      "Acurácia nos dados de teste: 0.9939749836921692\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "F1-Score do modelo: 0.9934839623932501\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Separar recursos (X) e rótulos (y)\n",
    "X1 = features\n",
    "y1 = actions\n",
    "\n",
    "# Normalizar os recursos (importante para redes neurais)\n",
    "scaler1 = StandardScaler()\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "\n",
    "# Divida seus dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "\n",
    "# Experimente diferentes funções de ativação, taxa de aprendizado e otimizador\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Aumente o número de épocas\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=64, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Acurácia nos dados de teste: {test_accuracy}')\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Arredondar as previsões para obter rótulos de classe\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calcular o F1-Score\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'F1-Score do modelo: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 31ms/step - accuracy: 0.9748 - loss: 0.2187 - val_accuracy: 0.9937 - val_loss: 0.0136\n",
      "Epoch 2/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9897 - loss: 0.0273 - val_accuracy: 0.9937 - val_loss: 0.0122\n",
      "Epoch 3/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9915 - loss: 0.0218 - val_accuracy: 0.9937 - val_loss: 0.0120\n",
      "Epoch 4/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.9937 - val_loss: 0.0119\n",
      "Epoch 5/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9933 - loss: 0.0175 - val_accuracy: 0.9937 - val_loss: 0.0077\n",
      "Epoch 6/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9939 - loss: 0.0163 - val_accuracy: 0.9937 - val_loss: 0.0158\n",
      "Epoch 7/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9940 - loss: 0.0223 - val_accuracy: 0.9937 - val_loss: 0.0075\n",
      "Epoch 8/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9943 - loss: 0.0145 - val_accuracy: 0.9937 - val_loss: 0.0082\n",
      "Epoch 9/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9950 - loss: 0.0130 - val_accuracy: 0.9937 - val_loss: 0.0107\n",
      "Epoch 10/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9952 - loss: 0.0126 - val_accuracy: 0.9937 - val_loss: 0.0079\n",
      "Epoch 11/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 31ms/step - accuracy: 0.9951 - loss: 0.0125 - val_accuracy: 0.9937 - val_loss: 0.0085\n",
      "Epoch 12/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 13/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9951 - loss: 0.0122 - val_accuracy: 0.9937 - val_loss: 0.0096\n",
      "Epoch 14/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9953 - loss: 0.0133 - val_accuracy: 0.9937 - val_loss: 0.0183\n",
      "Epoch 15/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.9937 - val_loss: 0.0088\n",
      "Epoch 16/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 31ms/step - accuracy: 0.9953 - loss: 0.0122 - val_accuracy: 0.9937 - val_loss: 0.0078\n",
      "Epoch 17/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0114 - val_accuracy: 0.9937 - val_loss: 0.0081\n",
      "Epoch 18/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0104 - val_accuracy: 0.9937 - val_loss: 0.0072\n",
      "Epoch 19/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 30ms/step - accuracy: 0.9960 - loss: 0.0092 - val_accuracy: 0.9937 - val_loss: 0.0102\n",
      "Epoch 20/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 21/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 35ms/step - accuracy: 0.9958 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 22/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.9957 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 23/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.9964 - loss: 0.0094 - val_accuracy: 0.9937 - val_loss: 0.0062\n",
      "Epoch 24/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9937 - val_loss: 0.0069\n",
      "Epoch 25/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 30ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 26/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 30ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 27/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.9937 - val_loss: 0.0087\n",
      "Epoch 28/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 29/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 31ms/step - accuracy: 0.9965 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 30/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9965 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 31/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.9967 - loss: 0.0090 - val_accuracy: 0.9937 - val_loss: 0.0073\n",
      "Epoch 32/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 31ms/step - accuracy: 0.9964 - loss: 0.0091 - val_accuracy: 0.9937 - val_loss: 0.0139\n",
      "Epoch 33/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.9966 - loss: 0.0083 - val_accuracy: 0.9937 - val_loss: 0.0073\n",
      "Epoch 34/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 34ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9937 - val_loss: 0.0071\n",
      "Epoch 35/250\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 44ms/step - accuracy: 0.9963 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 36/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mnadam, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Aumente o número de épocas\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcurácia nos dados de teste: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:313\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m--> 313\u001b[0m         \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n",
      "File \u001b[0;32m~/Documentos/Out/venv/lib/python3.10/site-packages/keras/src/callbacks/callback_list.py:98\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m     96\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     99\u001b[0m     logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "# Separar recursos (X) e rótulos (y)\n",
    "X1 = features\n",
    "y1 = actions\n",
    "\n",
    "# Normalizar os recursos (importante para redes neurais)\n",
    "scaler1 = StandardScaler()\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "\n",
    "# Divida seus dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(160, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(320, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(480, activation='relu'),\n",
    "    keras.layers.Dense(640, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "\n",
    "# Experimente diferentes funções de ativação, taxa de aprendizado e otimizador\n",
    "model.compile(optimizer=nadam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Aumente o número de épocas\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=160, validation_split=0.001, callbacks=[early_stopping])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Acurácia nos dados de teste: {test_accuracy}')\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Arredondar as previsões para obter rótulos de classe\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calcular o F1-Score\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'F1-Score do modelo: {f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
